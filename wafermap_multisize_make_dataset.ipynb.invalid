{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ウエハサイズを限定せずに機械学習させる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import，入力データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/LSWMD.pkl\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "import numpy as np\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU') memory growth: True\n",
      "PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU') memory growth: True\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU'), LogicalDevice(name='/device:GPU:1', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LSWMD.pkl']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "import csv\n",
    "\n",
    "import pickle\n",
    "import copy\n",
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "if len(physical_devices) > 0:\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "        print('{} memory growth: {}'.format(device, tf.config.experimental.get_memory_growth(device)))\n",
    "else:\n",
    "    print(\"Not enough GPU hardware devices available\")\n",
    "logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "print(logical_gpus)\n",
    "import keras\n",
    "from tensorflow.keras import layers, Input, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier \n",
    "import keras.backend.tensorflow_backend as tfback\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datapath = join('data', 'wafer')\n",
    "print(os.listdir(\"../input\"))\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define\n",
    "max_size = 300\n",
    "encord_size = int(max_size / 2)\n",
    "\n",
    "MAKE_DATASET = False\n",
    "TRAIN_AUTO_ENCODER = True\n",
    "\n",
    "auto_encoder_path = './model/ae_' + str(max_size) + '.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データについて"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    df=pd.read_pickle(\"../input/LSWMD.pkl\")\n",
    "\n",
    "    df = df.drop(['waferIndex'], axis = 1)\n",
    "\n",
    "    def find_dim(x):\n",
    "        dim0=np.size(x,axis=0)\n",
    "        dim1=np.size(x,axis=1)\n",
    "        return dim0,dim1\n",
    "    df['waferMapDim']=df.waferMap.apply(find_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    df['failureNum']=df.failureType\n",
    "    df['trainTestNum']=df.trianTestLabel\n",
    "    mapping_type={'Center':0,'Donut':1,'Edge-Loc':2,'Edge-Ring':3,'Loc':4,'Random':5,'Scratch':6,'Near-full':7,'none':8}\n",
    "    mapping_traintest={'Training':0,'Test':1}\n",
    "    df=df.replace({'failureNum':mapping_type, 'trainTestNum':mapping_traintest})\n",
    "\n",
    "    tol_wafers = df.shape[0]\n",
    "\n",
    "    df_withlabel = df[(df['failureNum']>=0) & (df['failureNum']<=8)]\n",
    "    df_withlabel =df_withlabel.reset_index()\n",
    "    df_withpattern = df[(df['failureNum']>=0) & (df['failureNum']<=7)]\n",
    "    df_withpattern = df_withpattern.reset_index()\n",
    "    df_nonpattern = df[(df['failureNum']==8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データサイズ関係なく処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使えるデータサイズを求める\n",
    "    - ラベル付きのデータすべて"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    uni_waferDim=np.unique(df.waferMapDim, return_counts=True)\n",
    "    wdim = uni_waferDim[0]\n",
    "    failure_list = ['Center', 'Donut', 'Edge-Loc', 'Edge-Ring', 'Loc', 'Random', 'Scratch', 'Near-full', 'none']\n",
    "    usable_wdim_list = []\n",
    "    usable_wafer_num = 0\n",
    "    for i in range(len(wdim)):\n",
    "        sub_df = df.loc[df['waferMapDim'] == wdim[i]]\n",
    "        pattern_num = [0] * 9\n",
    "        for j in range(len(sub_df)):\n",
    "            if len(sub_df.iloc[j,:]['failureType']) == 0:\n",
    "                continue\n",
    "            pattern = sub_df.iloc[j,:]['failureType'][0][0]\n",
    "            pattern_num[failure_list.index(pattern)] += 1\n",
    "        usable_wdim_list.append(wdim[i])\n",
    "        print(wdim[i], len(sub_df), sum(pattern_num))\n",
    "        usable_wafer_num += sum(pattern_num)\n",
    "    print(usable_wafer_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_unisize_wafer(size, wafer):\n",
    "    width, height = wafer.shape\n",
    "    unisize_wafer = np.zeros((size, size))\n",
    "    width_pad = int((size - width) / 2)\n",
    "    height_pad = int((size - height) / 2)\n",
    "    unisize_wafer[width_pad:width_pad + width, height_pad:height_pad + height] = wafer\n",
    "    return unisize_wafer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    sw = np.ones((usable_wafer_num, max_size, max_size), dtype='int8')\n",
    "    label = list()\n",
    "    count = 0\n",
    "    pattern_num_list = []\n",
    "    for usable_wdim in usable_wdim_list:\n",
    "        sub_df = df.loc[df['waferMapDim'] == usable_wdim]\n",
    "        sub_wafer = sub_df['waferMap'].values\n",
    "        print(usable_wdim)\n",
    "        print(len(sub_df))\n",
    "        \n",
    "        num = 0\n",
    "        for i in range(len(sub_df)):\n",
    "            # skip null label\n",
    "            if len(sub_df.iloc[i,:]['failureType']) == 0:\n",
    "                continue\n",
    "            sw[count] = make_unisize_wafer(max_size, sub_df.iloc[i,:]['waferMap'])\n",
    "            label.append(sub_df.iloc[i,:]['failureType'][0][0])\n",
    "            count += 1\n",
    "            num += 1\n",
    "            if i % 1000 == 0:\n",
    "                print(\" \", i)\n",
    "        pattern_num_list.append(num)\n",
    "    x = sw\n",
    "    y = np.array(label).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xとyをファイルに保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    faulty_case = np.unique(y)\n",
    "    print('Faulty case list : {}'.format(faulty_case))\n",
    "if not MAKE_DATASET:\n",
    "    faulty_case = ['Center', 'Donut', 'Edge-Loc', 'Edge-Ring', 'Loc', 'Near-full', 'Random', 'Scratch', 'none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    for f in faulty_case :\n",
    "        print('{} : {}'.format(f, len(y[y==f])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    for i, l in enumerate(faulty_case):\n",
    "        y[y==l] = int(i)\n",
    "        print(type(i))\n",
    "    y = y.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_dump(obj, path):\n",
    "    with open(path, mode='wb') as f:\n",
    "        pickle.dump(obj,f,protocol=4)\n",
    "\n",
    "def pickle_load(path):\n",
    "    with open(path, mode='rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    print('x shape : {}, y shape : {}'.format(x.shape, y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 最初のデータを可視化してみる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    x = x.reshape((-1, max_size, max_size, 1))\n",
    "    x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    # plot 1st data\n",
    "    plt.imshow(x[0,:, :, 0])\n",
    "    plt.show()\n",
    "\n",
    "    # check faulty case\n",
    "    print('Faulty case : {} '.format(faulty_case[y[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 14366枚の26x26ウエハの不良パターンは上記のようになっている．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    del df, sw, df_nonpattern, df_withlabel, df_withpattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- new_xを(14366, 26, 26, 3)とし，最後の次元にはウエハの値(0, 1, 2)がそれぞれの値毎にベクトルとしてまとめられている．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|            Variable Name|    Memory|\n",
      " ------------------------------------ \n",
      "|       ImageDataGenerator|      1064|\n",
      "|                       In|       272|\n",
      "|                    Input|       144|\n",
      "|                    KFold|      1064|\n",
      "|          KerasClassifier|      1064|\n",
      "|             MAKE_DATASET|        24|\n",
      "|                      Out|       248|\n",
      "|       TRAIN_AUTO_ENCODER|        28|\n",
      "|        auto_encoder_path|        66|\n",
      "|                     copy|        88|\n",
      "|          cross_val_score|       144|\n",
      "|                      csv|        88|\n",
      "|                      cv2|        88|\n",
      "|                 datapath|        59|\n",
      "|                   device|        80|\n",
      "|                  dirname|        57|\n",
      "|              encord_size|        28|\n",
      "|                     exit|        64|\n",
      "|              faulty_case|       144|\n",
      "|                 filename|        58|\n",
      "|                filenames|       104|\n",
      "|              get_ipython|        72|\n",
      "|                     glob|        88|\n",
      "|                    image|        88|\n",
      "|                   joblib|        88|\n",
      "|                     join|       144|\n",
      "|                    keras|        88|\n",
      "|                   layers|        88|\n",
      "|             logical_gpus|       104|\n",
      "|       make_unisize_wafer|       144|\n",
      "|                 max_size|        28|\n",
      "|                   models|        88|\n",
      "|                       np|        88|\n",
      "|                       os|        88|\n",
      "|                       pd|        88|\n",
      "|         physical_devices|       104|\n",
      "|                   pickle|        88|\n",
      "|              pickle_dump|       144|\n",
      "|              pickle_load|       144|\n",
      "|                      plt|        88|\n",
      "|                     quit|        64|\n",
      "|                   random|        88|\n",
      "|                      sys|        88|\n",
      "|                       tf|        88|\n",
      "|                   tfback|        88|\n",
      "|           to_categorical|       144|\n",
      "|         train_test_split|       144|\n",
      "|                 warnings|        88|\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n",
    "print(\" ------------------------------------ \")\n",
    "for var_name in dir():\n",
    "    if not var_name.startswith(\"_\"):\n",
    "        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3チャネルに拡張できない場合\n",
    "if MAKE_DATASET:\n",
    "    joblib.dump(x, './data/multi_' + str(max_size) + '/x_multi.pickle')\n",
    "    \n",
    "# if not MAKE_DATASET:\n",
    "#     x = joblib.load('./data/multi_' + str(max_size) + '/x_multi.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    joblib.dump(y, './data/multi_' + str(max_size) + '/y_multi.pickle')\n",
    "    \n",
    "# if not MAKE_DATASET:\n",
    "#     y = joblib.load('./data/multi_' + str(max_size) + '/y_multi.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    for i in range(9) :\n",
    "        print('{} : {}'.format(i, len(y[y==i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### かぶりの除去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern_num_for_dim = []\n",
    "# for i in pattern_num_list:\n",
    "#     if i == 0:\n",
    "#         continue\n",
    "#     pattern_num_for_dim.extend([i-j for j in range(i)])\n",
    "# len(pattern_num_for_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # かぶっているものを特定する\n",
    "# count = 0\n",
    "# no = 0\n",
    "# duplicate_list = []\n",
    "# for i in range(0, x.shape[0]):\n",
    "#     if i % 5000 == 0:\n",
    "#         print(i)\n",
    "#         print(count)\n",
    "#         print(no)\n",
    "#         print(duplicate_list)\n",
    "#     dup = 0\n",
    "#     for j in range(i+1, i+pattern_num_for_dim[i]):\n",
    "#         if x[i, encord_size, encord_size] != x[j, encord_size, encord_size]:\n",
    "#             continue\n",
    "#         if np.array_equal(x[i], x[j]):\n",
    "#             count += 1\n",
    "#             dup += 1\n",
    "#             if y[i][0] != y[j][0]:  \n",
    "#                 no += 1\n",
    "#                 print(str(i) + \":\" + str(y[i][0]) + \", \" + str(j) + \":\" + str(y[j][0]))\n",
    "# #                 plt.imshow(x[i])\n",
    "# #                 plt.show()\n",
    "#             else:\n",
    "#                 duplicate_list.append(j)\n",
    "#     if dup > 1:\n",
    "#         print(f\"dup: {i}\")\n",
    "\n",
    "# print(count)\n",
    "# print(no)\n",
    "# print(duplicate_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 重複しているウエハ（同じラベル）\n",
    "    - `duplicate_list`\n",
    "- 異なるラベル付けがされた重複しているウエハ14枚に対し，残すものをピックアップ\n",
    "    - 24433:none\n",
    "    - 30828:Edge-Loc\n",
    "    - 34759:Edge-Loc\n",
    "    - 25971:Center\n",
    "    - 33768:Loc\n",
    "    - 34871Edge-Loc\n",
    "    - 35321:Edge-Loc\n",
    "    - 28496:none\n",
    "    - 28889:Edge-Loc\n",
    "    - 33590:Loc\n",
    "    - 32891:Loc\n",
    "    - 34827:Edge-Loc\n",
    "    - 33021:Edge-Loc\n",
    "    - 35229:Edge-Loc\n",
    "- 残さないものはdupulicate_listに追加\n",
    "    - [31990, 25144, 25847, 34510, 26471, 27132, 27580, 34896, 33296, 29028, 29389, 29696, 29926, 30106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    duplicate_list = [32768, 32771, 32772, 32777, 32779, 32780, 32783, 32785, 32786, 32787, 32789, 32792, 32794, 32797, 32799, 32800, 32801, 32805, 32806, 32808, 32813, 32814, 32815, 32816, 32817, 32820, 32821, 32825, 32826, 32827, 32828, 32830, 32831, 32832, 32835, 32837, 32839, 32840, 32841, 32842, 32844, 32845, 32850, 32851, 32852, 32854, 32855, 32856, 32857, 32860, 32863, 32865, 32866, 32867, 32871, 32873, 32874, 32881, 32883, 32885, 32887, 32888, 32889, 32892, 32894, 32896, 32897, 32898, 32899, 32900, 32902, 32903, 32904, 32907, 32908, 32910, 32911, 32916, 32917, 32925, 32926, 32928, 32929, 32930, 32931, 32932, 32933, 32934, 32936, 32938, 32939, 32941, 32943, 32944, 32946, 32947, 32948, 32950, 32951, 32952, 32954, 32955, 32956, 32958, 32959, 32960, 32961, 32963, 32964, 32966, 32968, 32970, 32972, 32973, 32977, 32978, 32979, 32980, 32981, 32983, 32985, 32987, 32988, 32991, 32993, 32995, 32998, 32999, 33001, 33003, 33004, 33005, 33007, 33008, 33010, 33013, 33015, 33016, 33019, 33020, 33024, 33026, 33029, 33030, 33031, 33032, 33033, 164106, 164107, 164108, 164109, 33038, 164110, 164111, 164112, 33042, 33043, 33044, 164113, 33046, 164115, 164116, 33049, 33050, 33051, 33052, 164117, 164118, 33055, 164119, 164120, 33058, 164122, 33060, 33061, 33062, 33063, 33064, 33065, 33066, 33067, 33069, 33072, 33075, 33076, 164150, 33079, 33080, 33081, 33083, 33084, 33085, 33087, 33088, 33091, 33092, 33093, 33094, 33095, 33096, 33098, 33101, 33104, 33107, 33108, 33111, 33116, 33117, 33124, 33125, 33126, 33127, 33128, 33129, 33133, 33134, 33137, 33141, 33142, 33144, 33145, 33147, 33148, 33150, 33153, 33157, 33158, 33160, 33162, 33164, 33165, 33168, 33171, 33177, 33179, 33180, 33182, 33184, 33185, 33187, 33188, 33189, 33191, 33194, 33196, 33197, 33199, 33200, 33201, 33203, 33204, 33205, 33206, 33209, 33210, 33211, 33213, 33214, 33217, 33219, 33223, 33226, 33229, 33231, 33232, 33233, 33234, 33236, 33239, 33240, 33242, 33243, 33244, 33245, 33247, 33248, 33249, 33254, 33256, 33259, 33260, 33262, 33263, 33265, 33266, 33268, 33269, 33271, 33274, 33275, 33278, 33279, 33280, 33281, 33284, 33285, 33286, 33287, 33288, 33289, 33290, 33291, 33292, 33294, 33297, 33299, 33301, 33302, 33303, 33304, 33308, 33309, 33310, 33312, 33313, 33314, 33316, 33317, 33318, 33319, 33320, 33322, 33323, 33324, 33326, 33327, 33328, 33329, 33330, 33333, 33334, 33335, 33337, 33338, 33341, 33342, 33344, 33345, 33346, 33347, 33350, 33351, 33358, 33363, 33367, 33369, 33370, 33374, 33375, 33379, 33380, 33382, 33383, 33384, 33385, 33391, 33392, 33393, 33397, 33399, 33404, 33406, 33410, 33411, 33412, 33416, 33417, 33418, 33419, 33420, 33421, 33423, 33425, 33426, 33429, 33431, 33432, 33435, 33437, 33439, 33441, 33443, 33445, 33446, 33448, 33450, 33451, 33452, 33453, 33454, 33456, 33458, 33459, 33462, 33463, 33464, 33465, 33466, 33467, 33468, 33469, 33473, 33475, 33479, 33482, 33484, 33486, 33488, 33490, 33492, 33493, 33494, 33499, 33500, 33506, 33507, 33508, 33509, 33512, 33514, 33515, 33516, 33517, 33518, 33519, 33520, 33521, 33523, 33526, 33528, 33532, 33533, 33534, 33536, 33537, 33538, 33539, 33540, 33541, 33544, 33548, 33549, 33550, 33553, 33554, 33556, 33557, 33562, 33563, 33564, 33565, 33569, 33570, 33572, 33573, 33574, 33579, 33582, 33583, 33584, 33585, 33589, 33591, 33595, 33597, 33599, 33601, 33603, 33605, 33607, 33610, 33611, 33612, 33617, 33618, 33619, 33622, 33628, 33629, 33630, 33632, 33635, 33636, 33637, 33638, 33639, 33641, 33642, 33645, 33647, 172915, 33652, 33653, 33660, 33661, 33663, 33664, 33665, 33670, 33673, 33674, 33677, 33678, 33679, 33681, 33684, 33685, 33686, 33687, 33688, 33689, 33690, 33691, 33692, 33693, 33694, 33697, 33699, 33700, 33701, 33705, 33706, 33713, 33714, 33716, 33717, 33718, 33719, 33725, 33726, 33730, 33733, 33734, 33736, 33740, 33741, 33743, 33744, 33747, 33748, 33750, 33751, 33753, 33754, 33755, 33757, 33758, 33760, 33761, 33762, 33763, 33764, 33770, 33771, 33772, 33773, 33774, 33777, 33779, 33781, 33783, 33784, 33785, 33787, 33790, 33794, 33796, 33797, 33798, 33799, 33803, 33804, 33809, 33811, 33812, 33816, 33817, 33818, 33822, 33823, 33825, 33827, 33828, 33831, 33833, 33834, 33835, 33839, 33842, 33847, 33848, 33849, 33850, 33852, 33853, 33854, 33855, 33858, 33859, 33860, 33861, 33864, 33865, 33866, 33868, 33869, 33871, 33872, 33874, 33878, 33879, 33880, 33881, 33882, 33883, 33884, 33886, 33887, 33888, 33890, 33892, 33893, 33895, 33898, 33899, 33901, 33902, 33903, 33904, 33906, 33907, 33909, 33911, 33916, 33918, 33920, 33921, 33922, 33925, 33928, 33929, 33930, 33934, 33936, 33937, 33938, 33940, 33941, 33942, 33943, 33945, 33948, 33949, 33953, 33954, 33955, 33960, 33961, 33966, 33968, 33971, 33973, 33974, 33977, 33979, 33981, 33982, 33985, 33986, 33987, 33989, 33990, 33992, 33994, 33995, 33996, 33997, 34000, 34001, 34003, 34004, 34006, 34007, 34008, 34010, 34013, 34015, 34018, 34019, 34021, 34022, 34026, 34029, 34033, 34034, 34035, 34036, 34038, 34041, 34042, 34043, 34048, 34050, 34051, 34052, 34053, 34056, 34057, 34060, 34061, 34063, 34065, 34066, 34069, 34071, 34073, 34076, 34077, 34079, 34080, 34081, 34083, 34085, 34086, 34093, 34094, 34095, 34096, 34100, 34102, 34103, 34104, 34105, 34106, 34107, 34109, 34111, 34112, 34115, 34116, 34118, 34119, 34120, 34123, 34124, 34125, 34126, 34129, 34130, 34132, 34136, 34137, 34139, 34140, 34141, 34142, 34143, 34147, 34150, 34152, 34153, 34155, 34156, 34158, 34159, 34161, 34162, 34164, 34165, 34166, 34167, 34168, 34170, 34172, 34173, 34174, 34175, 34176, 34178, 34180, 34181, 34182, 34184, 34185, 34188, 34189, 34191, 34193, 34194, 34195, 34197, 34201, 34203, 34211, 34212, 34213, 34214, 34220, 34221, 34222, 34223, 34225, 34227, 34228, 34229, 34233, 34234, 34237, 34238, 34239, 34240, 34241, 34242, 34243, 34245, 34247, 34248, 34250, 34253, 34254, 34257, 34258, 34259, 34260, 34266, 34267, 34268, 34269, 34270, 34271, 34272, 34273, 34275, 34276, 34277, 34281, 34283, 34285, 34286, 34287, 34288, 34290, 34293, 34296, 34298, 34299, 34301, 34302, 34304, 34305, 34307, 34308, 34310, 34312, 34316, 34318, 34322, 34323, 34325, 34327, 34331, 34333, 34334, 34339, 34343, 34344, 34345, 34346, 34348, 34349, 34350, 34361, 34362, 34365, 34366, 34368, 34369, 34370, 34371, 34372, 34376, 34379, 34384, 34388, 34390, 34391, 34393, 34397, 34399, 34400, 34401, 34402, 34403, 34405, 34410, 34416, 34418, 34421, 34425, 34429, 34430, 34431, 34434, 34435, 34436, 34437, 34439, 34442, 34443, 34444, 34446, 34447, 34448, 34449, 34451, 34455, 34458, 34459, 34460, 34461, 34462, 34463, 34464, 34466, 34468, 34469, 34470, 34473, 34476, 34478, 34480, 34490, 34491, 34495, 34500, 34501, 34502, 34503, 34505, 34508, 34509, 34511, 34514, 34515, 34516, 34520, 34522, 34523, 34524, 34525, 34526, 34528, 34530, 34533, 34535, 34536, 34537, 34539, 34541, 34543, 34545, 34549, 34550, 34555, 34556, 34558, 34559, 34560, 34565, 34566, 34567, 34568, 34569, 34571, 34573, 34575, 34576, 34578, 34582, 34585, 34591, 34593, 34594, 34595, 34597, 34598, 34599, 34600, 34603, 34604, 34605, 34606, 34610, 34611, 34612, 34613, 34614, 34615, 34618, 34619, 34621, 34622, 34626, 34628, 34629, 34630, 34633, 34634, 34635, 34637, 34638, 34639, 34640, 34646, 34647, 34648, 34649, 34652, 34654, 34656, 34659, 34662, 34663, 34665, 34666, 34670, 34674, 34677, 34678, 34679, 34681, 34682, 34683, 34684, 34685, 34687, 34690, 34691, 34692, 34694, 34703, 34709, 34711, 34713, 34716, 34718, 34722, 34724, 34726, 34727, 34731, 34733, 34734, 34735, 34736, 34740, 34742, 34743, 34744, 34746, 34747, 34748, 34750, 34754, 34756, 34757, 34758, 34762, 34765, 34766, 34768, 34770, 34771, 34775, 34776, 34777, 34780, 34781, 34784, 34785, 34788, 34790, 34791, 34798, 34800, 34801, 34802, 34804, 34805, 34806, 34807, 34808, 34810, 34812, 34814, 34817, 34818, 34820, 34821, 34822, 34823, 34824, 34826, 34829, 34832, 34834, 34836, 34838, 34839, 34840, 34842, 34844, 34846, 34848, 34851, 34853, 34854, 34855, 34857, 34860, 34862, 34864, 34865, 34866, 34867, 34868, 34869, 34875, 34878, 34879, 34883, 34884, 34885, 34886, 34888, 34889, 34890, 34892, 34898, 34903, 34906, 34907, 34910, 34912, 34913, 34921, 34924, 34925, 34927, 34929, 34930, 34931, 34932, 34934, 34936, 34937, 34938, 34940, 34941, 34943, 34945, 34948, 34950, 34953, 34954, 34956, 34957, 34959, 34960, 34968, 34974, 34975, 34976, 34977, 34978, 34979, 34981, 34983, 34987, 34988, 34990, 34993, 34994, 34996, 34998, 34999, 35000, 35002, 35003, 35004, 35009, 35011, 35013, 35014, 35015, 35016, 35017, 35020, 35022, 35030, 35032, 35034, 35036, 35037, 35039, 35041, 35043, 35047, 35051, 35052, 35053, 35057, 35061, 35069, 35070, 35071, 35073, 35076, 35078, 35083, 35084, 35085, 35086, 35088, 35089, 35090, 35093, 35094, 35095, 35097, 35099, 35100, 35102, 35103, 35104, 35108, 35109, 35111, 35112, 35113, 35114, 35115, 35117, 35120, 35121, 35122, 35123, 35125, 35126, 35127, 35129, 35131, 35133, 35134, 35135, 35136, 35138, 35142, 35143, 35145, 35146, 35149, 35150, 35152, 35153, 35154, 35157, 35158, 35159, 35161, 35162, 35163, 35164, 35165, 35167, 35168, 35169, 35170, 35176, 35177, 35183, 35191, 35194, 35196, 35199, 35204, 35206, 35219, 35220, 35222, 35223, 35224, 35225, 35230, 35231, 35232, 35234, 35235, 35240, 35242, 35243, 35244, 35245, 35246, 35247, 35248, 35249, 35253, 35256, 35257, 35258, 35259, 35260, 35263, 35264, 35265, 35266, 35267, 35268, 35269, 35272, 35273, 35276, 35278, 35281, 35282, 35284, 35287, 35288, 35289, 35291, 35292, 35294, 35295, 35296, 35298, 35299, 35300, 35302, 35303, 35306, 35309, 35310, 35311, 35312, 35313, 35316, 35322, 35323, 35324, 35325, 35326, 35328, 35329, 35337, 35338, 35339, 35340, 35344, 35345, 35346, 35347, 35348, 35349, 35351, 35352, 35354, 35356, 35358, 35360, 35362, 35364, 35365, 35366, 35368, 35370, 35371, 35374, 35378, 35379, 35380, 35383, 35385, 35386, 35388, 35390, 35392, 35397, 35400, 35402, 35407, 35408, 35409, 35410, 35411, 35413, 35414, 43605, 35416, 35417, 35418, 35419, 35424, 35425, 35429, 35431, 35432, 35434, 35436, 35438, 35441, 35442, 35443, 35445, 35446, 35448, 35450, 35451, 35454, 35456, 35458, 35460, 35461, 35464, 35466, 35470, 35473, 35474, 35477, 35478, 35480, 35482, 35483, 35488, 35489, 35494, 35496, 35497, 35498, 35500, 35501, 35503, 35504, 35510, 35512, 35516, 35517, 35523, 35527, 35530, 35532, 35533, 35535, 35536, 35537, 35538, 35543, 35544, 35545, 35549, 35551, 35552, 35554, 35555, 35557, 35562, 35563, 35565, 35567, 35568, 35571, 35573, 35575, 35577, 35578, 35579, 35581, 35582, 35583, 35584, 35585, 35586, 35588, 35589, 35590, 35592, 35595, 35596, 35597, 35598, 35599, 35600, 35601, 35605, 35606, 35607, 35612, 35614, 35617, 35618, 35619, 35622, 35624, 35625, 35630, 35631, 35633, 35635, 35637, 35638, 35640, 35644, 35645, 35646, 35647, 35648, 35652, 35653, 35654, 35655, 35657, 35659, 35662, 35663, 35664, 35665, 35669, 35672, 35674, 35675, 35678, 35679, 35680, 35685, 35686, 35688, 35689, 35692, 35693, 35695, 35696, 35698, 27507, 35699, 35700, 35703, 35705, 35707, 35710, 35713, 35715, 35716, 35717, 35719, 35722, 35725, 35726, 35727, 35730, 35731, 35732, 35734, 35735, 35736, 35739, 35740, 35742, 35743, 35744, 35745, 35746, 35748, 35755, 35759, 35761, 35762, 35763, 35764, 35766, 35768, 35771, 35779, 35780, 35781, 35783, 35784, 35786, 35787, 35793, 35796, 35798, 35799, 35800, 35801, 35802, 35805, 35806, 35807, 35808, 35809, 35810, 35811, 35812, 35813, 35814, 35815, 35816, 35818, 35820, 35821, 35823, 35825, 35826, 35828, 35829, 35831, 35832, 35833, 35834, 35835, 35837, 35838, 35841, 35844, 35847, 35848, 35851, 35853, 35856, 35857, 35859, 35861, 35869, 35870, 35871, 35873, 35876, 35877, 35878, 35879, 35881, 35885, 35886, 35887, 35890, 35891, 35893, 35895, 35896, 35897, 35902, 166975, 35907, 35908, 35909, 35910, 35912, 35914, 35915, 35916, 35918, 35919, 35920, 35921, 35922, 35923, 35924, 35925, 35926, 35927, 35929, 35933, 35934, 35937, 35938, 35939, 35941, 35942, 35943, 35945, 35947, 35948, 35951, 35957, 35958, 35959, 35961, 35962, 35963, 35966, 35967, 35968, 35970, 35972, 35975, 35976, 35977, 35978, 35979, 35981, 35986, 35988, 35989, 35991, 35992, 35996, 35997, 35998, 35999, 36005, 36006, 36009, 36010, 36012, 36014, 36015, 36016, 36017, 36020, 36021, 36022, 36026, 36027, 36029, 36031, 36033, 36034, 36035, 36036, 36037, 36038, 36039, 36040, 36041, 36042, 36045, 36047, 36051, 36052, 36054, 36055, 36058, 36059, 36063, 36064, 36065, 36066, 36070, 36071, 36072, 36074, 36075, 36076, 36079, 36080, 36083, 36084, 36086, 36088, 36089, 36090, 36092, 36093, 36094, 36095, 36097, 36098, 36099, 36101, 36104, 36105, 36109, 36111, 36112, 36115, 36116, 36118, 36119, 36124, 36126, 36128, 36132, 36134, 36144, 36145, 36147, 36148, 36149, 36151, 36152, 36155, 36156, 36159, 36160, 36161, 36164, 36166, 36167, 36168, 36170, 36171, 36173, 36175, 36176, 36177, 36179, 36180, 36181, 36183, 36185, 36186, 36187, 36189, 36190, 36194, 36196, 36198, 36200, 36202, 36205, 36206, 36209, 36212, 36213, 36214, 36215, 36218, 36219, 36220, 36221, 36222, 36223, 36227, 36228, 36229, 36231, 36232, 36233, 36234, 36236, 36238, 36239, 36242, 36245, 36247, 36250, 36253, 36254, 36255, 36256, 36257, 36260, 36262, 36263, 36264, 36265, 36266, 36269, 36271, 36272, 36274, 36275, 36276, 36277, 36279, 36280, 36283, 36284, 36286, 36287, 36288, 36289, 36296, 36302, 36303, 36305, 36306, 36307, 36308, 36311, 36313, 36318, 36319, 36323, 36324, 36326, 36327, 36331, 36333, 36338, 36340, 36341, 36346, 36352, 36353, 36355, 36358, 36360, 36361, 36362, 36364, 36366, 36372, 36373, 36374, 36375, 36379, 36380, 36384, 36385, 36386, 36387, 36388, 36391, 36394, 36395, 36398, 36399, 36400, 36402, 36403, 36404, 36405, 36408, 36410, 36411, 36416, 36418, 36419, 36421, 36424, 36426, 36428, 36430, 36436, 36438, 36440, 36441, 36444, 36447, 36451, 36454, 36455, 36460, 36461, 36463, 36464, 36466, 36467, 36468, 36471, 36474, 36477, 36480, 36481, 36485, 36486, 36488, 36489, 36493, 36496, 36497, 36501, 36502, 36506, 36507, 36509, 36510, 36511, 36514, 36516, 36518, 36520, 36528, 36530, 36531, 36533, 36538, 36539, 36542, 36543, 36545, 36548, 36549, 36553, 36556, 36559, 36561, 36562, 36563, 36564, 36566, 36567, 36569, 36570, 36571, 36573, 36574, 36575, 36577, 36578, 36579, 36580, 36583, 36584, 36586, 36590, 36592, 36593, 36596, 36597, 36598, 36599, 36600, 36601, 36602, 36603, 36605, 36614, 36616, 36617, 36620, 36621, 36622, 36625, 36626, 36627, 36629, 36630, 36631, 36632, 36635, 36636, 36639, 36640, 36641, 36642, 36644, 36646, 36650, 36652, 36654, 36656, 36667, 168328, 62552, 46192, 46197, 46199, 46220, 46224, 46225, 46251, 46255, 46270, 46275, 46279, 46292, 46304, 46317, 46319, 46324, 46329, 46350, 46366, 46373, 46383, 46388, 46406, 46408, 46415, 46417, 46419, 46435, 46440, 46449, 46450, 46451, 46453, 46455, 46474, 46480, 46482, 46483, 46498, 46509, 46510, 46520, 46521, 46522, 46531, 46532, 46534, 46537, 46549, 46552, 46565, 46567, 46570, 46574, 46576, 46578, 46579, 30284, 30307, 30309, 30330, 30339, 79536, 30408, 79580, 30430, 30431, 30450, 30458, 30487, 30542, 30555, 30576, 30586, 30589, 30592, 30593, 30594, 161666, 30598, 30605, 30608, 30612, 30613, 30615, 30617, 30618, 30620, 30622, 30625, 30626, 30633, 30635, 30636, 30638, 30643, 30645, 30647, 30648, 30652, 30654, 30659, 30660, 30661, 30663, 30664, 30665, 30666, 30670, 30675, 30681, 30686, 30690, 30692, 30701, 30703, 30704, 30705, 30708, 161791, 30720, 30721, 30722, 30724, 30726, 30730, 30737, 30741, 30742, 30743, 30746, 30751, 30752, 30754, 30755, 30758, 30759, 30763, 30765, 30769, 30772, 30773, 30775, 30776, 30778, 30780, 30781, 30782, 30783, 30785, 30786, 30788, 30790, 30792, 30795, 30796, 30797, 30799, 30802, 30804, 30805, 30806, 30808, 30809, 30811, 30812, 30815, 30818, 30819, 30820, 30821, 30824, 30825, 30826, 30827, 30831, 30832, 30833, 30835, 30837, 30838, 30839, 30840, 30841, 30842, 30843, 30845, 30846, 30850, 30851, 30853, 30855, 30856, 30857, 30858, 30859, 30862, 30865, 30866, 30868, 30870, 30871, 30872, 30873, 30874, 161942, 30880, 30881, 30882, 30883, 30887, 30888, 30891, 30892, 30893, 30898, 30900, 30901, 30902, 30904, 30907, 30911, 30912, 30915, 30916, 30919, 30920, 30923, 30925, 30928, 162001, 30930, 30932, 30933, 30936, 30938, 30939, 30940, 30941, 30947, 30948, 30951, 30952, 30956, 30958, 30959, 30960, 30963, 30965, 30966, 30969, 30971, 30973, 30975, 30978, 30979, 30980, 30982, 30983, 30984, 30985, 30986, 30989, 30990, 30991, 30993, 30995, 30996, 30997, 31000, 31002, 31004, 31005, 31006, 31007, 31009, 31010, 31013, 31014, 31016, 31017, 31018, 31019, 31024, 31027, 31028, 31029, 31030, 31031, 31032, 31034, 31038, 31039, 31040, 31042, 31045, 31046, 31049, 31053, 31056, 31061, 31062, 31069, 31070, 31071, 31072, 31075, 31078, 31079, 31081, 31083, 31084, 31086, 31088, 31089, 31090, 31093, 31096, 31098, 31099, 31101, 31102, 31103, 31104, 31105, 31106, 31107, 31109, 164121, 31111, 31112, 31113, 31114, 31115, 31117, 31119, 164123, 31123, 31124, 31125, 164124, 31128, 31129, 31130, 164125, 31133, 31134, 164126, 31136, 31137, 31138, 31139, 164127, 31141, 31142, 31143, 31144, 31148, 31149, 31155, 31156, 31159, 31161, 31163, 31164, 31165, 31170, 31173, 31174, 31176, 31179, 31182, 31184, 31185, 31188, 31190, 31191, 31202, 31203, 31204, 31205, 31206, 31207, 31213, 31216, 31218, 31220, 31223, 31227, 31228, 31230, 31231, 31233, 31234, 31238, 31239, 31241, 31246, 31247, 31248, 31249, 31252, 31261, 31263, 31265, 31266, 31267, 31272, 31274, 31275, 31276, 31278, 31279, 31280, 31281, 31282, 31283, 31284, 31285, 31288, 31291, 31293, 31296, 31297, 31299, 31300, 31301, 31303, 31305, 31309, 31310, 31312, 31313, 31314, 31316, 31317, 31318, 31320, 31321, 31325, 31326, 31328, 31330, 31331, 31334, 31335, 31337, 31339, 31340, 31341, 31342, 31343, 31344, 31345, 31346, 31347, 31350, 31351, 31353, 31355, 31356, 31357, 31359, 31360, 31362, 31363, 31365, 31366, 31369, 31371, 31378, 31379, 31381, 31382, 31385, 31386, 31388, 31389, 31392, 31394, 31395, 31396, 31397, 31398, 31400, 31402, 31403, 31405, 31408, 31410, 31411, 31412, 31413, 31414, 31415, 31416, 31417, 31419, 31420, 31421, 31422, 31424, 31429, 31432, 31436, 31437, 31438, 31439, 31442, 31443, 31444, 31445, 31448, 31451, 31452, 31454, 31456, 31458, 31459, 31461, 31462, 31463, 31464, 31466, 31470, 31472, 31474, 31479, 31480, 31481, 31484, 31486, 31488, 31490, 31491, 31495, 31497, 31502, 31503, 31505, 31506, 31508, 31509, 31510, 31513, 31514, 31516, 31519, 31520, 31522, 31524, 31526, 31527, 31530, 31531, 31532, 31536, 31537, 31539, 31542, 31543, 31544, 31547, 31551, 31553, 31554, 31556, 31557, 31559, 31560, 31562, 31563, 31569, 31570, 31575, 31576, 31577, 31578, 31579, 31581, 31582, 31583, 31584, 31586, 31588, 31589, 31590, 31591, 31592, 31593, 31596, 31601, 31602, 31603, 31604, 31605, 31610, 31614, 31615, 31616, 31617, 31618, 31619, 31620, 31621, 31622, 31624, 31625, 31628, 31634, 31635, 31641, 31642, 31646, 31648, 31651, 31656, 31657, 31662, 31665, 31666, 31667, 31670, 31671, 31673, 31674, 31678, 31681, 31687, 31689, 31691, 31692, 31694, 31697, 31699, 31701, 31704, 31705, 31706, 31707, 31708, 31709, 31715, 31716, 31718, 31719, 31720, 31721, 31722, 31723, 31726, 31729, 31731, 31732, 31736, 31739, 31740, 31741, 31742, 31744, 31749, 31754, 31756, 31758, 31759, 31761, 31763, 31767, 31769, 31773, 31777, 31778, 31779, 31780, 31781, 31784, 31785, 31790, 31791, 31793, 31794, 31796, 31798, 31799, 31800, 31806, 31807, 31809, 31810, 31812, 31813, 31814, 31816, 31817, 31818, 31819, 31820, 89165, 31823, 31824, 31826, 31827, 31830, 31832, 31835, 31836, 31837, 31840, 31841, 31844, 31846, 31847, 31848, 31849, 31854, 31857, 31858, 31864, 31866, 31869, 31873, 31875, 31876, 31879, 31882, 31885, 31887, 31888, 31889, 31893, 31895, 31896, 31898, 31900, 31903, 31904, 31912, 31913, 31914, 31915, 31916, 31920, 31922, 31923, 31926, 31928, 31929, 31931, 31932, 31936, 31937, 31938, 31940, 31941, 31942, 31943, 31945, 31946, 31948, 31949, 31950, 31953, 31956, 31957, 31959, 31960, 31963, 31966, 31969, 31970, 31974, 31976, 31977, 31980, 31981, 31983, 31984, 31985, 31987, 31991, 31992, 31993, 31998, 171262, 32000, 32001, 32002, 171266, 32004, 32015, 32016, 32017, 32018, 32019, 32020, 32024, 32025, 32028, 32031, 32032, 32034, 32035, 32036, 32038, 32040, 32041, 32042, 32045, 32046, 32049, 32053, 32055, 32056, 32059, 32063, 32068, 32072, 32074, 32075, 32078, 32083, 32084, 32085, 32087, 32090, 32091, 32092, 32097, 32098, 32099, 32102, 32106, 32108, 32110, 32111, 32114, 32115, 32116, 32117, 32119, 32122, 32124, 32125, 32126, 32128, 32129, 32131, 32133, 32134, 32137, 32138, 32149, 32150, 32151, 32153, 32156, 32157, 32159, 32160, 32162, 32163, 32166, 32168, 32169, 32171, 32174, 32175, 32176, 32178, 32180, 32182, 32186, 32189, 32191, 32193, 32195, 32196, 32197, 32200, 32202, 32204, 32205, 32207, 32209, 32210, 32211, 32212, 32213, 32216, 32220, 32221, 32222, 32223, 32224, 32225, 32226, 32233, 32237, 32238, 32239, 32240, 32241, 32242, 32243, 32245, 32247, 32253, 32254, 32255, 32257, 32258, 32259, 32263, 32264, 32265, 32267, 32269, 32271, 32274, 32275, 32277, 32280, 32281, 32282, 32284, 32286, 32291, 32292, 32293, 32294, 32295, 32297, 32301, 32302, 32305, 32310, 32311, 32312, 32313, 32315, 32316, 32317, 32320, 32323, 32325, 32326, 32328, 32331, 32332, 32333, 32334, 32336, 32337, 32338, 32339, 32340, 32341, 32342, 32347, 32349, 32350, 32353, 32354, 32355, 32358, 32359, 32360, 32362, 32364, 32366, 32367, 32369, 32371, 32372, 32375, 32377, 32379, 32383, 32384, 32385, 32387, 32390, 32393, 32396, 32397, 32398, 32399, 32404, 32405, 32412, 32413, 32415, 32417, 32423, 32424, 32425, 32427, 32430, 32431, 32432, 32433, 32435, 32436, 32437, 32438, 32440, 32444, 32445, 32446, 32448, 32454, 32456, 32458, 32459, 32460, 32461, 32465, 32466, 32469, 32471, 32475, 32476, 32477, 32478, 32483, 32484, 32488, 32489, 32490, 32492, 32497, 32498, 32499, 32501, 32508, 32510, 32511, 32512, 32513, 32514, 32515, 32516, 32517, 32518, 32519, 32520, 32521, 32522, 32524, 32525, 32526, 32527, 32531, 32532, 32533, 32537, 32539, 32540, 32543, 32545, 32546, 32549, 32550, 32551, 32552, 32553, 32555, 32556, 32557, 32558, 32561, 32563, 32564, 32566, 32568, 32573, 32576, 32578, 32579, 32581, 32584, 32586, 32587, 32588, 32589, 32590, 32592, 32593, 32594, 32595, 32598, 32599, 32600, 32601, 32602, 32603, 32606, 32607, 32608, 32609, 32611, 32612, 32613, 32614, 32615, 32616, 32617, 32619, 32620, 32621, 32622, 32623, 32625, 32626, 32629, 32631, 32632, 32635, 32636, 32637, 32641, 32642, 32643, 32644, 32645, 32647, 32648, 32649, 32650, 32651, 32652, 32654, 32656, 32658, 32659, 32661, 32662, 32663, 32664, 32665, 32668, 32671, 32674, 32675, 32677, 32679, 32680, 32682, 32687, 32689, 32692, 32693, 32694, 32695, 32696, 32697, 32699, 32701, 32702, 32704, 32706, 32707, 32708, 32709, 32713, 32714, 32716, 32723, 32724, 32725, 32726, 32727, 32729, 32730, 32731, 32732, 32735, 32738, 32739, 32740, 32741, 32745, 32747, 32748, 32749, 32754, 32755, 32757, 32759, 32761, 32765, 32766]\n",
    "    duplicate_list.extend([31990, 25144, 25847, 34510, 26471, 27132, 27580, 34896, 33296, 29028, 29389, 29696, 29926, 30106])\n",
    "    duplicate_list = list(set(duplicate_list))\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    duplicate_list.sort()\n",
    "    no_duplicate_list = [i for i in range(x.shape[0]) if i not in duplicate_list]\n",
    "    x = x[no_duplicate_list, :, :, :]\n",
    "    #     y = y[no_duplicate_list, :]\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    del no_duplicate_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストデータを分割\n",
    "705枚をテストデータとする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_ints_nodup(a, b, k):\n",
    "    ns = []\n",
    "    while len(ns) < k:\n",
    "        n = random.randint(a, b)\n",
    "        if not n in ns:\n",
    "            ns.append(n)\n",
    "    return ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    pattern_testsize = 50\n",
    "    random.seed(1)\n",
    "    randlist = np.concatenate([random.sample(list(np.where(y==i)[0]), pattern_testsize) for i in range(9)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tempx, tempyにテストデータを分割\n",
    "- new_x, yからその分を削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    tempx = x.copy()[randlist, :, :, :]\n",
    "    tempy = y.copy()[randlist, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    new_tempx = np.zeros((len(tempx), max_size, max_size, 3), dtype='int8')\n",
    "    for w in range(len(tempx)):\n",
    "            for i in range(max_size):\n",
    "                for j in range(max_size):\n",
    "                    new_tempx[w, i, j, int(tempx[w, i, j])] = 1\n",
    "            print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    for i in range(9) :\n",
    "        print('{} : {}'.format(i, len(tempy[tempy==i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    x = np.delete(x, randlist, axis=0)\n",
    "    y = np.delete(y, randlist, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    joblib.dump(new_tempx, './data/multi_' + str(max_size) + '/test/xtest.pickle')\n",
    "    joblib.dump(tempy, './data/multi_' + str(max_size) + '/test/ytest.pickle')\n",
    "    # joblib.dump(tempx, './data/multi_' + str(max_size) + '_no_data_augmentation/test/xtest.pickle')\n",
    "    # joblib.dump(tempy, './data/multi_' + str(max_size) + '_no_data_augmentation/test/ytest.pickle')\n",
    "    del tempx, tempy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### オリジナルの学習データを3チャネルにして保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    import time\n",
    "    from multiprocessing import Pool\n",
    "\n",
    "    def save_np(file, count):\n",
    "        np.save('./data/multi_' + str(max_size) + '/original_data/' + str(count), file)\n",
    "\n",
    "    batch_size = 1000\n",
    "    start = time.time()\n",
    "    for count in range(x.shape[0]//batch_size + 1):\n",
    "        end = (count + 1) * batch_size if x.shape[0] > (count + 1) * batch_size else x.shape[0]\n",
    "        save_x = np.zeros((end - count * batch_size, max_size, max_size, 3), dtype='int8')\n",
    "        batch_count = 0\n",
    "        for batch in range(count * batch_size, end):\n",
    "    #         print(' ', batch_count)\n",
    "            for i in range(max_size):\n",
    "                for j in range(max_size):\n",
    "                    save_x[batch_count, i, j, int(x[batch, i, j, :])] = 1\n",
    "            batch_count += 1\n",
    "        save_xs = [save_x[i] for i in range(save_x.shape[0])]\n",
    "        args = list(zip(save_xs, list(range(count * batch_size, end))))\n",
    "        with Pool() as p:\n",
    "            p.starmap(save_np, args)\n",
    "\n",
    "        print(count)\n",
    "        print('elapsed time', time.time()-start)\n",
    "    joblib.dump(y, './data/multi_' + str(max_size) + '/original_data/y.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### オートエンコーダで学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データの読み出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_AUTO_ENCODER:\n",
    "    # acquire the .npy name\n",
    "    data_size = len(glob.glob('./data/multi_' + str(max_size) + '/original_data/' + '*.npy'))\n",
    "    TRAINS = ['./data/multi_' + str(max_size) + '/original_data/' + str(i) + '.npy' for i in range(data_size)]\n",
    "    x_train = TRAINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchを取得する関数\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "def load_array(file):\n",
    "    return np.load(file)\n",
    "\n",
    "def get_batch(batch_size): \n",
    "    global x_train\n",
    "    SIZE = len(x_train)\n",
    "    # n_batchs\n",
    "    n_batchs = SIZE//batch_size + 1\n",
    "    # for でyield\n",
    "    i = 0\n",
    "    start = time.time()\n",
    "    while (i < n_batchs):\n",
    "        print(\"doing\", i, \"/\", n_batchs)\n",
    "       \n",
    "        #あるbatchのfilenameの配列を持っておく\n",
    "        X_batch_name = x_train[(i * batch_size):((i + 1) * batch_size)]\n",
    "\n",
    "        # filenameにしたがってバッチのtensorを構築\n",
    "        with Pool() as p:\n",
    "            arr = p.map(load_array, X_batch_name)\n",
    "            \n",
    "        X_batch = np.array(arr).reshape(len(X_batch_name), max_size, max_size, 3)\n",
    "#         X_batch = np.array([np.load(file)\n",
    "#                             for file in X_batch_name]).reshape(len(X_batch_name), max_size, max_size, 3)\n",
    "        i += 1\n",
    "        print('elapsed time', time.time()-start)\n",
    "        yield X_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### エンコーダとデコーダのモデルを学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- モデルの定義をする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"], cross_device_ops = tf.distribute.HierarchicalCopyAllReduce())\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "if TRAIN_AUTO_ENCODER:\n",
    "    with strategy.scope():\n",
    "        # Encoder\n",
    "        input_shape = (max_size, max_size, 3)\n",
    "        input_tensor = Input(input_shape)\n",
    "        encode = layers.Conv2D(64, (3,3), padding='same', activation='relu')(input_tensor)\n",
    "\n",
    "        latent_vector = layers.MaxPool2D()(encode)\n",
    "\n",
    "        # Decoder\n",
    "        decode_layer_1 = layers.Conv2DTranspose(64, (3,3), padding='same', activation='relu')\n",
    "        decode_layer_2 = layers.UpSampling2D()\n",
    "        output_tensor = layers.Conv2DTranspose(3, (3,3), padding='same', activation='sigmoid')\n",
    "\n",
    "        # connect decoder layers\n",
    "        decode = decode_layer_1(latent_vector)\n",
    "        decode = decode_layer_2(decode)\n",
    "\n",
    "        ae = models.Model(input_tensor, output_tensor(decode))\n",
    "        ae.compile(optimizer = 'Adam',\n",
    "                      loss = 'mse',\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 層は\n",
    "    - 入力層\n",
    "    - 畳み込み層\n",
    "    - プーリング層\n",
    "    - 転置畳み込み層\n",
    "    - アップサンプリング層"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 学習を開始する．\n",
    "- `new_x`を`new_x`にエンコードしデコードする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 30\n",
    "batch_size = 256\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "0 / 30\n",
      "doing 0 / 662\n",
      "elapsed time 0.4536628723144531\n",
      "INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = hierarchical_copy, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = hierarchical_copy, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_AUTO_ENCODER:\n",
    "    epoch_train_loss = []\n",
    "    epoch_train_acc = []\n",
    "    for ep in range(epoch):\n",
    "        print(\"=\" * 50)\n",
    "        print(ep, \"/\", epoch)\n",
    "        step_loss = []\n",
    "        step_acc = []\n",
    "\n",
    "        # batch_size=1000でHDDからバッチを取得する\n",
    "        for X_batch in get_batch(batch_size):\n",
    "            ae.train_on_batch(X_batch, X_batch)\n",
    "            score = ae.evaluate(X_batch, X_batch)\n",
    "            print(\"batch loss:\", score[0])\n",
    "            print(\"batch accuracy:\", score[1])\n",
    "            step_loss.append(score[0])\n",
    "            step_acc.append(score[1])\n",
    "        print(\"Train loss\", np.mean(step_loss))\n",
    "        print(\"Train accuracy\", np.mean(step_acc))\n",
    "        epoch_train_loss.append(np.mean(step_loss))\n",
    "        epoch_train_acc.append(np.mean(step_acc))\n",
    "\n",
    "        shuffle_indices = random.sample(list(range(len(x_train))), len(x_train))\n",
    "        x_train = [x_train[i] for i in shuffle_indices]\n",
    "        \n",
    "    ae.save(auto_encoder_path)\n",
    "else:\n",
    "    ae = models.load_model(auto_encoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- エンコーダだけのモデルを定義する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (max_size, max_size, 3)\n",
    "input_tensor = Input(input_shape)\n",
    "encode = ae.layers[1](input_tensor)\n",
    "latent_vector = ae.layers[2](encode)\n",
    "\n",
    "encoder = models.Model(input_tensor, latent_vector)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- デコーダだけのモデルを定義する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoder_input = Input((encord_size, encord_size, 64))\n",
    "decode = ae.layers[3](decoder_input)\n",
    "decode = ae.layers[4](decode)\n",
    "output_tensor = ae.layers[5](decode)\n",
    "\n",
    "decoder = models.Model(decoder_input, output_tensor)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `encoder`を使って元のウエハ画像をエンコードする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Encode original faulty wafer\n",
    "# encoded_x = np.zeros((156581, 50, 50, 64), dtype=\"int8\")\n",
    "# encoded_x = (encoder.predict(new_x))\n",
    "# encoded_x0 = encoder.predict(new_x[0].reshape(1, 100, 100, 3))[0].reshape(1, 50, 50, 64)\n",
    "# print(new_x[0].dtype)\n",
    "# print(encoded_x0.dtype)\n",
    "# print(new_x[0].shape)\n",
    "# print(encoded_x0.shape)\n",
    "# print(new_x[0])\n",
    "# print(encoded_x0)\n",
    "# noised_x0 = encoded_x0 + np.random.normal(loc=0, scale=0.1, size = (1, 50, 50, 64))\n",
    "# noised_gen_x0 = np.argmax(convert_float_to_01(decoder.predict(noised_x0)[0]), axis=2)\n",
    "# plt.imshow(np.argmax(new_x[0], axis=2))\n",
    "# plt.show()\n",
    "# plt.imshow(noised_gen_x0)\n",
    "# plt.show()\n",
    "# print(np.array_equal(np.argmax(new_x[0], axis=2), noised_gen_x0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- エンコードされた潜伏的な不良ウエハにノイズを負荷する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise to encoded latent faulty wafers vector.\n",
    "# noised_encoded_x = encoded_x + np.random.normal(loc=0, scale=0.1, size = (len(encoded_x), 50, 50, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 元のウエハ画像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check original faulty wafer data\n",
    "# plt.imshow(np.argmax(new_x[3], axis=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ノイズが付加されたウエハ画像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check new noised faulty wafer data\n",
    "# noised_gen_x = np.argmax(decoder.predict(new_x[3].reshape(1, 100, 100, 3)), axis=3)\n",
    "# plt.imshow(noised_gen_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01に変換する\n",
    "def convert_float_to_01(wafer):\n",
    "    width, height, c = wafer.shape\n",
    "    int_wafer = np.zeros((width, height, c), dtype='int8')\n",
    "    for i in range(width):\n",
    "        for j in range(height):\n",
    "            max_index = np.argmax(wafer[i, j])\n",
    "            for k in range(3):\n",
    "                int_wafer[i, j, k] = 1 if k == max_index else 0\n",
    "    return int_wafer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データオーギュメンテーション前にそれぞれのラベルで保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAKE_DATASET = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "none_idx = np.where(y==8)[0][np.random.choice(len(np.where(y==8)[0]), size=100000, replace=False)]\n",
    "new_x = np.delete(new_x, none_idx, axis=0)\n",
    "y = np.delete(y, none_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51436, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_DATASET:\n",
    "    for i in range(9):\n",
    "        new_x_pattern = new_x[np.where(y[:, 0] == i)]\n",
    "        y_pattern = y[np.where(y[:, 0] == i)]\n",
    "        split_num = new_x_pattern.shape[0] // 5 + 1\n",
    "        for j in range(5):\n",
    "#             joblib.dump(new_x_pattern[split_num*j:split_num*(j+1)], './data/new_xmulti_' + str(max_size) + '_' + str(i) + '_' + str(j) + '.pickle')\n",
    "#             joblib.dump(y_pattern[split_num*j:split_num*(j+1)], './data/ymulti_' + str(max_size) + '_' + str(i) + '_' + str(j) + '.pickle')\n",
    "            joblib.dump(new_x_pattern[split_num*j:split_num*(j+1)], './data/new_xmulti_' + str(max_size) + '_no_data_augmentation_' + str(i) + '_' + str(j) + '.pickle')\n",
    "            joblib.dump(y_pattern[split_num*j:split_num*(j+1)], './data/ymulti_' + str(max_size) + '_no_data_augmentation_' + str(i) + '_' + str(j) + '.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データオーギュメンテーション"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- データオーギュメンテーションを行う関数を定義する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shawon = False\n",
    "# rotation_num = 3\n",
    "# inversion = False\n",
    "# pattern_num = 2000 if shawon else 10000\n",
    "pattern_num = 29000\n",
    "\n",
    "each_pattern_num = [y[y==i].shape[0] for i in range(9)]\n",
    "each_pattern_iteration = [pattern_num // each_pattern_num[i] for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3968, 470, 4422, 8700, 2936, 130, 736, 899, 29175]\n",
      "[7, 61, 6, 3, 9, 223, 39, 32]\n"
     ]
    }
   ],
   "source": [
    "print(each_pattern_num)\n",
    "print(each_pattern_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment function define\n",
    "def gen_data(wafer, label):\n",
    "    # Encode input wafer\n",
    "    encoded_x = encoder.predict(wafer)\n",
    "    \n",
    "    # dummy array for collecting noised wafer\n",
    "    gen_x = np.zeros((1, max_size, max_size, 3), dtype='int8')\n",
    "    int_noised_gen_x = np.zeros_like(wafer, dtype='int8')\n",
    "    \n",
    "    # Make wafer until total # of wafer to 2000\n",
    "    for i in range(each_pattern_iteration[label] + 1):\n",
    "        noised_encoded_x = encoded_x + np.random.normal(loc=0, scale=0.1, size = (len(encoded_x), encord_size, encord_size, 64)) \n",
    "        noised_gen_x = decoder.predict(noised_encoded_x)\n",
    "        for wafer_num in range(noised_gen_x.shape[0]):\n",
    "            int_noised_gen_x[wafer_num] = convert_float_to_01(noised_gen_x[wafer_num])\n",
    "        gen_x = np.concatenate((gen_x, int_noised_gen_x), axis=0)\n",
    "    # also make label vector with same length\n",
    "    gen_y = np.full((len(gen_x), 1), label)\n",
    "    \n",
    "    print(label, gen_x.shape)\n",
    "    \n",
    "    del encoded_x\n",
    "    del noised_encoded_x\n",
    "    del noised_gen_x\n",
    "    del int_noised_gen_x\n",
    "    \n",
    "    # return date without 1st dummy data.\n",
    "    return gen_x[1:], gen_y[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 不良ラベルが付いているデータに対してデータオーギュメンテーションを行う．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d409cbafd514>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Augmentation for all faulty case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Augmentation for all faulty case\n",
    "all_y = np.empty((0, 1))\n",
    "count = 0\n",
    "for i in range(9):\n",
    "    for k in range(5):\n",
    "        print(k, ' start')\n",
    "        new_x_pattern = joblib.load('./data/new_xmulti_' + str(max_size) + '_' + str(i) + '_' + str(k) + '.pickle')\n",
    "        y_pattern = joblib.load('./data/ymulti_' + str(max_size) + '_' + str(i) + '_' + str(k) + '.pickle')\n",
    "        # skip none case\n",
    "        if i != 8 :\n",
    "            gen_x, gen_y = gen_data(new_x_pattern, i)\n",
    "            new_x_pattern = np.concatenate((new_x_pattern, gen_x), axis=0)\n",
    "            y_pattern = np.concatenate((y_pattern, gen_y))\n",
    "            del gen_x, gen_y\n",
    "            print(new_x_pattern.shape)\n",
    "\n",
    "        for j in range(y_pattern.shape[0]):\n",
    "            np.save('./data/multi_' + str(max_size) + '/train/' + str(count), new_x_pattern[j])\n",
    "            count += 1\n",
    "            if count % 1000 == 0:\n",
    "                print(count)\n",
    "        all_y = np.concatenate((all_y, y_pattern))\n",
    "        joblib.dump(new_x_pattern, './data/new_xmulti_' + str(max_size) + '_' + str(i) + '_datagen_' + str(pattern_num) + '.pickle')\n",
    "        joblib.dump(y_pattern, './data/ymulti_' + str(max_size) + '_' + str(i) + '_datagen_' + str(pattern_num) + '.pickle')\n",
    "        del new_x_pattern, y_pattern\n",
    "    \n",
    "joblib.dump(all_y, './data/multi_' + str(max_size) + '/train/y.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  start\n",
      "(794, 100, 100, 3)\n",
      "1  start\n",
      "(794, 100, 100, 3)\n",
      "1000\n",
      "2  start\n",
      "(794, 100, 100, 3)\n",
      "2000\n",
      "3  start\n",
      "(794, 100, 100, 3)\n",
      "3000\n",
      "4  start\n",
      "(792, 100, 100, 3)\n",
      "0  start\n",
      "(95, 100, 100, 3)\n",
      "4000\n",
      "1  start\n",
      "(95, 100, 100, 3)\n",
      "2  start\n",
      "(95, 100, 100, 3)\n",
      "3  start\n",
      "(95, 100, 100, 3)\n",
      "4  start\n",
      "(90, 100, 100, 3)\n",
      "0  start\n",
      "(885, 100, 100, 3)\n",
      "5000\n",
      "1  start\n",
      "(885, 100, 100, 3)\n",
      "6000\n",
      "2  start\n",
      "(885, 100, 100, 3)\n",
      "7000\n",
      "3  start\n",
      "(885, 100, 100, 3)\n",
      "4  start\n",
      "(882, 100, 100, 3)\n",
      "8000\n",
      "0  start\n",
      "(1741, 100, 100, 3)\n",
      "9000\n",
      "10000\n",
      "1  start\n",
      "(1741, 100, 100, 3)\n",
      "11000\n",
      "12000\n",
      "2  start\n",
      "(1741, 100, 100, 3)\n",
      "13000\n",
      "14000\n",
      "3  start\n",
      "(1741, 100, 100, 3)\n",
      "15000\n",
      "4  start\n",
      "(1736, 100, 100, 3)\n",
      "16000\n",
      "17000\n",
      "0  start\n",
      "(588, 100, 100, 3)\n",
      "18000\n",
      "1  start\n",
      "(588, 100, 100, 3)\n",
      "2  start\n",
      "(588, 100, 100, 3)\n",
      "19000\n",
      "3  start\n",
      "(588, 100, 100, 3)\n",
      "4  start\n",
      "(584, 100, 100, 3)\n",
      "20000\n",
      "0  start\n",
      "(27, 100, 100, 3)\n",
      "1  start\n",
      "(27, 100, 100, 3)\n",
      "2  start\n",
      "(27, 100, 100, 3)\n",
      "3  start\n",
      "(27, 100, 100, 3)\n",
      "4  start\n",
      "(22, 100, 100, 3)\n",
      "0  start\n",
      "(148, 100, 100, 3)\n",
      "1  start\n",
      "(148, 100, 100, 3)\n",
      "2  start\n",
      "(148, 100, 100, 3)\n",
      "21000\n",
      "3  start\n",
      "(148, 100, 100, 3)\n",
      "4  start\n",
      "(144, 100, 100, 3)\n",
      "0  start\n",
      "(180, 100, 100, 3)\n",
      "1  start\n",
      "(180, 100, 100, 3)\n",
      "2  start\n",
      "(180, 100, 100, 3)\n",
      "3  start\n",
      "(180, 100, 100, 3)\n",
      "22000\n",
      "4  start\n",
      "(179, 100, 100, 3)\n",
      "0  start\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "1  start\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "2  start\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "3  start\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "4  start\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./data/multi_100_no_data_augmentation/train/y.pickle']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For no data agumentation\n",
    "all_y = np.empty((0, 1))\n",
    "count = 0\n",
    "for i in range(9):\n",
    "    for k in range(5):\n",
    "        print(k, ' start')\n",
    "#         new_x_pattern = joblib.load('./data/new_xmulti_' + str(max_size) + '_' + str(i) + '_' + str(k) + '.pickle')\n",
    "#         y_pattern = joblib.load('./data/ymulti_' + str(max_size) + '_' + str(i) + '_' + str(k) + '.pickle')\n",
    "        new_x_pattern = joblib.load('./data/new_xmulti_' + str(max_size) + '_no_data_augmentation_' + str(i) + '_' + str(k) + '.pickle')\n",
    "        y_pattern = joblib.load('./data/ymulti_' + str(max_size) + '_no_data_augmentation_' + str(i) + '_' + str(k) + '.pickle')\n",
    "        # skip none case\n",
    "        if i != 8 :\n",
    "            print(new_x_pattern.shape)\n",
    "\n",
    "        for j in range(y_pattern.shape[0]):\n",
    "#             np.save('./data/multi_' + str(max_size) + '/train/' + str(count), new_x_pattern[j])\n",
    "            np.save('./data/multi_' + str(max_size) + '_no_data_augmentation/train/' + str(count), new_x_pattern[j])\n",
    "            count += 1\n",
    "            if count % 1000 == 0:\n",
    "                print(count)\n",
    "        all_y = np.concatenate((all_y, y_pattern))\n",
    "#         joblib.dump(new_x_pattern, './data/new_xmulti_' + str(max_size) + '_' + str(i) + '_datagen_' + str(pattern_num) + '.pickle')\n",
    "#         joblib.dump(y_pattern, './data/ymulti_' + str(max_size) + '_' + str(i) + '_datagen_' + str(pattern_num) + '.pickle')\n",
    "        joblib.dump(new_x_pattern, './data/new_xmulti_' + str(max_size) + '_no_data_augmentation_' + str(i) + '_datagen_' + str(pattern_num) + '.pickle')\n",
    "        joblib.dump(y_pattern, './data/ymulti_' + str(max_size) + '_no_data_augmentation_' + str(i) + '_datagen_' + str(pattern_num) + '.pickle')\n",
    "        del new_x_pattern, y_pattern\n",
    "    \n",
    "# joblib.dump(all_y, './data/multi_' + str(max_size) + '/train/y.pickle')\n",
    "joblib.dump(all_y, './data/multi_' + str(max_size) + '_no_data_augmentation/train/y.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3968, 470, 4422, 8700, 2936, 130, 736, 899, 29175]\n"
     ]
    }
   ],
   "source": [
    "print([all_y[all_y==i].shape[0] for i in range(9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4080120000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Generate new_x shape : (136004, 100, 100, 3), new_y shape : (136004, 1)\n"
     ]
    }
   ],
   "source": [
    "print('After Generate new_x shape : {}, new_y shape : {}'.format(new_x.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 16100\n",
      "1 : 10902\n",
      "2 : 18048\n",
      "3 : 26457\n",
      "4 : 15000\n",
      "5 : 10147\n",
      "6 : 11400\n",
      "7 : 11016\n",
      "8 : 16934\n"
     ]
    }
   ],
   "source": [
    "for i in range(9) :\n",
    "    print('{} : {}'.format(i, len(y[y==i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- データオーギュメンテーションを行った結果，各不良データごとに2000枚増えた．\n",
    "- 合計は30707枚となった．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 不良ラベルのないデータは削除し，枚数を不良ラベルと同程度にする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# none_idx = np.where(y==8)[0][np.random.choice(len(np.where(y==8)[0]), size=120000, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_x = np.delete(new_x, none_idx, axis=0)\n",
    "# new_y = np.delete(y, none_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('After Delete \"none\" class new_x shape : {}, new_y shape : {}'.format(new_x.shape, new_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(9) :\n",
    "#     print('{} : {}'.format(i, len(new_y[new_y==i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 削除した結果，全体は19707枚となった．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習を行う\n",
    "- 不良ラベルを0-8の9次元のベクトルとして表現する．\n",
    "- one-hotエンコーディングを行っている．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, l in enumerate(faulty_case):\n",
    "#     new_y[new_y==l] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encoding\n",
    "new_y = to_categorical(new_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 学習データ（学習データと学習時のテストデータ）と最終的なテストデータに分割する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_X=new_x[0:19000]\n",
    "# new_Y=new_y[0:19000]\n",
    "# test_x=new_x[19001:19706]\n",
    "# test_y=new_y[19001:19706]\n",
    "# test_x.shape\n",
    "new_X = new_x\n",
    "new_Y = new_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 学習データを学習データと学習時のテストデータに分割する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(new_X, new_Y,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train x : (122403, 100, 100, 3), y : (122403, 9)\n",
      "Test x: (13601, 100, 100, 3), y : (13601, 9)\n"
     ]
    }
   ],
   "source": [
    "print('Train x : {}, y : {}'.format(x_train.shape, y_train.shape))\n",
    "print('Test x: {}, y : {}'.format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 学習データ12730枚，テストデータ6270枚．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- モデルの定義を行う．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    with tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"], \n",
    "                                        cross_device_ops = tf.distribute.HierarchicalCopyAllReduce()).scope():\n",
    "        input_shape = (max_size, max_size, 3)\n",
    "        input_tensor = Input(input_shape)\n",
    "\n",
    "        conv_1 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(input_tensor)\n",
    "        conv_2 = layers.Conv2D(32, (3,3), activation='relu', padding='same')(conv_1)\n",
    "        conv_3 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(conv_2)\n",
    "\n",
    "        flat = layers.Flatten()(conv_3)\n",
    "\n",
    "        dense_1 = layers.Dense(256, activation='relu')(flat)\n",
    "        dense_2 = layers.Dense(64, activation='relu')(dense_1)\n",
    "        output_tensor = layers.Dense(9, activation='softmax')(dense_2)\n",
    "\n",
    "        model = models.Model(input_tensor, output_tensor)\n",
    "        model.compile(optimizer='Adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3-Fold Cross validationで分割して学習する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=30, batch_size=1, verbose=1) \n",
    "# 3-Fold Crossvalidation\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=2019) \n",
    "#results = cross_val_score(model, x_train, y_train, cv=kfold)\n",
    "# Check 3-fold model's mean accuracy\n",
    "#print('Simple CNN Cross validation score : {:.4f}'.format(np.mean(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cross validiationによる精度は99.10%であった．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cross validationなしで学習する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del new_x\n",
    "# del new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "epoch=30\n",
    "batch_size=2048\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "INFO:tensorflow:batch_all_reduce: 12 all-reduces with algorithm = hierarchical_copy, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 12 all-reduces with algorithm = hierarchical_copy, num_packs = 1\n",
      "60/60 [==============================] - 38s 636ms/step - accuracy: 0.5935 - loss: 1.6482 - val_accuracy: 0.8198 - val_loss: 0.5184\n",
      "Epoch 2/30\n",
      "60/60 [==============================] - 36s 600ms/step - accuracy: 0.8620 - loss: 0.3911 - val_accuracy: 0.9020 - val_loss: 0.2809\n",
      "Epoch 3/30\n",
      "60/60 [==============================] - 35s 583ms/step - accuracy: 0.9356 - loss: 0.1967 - val_accuracy: 0.9442 - val_loss: 0.1640\n",
      "Epoch 4/30\n",
      "60/60 [==============================] - 37s 620ms/step - accuracy: 0.9679 - loss: 0.1085 - val_accuracy: 0.9731 - val_loss: 0.0940\n",
      "Epoch 5/30\n",
      "60/60 [==============================] - 36s 608ms/step - accuracy: 0.9858 - loss: 0.0561 - val_accuracy: 0.9868 - val_loss: 0.0507\n",
      "Epoch 6/30\n",
      "60/60 [==============================] - 37s 620ms/step - accuracy: 0.9837 - loss: 0.0626 - val_accuracy: 0.9699 - val_loss: 0.1055\n",
      "Epoch 7/30\n",
      "60/60 [==============================] - 37s 622ms/step - accuracy: 0.9932 - loss: 0.0308 - val_accuracy: 0.9932 - val_loss: 0.0278\n",
      "Epoch 8/30\n",
      "60/60 [==============================] - 37s 612ms/step - accuracy: 0.9985 - loss: 0.0101 - val_accuracy: 0.9940 - val_loss: 0.0219\n",
      "Epoch 9/30\n",
      "60/60 [==============================] - 35s 590ms/step - accuracy: 0.9992 - loss: 0.0067 - val_accuracy: 0.9942 - val_loss: 0.0207\n",
      "Epoch 10/30\n",
      "60/60 [==============================] - 37s 613ms/step - accuracy: 0.9996 - loss: 0.0040 - val_accuracy: 0.9953 - val_loss: 0.0171\n",
      "Epoch 11/30\n",
      "60/60 [==============================] - 37s 610ms/step - accuracy: 0.9997 - loss: 0.0027 - val_accuracy: 0.9964 - val_loss: 0.0145\n",
      "Epoch 12/30\n",
      "60/60 [==============================] - 36s 602ms/step - accuracy: 0.9997 - loss: 0.0024 - val_accuracy: 0.9954 - val_loss: 0.0190\n",
      "Epoch 13/30\n",
      "60/60 [==============================] - 38s 627ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.9953 - val_loss: 0.0183\n",
      "Epoch 14/30\n",
      "60/60 [==============================] - 37s 618ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.9954 - val_loss: 0.0166\n",
      "Epoch 15/30\n",
      "60/60 [==============================] - 38s 639ms/step - accuracy: 0.8611 - loss: 0.6188 - val_accuracy: 0.9569 - val_loss: 0.1358\n",
      "Epoch 16/30\n",
      "60/60 [==============================] - 38s 637ms/step - accuracy: 0.9857 - loss: 0.0508 - val_accuracy: 0.9921 - val_loss: 0.0289\n",
      "Epoch 17/30\n",
      "60/60 [==============================] - 39s 645ms/step - accuracy: 0.9984 - loss: 0.0097 - val_accuracy: 0.9946 - val_loss: 0.0192\n",
      "Epoch 18/30\n",
      "60/60 [==============================] - 40s 666ms/step - accuracy: 0.9997 - loss: 0.0032 - val_accuracy: 0.9951 - val_loss: 0.0162\n",
      "Epoch 19/30\n",
      "60/60 [==============================] - 39s 644ms/step - accuracy: 0.9998 - loss: 0.0019 - val_accuracy: 0.9951 - val_loss: 0.0183\n",
      "Epoch 20/30\n",
      "60/60 [==============================] - 39s 651ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.9951 - val_loss: 0.0159\n",
      "Epoch 21/30\n",
      "60/60 [==============================] - 39s 650ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.9953 - val_loss: 0.0163\n",
      "Epoch 22/30\n",
      "60/60 [==============================] - 39s 643ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9962 - val_loss: 0.0134\n",
      "Epoch 23/30\n",
      "60/60 [==============================] - 39s 648ms/step - accuracy: 0.9999 - loss: 8.5038e-04 - val_accuracy: 0.9947 - val_loss: 0.0188\n",
      "Epoch 24/30\n",
      "60/60 [==============================] - 38s 641ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 0.9950 - val_loss: 0.0195\n",
      "Epoch 25/30\n",
      "60/60 [==============================] - 40s 663ms/step - accuracy: 0.9999 - loss: 9.7947e-04 - val_accuracy: 0.9952 - val_loss: 0.0179\n",
      "Epoch 26/30\n",
      "60/60 [==============================] - 38s 632ms/step - accuracy: 0.9999 - loss: 8.2127e-04 - val_accuracy: 0.9951 - val_loss: 0.0178\n",
      "Epoch 27/30\n",
      "60/60 [==============================] - 39s 644ms/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 0.9943 - val_loss: 0.0215\n",
      "Epoch 28/30\n",
      "60/60 [==============================] - 39s 645ms/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 0.9949 - val_loss: 0.0222\n",
      "Epoch 29/30\n",
      "60/60 [==============================] - 39s 642ms/step - accuracy: 0.9999 - loss: 8.4898e-04 - val_accuracy: 0.9948 - val_loss: 0.0220\n",
      "Epoch 30/30\n",
      "60/60 [==============================] - 38s 638ms/step - accuracy: 0.9999 - loss: 7.7404e-04 - val_accuracy: 0.9954 - val_loss: 0.0183\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "         validation_data=(x_test, y_test),\n",
    "         epochs=epoch,\n",
    "         batch_size=batch_size,\n",
    "         verbose=1           \n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- テストデータで評価．    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 3s 7ms/step - accuracy: 0.9954 - loss: 0.0183\n",
      "Testing Accuracy: 0.9954414963722229\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "#print('Test Loss:', score[0])\n",
    "#print('Test accuracy:', score[1])\n",
    "print('Testing Accuracy:',score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- acuurayは99.31%であった．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- モデルは以下．\n",
    "    - 入力層\n",
    "    - 畳み込み層3つ\n",
    "    - Flatten層（1次元に）\n",
    "    - 全結合層3つ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 100, 100, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 100, 100, 16)      448       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 100, 100, 32)      4640      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 640000)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               163840256 \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 9)                 585       \n",
      "=================================================================\n",
      "Total params: 163,880,873\n",
      "Trainable params: 163,880,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- accuracyグラフ，lossグラフは以下．\n",
    "- 5epoch程度で落ち着いている．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracy plot \n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# loss plot\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wafermap",
   "language": "python",
   "name": "wafermap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
