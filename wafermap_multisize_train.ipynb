{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提案手法の実験（ラベルが適切か出力）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## マルチサイズ\n",
    "- データオーギュメンテーション（鏡映，回転を追加）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import，入力データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/LSWMD.pkl\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU') memory growth: True\n",
      "PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU') memory growth: True\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU'), LogicalDevice(name='/device:GPU:1', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LSWMD.pkl']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import copy\n",
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "if len(physical_devices) > 0:\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "        print('{} memory growth: {}'.format(device, tf.config.experimental.get_memory_growth(device)))\n",
    "else:\n",
    "    print(\"Not enough GPU hardware devices available\")\n",
    "logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "print(logical_gpus)\n",
    "import keras\n",
    "from tensorflow.keras import layers, Input, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier \n",
    "import keras.backend.tensorflow_backend as tfback\n",
    "# from tf.keras.utils import multi_gpu_model\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datapath = join('data', 'wafer')\n",
    "print(os.listdir(\"../input\"))\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define\n",
    "max_size = 100\n",
    "encord_size = int(max_size / 2)\n",
    "\n",
    "NOTEBOOK_NAME = 'wafermap_multisize_train'\n",
    "cnn_path = './model/cnn_' + str(max_size) + '_' + NOTEBOOK_NAME + '.h5'\n",
    "\n",
    "epoch = 30\n",
    "batch_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faulty case list : ['Center', 'Donut', 'Edge-Loc', 'Edge-Ring', 'Loc', 'Near-full', 'Random', 'Scratch', 'none']\n"
     ]
    }
   ],
   "source": [
    "faulty_case = ['Center', 'Donut', 'Edge-Loc', 'Edge-Ring', 'Loc', 'Near-full', 'Random', 'Scratch', 'none']\n",
    "print('Faulty case list : {}'.format(faulty_case))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = joblib.load('./data/multi_' + str(max_size) + '/test/xtest.pickle')\n",
    "y_test = joblib.load('./data/multi_' + str(max_size) + '/test/ytest.pickle')\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 25)\n",
      "(27, 25)\n",
      "(27, 25)\n",
      "(27, 25)\n",
      "(43, 50)\n",
      "(40, 40)\n",
      "(42, 41)\n",
      "(31, 35)\n",
      "(27, 25)\n",
      "(27, 25)\n",
      "(44, 44)\n",
      "(27, 25)\n",
      "(40, 35)\n",
      "(46, 39)\n",
      "(26, 25)\n",
      "(40, 40)\n",
      "(27, 25)\n",
      "(27, 25)\n",
      "(27, 25)\n",
      "(31, 31)\n",
      "(27, 25)\n",
      "(27, 25)\n",
      "(27, 25)\n",
      "(27, 25)\n",
      "(36, 35)\n",
      "(27, 25)\n",
      "(37, 39)\n",
      "(27, 25)\n",
      "(27, 25)\n",
      "(50, 39)\n",
      "(43, 50)\n",
      "(27, 25)\n",
      "(34, 34)\n",
      "(27, 25)\n",
      "(27, 25)\n",
      "(40, 40)\n",
      "(25, 27)\n",
      "(27, 25)\n",
      "(37, 39)\n",
      "(27, 25)\n",
      "(27, 25)\n",
      "(26, 29)\n",
      "(27, 25)\n",
      "(33, 31)\n",
      "(59, 52)\n",
      "(61, 62)\n",
      "(27, 25)\n",
      "(34, 30)\n",
      "(26, 26)\n",
      "(59, 52)\n",
      "(71, 54)\n",
      "(42, 41)\n",
      "(31, 35)\n",
      "(44, 51)\n",
      "(42, 41)\n",
      "(42, 41)\n",
      "(42, 41)\n",
      "(37, 39)\n",
      "(42, 41)\n",
      "(42, 41)\n",
      "(31, 35)\n",
      "(41, 44)\n",
      "(41, 56)\n",
      "(31, 35)\n",
      "(55, 37)\n",
      "(58, 57)\n",
      "(42, 41)\n",
      "(42, 54)\n",
      "(31, 35)\n",
      "(50, 45)\n",
      "(31, 35)\n",
      "(42, 41)\n",
      "(42, 41)\n",
      "(37, 39)\n",
      "(55, 37)\n",
      "(71, 54)\n",
      "(42, 41)\n",
      "(30, 30)\n",
      "(42, 41)\n",
      "(71, 76)\n",
      "(42, 41)\n",
      "(42, 41)\n",
      "(58, 57)\n",
      "(42, 41)\n",
      "(42, 41)\n",
      "(50, 45)\n",
      "(42, 41)\n",
      "(25, 27)\n",
      "(42, 41)\n",
      "(41, 56)\n",
      "(40, 35)\n",
      "(58, 57)\n",
      "(42, 41)\n",
      "(44, 42)\n",
      "(31, 35)\n",
      "(44, 51)\n",
      "(42, 41)\n",
      "(71, 54)\n",
      "(42, 41)\n",
      "(59, 53)\n",
      "(37, 39)\n",
      "(33, 41)\n",
      "(37, 39)\n",
      "(50, 22)\n",
      "(39, 49)\n",
      "(39, 49)\n",
      "(94, 80)\n",
      "(72, 64)\n",
      "(31, 39)\n",
      "(61, 42)\n",
      "(80, 58)\n",
      "(27, 25)\n",
      "(29, 33)\n",
      "(34, 30)\n",
      "(59, 51)\n",
      "(41, 56)\n",
      "(34, 30)\n",
      "(30, 26)\n",
      "(59, 51)\n",
      "(33, 33)\n",
      "(27, 25)\n",
      "(26, 26)\n",
      "(26, 26)\n",
      "(27, 25)\n",
      "(44, 42)\n",
      "(27, 25)\n",
      "(31, 35)\n",
      "(33, 33)\n",
      "(31, 34)\n",
      "(25, 27)\n",
      "(73, 81)\n",
      "(34, 30)\n",
      "(31, 39)\n",
      "(31, 35)\n",
      "(26, 26)\n",
      "(34, 30)\n",
      "(34, 30)\n",
      "(33, 33)\n",
      "(43, 45)\n",
      "(34, 30)\n",
      "(34, 34)\n",
      "(31, 35)\n",
      "(44, 42)\n",
      "(38, 38)\n",
      "(41, 44)\n",
      "(41, 44)\n",
      "(25, 27)\n",
      "(27, 25)\n",
      "(40, 35)\n",
      "(37, 39)\n",
      "(52, 53)\n",
      "(59, 60)\n",
      "(37, 39)\n",
      "(46, 46)\n",
      "(36, 38)\n",
      "(46, 46)\n",
      "(73, 69)\n",
      "(41, 40)\n",
      "(62, 63)\n",
      "(34, 30)\n",
      "(42, 43)\n",
      "(25, 29)\n",
      "(48, 55)\n",
      "(36, 38)\n",
      "(32, 33)\n",
      "(36, 38)\n",
      "(62, 63)\n",
      "(62, 63)\n",
      "(62, 63)\n",
      "(78, 73)\n",
      "(42, 43)\n",
      "(73, 69)\n",
      "(62, 63)\n",
      "(42, 43)\n",
      "(73, 69)\n",
      "(29, 32)\n",
      "(48, 55)\n",
      "(150, 107)\n",
      "(52, 53)\n",
      "(62, 63)\n",
      "(36, 38)\n",
      "(52, 53)\n",
      "(36, 38)\n",
      "(41, 40)\n",
      "(40, 35)\n",
      "(52, 53)\n",
      "(36, 38)\n",
      "(36, 38)\n",
      "(52, 53)\n",
      "(52, 53)\n",
      "(36, 38)\n",
      "(59, 60)\n",
      "(150, 107)\n",
      "(46, 46)\n",
      "(36, 38)\n",
      "(30, 26)\n",
      "(150, 107)\n",
      "(33, 33)\n",
      "(45, 41)\n",
      "(150, 107)\n",
      "(40, 35)\n",
      "(25, 29)\n",
      "(43, 72)\n",
      "(143, 126)\n",
      "(172, 152)\n",
      "(59, 52)\n",
      "(41, 44)\n",
      "(40, 41)\n",
      "(31, 39)\n",
      "(27, 25)\n",
      "(31, 35)\n",
      "(30, 30)\n",
      "(31, 34)\n",
      "(26, 26)\n",
      "(34, 30)\n",
      "(37, 39)\n",
      "(44, 43)\n",
      "(31, 35)\n",
      "(40, 40)\n",
      "(25, 29)\n",
      "(31, 39)\n",
      "(26, 26)\n",
      "(44, 42)\n",
      "(31, 35)\n",
      "(32, 32)\n",
      "(31, 39)\n",
      "(31, 39)\n",
      "(27, 25)\n",
      "(32, 33)\n",
      "(33, 41)\n",
      "(172, 152)\n",
      "(31, 35)\n",
      "(29, 32)\n",
      "(27, 25)\n",
      "(25, 27)\n",
      "(30, 30)\n",
      "(112, 89)\n",
      "(33, 33)\n",
      "(40, 60)\n",
      "(37, 39)\n",
      "(59, 52)\n",
      "(30, 26)\n",
      "(35, 33)\n",
      "(31, 35)\n",
      "(34, 30)\n",
      "(28, 31)\n",
      "(44, 43)\n",
      "(26, 26)\n",
      "(48, 75)\n",
      "(31, 35)\n",
      "(75, 62)\n",
      "(29, 33)\n",
      "(48, 48)\n",
      "(46, 39)\n",
      "(43, 50)\n",
      "(34, 30)\n",
      "(27, 25)\n",
      "(27, 25)\n",
      "(27, 25)\n",
      "(30, 26)\n",
      "(25, 27)\n",
      "(25, 27)\n",
      "(27, 29)\n",
      "(29, 33)\n",
      "(31, 35)\n",
      "(33, 41)\n",
      "(29, 33)\n",
      "(29, 33)\n",
      "(38, 38)\n",
      "(26, 26)\n",
      "(27, 27)\n",
      "(40, 41)\n",
      "(37, 39)\n",
      "(27, 25)\n",
      "(25, 27)\n",
      "(26, 26)\n",
      "(37, 39)\n",
      "(29, 33)\n",
      "(36, 38)\n",
      "(37, 33)\n",
      "(29, 33)\n",
      "(27, 25)\n",
      "(29, 33)\n",
      "(29, 33)\n",
      "(36, 38)\n",
      "(27, 25)\n",
      "(24, 26)\n",
      "(27, 25)\n",
      "(25, 29)\n",
      "(27, 25)\n",
      "(26, 28)\n",
      "(27, 25)\n",
      "(42, 43)\n",
      "(37, 39)\n",
      "(37, 39)\n",
      "(29, 33)\n",
      "(29, 33)\n",
      "(38, 38)\n",
      "(38, 38)\n",
      "(29, 33)\n",
      "(41, 41)\n",
      "(29, 32)\n",
      "(41, 41)\n",
      "(26, 26)\n",
      "(29, 33)\n",
      "(40, 35)\n",
      "(31, 34)\n",
      "(41, 41)\n",
      "(41, 41)\n",
      "(26, 26)\n",
      "(31, 39)\n",
      "(33, 33)\n",
      "(26, 26)\n",
      "(41, 44)\n",
      "(27, 25)\n",
      "(150, 107)\n",
      "(26, 25)\n",
      "(41, 41)\n",
      "(42, 41)\n",
      "(26, 25)\n",
      "(26, 26)\n",
      "(31, 37)\n",
      "(150, 107)\n",
      "(43, 45)\n",
      "(27, 25)\n",
      "(34, 30)\n",
      "(35, 32)\n",
      "(41, 44)\n",
      "(41, 41)\n",
      "(36, 38)\n",
      "(28, 28)\n",
      "(26, 26)\n",
      "(31, 39)\n",
      "(27, 29)\n",
      "(51, 41)\n",
      "(35, 32)\n",
      "(28, 28)\n",
      "(51, 41)\n",
      "(26, 26)\n",
      "(38, 38)\n",
      "(40, 35)\n",
      "(60, 58)\n",
      "(41, 41)\n",
      "(50, 72)\n",
      "(31, 34)\n",
      "(35, 32)\n",
      "(51, 41)\n",
      "(37, 39)\n",
      "(34, 34)\n",
      "(26, 26)\n",
      "(31, 35)\n",
      "(45, 41)\n",
      "(26, 26)\n",
      "(26, 26)\n",
      "(27, 25)\n",
      "(33, 41)\n",
      "(43, 42)\n",
      "(59, 52)\n",
      "(43, 45)\n",
      "(42, 41)\n",
      "(39, 49)\n",
      "(30, 26)\n",
      "(30, 26)\n",
      "(45, 41)\n",
      "(59, 52)\n",
      "(27, 29)\n",
      "(37, 39)\n",
      "(31, 35)\n",
      "(81, 88)\n",
      "(71, 54)\n",
      "(41, 44)\n",
      "(37, 39)\n",
      "(33, 33)\n",
      "(81, 88)\n",
      "(38, 41)\n",
      "(34, 34)\n",
      "(37, 39)\n",
      "(41, 44)\n",
      "(25, 29)\n",
      "(33, 41)\n",
      "(25, 29)\n",
      "(59, 52)\n",
      "(25, 29)\n",
      "(97, 133)\n",
      "(44, 42)\n",
      "(38, 38)\n",
      "(43, 45)\n",
      "(38, 41)\n",
      "(26, 26)\n",
      "(44, 42)\n",
      "(35, 33)\n",
      "(42, 41)\n",
      "(38, 41)\n",
      "(37, 39)\n",
      "(44, 42)\n",
      "(25, 29)\n",
      "(81, 88)\n",
      "(25, 29)\n",
      "(37, 39)\n",
      "(36, 35)\n",
      "(27, 25)\n",
      "(34, 30)\n",
      "(33, 41)\n",
      "(27, 25)\n",
      "(29, 33)\n",
      "(27, 25)\n",
      "(27, 25)\n",
      "(27, 25)\n",
      "(26, 25)\n",
      "(29, 33)\n",
      "(37, 39)\n",
      "(41, 44)\n",
      "(44, 42)\n",
      "(25, 27)\n",
      "(26, 26)\n",
      "(41, 44)\n",
      "(31, 35)\n",
      "(27, 25)\n",
      "(41, 44)\n",
      "(25, 29)\n",
      "(25, 29)\n",
      "(25, 26)\n",
      "(24, 25)\n",
      "(31, 34)\n",
      "(37, 33)\n",
      "(26, 26)\n",
      "(43, 44)\n",
      "(29, 33)\n",
      "(25, 27)\n",
      "(27, 29)\n",
      "(25, 27)\n",
      "(64, 62)\n",
      "(27, 25)\n",
      "(37, 33)\n",
      "(25, 29)\n",
      "(25, 29)\n",
      "(35, 33)\n",
      "(40, 41)\n",
      "(30, 51)\n",
      "(25, 27)\n",
      "(27, 25)\n",
      "(34, 30)\n",
      "(34, 30)\n",
      "(27, 25)\n",
      "(45, 41)\n",
      "(40, 41)\n",
      "(89, 86)\n",
      "(34, 30)\n",
      "(30, 51)\n",
      "(42, 41)\n"
     ]
    }
   ],
   "source": [
    "for i in range(x_test.shape[0]):\n",
    "#     plt.imshow(np.argmax(x_test[i], axis=2))\n",
    "#     print(np.argmax(y_test[i], axis=0))\n",
    "    print((np.count_nonzero(np.argmax(x_test[i, encord_size, :], axis=1) != 0), np.count_nonzero(np.argmax(x_test[i, :, encord_size], axis=1) != 0)))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('./model/cnn_300_NOTEBOOK_NAME.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9985921e-01, 4.0826977e-22, 1.7165874e-05, 1.1839517e-04,\n",
       "        2.3216962e-09, 1.4945446e-30, 2.5877157e-15, 2.2802613e-18,\n",
       "        5.2422101e-06]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test[0].reshape(1, 300, 300, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各ウエハにラベル付け"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials = 2\n",
    "# label_list = []\n",
    "# for i in range(new_x.shape[0]):\n",
    "#     label_dict = {'wafer_id':str(i).zfill(6), 'true_label':y[i][0], 'predict_label':None, 'augmentation':{'noise':0, 'rotation':0, 'inversion':0}, 'trials':trials}\n",
    "#     label_list.append(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(label_list[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 不良ラベルが付いているデータに対してデータオーギュメンテーションを行う．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習を行う\n",
    "- 不良ラベルを0-8の9次元のベクトルとして表現する．\n",
    "- one-hotエンコーディングを行っている．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 保存/読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE_DATASET = False\n",
    "# ver = 'shawon' if shawon else 'propose'\n",
    "# if MAKE_DATASET:\n",
    "#     pickle_dump(new_x, './data/new_x_' + ver + '.pickle')\n",
    "#     pickle_dump(new_y, './data/new_y_' + ver + '.pickle')\n",
    "#     pickle_dump(label_list, './data/label_list_' + ver + '.pickle')\n",
    "    \n",
    "# if not MAKE_DATASET:\n",
    "#     new_x = pickle_load('./data/new_x_' + ver + '.pickle')\n",
    "#     new_y = pickle_load('./data/new_y_' + ver + '.pickle')\n",
    "#     label_list = pickle_load('./data/label_list_' + ver + '.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, l in enumerate(faulty_case):\n",
    "#     new_y[new_y==l] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(label_list)):\n",
    "#     label_list[i]['true_label'] = new_y[i][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの読み出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire the .npy name\n",
    "data_size = len(glob.glob('./data/multi_' + str(max_size) + '/train2/' + '*.npy'))\n",
    "TRAINS = ['./data/multi_' + str(max_size) + '/train2/' + str(i) + '.npy' for i in range(data_size)]\n",
    "# one-hot-encoding\n",
    "y = joblib.load('./data/multi_' + str(max_size) + '/train2/y.pickle')\n",
    "new_y = to_categorical(y)\n",
    "# split test\n",
    "\n",
    "# shuffle_indices = random.sample(list(range(len(TRAINS))), 10000)\n",
    "# TRAINS = [TRAINS[i] for i in shuffle_indices]\n",
    "# new_y = new_y[shuffle_indices]\n",
    "\n",
    "indices = np.array(range(len(TRAINS)))\n",
    "x_train, x_validation, y_train, y_validation, indices_train, indices_validation = train_test_split(\n",
    "    TRAINS, new_y, indices, test_size=0.01, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchを取得する関数\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "def load_array(file):\n",
    "    return np.load(file)\n",
    "\n",
    "def get_batch(batch_size): \n",
    "    global x_train, y_train\n",
    "    SIZE = len(x_train)\n",
    "    # n_batchs\n",
    "    n_batchs = SIZE//batch_size + 1\n",
    "    # for でyield\n",
    "    i = 0\n",
    "    start = time.time()\n",
    "    while (i < n_batchs):\n",
    "        print(\"doing\", i, \"/\", n_batchs)\n",
    "        Y_batch = y_train[(i * batch_size):((i + 1) * batch_size)]\n",
    "        \n",
    "        #あるbatchのfilenameの配列を持っておく\n",
    "        X_batch_name = x_train[(i * batch_size):((i + 1) * batch_size)]\n",
    "\n",
    "        # filenameにしたがってバッチのtensorを構築\n",
    "        with Pool() as p:\n",
    "            arr = p.map(load_array, X_batch_name)\n",
    "            \n",
    "        X_batch = np.array(arr).reshape(len(X_batch_name), max_size, max_size, 3)\n",
    "#         X_batch = np.array([np.load(file)\n",
    "#                             for file in X_batch_name]).reshape(len(X_batch_name), max_size, max_size, 3)\n",
    "        i += 1\n",
    "        print('elapsed time', time.time()-start)\n",
    "        yield X_batch, Y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testsize = 2000\n",
    "# # randlist = rand_ints_nodup(0, new_x.shape[0]-1, testsize)\n",
    "\n",
    "# # valx = new_x.copy()[randlist, :, :, :]\n",
    "# # valy = y.copy()[randlist, :]\n",
    "\n",
    "# test_size = 705 #705\n",
    "# new_x_size = new_x.shape[0]\n",
    "# testlist = rand_ints_nodup(0, new_x_size-1, test_size)\n",
    "# trainlist = [i for i in range(new_x_size) if i != testlist]\n",
    "# new_X=new_x[trainlist]\n",
    "# new_Y=new_y[trainlist]\n",
    "# test_x=new_x[testlist]\n",
    "# test_y=new_y[testlist]\n",
    "\n",
    "# label_train = copy.deepcopy([label_list[i] for i in trainlist])\n",
    "# label_test = copy.deepcopy([label_list[i] for i in testlist])\n",
    "\n",
    "# test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_X=new_x\n",
    "# new_Y=new_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 学習データとテストデータに分割する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = np.array(range(new_X.shape[0]))\n",
    "\n",
    "# x_train, x_test, y_train, y_test, indices_train, indices_test = train_test_split(new_X, new_Y, indices,\n",
    "#                                                                 test_size=0.33,\n",
    "#                                                                 random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_vali = copy.deepcopy([label_train[i] for i in indices_test.tolist()])\n",
    "# label_train = copy.deepcopy([label_train[i] for i in indices_train.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train x : 299975, y : (299975, 9)\n",
      "Validation x: 3031, y : (3031, 9)\n"
     ]
    }
   ],
   "source": [
    "print('Train x : {}, y : {}'.format(len(x_train), y_train.shape))\n",
    "print('Validation x: {}, y : {}'.format(len(x_validation), y_validation.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading X_validation...\n"
     ]
    }
   ],
   "source": [
    "print(\"loading X_validation...\")\n",
    "with Pool() as p:\n",
    "    arr = p.map(load_array, x_validation)\n",
    "\n",
    "x_validation = np.array(arr).reshape(len(x_validation), max_size, max_size, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 学習データ246635枚，テストデータ121477枚．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- モデルの定義を行う．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    with tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\", \"/gpu:2\", \"/gpu:3\"], \n",
    "                                        cross_device_ops = tf.distribute.HierarchicalCopyAllReduce()).scope():\n",
    "        input_shape = (max_size, max_size, 3)\n",
    "        input_tensor = Input(input_shape)\n",
    "\n",
    "        conv_1 = layers.Conv2D(8, (3,3), activation='relu', padding='same')(input_tensor)\n",
    "        conv_2 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(conv_1)\n",
    "        conv_3 = layers.Conv2D(32, (3,3), activation='relu', padding='same')(conv_2)\n",
    "\n",
    "        flat = layers.Flatten()(conv_3)\n",
    "\n",
    "        dense_1 = layers.Dense(64, activation='relu')(flat)\n",
    "        dense_2 = layers.Dense(32, activation='relu')(dense_1)\n",
    "        output_tensor = layers.Dense(9, activation='softmax')(dense_2)\n",
    "\n",
    "        model = models.Model(input_tensor, output_tensor)\n",
    "        model.compile(optimizer='Adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3-Fold Cross validationで分割して学習する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = KerasClassifier(build_fn=create_model, epochs=30, batch_size=1024, verbose=1) \n",
    "# # 3-Fold Crossvalidation\n",
    "# kfold = KFold(n_splits=3, shuffle=True, random_state=2019) \n",
    "# # results = cross_val_score(model, x_train, y_train, cv=kfold)\n",
    "# # # Check 3-fold model's mean accuracy\n",
    "# # print('Simple CNN Cross validation score : {:.4f}'.format(np.mean(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cross validiationによる精度は99.55%であった．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cross validationなしで学習する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:XLA_GPU:0')\n",
      "Number of devices: 3\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\", \"device:XLA_GPU:0\"], cross_device_ops = tf.distribute.HierarchicalCopyAllReduce())\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=10\n",
    "batch_size=1024\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "==================================================\n",
      "0 / 10\n",
      "doing 0 / 293\n",
      "elapsed time 0.3655831813812256\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:0').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:0').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:0').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:0').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:0').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:0').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:0').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:0').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:0').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:0').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.7769 - accuracy: 0.1299\n",
      "batch loss: 5.77688455581665\n",
      "batch accuracy: 0.1298828125\n",
      "doing 1 / 293\n",
      "elapsed time 37.55572462081909\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.3493 - accuracy: 0.2266\n",
      "batch loss: 3.349308967590332\n",
      "batch accuracy: 0.2265625\n",
      "doing 2 / 293\n",
      "elapsed time 59.11628699302673\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.9526 - accuracy: 0.2158\n",
      "batch loss: 2.9525904655456543\n",
      "batch accuracy: 0.2158203125\n",
      "doing 3 / 293\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-47879b379cdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# batch_size=1000でHDDからバッチを取得する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ffff8e47e6ca>\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(batch_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# filenameにしたがってバッチのtensorを構築\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_batch_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "epoch_train_loss = []\n",
    "epoch_train_acc = []\n",
    "epoch_validation_loss = []\n",
    "epoch_validation_acc = []\n",
    "for ep in range(epoch):\n",
    "    print(\"=\" * 50)\n",
    "    print(ep, \"/\", epoch)\n",
    "    step_loss = []\n",
    "    step_acc = []\n",
    "    \n",
    "    # batch_size=1000でHDDからバッチを取得する\n",
    "    for X_batch, Y_batch in get_batch(batch_size):\n",
    "        model.train_on_batch(X_batch, Y_batch)\n",
    "        score = model.evaluate(X_batch, Y_batch)\n",
    "        print(\"batch loss:\", score[0])\n",
    "        print(\"batch accuracy:\", score[1])\n",
    "        step_loss.append(score[0])\n",
    "        step_acc.append(score[1])\n",
    "    print(\"Train loss\", np.mean(step_loss))\n",
    "    print(\"Train accuracy\", np.mean(step_acc))\n",
    "    score = model.evaluate(x_validation, y_validation)\n",
    "    print(\"Validation loss:\", score[0])\n",
    "    print(\"Validation accuracy:\", score[1])\n",
    "    epoch_train_loss.append(np.mean(step_loss))\n",
    "    epoch_train_acc.append(np.mean(step_acc))\n",
    "    epoch_validation_loss.append(score[0])\n",
    "    epoch_validation_acc.append(score[1])\n",
    "    \n",
    "    shuffle_indices = random.sample(list(range(len(x_train))), len(x_train))\n",
    "    x_train = [x_train[i] for i in shuffle_indices]\n",
    "    y_train = y_train[shuffle_indices]\n",
    "    \n",
    "    model.save(cnn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n",
    "print(\" ------------------------------------ \")\n",
    "for var_name in dir():\n",
    "    if not var_name.startswith(\"_\"):\n",
    "        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストデータで評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = joblib.load('./data/multi_' + str(max_size) + '/test/xtest.pickle')\n",
    "y_test = joblib.load('./data/multi_' + str(max_size) + '/test/ytest.pickle')\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "# score = model.evaluate(x_validation, y_validation)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "testscore = score[1]\n",
    "trainscore = epoch_train_acc[-1]\n",
    "valiscore = epoch_validation_acc[-1]\n",
    "print(\"Train accuracy:\", trainscore)\n",
    "print(\"Validation accuracy:\", valiscore)\n",
    "print(\"Test accuracy:\", testscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = np.argmax(model.predict(x_test), axis=1)\n",
    "y_test_max = np.argmax(y_test, axis=1)\n",
    "np.sum(y_test_max == y_predict, axis=0, dtype='float') / x_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- モデルは以下．\n",
    "    - 入力層\n",
    "    - 畳み込み層3つ\n",
    "    - Flatten層（1次元に）\n",
    "    - 全結合層3つ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- accuracyグラフ，lossグラフは以下．\n",
    "- 5epoch程度で落ち着いている．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy plot\n",
    "fig1 = plt.figure()\n",
    "plt.plot(epoch_train_acc)\n",
    "plt.plot(epoch_validation_acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "fig1.savefig(\"multisize_accuracy.png\")\n",
    "\n",
    "# loss plot\n",
    "fig2 = plt.figure()\n",
    "plt.plot(epoch_train_loss)\n",
    "plt.plot(epoch_validation_loss)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "fig2.savefig(\"multisize_loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    fmt = '.4f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.xticks([0, 1, 2, 3, 4, 5, 6, 7 ,8], [\"Center\", \"Donut\", \"Edge-Loc\", \"Edge-Ring\", \"Loc\", \"Near-full\", \"Random\", \"Scratch\", \"None\"])\n",
    "    plt.yticks([0, 1, 2, 3, 4, 5, 6, 7 ,8], [\"Center\", \"Donut\", \"Edge-Loc\", \"Edge-Ring\", \"Loc\", \"Near-full\", \"Random\", \"Scratch\", \"None\"])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- validation confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "y_validation_predict = np.argmax(model.predict(x_validation), axis=1)\n",
    "y_validation_max = np.argmax(y_validation, axis=1)\n",
    "cnf_matrix = confusion_matrix(y_validation_max, y_validation_predict)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "from matplotlib import gridspec\n",
    "fig = plt.figure(figsize=(8, 15)) \n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 1]) \n",
    "\n",
    "## Plot non-normalized confusion matrix\n",
    "plt.subplot(gs[0])\n",
    "plot_confusion_matrix(cnf_matrix, title='Confusion matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.subplot(gs[1])\n",
    "plot_confusion_matrix(cnf_matrix, normalize=True, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"multisize_valiconfmat.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "y_test_predict = np.argmax(model.predict(x_test), axis=1)\n",
    "y_test_max = np.argmax(y_test, axis=1)\n",
    "cnf_matrix = confusion_matrix(y_test_max, y_test_predict)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "from matplotlib import gridspec\n",
    "fig = plt.figure(figsize=(8, 15)) \n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 1]) \n",
    "\n",
    "## Plot non-normalized confusion matrix\n",
    "plt.subplot(gs[0])\n",
    "plot_confusion_matrix(cnf_matrix, title='Confusion matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.subplot(gs[1])\n",
    "plot_confusion_matrix(cnf_matrix, normalize=True, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"multisize_testconfmat.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# LINEの設定\n",
    "path = './lineapi.txt'\n",
    "with open(path) as f:\n",
    "    s = f.read()\n",
    "    line_token = s.rstrip('\\n')\n",
    "\n",
    "# LINEに通知する関数\n",
    "def line_notify(text):\n",
    "    url = \"https://notify-api.line.me/api/notify\"\n",
    "    data = {\"message\": text}\n",
    "    headers = {\"Authorization\": \"Bearer \" + line_token}\n",
    "    proxies = {\n",
    "        'http': 'http://proxy.uec.ac.jp:8080',\n",
    "        'https': 'https://proxy.uec.ac.jp:8080',\n",
    "    }\n",
    "    requests.post(url, headers=headers)#, proxies=proxies)\n",
    "\n",
    "# LINEに画像を送る関数\n",
    "def line_notify_img(text, imgpath):\n",
    "    url = \"https://notify-api.line.me/api/notify\"\n",
    "    data = {\"message\": text, \"notificationDisabled\": True}\n",
    "    files = {\"imageFile\": open(imgpath, \"rb\")}\n",
    "    headers = {\"Authorization\": \"Bearer \" + line_token}\n",
    "    proxies = {\n",
    "        'http': 'http://proxy.uec.ac.jp:8080',\n",
    "        'https': 'https://proxy.uec.ac.jp:8080',\n",
    "    }\n",
    "    requests.post(url, data=data, files=files, headers=headers)#, proxies=proxies)\n",
    "    \n",
    "line_notify(\"学習が終了しました \")\n",
    "# line_notify(\"Shawon: \" + str(shawon) + \", rotation_num: \" + str(rotation_num) + \", inversion: \" + str(inversion) + \", trials: \" + str(trials))\n",
    "line_notify_img(\"正解率\", \"multisize_accuracy.png\")\n",
    "line_notify_img(\"Loss\", \"multisize_loss.png\")\n",
    "line_notify_img(\"validation混同行列\", \"multisize_valiconfmat.png\")\n",
    "line_notify_img(\"test混同行列\", \"multisize_testconfmat.png\")\n",
    "line_notify(\"train:\" + str(trainscore) + \"\\nvali:\" + str(valiscore) + \"\\ntest:\" + str(testscore))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wafermap",
   "language": "python",
   "name": "wafermap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
