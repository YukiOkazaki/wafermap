{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提案手法の実験（ラベルが適切か出力）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## マルチサイズ\n",
    "- データオーギュメンテーション（鏡映，回転を追加）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import，入力データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/LSWMD.pkl\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# AIX環境での proxy の設定．\n",
    "# keras.datasetsでは，datasetを直接ダウンロードするので，学内マシンからは通常必要．\n",
    "os.environ[\"http_proxy\"] = \"http://proxy.uec.ac.jp:8080/\"\n",
    "os.environ[\"https_proxy\"] = \"https://proxy.uec.ac.jp:8080/\"\n",
    "for dirname, _, filenames in os.walk('../input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU') memory growth: True\n",
      "PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU') memory growth: True\n",
      "PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU') memory growth: True\n",
      "PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU') memory growth: True\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU'), LogicalDevice(name='/device:GPU:1', device_type='GPU'), LogicalDevice(name='/device:GPU:2', device_type='GPU'), LogicalDevice(name='/device:GPU:3', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LSWMD.pkl']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import copy\n",
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "if len(physical_devices) > 0:\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "        print('{} memory growth: {}'.format(device, tf.config.experimental.get_memory_growth(device)))\n",
    "else:\n",
    "    print(\"Not enough GPU hardware devices available\")\n",
    "logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "print(logical_gpus)\n",
    "import keras\n",
    "from tensorflow.keras import layers, Input, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier \n",
    "import keras.backend.tensorflow_backend as tfback\n",
    "# from tf.keras.utils import multi_gpu_model\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datapath = join('data', 'wafer')\n",
    "print(os.listdir(\"../input\"))\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define\n",
    "max_size = 100\n",
    "encord_size = int(max_size / 2)\n",
    "\n",
    "NOTEBOOK_NAME = 'wafermap_multisize_train_validation_rotation_vgg'\n",
    "cnn_path = './model/cnn_' + str(max_size) + '_' + NOTEBOOK_NAME + '.h5'\n",
    "\n",
    "epoch = 30\n",
    "batch_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faulty case list : ['Center', 'Donut', 'Edge-Loc', 'Edge-Ring', 'Loc', 'Near-full', 'Random', 'Scratch', 'none']\n"
     ]
    }
   ],
   "source": [
    "faulty_case = ['Center', 'Donut', 'Edge-Loc', 'Edge-Ring', 'Loc', 'Near-full', 'Random', 'Scratch', 'none']\n",
    "print('Faulty case list : {}'.format(faulty_case))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習を行う\n",
    "- 不良ラベルを0-8の9次元のベクトルとして表現する．\n",
    "- one-hotエンコーディングを行っている．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの読み出し"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire the .npy name\n",
    "data_size = len(glob.glob('./data/multi_' + str(max_size) + '/train_rotation/' + '*.npy'))\n",
    "TRAINS = ['./data/multi_' + str(max_size) + '/train_rotation/' + str(i) + '.npy' for i in range(data_size)]\n",
    "# one-hot-encoding\n",
    "y = joblib.load('./data/multi_' + str(max_size) + '/train_rotation/y.pickle')\n",
    "new_y = to_categorical(y)\n",
    "# split test\n",
    "\n",
    "# shuffle_indices = random.sample(list(range(len(TRAINS))), 10000)\n",
    "# TRAINS = [TRAINS[i] for i in shuffle_indices]\n",
    "# new_y = new_y[shuffle_indices]\n",
    "\n",
    "x_train = TRAINS\n",
    "y_train = new_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- validaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire the .npy name\n",
    "data_size = len(glob.glob('./data/multi_' + str(max_size) + '/validation_rotation/' + '*.npy'))\n",
    "VALIDATIONS = ['./data/multi_' + str(max_size) + '/validation_rotation/' + str(i) + '.npy' for i in range(data_size)]\n",
    "# one-hot-encoding\n",
    "y = joblib.load('./data/multi_' + str(max_size) + '/validation_rotation/y.pickle')\n",
    "new_y = to_categorical(y)\n",
    "# split test\n",
    "\n",
    "# shuffle_indices = random.sample(list(range(len(TRAINS))), 10000)\n",
    "# TRAINS = [TRAINS[i] for i in shuffle_indices]\n",
    "# new_y = new_y[shuffle_indices]\n",
    "\n",
    "x_validation = VALIDATIONS\n",
    "y_validation = new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchを取得する関数\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "def load_array(file):\n",
    "    return np.load(file)\n",
    "\n",
    "def get_batch(batch_size): \n",
    "    global x_train, y_train\n",
    "    SIZE = len(x_train)\n",
    "    # n_batchs\n",
    "    n_batchs = SIZE//batch_size + 1\n",
    "    # for でyield\n",
    "    i = 0\n",
    "    start = time.time()\n",
    "    while (i < n_batchs):\n",
    "        print(\"doing\", i, \"/\", n_batchs)\n",
    "        Y_batch = y_train[(i * batch_size):((i + 1) * batch_size)]\n",
    "        \n",
    "        #あるbatchのfilenameの配列を持っておく\n",
    "        X_batch_name = x_train[(i * batch_size):((i + 1) * batch_size)]\n",
    "\n",
    "        # filenameにしたがってバッチのtensorを構築\n",
    "        with Pool() as p:\n",
    "            arr = p.map(load_array, X_batch_name)\n",
    "            \n",
    "        X_batch = np.array(arr).reshape(len(X_batch_name), max_size, max_size, 3)\n",
    "#         X_batch = np.array([np.load(file)\n",
    "#                             for file in X_batch_name]).reshape(len(X_batch_name), max_size, max_size, 3)\n",
    "        i += 1\n",
    "        print('elapsed time', time.time()-start)\n",
    "        yield X_batch, Y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 学習データとテストデータに分割する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train x : 283171, y : (283171, 9)\n",
      "Validation x: 4500, y : (4500, 9)\n"
     ]
    }
   ],
   "source": [
    "print('Train x : {}, y : {}'.format(len(x_train), y_train.shape))\n",
    "print('Validation x: {}, y : {}'.format(len(x_validation), y_validation.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading X_validation...\n"
     ]
    }
   ],
   "source": [
    "print(\"loading X_validation...\")\n",
    "with Pool() as p:\n",
    "    arr = p.map(load_array, x_validation)\n",
    "\n",
    "x_validation = np.array(arr).reshape(len(x_validation), max_size, max_size, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 学習データ246635枚，テストデータ121477枚．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- モデルの定義を行う．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "#     with tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"], \n",
    "    with tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\", \"/gpu:2\", \"/gpu:3\"], \n",
    "                                        cross_device_ops = tf.distribute.HierarchicalCopyAllReduce()).scope():\n",
    "        input_shape = (max_size, max_size, 3)\n",
    "        input_tensor = Input(input_shape)\n",
    "\n",
    "        conv_1 = layers.Conv2D(8, (3,3), activation='relu', padding='same')(input_tensor)\n",
    "        conv_2 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(conv_1)\n",
    "        conv_3 = layers.Conv2D(32, (3,3), activation='relu', padding='same')(conv_2)\n",
    "\n",
    "        flat = layers.Flatten()(conv_3)\n",
    "\n",
    "        dense_1 = layers.Dense(64, activation='relu')(flat)\n",
    "        dense_2 = layers.Dense(32, activation='relu')(dense_1)\n",
    "        output_tensor = layers.Dense(9, activation='softmax')(dense_2)\n",
    "\n",
    "        model = models.Model(input_tensor, output_tensor)\n",
    "        model.compile(optimizer='Adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_model():\n",
    "#     with tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"], \n",
    "    with tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\", \"/gpu:2\", \"/gpu:3\"], \n",
    "                                        cross_device_ops = tf.distribute.HierarchicalCopyAllReduce()).scope():\n",
    "        \n",
    "        vgg = tf.keras.applications.vgg16.VGG16(\n",
    "            include_top=False, input_shape=(max_size, max_size, 3)\n",
    "        )\n",
    "        flat = layers.Flatten()(vgg.output)\n",
    "        dense_1 = layers.Dense(64, activation='relu')(flat)\n",
    "        dense_2 = layers.Dense(32, activation='relu')(dense_1)\n",
    "        x = layers.Dense(9, activation='softmax')(dense_2)\n",
    "        \n",
    "#         vgg.trainable = False\n",
    "\n",
    "        model = models.Model(vgg.input, x)\n",
    "        model.compile(optimizer='Adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100, 100, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 100, 100, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 100, 100, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 297       \n",
      "=================================================================\n",
      "Total params: 15,012,041\n",
      "Trainable params: 15,012,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = vgg_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cross validationなしで学習する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=10\n",
    "batch_size=1024\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "==================================================\n",
      "0 / 10\n",
      "doing 0 / 277\n",
      "elapsed time 85.57401371002197\n",
      "INFO:tensorflow:batch_all_reduce: 32 all-reduces with algorithm = hierarchical_copy, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 32 all-reduces with algorithm = hierarchical_copy, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.2218 - accuracy: 0.3623\n",
      "batch loss: 2.221791982650757\n",
      "batch accuracy: 0.3623046875\n",
      "doing 1 / 277\n",
      "elapsed time 178.96399974822998\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0489 - accuracy: 0.2422\n",
      "batch loss: 2.048910140991211\n",
      "batch accuracy: 0.2421875\n",
      "doing 2 / 277\n",
      "elapsed time 267.6527030467987\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 4.2619 - accuracy: 0.4463\n",
      "batch loss: 4.261909484863281\n",
      "batch accuracy: 0.4462890625\n",
      "doing 3 / 277\n",
      "elapsed time 354.3218400478363\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1711 - accuracy: 0.2207\n",
      "batch loss: 2.1710853576660156\n",
      "batch accuracy: 0.220703125\n",
      "doing 4 / 277\n",
      "elapsed time 444.5039520263672\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1786 - accuracy: 0.2471\n",
      "batch loss: 2.1786088943481445\n",
      "batch accuracy: 0.2470703125\n",
      "doing 5 / 277\n",
      "elapsed time 532.8752062320709\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1471 - accuracy: 0.3350\n",
      "batch loss: 2.1471290588378906\n",
      "batch accuracy: 0.3349609375\n",
      "doing 6 / 277\n",
      "elapsed time 622.0250871181488\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2383 - accuracy: 0.3643\n",
      "batch loss: 2.2383370399475098\n",
      "batch accuracy: 0.3642578125\n",
      "doing 7 / 277\n",
      "elapsed time 711.8624377250671\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2090 - accuracy: 0.0000e+00\n",
      "batch loss: 2.2090165615081787\n",
      "batch accuracy: 0.0\n",
      "doing 8 / 277\n",
      "elapsed time 801.7302634716034\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7777 - accuracy: 0.9062\n",
      "batch loss: 1.7777070999145508\n",
      "batch accuracy: 0.90625\n",
      "doing 9 / 277\n",
      "elapsed time 890.6828720569611\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.1461 - accuracy: 1.0000\n",
      "batch loss: 1.1461399793624878\n",
      "batch accuracy: 1.0\n",
      "doing 10 / 277\n",
      "elapsed time 953.5377788543701\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3674 - accuracy: 0.9727\n",
      "batch loss: 0.36738908290863037\n",
      "batch accuracy: 0.97265625\n",
      "doing 11 / 277\n",
      "elapsed time 1032.7556173801422\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5907 - accuracy: 0.9795\n",
      "batch loss: 0.5906948447227478\n",
      "batch accuracy: 0.9794921875\n",
      "doing 12 / 277\n",
      "elapsed time 1124.3319489955902\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6236 - accuracy: 0.9727\n",
      "batch loss: 0.623627781867981\n",
      "batch accuracy: 0.97265625\n",
      "doing 13 / 277\n",
      "elapsed time 1215.8346421718597\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5640 - accuracy: 0.9316\n",
      "batch loss: 0.5639632940292358\n",
      "batch accuracy: 0.931640625\n",
      "doing 14 / 277\n",
      "elapsed time 1304.7597250938416\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5200 - accuracy: 0.9590\n",
      "batch loss: 0.5200159549713135\n",
      "batch accuracy: 0.958984375\n",
      "doing 15 / 277\n",
      "elapsed time 1396.2222876548767\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1315 - accuracy: 0.9795\n",
      "batch loss: 0.13152939081192017\n",
      "batch accuracy: 0.9794921875\n",
      "doing 16 / 277\n",
      "elapsed time 1481.5698399543762\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0623 - accuracy: 0.9932\n",
      "batch loss: 0.06225145608186722\n",
      "batch accuracy: 0.9931640625\n",
      "doing 17 / 277\n",
      "elapsed time 1570.1125621795654\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3642 - accuracy: 0.9590\n",
      "batch loss: 0.3641650974750519\n",
      "batch accuracy: 0.958984375\n",
      "doing 18 / 277\n",
      "elapsed time 1663.458331823349\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6622 - accuracy: 0.9023\n",
      "batch loss: 0.6622127890586853\n",
      "batch accuracy: 0.90234375\n",
      "doing 19 / 277\n",
      "elapsed time 1753.4810252189636\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1866 - accuracy: 1.0000\n",
      "batch loss: 0.18656668066978455\n",
      "batch accuracy: 1.0\n",
      "doing 20 / 277\n",
      "elapsed time 1843.03142786026\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.2816 - accuracy: 0.6602\n",
      "batch loss: 1.2816462516784668\n",
      "batch accuracy: 0.66015625\n",
      "doing 21 / 277\n",
      "elapsed time 1933.663941860199\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.1553 - accuracy: 0.0068\n",
      "batch loss: 2.155324697494507\n",
      "batch accuracy: 0.0068359375\n",
      "doing 22 / 277\n",
      "elapsed time 2019.7289354801178\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8137 - accuracy: 0.0547\n",
      "batch loss: 1.813704490661621\n",
      "batch accuracy: 0.0546875\n",
      "doing 23 / 277\n",
      "elapsed time 2108.148721933365\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5961 - accuracy: 0.0361\n",
      "batch loss: 1.5960819721221924\n",
      "batch accuracy: 0.0361328125\n",
      "doing 24 / 277\n",
      "elapsed time 2199.156314134598\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6935 - accuracy: 0.5205\n",
      "batch loss: 1.693537712097168\n",
      "batch accuracy: 0.5205078125\n",
      "doing 25 / 277\n",
      "elapsed time 2290.878450155258\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6865 - accuracy: 0.3848\n",
      "batch loss: 1.6864819526672363\n",
      "batch accuracy: 0.384765625\n",
      "doing 26 / 277\n",
      "elapsed time 2376.5733802318573\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6271 - accuracy: 0.3848\n",
      "batch loss: 1.6271116733551025\n",
      "batch accuracy: 0.384765625\n",
      "doing 27 / 277\n",
      "elapsed time 2466.537444829941\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.7195 - accuracy: 0.3057\n",
      "batch loss: 1.7195327281951904\n",
      "batch accuracy: 0.3056640625\n",
      "doing 28 / 277\n",
      "elapsed time 2555.809731721878\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0386 - accuracy: 0.4248\n",
      "batch loss: 2.0385639667510986\n",
      "batch accuracy: 0.4248046875\n",
      "doing 29 / 277\n",
      "elapsed time 2644.3732578754425\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7556 - accuracy: 0.5117\n",
      "batch loss: 1.755647897720337\n",
      "batch accuracy: 0.51171875\n",
      "doing 30 / 277\n",
      "elapsed time 2736.553061723709\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9040 - accuracy: 0.4307\n",
      "batch loss: 1.9039840698242188\n",
      "batch accuracy: 0.4306640625\n",
      "doing 31 / 277\n",
      "elapsed time 2827.971422433853\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.0749 - accuracy: 0.1729\n",
      "batch loss: 2.074920177459717\n",
      "batch accuracy: 0.1728515625\n",
      "doing 32 / 277\n",
      "elapsed time 2916.0233290195465\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9257 - accuracy: 0.4346\n",
      "batch loss: 1.9256985187530518\n",
      "batch accuracy: 0.4345703125\n",
      "doing 33 / 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 3005.061782360077\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2017 - accuracy: 0.0000e+00\n",
      "batch loss: 2.201693058013916\n",
      "batch accuracy: 0.0\n",
      "doing 34 / 277\n",
      "elapsed time 3091.5307977199554\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.8332 - accuracy: 0.3848\n",
      "batch loss: 1.833184838294983\n",
      "batch accuracy: 0.384765625\n",
      "doing 35 / 277\n",
      "elapsed time 3181.9362485408783\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7843 - accuracy: 0.3848\n",
      "batch loss: 1.7843455076217651\n",
      "batch accuracy: 0.384765625\n",
      "doing 36 / 277\n",
      "elapsed time 3249.7999868392944\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8814 - accuracy: 0.3848\n",
      "batch loss: 1.8814334869384766\n",
      "batch accuracy: 0.384765625\n",
      "doing 37 / 277\n",
      "elapsed time 3316.0507497787476\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.6954 - accuracy: 0.3848\n",
      "batch loss: 1.695387840270996\n",
      "batch accuracy: 0.384765625\n",
      "doing 38 / 277\n",
      "elapsed time 3384.015406370163\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1282 - accuracy: 0.3799\n",
      "batch loss: 2.1282384395599365\n",
      "batch accuracy: 0.3798828125\n",
      "doing 39 / 277\n",
      "elapsed time 3448.3095462322235\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1500 - accuracy: 0.2041\n",
      "batch loss: 2.149974822998047\n",
      "batch accuracy: 0.2041015625\n",
      "doing 40 / 277\n",
      "elapsed time 3519.2841062545776\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2136 - accuracy: 0.0000e+00\n",
      "batch loss: 2.2135636806488037\n",
      "batch accuracy: 0.0\n",
      "doing 41 / 277\n",
      "elapsed time 3588.3067576885223\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1957 - accuracy: 0.0000e+00\n",
      "batch loss: 2.1956779956817627\n",
      "batch accuracy: 0.0\n",
      "doing 42 / 277\n",
      "elapsed time 3654.347538471222\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1431 - accuracy: 0.2783\n",
      "batch loss: 2.143092393875122\n",
      "batch accuracy: 0.2783203125\n",
      "doing 43 / 277\n",
      "elapsed time 3721.232314348221\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1912 - accuracy: 0.1064\n",
      "batch loss: 2.191209316253662\n",
      "batch accuracy: 0.1064453125\n",
      "doing 44 / 277\n",
      "elapsed time 3788.834408521652\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.8815 - accuracy: 0.3848\n",
      "batch loss: 1.881476640701294\n",
      "batch accuracy: 0.384765625\n",
      "doing 45 / 277\n",
      "elapsed time 3859.1831080913544\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2596 - accuracy: 0.0000e+00\n",
      "batch loss: 2.2595582008361816\n",
      "batch accuracy: 0.0\n",
      "doing 46 / 277\n",
      "elapsed time 3927.175210237503\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0189 - accuracy: 0.2451\n",
      "batch loss: 2.018925189971924\n",
      "batch accuracy: 0.2451171875\n",
      "doing 47 / 277\n",
      "elapsed time 3993.9850702285767\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1329 - accuracy: 0.1582\n",
      "batch loss: 2.1328587532043457\n",
      "batch accuracy: 0.158203125\n",
      "doing 48 / 277\n",
      "elapsed time 4061.8873257637024\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1338 - accuracy: 0.0479\n",
      "batch loss: 2.133780002593994\n",
      "batch accuracy: 0.0478515625\n",
      "doing 49 / 277\n",
      "elapsed time 4129.741007804871\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2296 - accuracy: 0.1201\n",
      "batch loss: 2.229590892791748\n",
      "batch accuracy: 0.1201171875\n",
      "doing 50 / 277\n",
      "elapsed time 4198.727480649948\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.0041 - accuracy: 0.4492\n",
      "batch loss: 2.004061222076416\n",
      "batch accuracy: 0.44921875\n",
      "doing 51 / 277\n",
      "elapsed time 4266.753804445267\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8373 - accuracy: 0.2393\n",
      "batch loss: 1.8372886180877686\n",
      "batch accuracy: 0.2392578125\n",
      "doing 52 / 277\n",
      "elapsed time 4337.360447645187\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8813 - accuracy: 0.1455\n",
      "batch loss: 1.8812955617904663\n",
      "batch accuracy: 0.1455078125\n",
      "doing 53 / 277\n",
      "elapsed time 4405.687832355499\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.6540 - accuracy: 0.6738\n",
      "batch loss: 1.6540387868881226\n",
      "batch accuracy: 0.673828125\n",
      "doing 54 / 277\n",
      "elapsed time 4472.628710985184\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5041 - accuracy: 0.7539\n",
      "batch loss: 1.5041342973709106\n",
      "batch accuracy: 0.75390625\n",
      "doing 55 / 277\n",
      "elapsed time 4541.662406206131\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5744 - accuracy: 0.6621\n",
      "batch loss: 0.5743977427482605\n",
      "batch accuracy: 0.662109375\n",
      "doing 56 / 277\n",
      "elapsed time 4611.783237218857\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.3580 - accuracy: 0.3848\n",
      "batch loss: 1.3579862117767334\n",
      "batch accuracy: 0.384765625\n",
      "doing 57 / 277\n",
      "elapsed time 4680.178718805313\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0507 - accuracy: 0.1484\n",
      "batch loss: 2.050727605819702\n",
      "batch accuracy: 0.1484375\n",
      "doing 58 / 277\n",
      "elapsed time 4748.500062704086\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5871 - accuracy: 0.4805\n",
      "batch loss: 1.5871317386627197\n",
      "batch accuracy: 0.48046875\n",
      "doing 59 / 277\n",
      "elapsed time 4817.841627836227\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0615 - accuracy: 0.2393\n",
      "batch loss: 2.061462640762329\n",
      "batch accuracy: 0.2392578125\n",
      "doing 60 / 277\n",
      "elapsed time 4887.549230098724\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0979 - accuracy: 0.3369\n",
      "batch loss: 2.0978598594665527\n",
      "batch accuracy: 0.3369140625\n",
      "doing 61 / 277\n",
      "elapsed time 4954.088958024979\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.0099 - accuracy: 0.3330\n",
      "batch loss: 2.009901285171509\n",
      "batch accuracy: 0.3330078125\n",
      "doing 62 / 277\n",
      "elapsed time 5022.252164840698\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1130 - accuracy: 0.3115\n",
      "batch loss: 2.113022804260254\n",
      "batch accuracy: 0.3115234375\n",
      "doing 63 / 277\n",
      "elapsed time 5089.607176065445\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8313 - accuracy: 0.4463\n",
      "batch loss: 1.831311821937561\n",
      "batch accuracy: 0.4462890625\n",
      "doing 64 / 277\n",
      "elapsed time 5156.612122535706\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.5660 - accuracy: 0.5186\n",
      "batch loss: 1.5659804344177246\n",
      "batch accuracy: 0.5185546875\n",
      "doing 65 / 277\n",
      "elapsed time 5225.182977437973\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0940 - accuracy: 0.0000e+00\n",
      "batch loss: 2.0939502716064453\n",
      "batch accuracy: 0.0\n",
      "doing 66 / 277\n",
      "elapsed time 5291.702289819717\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1751 - accuracy: 0.2412\n",
      "batch loss: 2.1750550270080566\n",
      "batch accuracy: 0.2412109375\n",
      "doing 67 / 277\n",
      "elapsed time 5360.209389209747\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9683 - accuracy: 0.7207\n",
      "batch loss: 0.9683101177215576\n",
      "batch accuracy: 0.720703125\n",
      "doing 68 / 277\n",
      "elapsed time 5426.670981168747\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.2890 - accuracy: 0.6631\n",
      "batch loss: 1.2889739274978638\n",
      "batch accuracy: 0.6630859375\n",
      "doing 69 / 277\n",
      "elapsed time 5496.826694011688\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.2172 - accuracy: 0.5957\n",
      "batch loss: 1.2171863317489624\n",
      "batch accuracy: 0.595703125\n",
      "doing 70 / 277\n",
      "elapsed time 5567.598369836807\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1041 - accuracy: 0.0635\n",
      "batch loss: 2.1041452884674072\n",
      "batch accuracy: 0.0634765625\n",
      "doing 71 / 277\n",
      "elapsed time 5636.938369512558\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9501 - accuracy: 0.4824\n",
      "batch loss: 1.950141191482544\n",
      "batch accuracy: 0.482421875\n",
      "doing 72 / 277\n",
      "elapsed time 5704.693735361099\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9590 - accuracy: 0.2510\n",
      "batch loss: 1.9590137004852295\n",
      "batch accuracy: 0.2509765625\n",
      "doing 73 / 277\n",
      "elapsed time 5772.2965977191925\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8803 - accuracy: 0.2383\n",
      "batch loss: 1.88031005859375\n",
      "batch accuracy: 0.23828125\n",
      "doing 74 / 277\n",
      "elapsed time 5842.923924446106\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7954 - accuracy: 0.1729\n",
      "batch loss: 1.7953829765319824\n",
      "batch accuracy: 0.1728515625\n",
      "doing 75 / 277\n",
      "elapsed time 5911.08747792244\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8385 - accuracy: 0.1797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: 1.8385343551635742\n",
      "batch accuracy: 0.1796875\n",
      "doing 76 / 277\n",
      "elapsed time 5980.233505725861\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.4689 - accuracy: 0.2461\n",
      "batch loss: 1.4688665866851807\n",
      "batch accuracy: 0.24609375\n",
      "doing 77 / 277\n",
      "elapsed time 6048.460407733917\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.7934 - accuracy: 0.4443\n",
      "batch loss: 1.7933982610702515\n",
      "batch accuracy: 0.4443359375\n",
      "doing 78 / 277\n",
      "elapsed time 6092.67945599556\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7620 - accuracy: 0.3457\n",
      "batch loss: 1.7619562149047852\n",
      "batch accuracy: 0.345703125\n",
      "doing 79 / 277\n",
      "elapsed time 6137.668464899063\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7836 - accuracy: 0.2705\n",
      "batch loss: 1.7835633754730225\n",
      "batch accuracy: 0.2705078125\n",
      "doing 80 / 277\n",
      "elapsed time 6183.917156219482\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.2363 - accuracy: 0.5703\n",
      "batch loss: 1.2362861633300781\n",
      "batch accuracy: 0.5703125\n",
      "doing 81 / 277\n",
      "elapsed time 6228.125151395798\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.7021 - accuracy: 0.3076\n",
      "batch loss: 1.7020635604858398\n",
      "batch accuracy: 0.3076171875\n",
      "doing 82 / 277\n",
      "elapsed time 6271.141406297684\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.4971 - accuracy: 0.0547\n",
      "batch loss: 2.4971189498901367\n",
      "batch accuracy: 0.0546875\n",
      "doing 83 / 277\n",
      "elapsed time 6318.959052562714\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.6418 - accuracy: 0.0049\n",
      "batch loss: 2.641773223876953\n",
      "batch accuracy: 0.0048828125\n",
      "doing 84 / 277\n",
      "elapsed time 6363.961416006088\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.6442 - accuracy: 0.0723\n",
      "batch loss: 2.6442484855651855\n",
      "batch accuracy: 0.072265625\n",
      "doing 85 / 277\n",
      "elapsed time 6382.1281905174255\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3634 - accuracy: 0.0225\n",
      "batch loss: 2.3633828163146973\n",
      "batch accuracy: 0.0224609375\n",
      "doing 86 / 277\n",
      "elapsed time 6429.528480529785\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1417 - accuracy: 0.0977\n",
      "batch loss: 2.1417274475097656\n",
      "batch accuracy: 0.09765625\n",
      "doing 87 / 277\n",
      "elapsed time 6472.9066426754\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8675 - accuracy: 0.2979\n",
      "batch loss: 1.8674516677856445\n",
      "batch accuracy: 0.2978515625\n",
      "doing 88 / 277\n",
      "elapsed time 6513.149724960327\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8592 - accuracy: 0.0205\n",
      "batch loss: 1.859179973602295\n",
      "batch accuracy: 0.0205078125\n",
      "doing 89 / 277\n",
      "elapsed time 6555.208131313324\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9365 - accuracy: 0.2764\n",
      "batch loss: 1.9365415573120117\n",
      "batch accuracy: 0.2763671875\n",
      "doing 90 / 277\n",
      "elapsed time 6600.388672113419\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8380 - accuracy: 0.1475\n",
      "batch loss: 1.8380396366119385\n",
      "batch accuracy: 0.1474609375\n",
      "doing 91 / 277\n",
      "elapsed time 6641.624117851257\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7717 - accuracy: 0.0684\n",
      "batch loss: 1.7717053890228271\n",
      "batch accuracy: 0.068359375\n",
      "doing 92 / 277\n",
      "elapsed time 6686.939013957977\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8374 - accuracy: 0.9824\n",
      "batch loss: 0.8374202847480774\n",
      "batch accuracy: 0.982421875\n",
      "doing 93 / 277\n",
      "elapsed time 6731.969191074371\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5185 - accuracy: 0.9189\n",
      "batch loss: 0.518525242805481\n",
      "batch accuracy: 0.9189453125\n",
      "doing 94 / 277\n",
      "elapsed time 6777.125031709671\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3720 - accuracy: 0.8818\n",
      "batch loss: 0.37204065918922424\n",
      "batch accuracy: 0.8818359375\n",
      "doing 95 / 277\n",
      "elapsed time 6821.09930229187\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6435 - accuracy: 0.2363\n",
      "batch loss: 1.6434595584869385\n",
      "batch accuracy: 0.236328125\n",
      "doing 96 / 277\n",
      "elapsed time 6867.477088928223\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.4426 - accuracy: 0.4238\n",
      "batch loss: 1.4425718784332275\n",
      "batch accuracy: 0.423828125\n",
      "doing 97 / 277\n",
      "elapsed time 6911.778124570847\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.4760 - accuracy: 0.4160\n",
      "batch loss: 1.4760148525238037\n",
      "batch accuracy: 0.416015625\n",
      "doing 98 / 277\n",
      "elapsed time 6954.404892921448\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.5290 - accuracy: 0.3711\n",
      "batch loss: 1.529045820236206\n",
      "batch accuracy: 0.37109375\n",
      "doing 99 / 277\n",
      "elapsed time 6996.412853479385\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8567 - accuracy: 0.2607\n",
      "batch loss: 1.856682538986206\n",
      "batch accuracy: 0.2607421875\n",
      "doing 100 / 277\n",
      "elapsed time 7042.515318393707\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9417 - accuracy: 0.2188\n",
      "batch loss: 1.9416711330413818\n",
      "batch accuracy: 0.21875\n",
      "doing 101 / 277\n",
      "elapsed time 7083.582644462585\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0134 - accuracy: 0.1289\n",
      "batch loss: 2.0134098529815674\n",
      "batch accuracy: 0.12890625\n",
      "doing 102 / 277\n",
      "elapsed time 7131.023714542389\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.8433 - accuracy: 0.2520\n",
      "batch loss: 1.8432536125183105\n",
      "batch accuracy: 0.251953125\n",
      "doing 103 / 277\n",
      "elapsed time 7177.99059176445\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.7753 - accuracy: 0.3223\n",
      "batch loss: 1.7753243446350098\n",
      "batch accuracy: 0.322265625\n",
      "doing 104 / 277\n",
      "elapsed time 7219.812784433365\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.0488 - accuracy: 0.6162\n",
      "batch loss: 1.0488353967666626\n",
      "batch accuracy: 0.6162109375\n",
      "doing 105 / 277\n",
      "elapsed time 7264.380660533905\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.2622 - accuracy: 0.4492\n",
      "batch loss: 1.2622004747390747\n",
      "batch accuracy: 0.44921875\n",
      "doing 106 / 277\n",
      "elapsed time 7308.4708614349365\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9180 - accuracy: 0.1953\n",
      "batch loss: 1.9180338382720947\n",
      "batch accuracy: 0.1953125\n",
      "doing 107 / 277\n",
      "elapsed time 7351.515887498856\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.0487 - accuracy: 0.1172\n",
      "batch loss: 2.048746347427368\n",
      "batch accuracy: 0.1171875\n",
      "doing 108 / 277\n",
      "elapsed time 7397.6284902095795\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.3095 - accuracy: 0.4580\n",
      "batch loss: 1.3095040321350098\n",
      "batch accuracy: 0.4580078125\n",
      "doing 109 / 277\n",
      "elapsed time 7440.502474069595\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2687 - accuracy: 0.1719\n",
      "batch loss: 2.2687275409698486\n",
      "batch accuracy: 0.171875\n",
      "doing 110 / 277\n",
      "elapsed time 7488.741422653198\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2235 - accuracy: 0.0430\n",
      "batch loss: 2.2234504222869873\n",
      "batch accuracy: 0.04296875\n",
      "doing 111 / 277\n",
      "elapsed time 7536.280436038971\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7232 - accuracy: 0.8037\n",
      "batch loss: 0.7232436537742615\n",
      "batch accuracy: 0.8037109375\n",
      "doing 112 / 277\n",
      "elapsed time 7581.785205841064\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0081 - accuracy: 0.2725\n",
      "batch loss: 2.008082866668701\n",
      "batch accuracy: 0.2724609375\n",
      "doing 113 / 277\n",
      "elapsed time 7628.60860824585\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0340 - accuracy: 0.1865\n",
      "batch loss: 2.034043073654175\n",
      "batch accuracy: 0.1865234375\n",
      "doing 114 / 277\n",
      "elapsed time 7676.038298368454\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3297 - accuracy: 0.2510\n",
      "batch loss: 2.329679489135742\n",
      "batch accuracy: 0.2509765625\n",
      "doing 115 / 277\n",
      "elapsed time 7718.842309713364\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.5651 - accuracy: 0.0859\n",
      "batch loss: 2.5650579929351807\n",
      "batch accuracy: 0.0859375\n",
      "doing 116 / 277\n",
      "elapsed time 7766.424734354019\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3000 - accuracy: 0.1846\n",
      "batch loss: 2.2999825477600098\n",
      "batch accuracy: 0.1845703125\n",
      "doing 117 / 277\n",
      "elapsed time 7806.417811632156\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2141 - accuracy: 0.1631\n",
      "batch loss: 2.214068651199341\n",
      "batch accuracy: 0.1630859375\n",
      "doing 118 / 277\n",
      "elapsed time 7851.61993432045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 9ms/step - loss: 1.8608 - accuracy: 0.3330\n",
      "batch loss: 1.860835075378418\n",
      "batch accuracy: 0.3330078125\n",
      "doing 119 / 277\n",
      "elapsed time 7896.995178222656\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7165 - accuracy: 0.5605\n",
      "batch loss: 1.7165166139602661\n",
      "batch accuracy: 0.560546875\n",
      "doing 120 / 277\n",
      "elapsed time 7939.723890542984\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5852 - accuracy: 0.6953\n",
      "batch loss: 1.5852152109146118\n",
      "batch accuracy: 0.6953125\n",
      "doing 121 / 277\n",
      "elapsed time 7980.865993976593\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.5350 - accuracy: 0.6807\n",
      "batch loss: 1.535017967224121\n",
      "batch accuracy: 0.6806640625\n",
      "doing 122 / 277\n",
      "elapsed time 8025.615693807602\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9490 - accuracy: 0.4443\n",
      "batch loss: 1.9489741325378418\n",
      "batch accuracy: 0.4443359375\n",
      "doing 123 / 277\n",
      "elapsed time 8071.841468095779\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.8359 - accuracy: 0.4102\n",
      "batch loss: 1.8358640670776367\n",
      "batch accuracy: 0.41015625\n",
      "doing 124 / 277\n",
      "elapsed time 8117.572446346283\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.5032 - accuracy: 0.6270\n",
      "batch loss: 1.50324547290802\n",
      "batch accuracy: 0.626953125\n",
      "doing 125 / 277\n",
      "elapsed time 8163.131548643112\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3753 - accuracy: 0.0732\n",
      "batch loss: 2.3753342628479004\n",
      "batch accuracy: 0.0732421875\n",
      "doing 126 / 277\n",
      "elapsed time 8210.044543981552\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.5252 - accuracy: 0.0127\n",
      "batch loss: 2.5251684188842773\n",
      "batch accuracy: 0.0126953125\n",
      "doing 127 / 277\n",
      "elapsed time 8255.36998462677\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2782 - accuracy: 0.0615\n",
      "batch loss: 2.2781999111175537\n",
      "batch accuracy: 0.0615234375\n",
      "doing 128 / 277\n",
      "elapsed time 8297.260950088501\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0749 - accuracy: 0.3115\n",
      "batch loss: 2.0748777389526367\n",
      "batch accuracy: 0.3115234375\n",
      "doing 129 / 277\n",
      "elapsed time 8345.241321086884\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5245 - accuracy: 0.2197\n",
      "batch loss: 1.5244536399841309\n",
      "batch accuracy: 0.2197265625\n",
      "doing 130 / 277\n",
      "elapsed time 8390.15481209755\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7238 - accuracy: 0.5781\n",
      "batch loss: 1.723759651184082\n",
      "batch accuracy: 0.578125\n",
      "doing 131 / 277\n",
      "elapsed time 8436.97225689888\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6702 - accuracy: 0.7041\n",
      "batch loss: 1.670203447341919\n",
      "batch accuracy: 0.7041015625\n",
      "doing 132 / 277\n",
      "elapsed time 8481.129885673523\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.8696 - accuracy: 0.4131\n",
      "batch loss: 1.8696004152297974\n",
      "batch accuracy: 0.4130859375\n",
      "doing 133 / 277\n",
      "elapsed time 8528.268759965897\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.0802 - accuracy: 0.1572\n",
      "batch loss: 2.080193042755127\n",
      "batch accuracy: 0.1572265625\n",
      "doing 134 / 277\n",
      "elapsed time 8572.42038154602\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9074 - accuracy: 0.3252\n",
      "batch loss: 1.907407522201538\n",
      "batch accuracy: 0.3251953125\n",
      "doing 135 / 277\n",
      "elapsed time 8615.114531755447\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.4951 - accuracy: 0.2861\n",
      "batch loss: 2.495084047317505\n",
      "batch accuracy: 0.2861328125\n",
      "doing 136 / 277\n",
      "elapsed time 8661.579787254333\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.7230 - accuracy: 0.0000e+00\n",
      "batch loss: 2.72295880317688\n",
      "batch accuracy: 0.0\n",
      "doing 137 / 277\n",
      "elapsed time 8704.950364589691\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 3.6998 - accuracy: 0.0000e+00\n",
      "batch loss: 3.6998274326324463\n",
      "batch accuracy: 0.0\n",
      "doing 138 / 277\n",
      "elapsed time 8752.947570562363\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.5553 - accuracy: 0.0000e+00\n",
      "batch loss: 2.555299997329712\n",
      "batch accuracy: 0.0\n",
      "doing 139 / 277\n",
      "elapsed time 8795.816687583923\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.4999 - accuracy: 0.0000e+00\n",
      "batch loss: 2.49992299079895\n",
      "batch accuracy: 0.0\n",
      "doing 140 / 277\n",
      "elapsed time 8842.504987955093\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3430 - accuracy: 0.0000e+00\n",
      "batch loss: 2.3430325984954834\n",
      "batch accuracy: 0.0\n",
      "doing 141 / 277\n",
      "elapsed time 8878.6265604496\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1659 - accuracy: 0.0000e+00\n",
      "batch loss: 2.165940046310425\n",
      "batch accuracy: 0.0\n",
      "doing 142 / 277\n",
      "elapsed time 8924.361097335815\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9989 - accuracy: 0.0000e+00\n",
      "batch loss: 1.9989219903945923\n",
      "batch accuracy: 0.0\n",
      "doing 143 / 277\n",
      "elapsed time 8962.565100193024\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1785 - accuracy: 0.2939\n",
      "batch loss: 2.1785433292388916\n",
      "batch accuracy: 0.2939453125\n",
      "doing 144 / 277\n",
      "elapsed time 9007.634702682495\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1673 - accuracy: 0.5039\n",
      "batch loss: 2.167287826538086\n",
      "batch accuracy: 0.50390625\n",
      "doing 145 / 277\n",
      "elapsed time 9053.574211597443\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3722 - accuracy: 0.2520\n",
      "batch loss: 2.372169017791748\n",
      "batch accuracy: 0.251953125\n",
      "doing 146 / 277\n",
      "elapsed time 9102.867545843124\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.4511 - accuracy: 0.0420\n",
      "batch loss: 2.451075792312622\n",
      "batch accuracy: 0.0419921875\n",
      "doing 147 / 277\n",
      "elapsed time 9148.676453113556\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.4985 - accuracy: 0.0420\n",
      "batch loss: 2.4985177516937256\n",
      "batch accuracy: 0.0419921875\n",
      "doing 148 / 277\n",
      "elapsed time 9189.027746677399\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.4423 - accuracy: 0.0039\n",
      "batch loss: 2.4422833919525146\n",
      "batch accuracy: 0.00390625\n",
      "doing 149 / 277\n",
      "elapsed time 9233.483307600021\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2250 - accuracy: 0.0420\n",
      "batch loss: 2.225036382675171\n",
      "batch accuracy: 0.0419921875\n",
      "doing 150 / 277\n",
      "elapsed time 9276.411532878876\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1248 - accuracy: 0.1914\n",
      "batch loss: 2.1247565746307373\n",
      "batch accuracy: 0.19140625\n",
      "doing 151 / 277\n",
      "elapsed time 9322.275587320328\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0032 - accuracy: 0.0000e+00\n",
      "batch loss: 2.0032310485839844\n",
      "batch accuracy: 0.0\n",
      "doing 152 / 277\n",
      "elapsed time 9368.035212993622\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1296 - accuracy: 0.0000e+00\n",
      "batch loss: 2.1295721530914307\n",
      "batch accuracy: 0.0\n",
      "doing 153 / 277\n",
      "elapsed time 9412.964881181717\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1728 - accuracy: 0.0000e+00\n",
      "batch loss: 2.1728153228759766\n",
      "batch accuracy: 0.0\n",
      "doing 154 / 277\n",
      "elapsed time 9457.446396827698\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2213 - accuracy: 0.1719\n",
      "batch loss: 2.221299648284912\n",
      "batch accuracy: 0.171875\n",
      "doing 155 / 277\n",
      "elapsed time 9483.734065055847\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0991 - accuracy: 0.2734\n",
      "batch loss: 2.099074602127075\n",
      "batch accuracy: 0.2734375\n",
      "doing 156 / 277\n",
      "elapsed time 9530.84412574768\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1466 - accuracy: 0.1172\n",
      "batch loss: 2.1466338634490967\n",
      "batch accuracy: 0.1171875\n",
      "doing 157 / 277\n",
      "elapsed time 9575.504593372345\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1966 - accuracy: 0.0488\n",
      "batch loss: 2.196605682373047\n",
      "batch accuracy: 0.048828125\n",
      "doing 158 / 277\n",
      "elapsed time 9621.948701620102\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2157 - accuracy: 0.0752\n",
      "batch loss: 2.2156577110290527\n",
      "batch accuracy: 0.0751953125\n",
      "doing 159 / 277\n",
      "elapsed time 9667.762431144714\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2754 - accuracy: 0.0684\n",
      "batch loss: 2.2753689289093018\n",
      "batch accuracy: 0.068359375\n",
      "doing 160 / 277\n",
      "elapsed time 9709.259704351425\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2849 - accuracy: 0.1572\n",
      "batch loss: 2.284904718399048\n",
      "batch accuracy: 0.1572265625\n",
      "doing 161 / 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 9754.028810739517\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1798 - accuracy: 0.2354\n",
      "batch loss: 2.1798152923583984\n",
      "batch accuracy: 0.2353515625\n",
      "doing 162 / 277\n",
      "elapsed time 9800.25289940834\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1982 - accuracy: 0.2295\n",
      "batch loss: 2.1981663703918457\n",
      "batch accuracy: 0.2294921875\n",
      "doing 163 / 277\n",
      "elapsed time 9847.927404165268\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1801 - accuracy: 0.0137\n",
      "batch loss: 2.180147171020508\n",
      "batch accuracy: 0.013671875\n",
      "doing 164 / 277\n",
      "elapsed time 9883.080276727676\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1266 - accuracy: 0.0000e+00\n",
      "batch loss: 2.126556158065796\n",
      "batch accuracy: 0.0\n",
      "doing 165 / 277\n",
      "elapsed time 9910.037813901901\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1799 - accuracy: 0.0000e+00\n",
      "batch loss: 2.1798691749572754\n",
      "batch accuracy: 0.0\n",
      "doing 166 / 277\n",
      "elapsed time 9952.718770980835\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1711 - accuracy: 0.0273\n",
      "batch loss: 2.1710782051086426\n",
      "batch accuracy: 0.02734375\n",
      "doing 167 / 277\n",
      "elapsed time 9998.634360551834\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2946 - accuracy: 0.0205\n",
      "batch loss: 2.2946479320526123\n",
      "batch accuracy: 0.0205078125\n",
      "doing 168 / 277\n",
      "elapsed time 10044.152210950851\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.0059 - accuracy: 0.4238\n",
      "batch loss: 2.005913496017456\n",
      "batch accuracy: 0.423828125\n",
      "doing 169 / 277\n",
      "elapsed time 10086.745121955872\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2085 - accuracy: 0.3418\n",
      "batch loss: 2.208495616912842\n",
      "batch accuracy: 0.341796875\n",
      "doing 170 / 277\n",
      "elapsed time 10125.816744089127\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3515 - accuracy: 0.0547\n",
      "batch loss: 2.3515431880950928\n",
      "batch accuracy: 0.0546875\n",
      "doing 171 / 277\n",
      "elapsed time 10170.346165657043\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8582 - accuracy: 0.7314\n",
      "batch loss: 1.8581571578979492\n",
      "batch accuracy: 0.7314453125\n",
      "doing 172 / 277\n",
      "elapsed time 10214.39990568161\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0789 - accuracy: 0.3828\n",
      "batch loss: 2.078883409500122\n",
      "batch accuracy: 0.3828125\n",
      "doing 173 / 277\n",
      "elapsed time 10253.93487071991\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3311 - accuracy: 0.0820\n",
      "batch loss: 2.3311455249786377\n",
      "batch accuracy: 0.08203125\n",
      "doing 174 / 277\n",
      "elapsed time 10298.817630290985\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3313 - accuracy: 0.0752\n",
      "batch loss: 2.331275701522827\n",
      "batch accuracy: 0.0751953125\n",
      "doing 175 / 277\n",
      "elapsed time 10343.038694381714\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2259 - accuracy: 0.0137\n",
      "batch loss: 2.2258875370025635\n",
      "batch accuracy: 0.013671875\n",
      "doing 176 / 277\n",
      "elapsed time 10387.863729953766\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1969 - accuracy: 0.0547\n",
      "batch loss: 2.19686222076416\n",
      "batch accuracy: 0.0546875\n",
      "doing 177 / 277\n",
      "elapsed time 10435.766464233398\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3000 - accuracy: 0.0410\n",
      "batch loss: 2.29999041557312\n",
      "batch accuracy: 0.041015625\n",
      "doing 178 / 277\n",
      "elapsed time 10481.106587648392\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2989 - accuracy: 0.1299\n",
      "batch loss: 2.2988734245300293\n",
      "batch accuracy: 0.1298828125\n",
      "doing 179 / 277\n",
      "elapsed time 10528.25077700615\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3371 - accuracy: 0.0273\n",
      "batch loss: 2.3370580673217773\n",
      "batch accuracy: 0.02734375\n",
      "doing 180 / 277\n",
      "elapsed time 10577.83253288269\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1781 - accuracy: 0.0068\n",
      "batch loss: 2.178058624267578\n",
      "batch accuracy: 0.0068359375\n",
      "doing 181 / 277\n",
      "elapsed time 10621.892657518387\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3307 - accuracy: 0.0068\n",
      "batch loss: 2.330749750137329\n",
      "batch accuracy: 0.0068359375\n",
      "doing 182 / 277\n",
      "elapsed time 10667.270444869995\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3084 - accuracy: 0.0000e+00\n",
      "batch loss: 2.308415174484253\n",
      "batch accuracy: 0.0\n",
      "doing 183 / 277\n",
      "elapsed time 10710.952364444733\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2783 - accuracy: 0.0000e+00\n",
      "batch loss: 2.2783098220825195\n",
      "batch accuracy: 0.0\n",
      "doing 184 / 277\n",
      "elapsed time 10754.72070479393\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2421 - accuracy: 0.0000e+00\n",
      "batch loss: 2.2420711517333984\n",
      "batch accuracy: 0.0\n",
      "doing 185 / 277\n",
      "elapsed time 10805.802112817764\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1978 - accuracy: 0.0225\n",
      "batch loss: 2.197805881500244\n",
      "batch accuracy: 0.0224609375\n",
      "doing 186 / 277\n",
      "elapsed time 10848.06005692482\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1333 - accuracy: 0.0420\n",
      "batch loss: 2.133272171020508\n",
      "batch accuracy: 0.0419921875\n",
      "doing 187 / 277\n",
      "elapsed time 10890.663069963455\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2048 - accuracy: 0.0000e+00\n",
      "batch loss: 2.2047650814056396\n",
      "batch accuracy: 0.0\n",
      "doing 188 / 277\n",
      "elapsed time 10938.840717554092\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1779 - accuracy: 0.4199\n",
      "batch loss: 2.1778993606567383\n",
      "batch accuracy: 0.419921875\n",
      "doing 189 / 277\n",
      "elapsed time 10987.867534160614\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2690 - accuracy: 0.0000e+00\n",
      "batch loss: 2.2690205574035645\n",
      "batch accuracy: 0.0\n",
      "doing 190 / 277\n",
      "elapsed time 11033.59005188942\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2587 - accuracy: 0.0000e+00\n",
      "batch loss: 2.2586677074432373\n",
      "batch accuracy: 0.0\n",
      "doing 191 / 277\n",
      "elapsed time 11076.846022844315\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2321 - accuracy: 0.0840\n",
      "batch loss: 2.2321364879608154\n",
      "batch accuracy: 0.083984375\n",
      "doing 192 / 277\n",
      "elapsed time 11123.369792699814\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2477 - accuracy: 0.0000e+00\n",
      "batch loss: 2.2477450370788574\n",
      "batch accuracy: 0.0\n",
      "doing 193 / 277\n",
      "elapsed time 11165.291301727295\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2335 - accuracy: 0.0000e+00\n",
      "batch loss: 2.2335152626037598\n",
      "batch accuracy: 0.0\n",
      "doing 194 / 277\n",
      "elapsed time 11211.576854467392\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2169 - accuracy: 0.0000e+00\n",
      "batch loss: 2.216890811920166\n",
      "batch accuracy: 0.0\n",
      "doing 195 / 277\n",
      "elapsed time 11254.0979886055\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1925 - accuracy: 0.0000e+00\n",
      "batch loss: 2.1925368309020996\n",
      "batch accuracy: 0.0\n",
      "doing 196 / 277\n",
      "elapsed time 11300.03509759903\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1654 - accuracy: 0.0000e+00\n",
      "batch loss: 2.165432929992676\n",
      "batch accuracy: 0.0\n",
      "doing 197 / 277\n",
      "elapsed time 11344.434743404388\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1287 - accuracy: 0.0000e+00\n",
      "batch loss: 2.1287176609039307\n",
      "batch accuracy: 0.0\n",
      "doing 198 / 277\n",
      "elapsed time 11389.672669410706\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0751 - accuracy: 0.0000e+00\n",
      "batch loss: 2.0751395225524902\n",
      "batch accuracy: 0.0\n",
      "doing 199 / 277\n",
      "elapsed time 11438.486354112625\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.0223 - accuracy: 0.0000e+00\n",
      "batch loss: 2.022338390350342\n",
      "batch accuracy: 0.0\n",
      "doing 200 / 277\n",
      "elapsed time 11484.381168365479\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5475 - accuracy: 0.0000e+00\n",
      "batch loss: 1.5474603176116943\n",
      "batch accuracy: 0.0\n",
      "doing 201 / 277\n",
      "elapsed time 11530.206143379211\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.0053 - accuracy: 0.8770\n",
      "batch loss: 1.0053279399871826\n",
      "batch accuracy: 0.876953125\n",
      "doing 202 / 277\n",
      "elapsed time 11568.265589952469\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5716 - accuracy: 0.8271\n",
      "batch loss: 1.5716259479522705\n",
      "batch accuracy: 0.8271484375\n",
      "doing 203 / 277\n",
      "elapsed time 11613.451448202133\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.6205 - accuracy: 0.0000e+00\n",
      "batch loss: 2.6204776763916016\n",
      "batch accuracy: 0.0\n",
      "doing 204 / 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 11658.541137933731\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2783 - accuracy: 0.0000e+00\n",
      "batch loss: 2.2782630920410156\n",
      "batch accuracy: 0.0\n",
      "doing 205 / 277\n",
      "elapsed time 11699.64229297638\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2989 - accuracy: 0.0840\n",
      "batch loss: 2.298900842666626\n",
      "batch accuracy: 0.083984375\n",
      "doing 206 / 277\n",
      "elapsed time 11749.281633377075\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0670 - accuracy: 0.4541\n",
      "batch loss: 2.067016124725342\n",
      "batch accuracy: 0.4541015625\n",
      "doing 207 / 277\n",
      "elapsed time 11798.174724340439\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5512 - accuracy: 1.0000\n",
      "batch loss: 1.5512089729309082\n",
      "batch accuracy: 1.0\n",
      "doing 208 / 277\n",
      "elapsed time 11842.836236715317\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.3182 - accuracy: 1.0000\n",
      "batch loss: 1.318176031112671\n",
      "batch accuracy: 1.0\n",
      "doing 209 / 277\n",
      "elapsed time 11889.648158550262\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.4478 - accuracy: 0.6953\n",
      "batch loss: 1.4477570056915283\n",
      "batch accuracy: 0.6953125\n",
      "doing 210 / 277\n",
      "elapsed time 11937.180580615997\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.9931 - accuracy: 0.0000e+00\n",
      "batch loss: 2.993083953857422\n",
      "batch accuracy: 0.0\n",
      "doing 211 / 277\n",
      "elapsed time 11985.17962527275\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.5515 - accuracy: 0.0000e+00\n",
      "batch loss: 2.551525115966797\n",
      "batch accuracy: 0.0\n",
      "doing 212 / 277\n",
      "elapsed time 12033.600240707397\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.4613 - accuracy: 0.0000e+00\n",
      "batch loss: 2.4612650871276855\n",
      "batch accuracy: 0.0\n",
      "doing 213 / 277\n",
      "elapsed time 12078.320581912994\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3112 - accuracy: 0.1240\n",
      "batch loss: 2.311234951019287\n",
      "batch accuracy: 0.1240234375\n",
      "doing 214 / 277\n",
      "elapsed time 12124.35792708397\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2167 - accuracy: 0.2959\n",
      "batch loss: 2.216675281524658\n",
      "batch accuracy: 0.2958984375\n",
      "doing 215 / 277\n",
      "elapsed time 12168.589808702469\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1286 - accuracy: 0.2100\n",
      "batch loss: 2.128573179244995\n",
      "batch accuracy: 0.2099609375\n",
      "doing 216 / 277\n",
      "elapsed time 12219.11909532547\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1936 - accuracy: 0.0840\n",
      "batch loss: 2.193605899810791\n",
      "batch accuracy: 0.083984375\n",
      "doing 217 / 277\n",
      "elapsed time 12262.489644527435\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2483 - accuracy: 0.0420\n",
      "batch loss: 2.248272180557251\n",
      "batch accuracy: 0.0419921875\n",
      "doing 218 / 277\n",
      "elapsed time 12306.221230745316\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1836 - accuracy: 0.1260\n",
      "batch loss: 2.183600425720215\n",
      "batch accuracy: 0.1259765625\n",
      "doing 219 / 277\n",
      "elapsed time 12350.762712955475\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2213 - accuracy: 0.1299\n",
      "batch loss: 2.22133207321167\n",
      "batch accuracy: 0.1298828125\n",
      "doing 220 / 277\n",
      "elapsed time 12393.586708545685\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2290 - accuracy: 0.1221\n",
      "batch loss: 2.2290077209472656\n",
      "batch accuracy: 0.1220703125\n",
      "doing 221 / 277\n",
      "elapsed time 12440.513525724411\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2192 - accuracy: 0.0420\n",
      "batch loss: 2.2192153930664062\n",
      "batch accuracy: 0.0419921875\n",
      "doing 222 / 277\n",
      "elapsed time 12487.80459189415\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2222 - accuracy: 0.0000e+00\n",
      "batch loss: 2.2221832275390625\n",
      "batch accuracy: 0.0\n",
      "doing 223 / 277\n",
      "elapsed time 12533.314197778702\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1238 - accuracy: 0.2529\n",
      "batch loss: 2.1238324642181396\n",
      "batch accuracy: 0.2529296875\n",
      "doing 224 / 277\n",
      "elapsed time 12578.514234542847\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1206 - accuracy: 0.3184\n",
      "batch loss: 2.120622158050537\n",
      "batch accuracy: 0.318359375\n",
      "doing 225 / 277\n",
      "elapsed time 12626.47374677658\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1372 - accuracy: 0.2764\n",
      "batch loss: 2.137249708175659\n",
      "batch accuracy: 0.2763671875\n",
      "doing 226 / 277\n",
      "elapsed time 12669.133741617203\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0914 - accuracy: 0.3027\n",
      "batch loss: 2.0914225578308105\n",
      "batch accuracy: 0.302734375\n",
      "doing 227 / 277\n",
      "elapsed time 12714.153886079788\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0175 - accuracy: 0.1807\n",
      "batch loss: 2.0174801349639893\n",
      "batch accuracy: 0.1806640625\n",
      "doing 228 / 277\n",
      "elapsed time 12759.203540325165\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1347 - accuracy: 0.1973\n",
      "batch loss: 2.134678840637207\n",
      "batch accuracy: 0.197265625\n",
      "doing 229 / 277\n",
      "elapsed time 12802.314613580704\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9871 - accuracy: 0.1650\n",
      "batch loss: 1.9871151447296143\n",
      "batch accuracy: 0.1650390625\n",
      "doing 230 / 277\n",
      "elapsed time 12844.562850952148\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.0824 - accuracy: 0.0928\n",
      "batch loss: 2.0823826789855957\n",
      "batch accuracy: 0.0927734375\n",
      "doing 231 / 277\n",
      "elapsed time 12892.373651981354\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1030 - accuracy: 0.0000e+00\n",
      "batch loss: 2.1029558181762695\n",
      "batch accuracy: 0.0\n",
      "doing 232 / 277\n",
      "elapsed time 12939.532000780106\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.0200 - accuracy: 0.9727\n",
      "batch loss: 2.0199527740478516\n",
      "batch accuracy: 0.97265625\n",
      "doing 233 / 277\n",
      "elapsed time 12967.249776601791\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0802 - accuracy: 0.5127\n",
      "batch loss: 2.08017635345459\n",
      "batch accuracy: 0.5126953125\n",
      "doing 234 / 277\n",
      "elapsed time 13010.71185016632\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1293 - accuracy: 0.4678\n",
      "batch loss: 2.1293277740478516\n",
      "batch accuracy: 0.4677734375\n",
      "doing 235 / 277\n",
      "elapsed time 13054.229186534882\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0689 - accuracy: 0.0420\n",
      "batch loss: 2.0688583850860596\n",
      "batch accuracy: 0.0419921875\n",
      "doing 236 / 277\n",
      "elapsed time 13101.830779075623\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1820 - accuracy: 0.0420\n",
      "batch loss: 2.18198299407959\n",
      "batch accuracy: 0.0419921875\n",
      "doing 237 / 277\n",
      "elapsed time 13145.650047779083\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0792 - accuracy: 0.0840\n",
      "batch loss: 2.0792360305786133\n",
      "batch accuracy: 0.083984375\n",
      "doing 238 / 277\n",
      "elapsed time 13190.375177621841\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.0175 - accuracy: 0.1260\n",
      "batch loss: 2.017490863800049\n",
      "batch accuracy: 0.1259765625\n",
      "doing 239 / 277\n",
      "elapsed time 13240.087492465973\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2375 - accuracy: 0.0420\n",
      "batch loss: 2.2375271320343018\n",
      "batch accuracy: 0.0419921875\n",
      "doing 240 / 277\n",
      "elapsed time 13273.750038862228\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1788 - accuracy: 0.0000e+00\n",
      "batch loss: 2.1787514686584473\n",
      "batch accuracy: 0.0\n",
      "doing 241 / 277\n",
      "elapsed time 13318.19612979889\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2034 - accuracy: 0.0420\n",
      "batch loss: 2.203444004058838\n",
      "batch accuracy: 0.0419921875\n",
      "doing 242 / 277\n",
      "elapsed time 13344.418919563293\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1756 - accuracy: 0.0000e+00\n",
      "batch loss: 2.1756136417388916\n",
      "batch accuracy: 0.0\n",
      "doing 243 / 277\n",
      "elapsed time 13390.329383611679\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.0820 - accuracy: 0.6699\n",
      "batch loss: 2.0820398330688477\n",
      "batch accuracy: 0.669921875\n",
      "doing 244 / 277\n",
      "elapsed time 13437.7767932415\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1924 - accuracy: 0.0000e+00\n",
      "batch loss: 2.192443370819092\n",
      "batch accuracy: 0.0\n",
      "doing 245 / 277\n",
      "elapsed time 13485.827017784119\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.8599 - accuracy: 0.0000e+00\n",
      "batch loss: 2.859907865524292\n",
      "batch accuracy: 0.0\n",
      "doing 246 / 277\n",
      "elapsed time 13528.594678401947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 2.6623 - accuracy: 0.0000e+00\n",
      "batch loss: 2.662266731262207\n",
      "batch accuracy: 0.0\n",
      "doing 247 / 277\n",
      "elapsed time 13577.086655139923\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.4843 - accuracy: 0.0000e+00\n",
      "batch loss: 2.484267234802246\n",
      "batch accuracy: 0.0\n",
      "doing 248 / 277\n",
      "elapsed time 13627.0263504982\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2753 - accuracy: 0.0000e+00\n",
      "batch loss: 2.27530837059021\n",
      "batch accuracy: 0.0\n",
      "doing 249 / 277\n",
      "elapsed time 13674.63527417183\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2213 - accuracy: 0.0000e+00\n",
      "batch loss: 2.2213327884674072\n",
      "batch accuracy: 0.0\n",
      "doing 250 / 277\n",
      "elapsed time 13721.562468290329\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1765 - accuracy: 0.0391\n",
      "batch loss: 2.176482677459717\n",
      "batch accuracy: 0.0390625\n",
      "doing 251 / 277\n",
      "elapsed time 13763.836558580399\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1845 - accuracy: 0.0098\n",
      "batch loss: 2.1845247745513916\n",
      "batch accuracy: 0.009765625\n",
      "doing 252 / 277\n",
      "elapsed time 13807.063859462738\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1768 - accuracy: 0.1172\n",
      "batch loss: 2.176765203475952\n",
      "batch accuracy: 0.1171875\n",
      "doing 253 / 277\n",
      "elapsed time 13851.74562048912\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1857 - accuracy: 0.0977\n",
      "batch loss: 2.185661792755127\n",
      "batch accuracy: 0.09765625\n",
      "doing 254 / 277\n",
      "elapsed time 13892.795009851456\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1652 - accuracy: 0.0195\n",
      "batch loss: 2.1652331352233887\n",
      "batch accuracy: 0.01953125\n",
      "doing 255 / 277\n",
      "elapsed time 13936.505464076996\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1671 - accuracy: 0.1201\n",
      "batch loss: 2.167081832885742\n",
      "batch accuracy: 0.1201171875\n",
      "doing 256 / 277\n",
      "elapsed time 13984.25561285019\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1680 - accuracy: 0.0938\n",
      "batch loss: 2.167997360229492\n",
      "batch accuracy: 0.09375\n",
      "doing 257 / 277\n",
      "elapsed time 14023.419115304947\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1461 - accuracy: 0.1377\n",
      "batch loss: 2.146101474761963\n",
      "batch accuracy: 0.1376953125\n",
      "doing 258 / 277\n",
      "elapsed time 14066.174052476883\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1413 - accuracy: 0.0977\n",
      "batch loss: 2.141328811645508\n",
      "batch accuracy: 0.09765625\n",
      "doing 259 / 277\n",
      "elapsed time 14111.953021764755\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0733 - accuracy: 0.0000e+00\n",
      "batch loss: 2.0733468532562256\n",
      "batch accuracy: 0.0\n",
      "doing 260 / 277\n",
      "elapsed time 14158.770171403885\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2423 - accuracy: 0.0000e+00\n",
      "batch loss: 2.2422783374786377\n",
      "batch accuracy: 0.0\n",
      "doing 261 / 277\n",
      "elapsed time 14206.557397603989\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2032 - accuracy: 0.1367\n",
      "batch loss: 2.2031660079956055\n",
      "batch accuracy: 0.13671875\n",
      "doing 262 / 277\n",
      "elapsed time 14252.190014362335\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2191 - accuracy: 0.0000e+00\n",
      "batch loss: 2.2190663814544678\n",
      "batch accuracy: 0.0\n",
      "doing 263 / 277\n",
      "elapsed time 14282.620334386826\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2103 - accuracy: 0.0000e+00\n",
      "batch loss: 2.210340976715088\n",
      "batch accuracy: 0.0\n",
      "doing 264 / 277\n",
      "elapsed time 14323.758691549301\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1983 - accuracy: 0.0000e+00\n",
      "batch loss: 2.1982641220092773\n",
      "batch accuracy: 0.0\n",
      "doing 265 / 277\n",
      "elapsed time 14368.41941022873\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1871 - accuracy: 0.0000e+00\n",
      "batch loss: 2.187058687210083\n",
      "batch accuracy: 0.0\n",
      "doing 266 / 277\n",
      "elapsed time 14415.0405523777\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1666 - accuracy: 0.0000e+00\n",
      "batch loss: 2.166553258895874\n",
      "batch accuracy: 0.0\n",
      "doing 267 / 277\n",
      "elapsed time 14459.35642504692\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2092 - accuracy: 0.0420\n",
      "batch loss: 2.20922589302063\n",
      "batch accuracy: 0.0419921875\n",
      "doing 268 / 277\n",
      "elapsed time 14500.151715040207\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1789 - accuracy: 0.0420\n",
      "batch loss: 2.178948163986206\n",
      "batch accuracy: 0.0419921875\n",
      "doing 269 / 277\n",
      "elapsed time 14546.26915049553\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1553 - accuracy: 0.0000e+00\n",
      "batch loss: 2.15531587600708\n",
      "batch accuracy: 0.0\n",
      "doing 270 / 277\n",
      "elapsed time 14587.373439311981\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1538 - accuracy: 0.0420\n",
      "batch loss: 2.1537559032440186\n",
      "batch accuracy: 0.0419921875\n",
      "doing 271 / 277\n",
      "elapsed time 14632.285239696503\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1643 - accuracy: 0.0000e+00\n",
      "batch loss: 2.1643178462982178\n",
      "batch accuracy: 0.0\n",
      "doing 272 / 277\n",
      "elapsed time 14674.84488081932\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1476 - accuracy: 0.0000e+00\n",
      "batch loss: 2.147557258605957\n",
      "batch accuracy: 0.0\n",
      "doing 273 / 277\n",
      "elapsed time 14722.746720314026\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1857 - accuracy: 0.1260\n",
      "batch loss: 2.1856651306152344\n",
      "batch accuracy: 0.1259765625\n",
      "doing 274 / 277\n",
      "elapsed time 14773.145047426224\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1579 - accuracy: 0.0000e+00\n",
      "batch loss: 2.1579370498657227\n",
      "batch accuracy: 0.0\n",
      "doing 275 / 277\n",
      "elapsed time 14816.364451646805\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1438 - accuracy: 0.0000e+00\n",
      "batch loss: 2.1438345909118652\n",
      "batch accuracy: 0.0\n",
      "doing 276 / 277\n",
      "elapsed time 14840.269699573517\n",
      "WARNING:tensorflow:From /data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:batch_all_reduce: 32 all-reduces with algorithm = hierarchical_copy, num_packs = 1\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 2.1264 - accuracy: 0.0000e+00\n",
      "batch loss: 2.126390218734741\n",
      "batch accuracy: 0.0\n",
      "Train loss 1.9824818055606062\n",
      "Train accuracy 0.24772605482851986\n",
      "141/141 [==============================] - 2s 13ms/step - loss: 2.2505 - accuracy: 0.0127\n",
      "Validation loss: 2.250528335571289\n",
      "Validation accuracy: 0.012666666880249977\n",
      "==================================================\n",
      "1 / 10\n",
      "doing 0 / 277\n",
      "elapsed time 15.693015813827515\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2003 - accuracy: 0.1064\n",
      "batch loss: 2.200314998626709\n",
      "batch accuracy: 0.1064453125\n",
      "doing 1 / 277\n",
      "elapsed time 32.05485224723816\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1963 - accuracy: 0.1182\n",
      "batch loss: 2.196320056915283\n",
      "batch accuracy: 0.1181640625\n",
      "doing 2 / 277\n",
      "elapsed time 48.92084336280823\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1954 - accuracy: 0.1113\n",
      "batch loss: 2.195425510406494\n",
      "batch accuracy: 0.111328125\n",
      "doing 3 / 277\n",
      "elapsed time 73.7119951248169\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2013 - accuracy: 0.1055\n",
      "batch loss: 2.2013118267059326\n",
      "batch accuracy: 0.10546875\n",
      "doing 4 / 277\n",
      "elapsed time 102.39301490783691\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1927 - accuracy: 0.1123\n",
      "batch loss: 2.1927175521850586\n",
      "batch accuracy: 0.1123046875\n",
      "doing 5 / 277\n",
      "elapsed time 128.13950109481812\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1925 - accuracy: 0.1045\n",
      "batch loss: 2.192519426345825\n",
      "batch accuracy: 0.1044921875\n",
      "doing 6 / 277\n",
      "elapsed time 156.39872550964355\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1708 - accuracy: 0.2520\n",
      "batch loss: 2.170776605606079\n",
      "batch accuracy: 0.251953125\n",
      "doing 7 / 277\n",
      "elapsed time 182.84287190437317\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1780 - accuracy: 0.1357\n",
      "batch loss: 2.177954912185669\n",
      "batch accuracy: 0.1357421875\n",
      "doing 8 / 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 211.29955410957336\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1408 - accuracy: 0.1816\n",
      "batch loss: 2.1407785415649414\n",
      "batch accuracy: 0.181640625\n",
      "doing 9 / 277\n",
      "elapsed time 237.95405316352844\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0756 - accuracy: 0.2139\n",
      "batch loss: 2.0755884647369385\n",
      "batch accuracy: 0.2138671875\n",
      "doing 10 / 277\n",
      "elapsed time 268.050589799881\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9854 - accuracy: 0.2373\n",
      "batch loss: 1.9853999614715576\n",
      "batch accuracy: 0.2373046875\n",
      "doing 11 / 277\n",
      "elapsed time 295.1806831359863\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9488 - accuracy: 0.2617\n",
      "batch loss: 1.9488282203674316\n",
      "batch accuracy: 0.26171875\n",
      "doing 12 / 277\n",
      "elapsed time 323.12076592445374\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9255 - accuracy: 0.2021\n",
      "batch loss: 1.9255428314208984\n",
      "batch accuracy: 0.2021484375\n",
      "doing 13 / 277\n",
      "elapsed time 351.27042603492737\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9383 - accuracy: 0.2158\n",
      "batch loss: 1.9383028745651245\n",
      "batch accuracy: 0.2158203125\n",
      "doing 14 / 277\n",
      "elapsed time 377.5988419055939\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9215 - accuracy: 0.3135\n",
      "batch loss: 1.9214868545532227\n",
      "batch accuracy: 0.3134765625\n",
      "doing 15 / 277\n",
      "elapsed time 403.6422395706177\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9427 - accuracy: 0.2764\n",
      "batch loss: 1.9426575899124146\n",
      "batch accuracy: 0.2763671875\n",
      "doing 16 / 277\n",
      "elapsed time 432.6015627384186\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9274 - accuracy: 0.2852\n",
      "batch loss: 1.9274036884307861\n",
      "batch accuracy: 0.28515625\n",
      "doing 17 / 277\n",
      "elapsed time 460.9983592033386\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9021 - accuracy: 0.3057\n",
      "batch loss: 1.902087688446045\n",
      "batch accuracy: 0.3056640625\n",
      "doing 18 / 277\n",
      "elapsed time 488.32872128486633\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9069 - accuracy: 0.2988\n",
      "batch loss: 1.9069263935089111\n",
      "batch accuracy: 0.298828125\n",
      "doing 19 / 277\n",
      "elapsed time 518.4866960048676\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.8917 - accuracy: 0.2451\n",
      "batch loss: 1.8917322158813477\n",
      "batch accuracy: 0.2451171875\n",
      "doing 20 / 277\n",
      "elapsed time 546.8040435314178\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9031 - accuracy: 0.2529\n",
      "batch loss: 1.9030841588974\n",
      "batch accuracy: 0.2529296875\n",
      "doing 21 / 277\n",
      "elapsed time 575.6670191287994\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9430 - accuracy: 0.2314\n",
      "batch loss: 1.9430173635482788\n",
      "batch accuracy: 0.2314453125\n",
      "doing 22 / 277\n",
      "elapsed time 601.951740026474\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9493 - accuracy: 0.2471\n",
      "batch loss: 1.949292540550232\n",
      "batch accuracy: 0.2470703125\n",
      "doing 23 / 277\n",
      "elapsed time 630.2618677616119\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9055 - accuracy: 0.2510\n",
      "batch loss: 1.9054746627807617\n",
      "batch accuracy: 0.2509765625\n",
      "doing 24 / 277\n",
      "elapsed time 658.229770898819\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9239 - accuracy: 0.2666\n",
      "batch loss: 1.9239022731781006\n",
      "batch accuracy: 0.2666015625\n",
      "doing 25 / 277\n",
      "elapsed time 684.0132644176483\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9167 - accuracy: 0.2891\n",
      "batch loss: 1.9167132377624512\n",
      "batch accuracy: 0.2890625\n",
      "doing 26 / 277\n",
      "elapsed time 711.5601975917816\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9230 - accuracy: 0.2705\n",
      "batch loss: 1.9230494499206543\n",
      "batch accuracy: 0.2705078125\n",
      "doing 27 / 277\n",
      "elapsed time 740.1386134624481\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9191 - accuracy: 0.2383\n",
      "batch loss: 1.9191017150878906\n",
      "batch accuracy: 0.23828125\n",
      "doing 28 / 277\n",
      "elapsed time 768.7753019332886\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9278 - accuracy: 0.2373\n",
      "batch loss: 1.9278463125228882\n",
      "batch accuracy: 0.2373046875\n",
      "doing 29 / 277\n",
      "elapsed time 795.6364607810974\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.8816 - accuracy: 0.3125\n",
      "batch loss: 1.8815712928771973\n",
      "batch accuracy: 0.3125\n",
      "doing 30 / 277\n",
      "elapsed time 819.8782253265381\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9025 - accuracy: 0.3213\n",
      "batch loss: 1.9024790525436401\n",
      "batch accuracy: 0.3212890625\n",
      "doing 31 / 277\n",
      "elapsed time 848.4575834274292\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.8897 - accuracy: 0.2930\n",
      "batch loss: 1.889747142791748\n",
      "batch accuracy: 0.29296875\n",
      "doing 32 / 277\n",
      "elapsed time 876.0739796161652\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.8603 - accuracy: 0.2676\n",
      "batch loss: 1.8603081703186035\n",
      "batch accuracy: 0.267578125\n",
      "doing 33 / 277\n",
      "elapsed time 904.7353181838989\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8411 - accuracy: 0.3066\n",
      "batch loss: 1.8411225080490112\n",
      "batch accuracy: 0.306640625\n",
      "doing 34 / 277\n",
      "elapsed time 932.5284280776978\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.8824 - accuracy: 0.3398\n",
      "batch loss: 1.8823771476745605\n",
      "batch accuracy: 0.33984375\n",
      "doing 35 / 277\n",
      "elapsed time 960.7652463912964\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9133 - accuracy: 0.3115\n",
      "batch loss: 1.9133275747299194\n",
      "batch accuracy: 0.3115234375\n",
      "doing 36 / 277\n",
      "elapsed time 988.6369705200195\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8548 - accuracy: 0.3291\n",
      "batch loss: 1.8547508716583252\n",
      "batch accuracy: 0.3291015625\n",
      "doing 37 / 277\n",
      "elapsed time 1016.2049140930176\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8476 - accuracy: 0.2822\n",
      "batch loss: 1.847589135169983\n",
      "batch accuracy: 0.2822265625\n",
      "doing 38 / 277\n",
      "elapsed time 1043.4383745193481\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.8733 - accuracy: 0.2930\n",
      "batch loss: 1.8732810020446777\n",
      "batch accuracy: 0.29296875\n",
      "doing 39 / 277\n",
      "elapsed time 1069.1434090137482\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9058 - accuracy: 0.2559\n",
      "batch loss: 1.905754566192627\n",
      "batch accuracy: 0.255859375\n",
      "doing 40 / 277\n",
      "elapsed time 1096.7068037986755\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.8089 - accuracy: 0.2891\n",
      "batch loss: 1.8088992834091187\n",
      "batch accuracy: 0.2890625\n",
      "doing 41 / 277\n",
      "elapsed time 1124.8863441944122\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7966 - accuracy: 0.3223\n",
      "batch loss: 1.7966346740722656\n",
      "batch accuracy: 0.322265625\n",
      "doing 42 / 277\n",
      "elapsed time 1152.2717399597168\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.7938 - accuracy: 0.3193\n",
      "batch loss: 1.793811559677124\n",
      "batch accuracy: 0.3193359375\n",
      "doing 43 / 277\n",
      "elapsed time 1180.445992231369\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8010 - accuracy: 0.2773\n",
      "batch loss: 1.8009545803070068\n",
      "batch accuracy: 0.27734375\n",
      "doing 44 / 277\n",
      "elapsed time 1205.3702857494354\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7830 - accuracy: 0.3164\n",
      "batch loss: 1.7830110788345337\n",
      "batch accuracy: 0.31640625\n",
      "doing 45 / 277\n",
      "elapsed time 1235.2347073554993\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.8162 - accuracy: 0.3086\n",
      "batch loss: 1.8162028789520264\n",
      "batch accuracy: 0.30859375\n",
      "doing 46 / 277\n",
      "elapsed time 1265.290400981903\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.7715 - accuracy: 0.3311\n",
      "batch loss: 1.7714977264404297\n",
      "batch accuracy: 0.3310546875\n",
      "doing 47 / 277\n",
      "elapsed time 1289.6433560848236\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.7837 - accuracy: 0.2988\n",
      "batch loss: 1.7836850881576538\n",
      "batch accuracy: 0.298828125\n",
      "doing 48 / 277\n",
      "elapsed time 1318.9682502746582\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8003 - accuracy: 0.2764\n",
      "batch loss: 1.8002955913543701\n",
      "batch accuracy: 0.2763671875\n",
      "doing 49 / 277\n",
      "elapsed time 1346.6316344738007\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.7222 - accuracy: 0.3555\n",
      "batch loss: 1.722200632095337\n",
      "batch accuracy: 0.35546875\n",
      "doing 50 / 277\n",
      "elapsed time 1372.6414818763733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7631 - accuracy: 0.3525\n",
      "batch loss: 1.7630717754364014\n",
      "batch accuracy: 0.3525390625\n",
      "doing 51 / 277\n",
      "elapsed time 1398.7187778949738\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.7819 - accuracy: 0.3330\n",
      "batch loss: 1.7818634510040283\n",
      "batch accuracy: 0.3330078125\n",
      "doing 52 / 277\n",
      "elapsed time 1425.3731229305267\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7104 - accuracy: 0.3711\n",
      "batch loss: 1.7104136943817139\n",
      "batch accuracy: 0.37109375\n",
      "doing 53 / 277\n",
      "elapsed time 1453.8168540000916\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7069 - accuracy: 0.3936\n",
      "batch loss: 1.7068979740142822\n",
      "batch accuracy: 0.3935546875\n",
      "doing 54 / 277\n",
      "elapsed time 1481.4833006858826\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7481 - accuracy: 0.3525\n",
      "batch loss: 1.7480792999267578\n",
      "batch accuracy: 0.3525390625\n",
      "doing 55 / 277\n",
      "elapsed time 1509.1318247318268\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.7193 - accuracy: 0.3252\n",
      "batch loss: 1.719325065612793\n",
      "batch accuracy: 0.3251953125\n",
      "doing 56 / 277\n",
      "elapsed time 1534.6179103851318\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6848 - accuracy: 0.3848\n",
      "batch loss: 1.6848256587982178\n",
      "batch accuracy: 0.384765625\n",
      "doing 57 / 277\n",
      "elapsed time 1561.3427827358246\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8257 - accuracy: 0.3359\n",
      "batch loss: 1.8257365226745605\n",
      "batch accuracy: 0.3359375\n",
      "doing 58 / 277\n",
      "elapsed time 1588.9030542373657\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7033 - accuracy: 0.3223\n",
      "batch loss: 1.7032556533813477\n",
      "batch accuracy: 0.322265625\n",
      "doing 59 / 277\n",
      "elapsed time 1615.9300124645233\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7429 - accuracy: 0.3027\n",
      "batch loss: 1.7428585290908813\n",
      "batch accuracy: 0.302734375\n",
      "doing 60 / 277\n",
      "elapsed time 1642.7440173625946\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7056 - accuracy: 0.3516\n",
      "batch loss: 1.7056033611297607\n",
      "batch accuracy: 0.3515625\n",
      "doing 61 / 277\n",
      "elapsed time 1673.3711619377136\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6606 - accuracy: 0.3643\n",
      "batch loss: 1.6606194972991943\n",
      "batch accuracy: 0.3642578125\n",
      "doing 62 / 277\n",
      "elapsed time 1698.8510053157806\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.6829 - accuracy: 0.3145\n",
      "batch loss: 1.6828962564468384\n",
      "batch accuracy: 0.314453125\n",
      "doing 63 / 277\n",
      "elapsed time 1730.5621044635773\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.6406 - accuracy: 0.3379\n",
      "batch loss: 1.6405541896820068\n",
      "batch accuracy: 0.337890625\n",
      "doing 64 / 277\n",
      "elapsed time 1756.3666396141052\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6400 - accuracy: 0.3730\n",
      "batch loss: 1.639969825744629\n",
      "batch accuracy: 0.373046875\n",
      "doing 65 / 277\n",
      "elapsed time 1785.706237077713\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2559 - accuracy: 0.3047\n",
      "batch loss: 2.2558796405792236\n",
      "batch accuracy: 0.3046875\n",
      "doing 66 / 277\n",
      "elapsed time 1813.577603816986\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.1741 - accuracy: 0.2852\n",
      "batch loss: 2.174055337905884\n",
      "batch accuracy: 0.28515625\n",
      "doing 67 / 277\n",
      "elapsed time 1841.788547039032\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6949 - accuracy: 0.3438\n",
      "batch loss: 1.694911241531372\n",
      "batch accuracy: 0.34375\n",
      "doing 68 / 277\n",
      "elapsed time 1869.298511505127\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8873 - accuracy: 0.2930\n",
      "batch loss: 1.8873088359832764\n",
      "batch accuracy: 0.29296875\n",
      "doing 69 / 277\n",
      "elapsed time 1896.1667804718018\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8383 - accuracy: 0.2881\n",
      "batch loss: 1.8383142948150635\n",
      "batch accuracy: 0.2880859375\n",
      "doing 70 / 277\n",
      "elapsed time 1923.077532529831\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7744 - accuracy: 0.3105\n",
      "batch loss: 1.774375319480896\n",
      "batch accuracy: 0.310546875\n",
      "doing 71 / 277\n",
      "elapsed time 1953.9758658409119\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8607 - accuracy: 0.3076\n",
      "batch loss: 1.8606843948364258\n",
      "batch accuracy: 0.3076171875\n",
      "doing 72 / 277\n",
      "elapsed time 1981.274225473404\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8247 - accuracy: 0.3037\n",
      "batch loss: 1.8246591091156006\n",
      "batch accuracy: 0.3037109375\n",
      "doing 73 / 277\n",
      "elapsed time 2007.5958156585693\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8420 - accuracy: 0.2881\n",
      "batch loss: 1.8420114517211914\n",
      "batch accuracy: 0.2880859375\n",
      "doing 74 / 277\n",
      "elapsed time 2030.7620952129364\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8208 - accuracy: 0.3418\n",
      "batch loss: 1.8207969665527344\n",
      "batch accuracy: 0.341796875\n",
      "doing 75 / 277\n",
      "elapsed time 2058.7471039295197\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7657 - accuracy: 0.3340\n",
      "batch loss: 1.765708565711975\n",
      "batch accuracy: 0.333984375\n",
      "doing 76 / 277\n",
      "elapsed time 2083.837577342987\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7103 - accuracy: 0.3184\n",
      "batch loss: 1.7102919816970825\n",
      "batch accuracy: 0.318359375\n",
      "doing 77 / 277\n",
      "elapsed time 2109.4424986839294\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8102 - accuracy: 0.2637\n",
      "batch loss: 1.810225486755371\n",
      "batch accuracy: 0.263671875\n",
      "doing 78 / 277\n",
      "elapsed time 2140.0629703998566\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.6973 - accuracy: 0.3223\n",
      "batch loss: 1.6972928047180176\n",
      "batch accuracy: 0.322265625\n",
      "doing 79 / 277\n",
      "elapsed time 2167.8749170303345\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.7118 - accuracy: 0.3359\n",
      "batch loss: 1.7118334770202637\n",
      "batch accuracy: 0.3359375\n",
      "doing 80 / 277\n",
      "elapsed time 2195.619717359543\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7119 - accuracy: 0.3340\n",
      "batch loss: 1.7119393348693848\n",
      "batch accuracy: 0.333984375\n",
      "doing 81 / 277\n",
      "elapsed time 2221.6841843128204\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6668 - accuracy: 0.3184\n",
      "batch loss: 1.6667641401290894\n",
      "batch accuracy: 0.318359375\n",
      "doing 82 / 277\n",
      "elapsed time 2249.515136241913\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6256 - accuracy: 0.3154\n",
      "batch loss: 1.6256461143493652\n",
      "batch accuracy: 0.3154296875\n",
      "doing 83 / 277\n",
      "elapsed time 2278.3824009895325\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6598 - accuracy: 0.3613\n",
      "batch loss: 1.6597673892974854\n",
      "batch accuracy: 0.361328125\n",
      "doing 84 / 277\n",
      "elapsed time 2302.8840250968933\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6382 - accuracy: 0.3369\n",
      "batch loss: 1.6381592750549316\n",
      "batch accuracy: 0.3369140625\n",
      "doing 85 / 277\n",
      "elapsed time 2331.0969445705414\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.6451 - accuracy: 0.3438\n",
      "batch loss: 1.6451013088226318\n",
      "batch accuracy: 0.34375\n",
      "doing 86 / 277\n",
      "elapsed time 2357.3924095630646\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6411 - accuracy: 0.3311\n",
      "batch loss: 1.6411449909210205\n",
      "batch accuracy: 0.3310546875\n",
      "doing 87 / 277\n",
      "elapsed time 2384.9110782146454\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6048 - accuracy: 0.3281\n",
      "batch loss: 1.6048160791397095\n",
      "batch accuracy: 0.328125\n",
      "doing 88 / 277\n",
      "elapsed time 2413.0616188049316\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6453 - accuracy: 0.3213\n",
      "batch loss: 1.6452901363372803\n",
      "batch accuracy: 0.3212890625\n",
      "doing 89 / 277\n",
      "elapsed time 2442.2951836586\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6407 - accuracy: 0.3496\n",
      "batch loss: 1.6406821012496948\n",
      "batch accuracy: 0.349609375\n",
      "doing 90 / 277\n",
      "elapsed time 2472.4814891815186\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6394 - accuracy: 0.3359\n",
      "batch loss: 1.6394286155700684\n",
      "batch accuracy: 0.3359375\n",
      "doing 91 / 277\n",
      "elapsed time 2498.3771533966064\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5910 - accuracy: 0.3555\n",
      "batch loss: 1.5909526348114014\n",
      "batch accuracy: 0.35546875\n",
      "doing 92 / 277\n",
      "elapsed time 2526.6012094020844\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6086 - accuracy: 0.3359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: 1.6085585355758667\n",
      "batch accuracy: 0.3359375\n",
      "doing 93 / 277\n",
      "elapsed time 2555.168874979019\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6034 - accuracy: 0.3291\n",
      "batch loss: 1.6034036874771118\n",
      "batch accuracy: 0.3291015625\n",
      "doing 94 / 277\n",
      "elapsed time 2583.782739639282\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.6197 - accuracy: 0.3691\n",
      "batch loss: 1.6197476387023926\n",
      "batch accuracy: 0.369140625\n",
      "doing 95 / 277\n",
      "elapsed time 2612.1411352157593\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.6345 - accuracy: 0.3672\n",
      "batch loss: 1.6345046758651733\n",
      "batch accuracy: 0.3671875\n",
      "doing 96 / 277\n",
      "elapsed time 2638.3758506774902\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.5621 - accuracy: 0.3789\n",
      "batch loss: 1.562134027481079\n",
      "batch accuracy: 0.37890625\n",
      "doing 97 / 277\n",
      "elapsed time 2667.7790789604187\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.5624 - accuracy: 0.3564\n",
      "batch loss: 1.5623847246170044\n",
      "batch accuracy: 0.3564453125\n",
      "doing 98 / 277\n",
      "elapsed time 2696.7934863567352\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.5125 - accuracy: 0.3896\n",
      "batch loss: 1.5124964714050293\n",
      "batch accuracy: 0.3896484375\n",
      "doing 99 / 277\n",
      "elapsed time 2726.4692330360413\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.5631 - accuracy: 0.3555\n",
      "batch loss: 1.5630686283111572\n",
      "batch accuracy: 0.35546875\n",
      "doing 100 / 277\n",
      "elapsed time 2753.1642656326294\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5602 - accuracy: 0.3916\n",
      "batch loss: 1.5601508617401123\n",
      "batch accuracy: 0.3916015625\n",
      "doing 101 / 277\n",
      "elapsed time 2781.1867620944977\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.5882 - accuracy: 0.3506\n",
      "batch loss: 1.5882091522216797\n",
      "batch accuracy: 0.3505859375\n",
      "doing 102 / 277\n",
      "elapsed time 2807.2098865509033\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.5085 - accuracy: 0.3945\n",
      "batch loss: 1.508544921875\n",
      "batch accuracy: 0.39453125\n",
      "doing 103 / 277\n",
      "elapsed time 2834.638916492462\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.5407 - accuracy: 0.3867\n",
      "batch loss: 1.5406930446624756\n",
      "batch accuracy: 0.38671875\n",
      "doing 104 / 277\n",
      "elapsed time 2862.589948415756\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.4921 - accuracy: 0.3838\n",
      "batch loss: 1.492142677307129\n",
      "batch accuracy: 0.3837890625\n",
      "doing 105 / 277\n",
      "elapsed time 2890.0875556468964\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.4864 - accuracy: 0.4141\n",
      "batch loss: 1.4864442348480225\n",
      "batch accuracy: 0.4140625\n",
      "doing 106 / 277\n",
      "elapsed time 2915.569170475006\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.4752 - accuracy: 0.4346\n",
      "batch loss: 1.4751551151275635\n",
      "batch accuracy: 0.4345703125\n",
      "doing 107 / 277\n",
      "elapsed time 2944.946643590927\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5325 - accuracy: 0.3477\n",
      "batch loss: 1.5325266122817993\n",
      "batch accuracy: 0.34765625\n",
      "doing 108 / 277\n",
      "elapsed time 2972.1978693008423\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.4841 - accuracy: 0.4336\n",
      "batch loss: 1.4840911626815796\n",
      "batch accuracy: 0.43359375\n",
      "doing 109 / 277\n",
      "elapsed time 2999.179812669754\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.5131 - accuracy: 0.4102\n",
      "batch loss: 1.5131362676620483\n",
      "batch accuracy: 0.41015625\n",
      "doing 110 / 277\n",
      "elapsed time 3030.556650161743\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.5250 - accuracy: 0.4111\n",
      "batch loss: 1.5249552726745605\n",
      "batch accuracy: 0.4111328125\n",
      "doing 111 / 277\n",
      "elapsed time 3060.2558007240295\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.4922 - accuracy: 0.3721\n",
      "batch loss: 1.4921948909759521\n",
      "batch accuracy: 0.3720703125\n",
      "doing 112 / 277\n",
      "elapsed time 3092.028522491455\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.4818 - accuracy: 0.3711\n",
      "batch loss: 1.481795072555542\n",
      "batch accuracy: 0.37109375\n",
      "doing 113 / 277\n",
      "elapsed time 3126.8374042510986\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5092 - accuracy: 0.4209\n",
      "batch loss: 1.5092291831970215\n",
      "batch accuracy: 0.4208984375\n",
      "doing 114 / 277\n",
      "elapsed time 3159.1489551067352\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.4899 - accuracy: 0.4238\n",
      "batch loss: 1.4898533821105957\n",
      "batch accuracy: 0.423828125\n",
      "doing 115 / 277\n",
      "elapsed time 3193.233852624893\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.4830 - accuracy: 0.4326\n",
      "batch loss: 1.482983112335205\n",
      "batch accuracy: 0.4326171875\n",
      "doing 116 / 277\n",
      "elapsed time 3220.3339529037476\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.3956 - accuracy: 0.4307\n",
      "batch loss: 1.39557683467865\n",
      "batch accuracy: 0.4306640625\n",
      "doing 117 / 277\n",
      "elapsed time 3253.4236810207367\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.4892 - accuracy: 0.4023\n",
      "batch loss: 1.4892040491104126\n",
      "batch accuracy: 0.40234375\n",
      "doing 118 / 277\n",
      "elapsed time 3284.485183238983\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6116 - accuracy: 0.3848\n",
      "batch loss: 1.6116483211517334\n",
      "batch accuracy: 0.384765625\n",
      "doing 119 / 277\n",
      "elapsed time 3314.7337911129\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.3895 - accuracy: 0.4238\n",
      "batch loss: 1.3895249366760254\n",
      "batch accuracy: 0.423828125\n",
      "doing 120 / 277\n",
      "elapsed time 3344.7924466133118\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5000 - accuracy: 0.4248\n",
      "batch loss: 1.5000121593475342\n",
      "batch accuracy: 0.4248046875\n",
      "doing 121 / 277\n",
      "elapsed time 3372.464761018753\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.3450 - accuracy: 0.4648\n",
      "batch loss: 1.344951868057251\n",
      "batch accuracy: 0.46484375\n",
      "doing 122 / 277\n",
      "elapsed time 3398.9650888442993\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.4342 - accuracy: 0.4297\n",
      "batch loss: 1.4341809749603271\n",
      "batch accuracy: 0.4296875\n",
      "doing 123 / 277\n",
      "elapsed time 3427.37162566185\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.4127 - accuracy: 0.4336\n",
      "batch loss: 1.412741780281067\n",
      "batch accuracy: 0.43359375\n",
      "doing 124 / 277\n",
      "elapsed time 3457.1652076244354\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.3472 - accuracy: 0.4336\n",
      "batch loss: 1.3471554517745972\n",
      "batch accuracy: 0.43359375\n",
      "doing 125 / 277\n",
      "elapsed time 3487.465048789978\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.3941 - accuracy: 0.4727\n",
      "batch loss: 1.394085168838501\n",
      "batch accuracy: 0.47265625\n",
      "doing 126 / 277\n",
      "elapsed time 3519.6684906482697\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.3765 - accuracy: 0.4404\n",
      "batch loss: 1.3764662742614746\n",
      "batch accuracy: 0.4404296875\n",
      "doing 127 / 277\n",
      "elapsed time 3550.089495897293\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.3595 - accuracy: 0.4697\n",
      "batch loss: 1.3595362901687622\n",
      "batch accuracy: 0.4697265625\n",
      "doing 128 / 277\n",
      "elapsed time 3579.8105130195618\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.3693 - accuracy: 0.4365\n",
      "batch loss: 1.369272232055664\n",
      "batch accuracy: 0.4365234375\n",
      "doing 129 / 277\n",
      "elapsed time 3610.4881358146667\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.4031 - accuracy: 0.4082\n",
      "batch loss: 1.403083086013794\n",
      "batch accuracy: 0.408203125\n",
      "doing 130 / 277\n",
      "elapsed time 3638.489890098572\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.2949 - accuracy: 0.4482\n",
      "batch loss: 1.2948707342147827\n",
      "batch accuracy: 0.4482421875\n",
      "doing 131 / 277\n",
      "elapsed time 3670.410514831543\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.3119 - accuracy: 0.4756\n",
      "batch loss: 1.3118760585784912\n",
      "batch accuracy: 0.4755859375\n",
      "doing 132 / 277\n",
      "elapsed time 3702.7158501148224\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.3820 - accuracy: 0.4502\n",
      "batch loss: 1.3820122480392456\n",
      "batch accuracy: 0.4501953125\n",
      "doing 133 / 277\n",
      "elapsed time 3731.35156083107\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.2942 - accuracy: 0.4824\n",
      "batch loss: 1.2941696643829346\n",
      "batch accuracy: 0.482421875\n",
      "doing 134 / 277\n",
      "elapsed time 3763.1430208683014\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.2973 - accuracy: 0.4814\n",
      "batch loss: 1.297324776649475\n",
      "batch accuracy: 0.4814453125\n",
      "doing 135 / 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 3793.6878955364227\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.2499 - accuracy: 0.4932\n",
      "batch loss: 1.2499229907989502\n",
      "batch accuracy: 0.4931640625\n",
      "doing 136 / 277\n",
      "elapsed time 3823.3734300136566\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.2439 - accuracy: 0.4980\n",
      "batch loss: 1.2438929080963135\n",
      "batch accuracy: 0.498046875\n",
      "doing 137 / 277\n",
      "elapsed time 3852.9512486457825\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.1978 - accuracy: 0.4736\n",
      "batch loss: 1.1978381872177124\n",
      "batch accuracy: 0.4736328125\n",
      "doing 138 / 277\n",
      "elapsed time 3881.227948665619\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.2491 - accuracy: 0.4463\n",
      "batch loss: 1.2491172552108765\n",
      "batch accuracy: 0.4462890625\n",
      "doing 139 / 277\n",
      "elapsed time 3912.999411582947\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.1858 - accuracy: 0.4902\n",
      "batch loss: 1.1858316659927368\n",
      "batch accuracy: 0.490234375\n",
      "doing 140 / 277\n",
      "elapsed time 3943.013413667679\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.2755 - accuracy: 0.4629\n",
      "batch loss: 1.2754744291305542\n",
      "batch accuracy: 0.462890625\n",
      "doing 141 / 277\n",
      "elapsed time 3973.3581511974335\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.2177 - accuracy: 0.4639\n",
      "batch loss: 1.2177448272705078\n",
      "batch accuracy: 0.4638671875\n",
      "doing 142 / 277\n",
      "elapsed time 4001.1280188560486\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.2508 - accuracy: 0.4775\n",
      "batch loss: 1.2508023977279663\n",
      "batch accuracy: 0.4775390625\n",
      "doing 143 / 277\n",
      "elapsed time 4031.5099020004272\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.2657 - accuracy: 0.4551\n",
      "batch loss: 1.2656617164611816\n",
      "batch accuracy: 0.455078125\n",
      "doing 144 / 277\n",
      "elapsed time 4061.4683709144592\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.2246 - accuracy: 0.4639\n",
      "batch loss: 1.2245937585830688\n",
      "batch accuracy: 0.4638671875\n",
      "doing 145 / 277\n",
      "elapsed time 4092.9752774238586\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.1666 - accuracy: 0.4746\n",
      "batch loss: 1.1666209697723389\n",
      "batch accuracy: 0.474609375\n",
      "doing 146 / 277\n",
      "elapsed time 4122.897143363953\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.1479 - accuracy: 0.4844\n",
      "batch loss: 1.1479434967041016\n",
      "batch accuracy: 0.484375\n",
      "doing 147 / 277\n",
      "elapsed time 4150.84041762352\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.1665 - accuracy: 0.4688\n",
      "batch loss: 1.166476845741272\n",
      "batch accuracy: 0.46875\n",
      "doing 148 / 277\n",
      "elapsed time 4181.305873394012\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.2169 - accuracy: 0.4727\n",
      "batch loss: 1.216854214668274\n",
      "batch accuracy: 0.47265625\n",
      "doing 149 / 277\n",
      "elapsed time 4210.838336467743\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.1752 - accuracy: 0.4902\n",
      "batch loss: 1.1752187013626099\n",
      "batch accuracy: 0.490234375\n",
      "doing 150 / 277\n",
      "elapsed time 4240.7262988090515\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.1086 - accuracy: 0.5430\n",
      "batch loss: 1.1086403131484985\n",
      "batch accuracy: 0.54296875\n",
      "doing 151 / 277\n",
      "elapsed time 4271.488924503326\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.1127 - accuracy: 0.5273\n",
      "batch loss: 1.1126669645309448\n",
      "batch accuracy: 0.52734375\n",
      "doing 152 / 277\n",
      "elapsed time 4302.593137979507\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.0788 - accuracy: 0.5771\n",
      "batch loss: 1.0787603855133057\n",
      "batch accuracy: 0.5771484375\n",
      "doing 153 / 277\n",
      "elapsed time 4332.945100784302\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.1222 - accuracy: 0.5762\n",
      "batch loss: 1.122218132019043\n",
      "batch accuracy: 0.576171875\n",
      "doing 154 / 277\n",
      "elapsed time 4367.382020235062\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.0661 - accuracy: 0.5703\n",
      "batch loss: 1.0661063194274902\n",
      "batch accuracy: 0.5703125\n",
      "doing 155 / 277\n",
      "elapsed time 4397.477848291397\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.0355 - accuracy: 0.5977\n",
      "batch loss: 1.0354927778244019\n",
      "batch accuracy: 0.59765625\n",
      "doing 156 / 277\n",
      "elapsed time 4425.446143627167\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.0836 - accuracy: 0.5762\n",
      "batch loss: 1.0836186408996582\n",
      "batch accuracy: 0.576171875\n",
      "doing 157 / 277\n",
      "elapsed time 4457.397925615311\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.0689 - accuracy: 0.5605\n",
      "batch loss: 1.068934679031372\n",
      "batch accuracy: 0.560546875\n",
      "doing 158 / 277\n",
      "elapsed time 4513.014625072479\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.1115 - accuracy: 0.5576\n",
      "batch loss: 1.1115105152130127\n",
      "batch accuracy: 0.5576171875\n",
      "doing 159 / 277\n",
      "elapsed time 4580.585285902023\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.0992 - accuracy: 0.5596\n",
      "batch loss: 1.0992498397827148\n",
      "batch accuracy: 0.5595703125\n",
      "doing 160 / 277\n",
      "elapsed time 4649.43555355072\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.1026 - accuracy: 0.5850\n",
      "batch loss: 1.1025581359863281\n",
      "batch accuracy: 0.5849609375\n",
      "doing 161 / 277\n",
      "elapsed time 4717.647165775299\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.1907 - accuracy: 0.5586\n",
      "batch loss: 1.1906729936599731\n",
      "batch accuracy: 0.55859375\n",
      "doing 162 / 277\n",
      "elapsed time 4788.3755848407745\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.0304 - accuracy: 0.6377\n",
      "batch loss: 1.0304124355316162\n",
      "batch accuracy: 0.6376953125\n",
      "doing 163 / 277\n",
      "elapsed time 4853.9301862716675\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.1134 - accuracy: 0.6270\n",
      "batch loss: 1.1133874654769897\n",
      "batch accuracy: 0.626953125\n",
      "doing 164 / 277\n",
      "elapsed time 4923.231099128723\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.9957 - accuracy: 0.6465\n",
      "batch loss: 0.9957014322280884\n",
      "batch accuracy: 0.646484375\n",
      "doing 165 / 277\n",
      "elapsed time 4991.608253240585\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.0386 - accuracy: 0.6143\n",
      "batch loss: 1.0385576486587524\n",
      "batch accuracy: 0.6142578125\n",
      "doing 166 / 277\n",
      "elapsed time 5057.35062289238\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.9189 - accuracy: 0.6494\n",
      "batch loss: 0.9189152121543884\n",
      "batch accuracy: 0.6494140625\n",
      "doing 167 / 277\n",
      "elapsed time 5127.857059955597\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.9780 - accuracy: 0.6592\n",
      "batch loss: 0.9779857397079468\n",
      "batch accuracy: 0.6591796875\n",
      "doing 168 / 277\n",
      "elapsed time 5197.017984628677\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.9901 - accuracy: 0.6611\n",
      "batch loss: 0.9901049137115479\n",
      "batch accuracy: 0.6611328125\n",
      "doing 169 / 277\n",
      "elapsed time 5265.886446714401\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.9902 - accuracy: 0.6455\n",
      "batch loss: 0.9901812076568604\n",
      "batch accuracy: 0.6455078125\n",
      "doing 170 / 277\n",
      "elapsed time 5335.653980016708\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.9507 - accuracy: 0.6348\n",
      "batch loss: 0.9507163763046265\n",
      "batch accuracy: 0.634765625\n",
      "doing 171 / 277\n",
      "elapsed time 5409.9752604961395\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.9092 - accuracy: 0.6797\n",
      "batch loss: 0.9091992378234863\n",
      "batch accuracy: 0.6796875\n",
      "doing 172 / 277\n",
      "elapsed time 5480.581455230713\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.9862 - accuracy: 0.6475\n",
      "batch loss: 0.9861615896224976\n",
      "batch accuracy: 0.6474609375\n",
      "doing 173 / 277\n",
      "elapsed time 5546.0463626384735\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.9185 - accuracy: 0.6914\n",
      "batch loss: 0.9185260534286499\n",
      "batch accuracy: 0.69140625\n",
      "doing 174 / 277\n",
      "elapsed time 5618.142541885376\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.9823 - accuracy: 0.6201\n",
      "batch loss: 0.9823394417762756\n",
      "batch accuracy: 0.6201171875\n",
      "doing 175 / 277\n",
      "elapsed time 5685.985549688339\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.0082 - accuracy: 0.6455\n",
      "batch loss: 1.0082273483276367\n",
      "batch accuracy: 0.6455078125\n",
      "doing 176 / 277\n",
      "elapsed time 5753.512984991074\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.9317 - accuracy: 0.6670\n",
      "batch loss: 0.9316511154174805\n",
      "batch accuracy: 0.6669921875\n",
      "doing 177 / 277\n",
      "elapsed time 5824.652588129044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.9367 - accuracy: 0.6943\n",
      "batch loss: 0.9367097020149231\n",
      "batch accuracy: 0.6943359375\n",
      "doing 178 / 277\n",
      "elapsed time 5893.123055458069\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.9360 - accuracy: 0.6895\n",
      "batch loss: 0.9359884858131409\n",
      "batch accuracy: 0.689453125\n",
      "doing 179 / 277\n",
      "elapsed time 5964.049388170242\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.9168 - accuracy: 0.6973\n",
      "batch loss: 0.9168165922164917\n",
      "batch accuracy: 0.697265625\n",
      "doing 180 / 277\n",
      "elapsed time 6029.588069438934\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.9190 - accuracy: 0.6885\n",
      "batch loss: 0.9190306663513184\n",
      "batch accuracy: 0.6884765625\n",
      "doing 181 / 277\n",
      "elapsed time 6096.724503993988\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8896 - accuracy: 0.6836\n",
      "batch loss: 0.8895620107650757\n",
      "batch accuracy: 0.68359375\n",
      "doing 182 / 277\n",
      "elapsed time 6165.2542243003845\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.9224 - accuracy: 0.6836\n",
      "batch loss: 0.9224252700805664\n",
      "batch accuracy: 0.68359375\n",
      "doing 183 / 277\n",
      "elapsed time 6230.962891340256\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8823 - accuracy: 0.7051\n",
      "batch loss: 0.8822711110115051\n",
      "batch accuracy: 0.705078125\n",
      "doing 184 / 277\n",
      "elapsed time 6296.280616044998\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8298 - accuracy: 0.7217\n",
      "batch loss: 0.8297967910766602\n",
      "batch accuracy: 0.7216796875\n",
      "doing 185 / 277\n",
      "elapsed time 6362.3743143081665\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7840 - accuracy: 0.7383\n",
      "batch loss: 0.7839796543121338\n",
      "batch accuracy: 0.73828125\n",
      "doing 186 / 277\n",
      "elapsed time 6435.316162586212\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7969 - accuracy: 0.7529\n",
      "batch loss: 0.7969374060630798\n",
      "batch accuracy: 0.7529296875\n",
      "doing 187 / 277\n",
      "elapsed time 6502.312449932098\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7601 - accuracy: 0.7393\n",
      "batch loss: 0.7600863575935364\n",
      "batch accuracy: 0.7392578125\n",
      "doing 188 / 277\n",
      "elapsed time 6570.686733961105\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8240 - accuracy: 0.7197\n",
      "batch loss: 0.8240408897399902\n",
      "batch accuracy: 0.7197265625\n",
      "doing 189 / 277\n",
      "elapsed time 6638.707893848419\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7760 - accuracy: 0.7471\n",
      "batch loss: 0.7760477066040039\n",
      "batch accuracy: 0.7470703125\n",
      "doing 190 / 277\n",
      "elapsed time 6711.456763744354\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8022 - accuracy: 0.7295\n",
      "batch loss: 0.8021647930145264\n",
      "batch accuracy: 0.7294921875\n",
      "doing 191 / 277\n",
      "elapsed time 6780.541163682938\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7672 - accuracy: 0.7500\n",
      "batch loss: 0.7671918869018555\n",
      "batch accuracy: 0.75\n",
      "doing 192 / 277\n",
      "elapsed time 6848.897291898727\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7590 - accuracy: 0.7324\n",
      "batch loss: 0.7589976191520691\n",
      "batch accuracy: 0.732421875\n",
      "doing 193 / 277\n",
      "elapsed time 6916.041962862015\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7948 - accuracy: 0.7295\n",
      "batch loss: 0.7947643995285034\n",
      "batch accuracy: 0.7294921875\n",
      "doing 194 / 277\n",
      "elapsed time 6986.520520210266\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8051 - accuracy: 0.7354\n",
      "batch loss: 0.805141270160675\n",
      "batch accuracy: 0.7353515625\n",
      "doing 195 / 277\n",
      "elapsed time 7052.309099435806\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7520 - accuracy: 0.7354\n",
      "batch loss: 0.7519603967666626\n",
      "batch accuracy: 0.7353515625\n",
      "doing 196 / 277\n",
      "elapsed time 7121.249101638794\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7106 - accuracy: 0.7510\n",
      "batch loss: 0.7105689644813538\n",
      "batch accuracy: 0.7509765625\n",
      "doing 197 / 277\n",
      "elapsed time 7191.7589457035065\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7377 - accuracy: 0.7480\n",
      "batch loss: 0.7376620769500732\n",
      "batch accuracy: 0.748046875\n",
      "doing 198 / 277\n",
      "elapsed time 7257.520690917969\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7434 - accuracy: 0.7334\n",
      "batch loss: 0.7434412240982056\n",
      "batch accuracy: 0.7333984375\n",
      "doing 199 / 277\n",
      "elapsed time 7323.951066017151\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6843 - accuracy: 0.7773\n",
      "batch loss: 0.6842598915100098\n",
      "batch accuracy: 0.77734375\n",
      "doing 200 / 277\n",
      "elapsed time 7393.077808380127\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7229 - accuracy: 0.7422\n",
      "batch loss: 0.7229065895080566\n",
      "batch accuracy: 0.7421875\n",
      "doing 201 / 277\n",
      "elapsed time 7460.656363487244\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6543 - accuracy: 0.7812\n",
      "batch loss: 0.654284656047821\n",
      "batch accuracy: 0.78125\n",
      "doing 202 / 277\n",
      "elapsed time 7530.876162528992\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6777 - accuracy: 0.7695\n",
      "batch loss: 0.6776979565620422\n",
      "batch accuracy: 0.76953125\n",
      "doing 203 / 277\n",
      "elapsed time 7599.901149749756\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7070 - accuracy: 0.7676\n",
      "batch loss: 0.706993579864502\n",
      "batch accuracy: 0.767578125\n",
      "doing 204 / 277\n",
      "elapsed time 7667.464351654053\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7017 - accuracy: 0.7598\n",
      "batch loss: 0.7016516923904419\n",
      "batch accuracy: 0.759765625\n",
      "doing 205 / 277\n",
      "elapsed time 7737.624217987061\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7199 - accuracy: 0.7373\n",
      "batch loss: 0.719887375831604\n",
      "batch accuracy: 0.7373046875\n",
      "doing 206 / 277\n",
      "elapsed time 7805.706414222717\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6872 - accuracy: 0.7520\n",
      "batch loss: 0.687225341796875\n",
      "batch accuracy: 0.751953125\n",
      "doing 207 / 277\n",
      "elapsed time 7874.353724718094\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7039 - accuracy: 0.7588\n",
      "batch loss: 0.7039094567298889\n",
      "batch accuracy: 0.7587890625\n",
      "doing 208 / 277\n",
      "elapsed time 7941.787440299988\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6504 - accuracy: 0.7666\n",
      "batch loss: 0.6504112482070923\n",
      "batch accuracy: 0.7666015625\n",
      "doing 209 / 277\n",
      "elapsed time 8013.612442731857\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6595 - accuracy: 0.7666\n",
      "batch loss: 0.6595047116279602\n",
      "batch accuracy: 0.7666015625\n",
      "doing 210 / 277\n",
      "elapsed time 8082.354038000107\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6880 - accuracy: 0.7686\n",
      "batch loss: 0.6879967451095581\n",
      "batch accuracy: 0.7685546875\n",
      "doing 211 / 277\n",
      "elapsed time 8152.812433958054\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7226 - accuracy: 0.7471\n",
      "batch loss: 0.7226434350013733\n",
      "batch accuracy: 0.7470703125\n",
      "doing 212 / 277\n",
      "elapsed time 8222.210205554962\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6267 - accuracy: 0.7705\n",
      "batch loss: 0.6267355680465698\n",
      "batch accuracy: 0.7705078125\n",
      "doing 213 / 277\n",
      "elapsed time 8290.834294080734\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6333 - accuracy: 0.7881\n",
      "batch loss: 0.6332994699478149\n",
      "batch accuracy: 0.7880859375\n",
      "doing 214 / 277\n",
      "elapsed time 8361.051262140274\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6546 - accuracy: 0.7676\n",
      "batch loss: 0.6546400189399719\n",
      "batch accuracy: 0.767578125\n",
      "doing 215 / 277\n",
      "elapsed time 8428.077314376831\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6140 - accuracy: 0.7754\n",
      "batch loss: 0.6139992475509644\n",
      "batch accuracy: 0.775390625\n",
      "doing 216 / 277\n",
      "elapsed time 8498.13697218895\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5979 - accuracy: 0.7930\n",
      "batch loss: 0.5979482531547546\n",
      "batch accuracy: 0.79296875\n",
      "doing 217 / 277\n",
      "elapsed time 8567.868448019028\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5950 - accuracy: 0.7783\n",
      "batch loss: 0.5950136184692383\n",
      "batch accuracy: 0.7783203125\n",
      "doing 218 / 277\n",
      "elapsed time 8642.1966984272\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5460 - accuracy: 0.8096\n",
      "batch loss: 0.5460101366043091\n",
      "batch accuracy: 0.8095703125\n",
      "doing 219 / 277\n",
      "elapsed time 8710.87973332405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6660 - accuracy: 0.7627\n",
      "batch loss: 0.6660336852073669\n",
      "batch accuracy: 0.7626953125\n",
      "doing 220 / 277\n",
      "elapsed time 8782.226058721542\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6155 - accuracy: 0.7793\n",
      "batch loss: 0.615492045879364\n",
      "batch accuracy: 0.779296875\n",
      "doing 221 / 277\n",
      "elapsed time 8850.620406866074\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6076 - accuracy: 0.7891\n",
      "batch loss: 0.6076440811157227\n",
      "batch accuracy: 0.7890625\n",
      "doing 222 / 277\n",
      "elapsed time 8922.477227926254\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6015 - accuracy: 0.7930\n",
      "batch loss: 0.6015257835388184\n",
      "batch accuracy: 0.79296875\n",
      "doing 223 / 277\n",
      "elapsed time 8987.72856760025\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5759 - accuracy: 0.7793\n",
      "batch loss: 0.5758706331253052\n",
      "batch accuracy: 0.779296875\n",
      "doing 224 / 277\n",
      "elapsed time 9054.783532381058\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6042 - accuracy: 0.7871\n",
      "batch loss: 0.6041902303695679\n",
      "batch accuracy: 0.787109375\n",
      "doing 225 / 277\n",
      "elapsed time 9124.405611753464\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6169 - accuracy: 0.7783\n",
      "batch loss: 0.6168984770774841\n",
      "batch accuracy: 0.7783203125\n",
      "doing 226 / 277\n",
      "elapsed time 9192.481207370758\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6126 - accuracy: 0.7705\n",
      "batch loss: 0.6126424074172974\n",
      "batch accuracy: 0.7705078125\n",
      "doing 227 / 277\n",
      "elapsed time 9259.603048563004\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5885 - accuracy: 0.7910\n",
      "batch loss: 0.5885255336761475\n",
      "batch accuracy: 0.791015625\n",
      "doing 228 / 277\n",
      "elapsed time 9329.877096891403\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6118 - accuracy: 0.7852\n",
      "batch loss: 0.6118298172950745\n",
      "batch accuracy: 0.78515625\n",
      "doing 229 / 277\n",
      "elapsed time 9399.138401508331\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6113 - accuracy: 0.7939\n",
      "batch loss: 0.6113382577896118\n",
      "batch accuracy: 0.7939453125\n",
      "doing 230 / 277\n",
      "elapsed time 9468.101485729218\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5892 - accuracy: 0.7910\n",
      "batch loss: 0.5891872644424438\n",
      "batch accuracy: 0.791015625\n",
      "doing 231 / 277\n",
      "elapsed time 9536.092959880829\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5485 - accuracy: 0.8271\n",
      "batch loss: 0.5485052466392517\n",
      "batch accuracy: 0.8271484375\n",
      "doing 232 / 277\n",
      "elapsed time 9601.756891965866\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5851 - accuracy: 0.8037\n",
      "batch loss: 0.5850597620010376\n",
      "batch accuracy: 0.8037109375\n",
      "doing 233 / 277\n",
      "elapsed time 9670.0795211792\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5626 - accuracy: 0.8193\n",
      "batch loss: 0.562631368637085\n",
      "batch accuracy: 0.8193359375\n",
      "doing 234 / 277\n",
      "elapsed time 9738.339233875275\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5968 - accuracy: 0.7861\n",
      "batch loss: 0.5968447923660278\n",
      "batch accuracy: 0.7861328125\n",
      "doing 235 / 277\n",
      "elapsed time 9805.658344507217\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5495 - accuracy: 0.7900\n",
      "batch loss: 0.5494683384895325\n",
      "batch accuracy: 0.7900390625\n",
      "doing 236 / 277\n",
      "elapsed time 9874.333709716797\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5535 - accuracy: 0.7988\n",
      "batch loss: 0.5535492897033691\n",
      "batch accuracy: 0.798828125\n",
      "doing 237 / 277\n",
      "elapsed time 9945.090991735458\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6174 - accuracy: 0.7842\n",
      "batch loss: 0.6173806190490723\n",
      "batch accuracy: 0.7841796875\n",
      "doing 238 / 277\n",
      "elapsed time 10014.277535915375\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5583 - accuracy: 0.8018\n",
      "batch loss: 0.558295488357544\n",
      "batch accuracy: 0.8017578125\n",
      "doing 239 / 277\n",
      "elapsed time 10081.250844478607\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5223 - accuracy: 0.8135\n",
      "batch loss: 0.5223157405853271\n",
      "batch accuracy: 0.8134765625\n",
      "doing 240 / 277\n",
      "elapsed time 10148.275336027145\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5020 - accuracy: 0.8232\n",
      "batch loss: 0.5019716024398804\n",
      "batch accuracy: 0.8232421875\n",
      "doing 241 / 277\n",
      "elapsed time 10218.40248131752\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5222 - accuracy: 0.8193\n",
      "batch loss: 0.522231936454773\n",
      "batch accuracy: 0.8193359375\n",
      "doing 242 / 277\n",
      "elapsed time 10286.00427365303\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4803 - accuracy: 0.8242\n",
      "batch loss: 0.4802873432636261\n",
      "batch accuracy: 0.82421875\n",
      "doing 243 / 277\n",
      "elapsed time 10352.993810653687\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4928 - accuracy: 0.8369\n",
      "batch loss: 0.49276837706565857\n",
      "batch accuracy: 0.8369140625\n",
      "doing 244 / 277\n",
      "elapsed time 10421.71109366417\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5102 - accuracy: 0.8125\n",
      "batch loss: 0.5102425217628479\n",
      "batch accuracy: 0.8125\n",
      "doing 245 / 277\n",
      "elapsed time 10489.939370632172\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5421 - accuracy: 0.7959\n",
      "batch loss: 0.5420917868614197\n",
      "batch accuracy: 0.7958984375\n",
      "doing 246 / 277\n",
      "elapsed time 10559.833859920502\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5683 - accuracy: 0.7959\n",
      "batch loss: 0.5683282613754272\n",
      "batch accuracy: 0.7958984375\n",
      "doing 247 / 277\n",
      "elapsed time 10629.45103597641\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5273 - accuracy: 0.8164\n",
      "batch loss: 0.5272756218910217\n",
      "batch accuracy: 0.81640625\n",
      "doing 248 / 277\n",
      "elapsed time 10701.526805400848\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5387 - accuracy: 0.8105\n",
      "batch loss: 0.5387266874313354\n",
      "batch accuracy: 0.810546875\n",
      "doing 249 / 277\n",
      "elapsed time 10768.56846499443\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5279 - accuracy: 0.8174\n",
      "batch loss: 0.5279251933097839\n",
      "batch accuracy: 0.8173828125\n",
      "doing 250 / 277\n",
      "elapsed time 10839.181763887405\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5301 - accuracy: 0.7959\n",
      "batch loss: 0.5300924777984619\n",
      "batch accuracy: 0.7958984375\n",
      "doing 251 / 277\n",
      "elapsed time 10908.266596794128\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5475 - accuracy: 0.8105\n",
      "batch loss: 0.5475141406059265\n",
      "batch accuracy: 0.810546875\n",
      "doing 252 / 277\n",
      "elapsed time 10982.073647499084\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4854 - accuracy: 0.8223\n",
      "batch loss: 0.48541587591171265\n",
      "batch accuracy: 0.822265625\n",
      "doing 253 / 277\n",
      "elapsed time 11051.736819505692\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6174 - accuracy: 0.7773\n",
      "batch loss: 0.617371678352356\n",
      "batch accuracy: 0.77734375\n",
      "doing 254 / 277\n",
      "elapsed time 11119.487545013428\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5147 - accuracy: 0.8135\n",
      "batch loss: 0.514650285243988\n",
      "batch accuracy: 0.8134765625\n",
      "doing 255 / 277\n",
      "elapsed time 11189.809300899506\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5589 - accuracy: 0.7949\n",
      "batch loss: 0.558855414390564\n",
      "batch accuracy: 0.794921875\n",
      "doing 256 / 277\n",
      "elapsed time 11257.333027124405\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5295 - accuracy: 0.8027\n",
      "batch loss: 0.5294665694236755\n",
      "batch accuracy: 0.802734375\n",
      "doing 257 / 277\n",
      "elapsed time 11324.97627210617\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4974 - accuracy: 0.8350\n",
      "batch loss: 0.4973877966403961\n",
      "batch accuracy: 0.8349609375\n",
      "doing 258 / 277\n",
      "elapsed time 11392.014830827713\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5197 - accuracy: 0.8184\n",
      "batch loss: 0.5196687579154968\n",
      "batch accuracy: 0.818359375\n",
      "doing 259 / 277\n",
      "elapsed time 11460.441725254059\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5132 - accuracy: 0.8135\n",
      "batch loss: 0.5132458209991455\n",
      "batch accuracy: 0.8134765625\n",
      "doing 260 / 277\n",
      "elapsed time 11531.54394197464\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5772 - accuracy: 0.8154\n",
      "batch loss: 0.5772497653961182\n",
      "batch accuracy: 0.8154296875\n",
      "doing 261 / 277\n",
      "elapsed time 11599.997912406921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5023 - accuracy: 0.8330\n",
      "batch loss: 0.5022686719894409\n",
      "batch accuracy: 0.8330078125\n",
      "doing 262 / 277\n",
      "elapsed time 11668.457404851913\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5093 - accuracy: 0.8193\n",
      "batch loss: 0.5093014240264893\n",
      "batch accuracy: 0.8193359375\n",
      "doing 263 / 277\n",
      "elapsed time 11732.446952342987\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4931 - accuracy: 0.8164\n",
      "batch loss: 0.49313920736312866\n",
      "batch accuracy: 0.81640625\n",
      "doing 264 / 277\n",
      "elapsed time 11801.699652194977\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4829 - accuracy: 0.8311\n",
      "batch loss: 0.4828660786151886\n",
      "batch accuracy: 0.8310546875\n",
      "doing 265 / 277\n",
      "elapsed time 11871.579493522644\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4962 - accuracy: 0.8135\n",
      "batch loss: 0.49620404839515686\n",
      "batch accuracy: 0.8134765625\n",
      "doing 266 / 277\n",
      "elapsed time 11939.021983385086\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4746 - accuracy: 0.8223\n",
      "batch loss: 0.4745979309082031\n",
      "batch accuracy: 0.822265625\n",
      "doing 267 / 277\n",
      "elapsed time 12004.691403388977\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4719 - accuracy: 0.8320\n",
      "batch loss: 0.47190988063812256\n",
      "batch accuracy: 0.83203125\n",
      "doing 268 / 277\n",
      "elapsed time 12069.72287607193\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4425 - accuracy: 0.8232\n",
      "batch loss: 0.44247159361839294\n",
      "batch accuracy: 0.8232421875\n",
      "doing 269 / 277\n",
      "elapsed time 12126.628284215927\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5591 - accuracy: 0.8047\n",
      "batch loss: 0.559141993522644\n",
      "batch accuracy: 0.8046875\n",
      "doing 270 / 277\n",
      "elapsed time 12175.647446155548\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5230 - accuracy: 0.8115\n",
      "batch loss: 0.5230133533477783\n",
      "batch accuracy: 0.8115234375\n",
      "doing 271 / 277\n",
      "elapsed time 12225.002660751343\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5113 - accuracy: 0.8125\n",
      "batch loss: 0.5113418102264404\n",
      "batch accuracy: 0.8125\n",
      "doing 272 / 277\n",
      "elapsed time 12279.505102396011\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4803 - accuracy: 0.8271\n",
      "batch loss: 0.4802851974964142\n",
      "batch accuracy: 0.8271484375\n",
      "doing 273 / 277\n",
      "elapsed time 12330.635690927505\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5048 - accuracy: 0.8193\n",
      "batch loss: 0.5048438310623169\n",
      "batch accuracy: 0.8193359375\n",
      "doing 274 / 277\n",
      "elapsed time 12376.802508354187\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4794 - accuracy: 0.8135\n",
      "batch loss: 0.4794011116027832\n",
      "batch accuracy: 0.8134765625\n",
      "doing 275 / 277\n",
      "elapsed time 12421.62505698204\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4851 - accuracy: 0.8291\n",
      "batch loss: 0.4851054549217224\n",
      "batch accuracy: 0.8291015625\n",
      "doing 276 / 277\n",
      "elapsed time 12444.585490226746\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.5894 - accuracy: 0.8026\n",
      "batch loss: 0.5894317626953125\n",
      "batch accuracy: 0.8025594353675842\n",
      "Train loss 1.2352259321548449\n",
      "Train accuracy 0.5271351141619769\n",
      "141/141 [==============================] - 2s 13ms/step - loss: 0.5022 - accuracy: 0.8631\n",
      "Validation loss: 0.5021517276763916\n",
      "Validation accuracy: 0.863111138343811\n",
      "==================================================\n",
      "2 / 10\n",
      "doing 0 / 277\n",
      "elapsed time 15.85820746421814\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5104 - accuracy: 0.8115\n",
      "batch loss: 0.5104076862335205\n",
      "batch accuracy: 0.8115234375\n",
      "doing 1 / 277\n",
      "elapsed time 33.54187083244324\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4854 - accuracy: 0.8291\n",
      "batch loss: 0.4854300916194916\n",
      "batch accuracy: 0.8291015625\n",
      "doing 2 / 277\n",
      "elapsed time 59.61024570465088\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5121 - accuracy: 0.8096\n",
      "batch loss: 0.5121212601661682\n",
      "batch accuracy: 0.8095703125\n",
      "doing 3 / 277\n",
      "elapsed time 89.35496044158936\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4791 - accuracy: 0.8213\n",
      "batch loss: 0.47914978861808777\n",
      "batch accuracy: 0.8212890625\n",
      "doing 4 / 277\n",
      "elapsed time 126.37801027297974\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4233 - accuracy: 0.8477\n",
      "batch loss: 0.4232512414455414\n",
      "batch accuracy: 0.84765625\n",
      "doing 5 / 277\n",
      "elapsed time 159.4776599407196\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4480 - accuracy: 0.8330\n",
      "batch loss: 0.447963148355484\n",
      "batch accuracy: 0.8330078125\n",
      "doing 6 / 277\n",
      "elapsed time 187.92900967597961\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4397 - accuracy: 0.8447\n",
      "batch loss: 0.43972086906433105\n",
      "batch accuracy: 0.8447265625\n",
      "doing 7 / 277\n",
      "elapsed time 225.05932998657227\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4260 - accuracy: 0.8516\n",
      "batch loss: 0.42600739002227783\n",
      "batch accuracy: 0.8515625\n",
      "doing 8 / 277\n",
      "elapsed time 257.0085561275482\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4169 - accuracy: 0.8584\n",
      "batch loss: 0.4169193506240845\n",
      "batch accuracy: 0.8583984375\n",
      "doing 9 / 277\n",
      "elapsed time 291.3784427642822\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4360 - accuracy: 0.8506\n",
      "batch loss: 0.43602582812309265\n",
      "batch accuracy: 0.8505859375\n",
      "doing 10 / 277\n",
      "elapsed time 321.6792242527008\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4461 - accuracy: 0.8311\n",
      "batch loss: 0.44610369205474854\n",
      "batch accuracy: 0.8310546875\n",
      "doing 11 / 277\n",
      "elapsed time 359.52387833595276\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4365 - accuracy: 0.8516\n",
      "batch loss: 0.4365125894546509\n",
      "batch accuracy: 0.8515625\n",
      "doing 12 / 277\n",
      "elapsed time 394.0763695240021\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4280 - accuracy: 0.8330\n",
      "batch loss: 0.42795276641845703\n",
      "batch accuracy: 0.8330078125\n",
      "doing 13 / 277\n",
      "elapsed time 427.53856444358826\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4251 - accuracy: 0.8545\n",
      "batch loss: 0.4250635504722595\n",
      "batch accuracy: 0.8544921875\n",
      "doing 14 / 277\n",
      "elapsed time 469.5674252510071\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4552 - accuracy: 0.8408\n",
      "batch loss: 0.45518234372138977\n",
      "batch accuracy: 0.8408203125\n",
      "doing 15 / 277\n",
      "elapsed time 497.223393201828\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4493 - accuracy: 0.8447\n",
      "batch loss: 0.44933080673217773\n",
      "batch accuracy: 0.8447265625\n",
      "doing 16 / 277\n",
      "elapsed time 536.6339473724365\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3987 - accuracy: 0.8584\n",
      "batch loss: 0.3986740708351135\n",
      "batch accuracy: 0.8583984375\n",
      "doing 17 / 277\n",
      "elapsed time 563.6648063659668\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3937 - accuracy: 0.8633\n",
      "batch loss: 0.39367741346359253\n",
      "batch accuracy: 0.86328125\n",
      "doing 18 / 277\n",
      "elapsed time 601.5589418411255\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3904 - accuracy: 0.8623\n",
      "batch loss: 0.3904179036617279\n",
      "batch accuracy: 0.8623046875\n",
      "doing 19 / 277\n",
      "elapsed time 629.5058915615082\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4126 - accuracy: 0.8652\n",
      "batch loss: 0.4125606417655945\n",
      "batch accuracy: 0.865234375\n",
      "doing 20 / 277\n",
      "elapsed time 668.5831997394562\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4578 - accuracy: 0.8408\n",
      "batch loss: 0.45783862471580505\n",
      "batch accuracy: 0.8408203125\n",
      "doing 21 / 277\n",
      "elapsed time 701.1143803596497\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3985 - accuracy: 0.8555\n",
      "batch loss: 0.39850497245788574\n",
      "batch accuracy: 0.85546875\n",
      "doing 22 / 277\n",
      "elapsed time 743.0146291255951\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4308 - accuracy: 0.8535\n",
      "batch loss: 0.4307975769042969\n",
      "batch accuracy: 0.853515625\n",
      "doing 23 / 277\n",
      "elapsed time 788.6832466125488\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4085 - accuracy: 0.8535\n",
      "batch loss: 0.40850651264190674\n",
      "batch accuracy: 0.853515625\n",
      "doing 24 / 277\n",
      "elapsed time 854.0504412651062\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3958 - accuracy: 0.8535\n",
      "batch loss: 0.3957673907279968\n",
      "batch accuracy: 0.853515625\n",
      "doing 25 / 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 933.3609871864319\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4510 - accuracy: 0.8438\n",
      "batch loss: 0.4509996771812439\n",
      "batch accuracy: 0.84375\n",
      "doing 26 / 277\n",
      "elapsed time 1014.7861590385437\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4258 - accuracy: 0.8516\n",
      "batch loss: 0.4257984459400177\n",
      "batch accuracy: 0.8515625\n",
      "doing 27 / 277\n",
      "elapsed time 1089.2418265342712\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3954 - accuracy: 0.8594\n",
      "batch loss: 0.3954489827156067\n",
      "batch accuracy: 0.859375\n",
      "doing 28 / 277\n",
      "elapsed time 1161.6166939735413\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4283 - accuracy: 0.8564\n",
      "batch loss: 0.42827922105789185\n",
      "batch accuracy: 0.8564453125\n",
      "doing 29 / 277\n",
      "elapsed time 1234.2989814281464\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4425 - accuracy: 0.8486\n",
      "batch loss: 0.44254186749458313\n",
      "batch accuracy: 0.8486328125\n",
      "doing 30 / 277\n",
      "elapsed time 1305.828155040741\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3947 - accuracy: 0.8486\n",
      "batch loss: 0.3947036862373352\n",
      "batch accuracy: 0.8486328125\n",
      "doing 31 / 277\n",
      "elapsed time 1378.3588585853577\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4239 - accuracy: 0.8535\n",
      "batch loss: 0.423903226852417\n",
      "batch accuracy: 0.853515625\n",
      "doing 32 / 277\n",
      "elapsed time 1454.9083573818207\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3399 - accuracy: 0.8750\n",
      "batch loss: 0.33991193771362305\n",
      "batch accuracy: 0.875\n",
      "doing 33 / 277\n",
      "elapsed time 1532.6637382507324\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3799 - accuracy: 0.8623\n",
      "batch loss: 0.3798823058605194\n",
      "batch accuracy: 0.8623046875\n",
      "doing 34 / 277\n",
      "elapsed time 1612.9328808784485\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4381 - accuracy: 0.8545\n",
      "batch loss: 0.4381444752216339\n",
      "batch accuracy: 0.8544921875\n",
      "doing 35 / 277\n",
      "elapsed time 1693.5564818382263\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3885 - accuracy: 0.8574\n",
      "batch loss: 0.38849958777427673\n",
      "batch accuracy: 0.857421875\n",
      "doing 36 / 277\n",
      "elapsed time 1778.3832037448883\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4035 - accuracy: 0.8564\n",
      "batch loss: 0.4034687876701355\n",
      "batch accuracy: 0.8564453125\n",
      "doing 37 / 277\n",
      "elapsed time 1860.9407629966736\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3691 - accuracy: 0.8623\n",
      "batch loss: 0.36906781792640686\n",
      "batch accuracy: 0.8623046875\n",
      "doing 38 / 277\n",
      "elapsed time 1942.0208032131195\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3843 - accuracy: 0.8555\n",
      "batch loss: 0.38432577252388\n",
      "batch accuracy: 0.85546875\n",
      "doing 39 / 277\n",
      "elapsed time 2035.4601850509644\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3847 - accuracy: 0.8740\n",
      "batch loss: 0.3847261965274811\n",
      "batch accuracy: 0.8740234375\n",
      "doing 40 / 277\n",
      "elapsed time 2114.2834615707397\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3903 - accuracy: 0.8770\n",
      "batch loss: 0.39025384187698364\n",
      "batch accuracy: 0.876953125\n",
      "doing 41 / 277\n",
      "elapsed time 2197.3126928806305\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4050 - accuracy: 0.8711\n",
      "batch loss: 0.404998242855072\n",
      "batch accuracy: 0.87109375\n",
      "doing 42 / 277\n",
      "elapsed time 2283.2271275520325\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3693 - accuracy: 0.8691\n",
      "batch loss: 0.3693428337574005\n",
      "batch accuracy: 0.869140625\n",
      "doing 43 / 277\n",
      "elapsed time 2360.9390456676483\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4333 - accuracy: 0.8584\n",
      "batch loss: 0.4332638382911682\n",
      "batch accuracy: 0.8583984375\n",
      "doing 44 / 277\n",
      "elapsed time 2441.18612408638\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3749 - accuracy: 0.8721\n",
      "batch loss: 0.37485992908477783\n",
      "batch accuracy: 0.8720703125\n",
      "doing 45 / 277\n",
      "elapsed time 2518.4672462940216\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3818 - accuracy: 0.8760\n",
      "batch loss: 0.38181501626968384\n",
      "batch accuracy: 0.8759765625\n",
      "doing 46 / 277\n",
      "elapsed time 2596.733538866043\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3782 - accuracy: 0.8604\n",
      "batch loss: 0.37824729084968567\n",
      "batch accuracy: 0.8603515625\n",
      "doing 47 / 277\n",
      "elapsed time 2681.51265001297\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3652 - accuracy: 0.8691\n",
      "batch loss: 0.3652300536632538\n",
      "batch accuracy: 0.869140625\n",
      "doing 48 / 277\n",
      "elapsed time 2769.9443719387054\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3730 - accuracy: 0.8584\n",
      "batch loss: 0.3730033338069916\n",
      "batch accuracy: 0.8583984375\n",
      "doing 49 / 277\n",
      "elapsed time 2853.623774290085\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3918 - accuracy: 0.8633\n",
      "batch loss: 0.39182335138320923\n",
      "batch accuracy: 0.86328125\n",
      "doing 50 / 277\n",
      "elapsed time 2921.2430653572083\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3570 - accuracy: 0.8789\n",
      "batch loss: 0.3569755554199219\n",
      "batch accuracy: 0.87890625\n",
      "doing 51 / 277\n",
      "elapsed time 2966.040058374405\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3964 - accuracy: 0.8447\n",
      "batch loss: 0.39642956852912903\n",
      "batch accuracy: 0.8447265625\n",
      "doing 52 / 277\n",
      "elapsed time 3041.9434475898743\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3990 - accuracy: 0.8516\n",
      "batch loss: 0.398979127407074\n",
      "batch accuracy: 0.8515625\n",
      "doing 53 / 277\n",
      "elapsed time 3089.5936732292175\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4035 - accuracy: 0.8496\n",
      "batch loss: 0.4034728407859802\n",
      "batch accuracy: 0.849609375\n",
      "doing 54 / 277\n",
      "elapsed time 3175.8491249084473\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3663 - accuracy: 0.8721\n",
      "batch loss: 0.36629077792167664\n",
      "batch accuracy: 0.8720703125\n",
      "doing 55 / 277\n",
      "elapsed time 3259.295706987381\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3776 - accuracy: 0.8584\n",
      "batch loss: 0.3776095509529114\n",
      "batch accuracy: 0.8583984375\n",
      "doing 56 / 277\n",
      "elapsed time 3342.33628988266\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3823 - accuracy: 0.8711\n",
      "batch loss: 0.3823052644729614\n",
      "batch accuracy: 0.87109375\n",
      "doing 57 / 277\n",
      "elapsed time 3427.027873277664\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3424 - accuracy: 0.8877\n",
      "batch loss: 0.3423907160758972\n",
      "batch accuracy: 0.8876953125\n",
      "doing 58 / 277\n",
      "elapsed time 3512.700453519821\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3512 - accuracy: 0.8789\n",
      "batch loss: 0.35117632150650024\n",
      "batch accuracy: 0.87890625\n",
      "doing 59 / 277\n",
      "elapsed time 3593.5682888031006\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3444 - accuracy: 0.8750\n",
      "batch loss: 0.3444344997406006\n",
      "batch accuracy: 0.875\n",
      "doing 60 / 277\n",
      "elapsed time 3671.9937081336975\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3966 - accuracy: 0.8672\n",
      "batch loss: 0.39656543731689453\n",
      "batch accuracy: 0.8671875\n",
      "doing 61 / 277\n",
      "elapsed time 3753.8991973400116\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3047 - accuracy: 0.8994\n",
      "batch loss: 0.3047191798686981\n",
      "batch accuracy: 0.8994140625\n",
      "doing 62 / 277\n",
      "elapsed time 3836.3732149600983\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3523 - accuracy: 0.8750\n",
      "batch loss: 0.35227853059768677\n",
      "batch accuracy: 0.875\n",
      "doing 63 / 277\n",
      "elapsed time 3920.075742483139\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3385 - accuracy: 0.8760\n",
      "batch loss: 0.33854371309280396\n",
      "batch accuracy: 0.8759765625\n",
      "doing 64 / 277\n",
      "elapsed time 4003.454059123993\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3610 - accuracy: 0.8770\n",
      "batch loss: 0.3609711825847626\n",
      "batch accuracy: 0.876953125\n",
      "doing 65 / 277\n",
      "elapsed time 4088.0504813194275\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3292 - accuracy: 0.8799\n",
      "batch loss: 0.329179048538208\n",
      "batch accuracy: 0.8798828125\n",
      "doing 66 / 277\n",
      "elapsed time 4172.042706251144\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3462 - accuracy: 0.8701\n",
      "batch loss: 0.34622836112976074\n",
      "batch accuracy: 0.8701171875\n",
      "doing 67 / 277\n",
      "elapsed time 4254.840998649597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3643 - accuracy: 0.8701\n",
      "batch loss: 0.36426523327827454\n",
      "batch accuracy: 0.8701171875\n",
      "doing 68 / 277\n",
      "elapsed time 4335.140256404877\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3687 - accuracy: 0.8691\n",
      "batch loss: 0.36871522665023804\n",
      "batch accuracy: 0.869140625\n",
      "doing 69 / 277\n",
      "elapsed time 4429.778898715973\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3488 - accuracy: 0.8750\n",
      "batch loss: 0.348818302154541\n",
      "batch accuracy: 0.875\n",
      "doing 70 / 277\n",
      "elapsed time 4531.578082561493\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3220 - accuracy: 0.8789\n",
      "batch loss: 0.3220292925834656\n",
      "batch accuracy: 0.87890625\n",
      "doing 71 / 277\n",
      "elapsed time 4647.969127416611\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3209 - accuracy: 0.8848\n",
      "batch loss: 0.3208776116371155\n",
      "batch accuracy: 0.884765625\n",
      "doing 72 / 277\n",
      "elapsed time 4708.648528814316\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3693 - accuracy: 0.8613\n",
      "batch loss: 0.3693130314350128\n",
      "batch accuracy: 0.861328125\n",
      "doing 73 / 277\n",
      "elapsed time 4771.9612646102905\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3460 - accuracy: 0.8809\n",
      "batch loss: 0.34601926803588867\n",
      "batch accuracy: 0.880859375\n",
      "doing 74 / 277\n",
      "elapsed time 4835.245116233826\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3215 - accuracy: 0.8818\n",
      "batch loss: 0.32153138518333435\n",
      "batch accuracy: 0.8818359375\n",
      "doing 75 / 277\n",
      "elapsed time 4898.421356916428\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3608 - accuracy: 0.8691\n",
      "batch loss: 0.36082321405410767\n",
      "batch accuracy: 0.869140625\n",
      "doing 76 / 277\n",
      "elapsed time 4967.370051383972\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3717 - accuracy: 0.8760\n",
      "batch loss: 0.37172478437423706\n",
      "batch accuracy: 0.8759765625\n",
      "doing 77 / 277\n",
      "elapsed time 5031.744934558868\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3740 - accuracy: 0.8682\n",
      "batch loss: 0.3740013539791107\n",
      "batch accuracy: 0.8681640625\n",
      "doing 78 / 277\n",
      "elapsed time 5096.033472299576\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3602 - accuracy: 0.8828\n",
      "batch loss: 0.3602250814437866\n",
      "batch accuracy: 0.8828125\n",
      "doing 79 / 277\n",
      "elapsed time 5160.023818969727\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3566 - accuracy: 0.8730\n",
      "batch loss: 0.3566347658634186\n",
      "batch accuracy: 0.873046875\n",
      "doing 80 / 277\n",
      "elapsed time 5225.584824085236\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3375 - accuracy: 0.8770\n",
      "batch loss: 0.33745142817497253\n",
      "batch accuracy: 0.876953125\n",
      "doing 81 / 277\n",
      "elapsed time 5348.492013216019\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3671 - accuracy: 0.8818\n",
      "batch loss: 0.3671312928199768\n",
      "batch accuracy: 0.8818359375\n",
      "doing 82 / 277\n",
      "elapsed time 5474.8107817173\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3374 - accuracy: 0.8750\n",
      "batch loss: 0.3374116122722626\n",
      "batch accuracy: 0.875\n",
      "doing 83 / 277\n",
      "elapsed time 5598.202112674713\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3595 - accuracy: 0.8730\n",
      "batch loss: 0.3595273494720459\n",
      "batch accuracy: 0.873046875\n",
      "doing 84 / 277\n",
      "elapsed time 5721.145604133606\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3888 - accuracy: 0.8604\n",
      "batch loss: 0.3887775242328644\n",
      "batch accuracy: 0.8603515625\n",
      "doing 85 / 277\n",
      "elapsed time 5844.935287952423\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4284 - accuracy: 0.8594\n",
      "batch loss: 0.4283928871154785\n",
      "batch accuracy: 0.859375\n",
      "doing 86 / 277\n",
      "elapsed time 5967.872907161713\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3467 - accuracy: 0.8779\n",
      "batch loss: 0.3466510772705078\n",
      "batch accuracy: 0.8779296875\n",
      "doing 87 / 277\n",
      "elapsed time 6094.284423589706\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3998 - accuracy: 0.8574\n",
      "batch loss: 0.39983969926834106\n",
      "batch accuracy: 0.857421875\n",
      "doing 88 / 277\n",
      "elapsed time 6218.737730264664\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4451 - accuracy: 0.8516\n",
      "batch loss: 0.4450661242008209\n",
      "batch accuracy: 0.8515625\n",
      "doing 89 / 277\n",
      "elapsed time 6345.711202383041\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3868 - accuracy: 0.8535\n",
      "batch loss: 0.3868263363838196\n",
      "batch accuracy: 0.853515625\n",
      "doing 90 / 277\n",
      "elapsed time 6473.512907505035\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3969 - accuracy: 0.8584\n",
      "batch loss: 0.3968864679336548\n",
      "batch accuracy: 0.8583984375\n",
      "doing 91 / 277\n",
      "elapsed time 6593.549918174744\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4063 - accuracy: 0.8516\n",
      "batch loss: 0.40631431341171265\n",
      "batch accuracy: 0.8515625\n",
      "doing 92 / 277\n",
      "elapsed time 6712.49244093895\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4058 - accuracy: 0.8564\n",
      "batch loss: 0.40575677156448364\n",
      "batch accuracy: 0.8564453125\n",
      "doing 93 / 277\n",
      "elapsed time 6835.927517652512\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3089 - accuracy: 0.8867\n",
      "batch loss: 0.3088669776916504\n",
      "batch accuracy: 0.88671875\n",
      "doing 94 / 277\n",
      "elapsed time 6961.797563314438\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3955 - accuracy: 0.8584\n",
      "batch loss: 0.39545726776123047\n",
      "batch accuracy: 0.8583984375\n",
      "doing 95 / 277\n",
      "elapsed time 7084.218495845795\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3743 - accuracy: 0.8525\n",
      "batch loss: 0.3742922842502594\n",
      "batch accuracy: 0.8525390625\n",
      "doing 96 / 277\n",
      "elapsed time 7207.316016197205\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3404 - accuracy: 0.8730\n",
      "batch loss: 0.3403843343257904\n",
      "batch accuracy: 0.873046875\n",
      "doing 97 / 277\n",
      "elapsed time 7330.034598827362\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3053 - accuracy: 0.8828\n",
      "batch loss: 0.30530068278312683\n",
      "batch accuracy: 0.8828125\n",
      "doing 98 / 277\n",
      "elapsed time 7453.603134870529\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3426 - accuracy: 0.8828\n",
      "batch loss: 0.3425610661506653\n",
      "batch accuracy: 0.8828125\n",
      "doing 99 / 277\n",
      "elapsed time 7576.9625334739685\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3944 - accuracy: 0.8701\n",
      "batch loss: 0.3944098949432373\n",
      "batch accuracy: 0.8701171875\n",
      "doing 100 / 277\n",
      "elapsed time 7700.686049461365\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2977 - accuracy: 0.8975\n",
      "batch loss: 0.2977197766304016\n",
      "batch accuracy: 0.8974609375\n",
      "doing 101 / 277\n",
      "elapsed time 7828.198278188705\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3426 - accuracy: 0.8604\n",
      "batch loss: 0.3425535261631012\n",
      "batch accuracy: 0.8603515625\n",
      "doing 102 / 277\n",
      "elapsed time 7949.089272737503\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3461 - accuracy: 0.8867\n",
      "batch loss: 0.34605130553245544\n",
      "batch accuracy: 0.88671875\n",
      "doing 103 / 277\n",
      "elapsed time 8073.036800861359\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3064 - accuracy: 0.8877\n",
      "batch loss: 0.30639439821243286\n",
      "batch accuracy: 0.8876953125\n",
      "doing 104 / 277\n",
      "elapsed time 8198.295838832855\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3336 - accuracy: 0.8848\n",
      "batch loss: 0.33361780643463135\n",
      "batch accuracy: 0.884765625\n",
      "doing 105 / 277\n",
      "elapsed time 8320.426170825958\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3370 - accuracy: 0.8848\n",
      "batch loss: 0.3369516134262085\n",
      "batch accuracy: 0.884765625\n",
      "doing 106 / 277\n",
      "elapsed time 8444.446198940277\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3830 - accuracy: 0.8721\n",
      "batch loss: 0.383015513420105\n",
      "batch accuracy: 0.8720703125\n",
      "doing 107 / 277\n",
      "elapsed time 8599.221455574036\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3448 - accuracy: 0.8818\n",
      "batch loss: 0.34476834535598755\n",
      "batch accuracy: 0.8818359375\n",
      "doing 108 / 277\n",
      "elapsed time 8799.150757312775\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3263 - accuracy: 0.8887\n",
      "batch loss: 0.32634633779525757\n",
      "batch accuracy: 0.888671875\n",
      "doing 109 / 277\n",
      "elapsed time 8998.626794576645\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4056 - accuracy: 0.8584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: 0.4056428372859955\n",
      "batch accuracy: 0.8583984375\n",
      "doing 110 / 277\n",
      "elapsed time 9202.444400787354\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3544 - accuracy: 0.8760\n",
      "batch loss: 0.3544169068336487\n",
      "batch accuracy: 0.8759765625\n",
      "doing 111 / 277\n",
      "elapsed time 9408.18256020546\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3324 - accuracy: 0.8818\n",
      "batch loss: 0.33241045475006104\n",
      "batch accuracy: 0.8818359375\n",
      "doing 112 / 277\n",
      "elapsed time 9618.235576868057\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3342 - accuracy: 0.8682\n",
      "batch loss: 0.33415788412094116\n",
      "batch accuracy: 0.8681640625\n",
      "doing 113 / 277\n",
      "elapsed time 9824.630115509033\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3425 - accuracy: 0.8965\n",
      "batch loss: 0.34245654940605164\n",
      "batch accuracy: 0.896484375\n",
      "doing 114 / 277\n",
      "elapsed time 10037.96241402626\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3157 - accuracy: 0.8936\n",
      "batch loss: 0.3156806230545044\n",
      "batch accuracy: 0.8935546875\n",
      "doing 115 / 277\n",
      "elapsed time 10252.356932401657\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3733 - accuracy: 0.8604\n",
      "batch loss: 0.37325429916381836\n",
      "batch accuracy: 0.8603515625\n",
      "doing 116 / 277\n",
      "elapsed time 10460.336826562881\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3425 - accuracy: 0.8789\n",
      "batch loss: 0.3424985110759735\n",
      "batch accuracy: 0.87890625\n",
      "doing 117 / 277\n",
      "elapsed time 10667.008459091187\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3908 - accuracy: 0.8623\n",
      "batch loss: 0.3908146619796753\n",
      "batch accuracy: 0.8623046875\n",
      "doing 118 / 277\n",
      "elapsed time 10874.754110574722\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3190 - accuracy: 0.8809\n",
      "batch loss: 0.3190460801124573\n",
      "batch accuracy: 0.880859375\n",
      "doing 119 / 277\n",
      "elapsed time 11077.465957641602\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3429 - accuracy: 0.8740\n",
      "batch loss: 0.3429045081138611\n",
      "batch accuracy: 0.8740234375\n",
      "doing 120 / 277\n",
      "elapsed time 11281.769898176193\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3443 - accuracy: 0.8711\n",
      "batch loss: 0.3443222641944885\n",
      "batch accuracy: 0.87109375\n",
      "doing 121 / 277\n",
      "elapsed time 11490.359122514725\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3396 - accuracy: 0.8721\n",
      "batch loss: 0.33958256244659424\n",
      "batch accuracy: 0.8720703125\n",
      "doing 122 / 277\n",
      "elapsed time 11691.137230873108\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3469 - accuracy: 0.8750\n",
      "batch loss: 0.34690579771995544\n",
      "batch accuracy: 0.875\n",
      "doing 123 / 277\n",
      "elapsed time 11896.777035474777\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3280 - accuracy: 0.8867\n",
      "batch loss: 0.32797810435295105\n",
      "batch accuracy: 0.88671875\n",
      "doing 124 / 277\n",
      "elapsed time 12098.468716859818\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3543 - accuracy: 0.8721\n",
      "batch loss: 0.3543185591697693\n",
      "batch accuracy: 0.8720703125\n",
      "doing 125 / 277\n",
      "elapsed time 12304.921402931213\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3153 - accuracy: 0.8848\n",
      "batch loss: 0.31533610820770264\n",
      "batch accuracy: 0.884765625\n",
      "doing 126 / 277\n",
      "elapsed time 12506.791859865189\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3602 - accuracy: 0.8633\n",
      "batch loss: 0.36021673679351807\n",
      "batch accuracy: 0.86328125\n",
      "doing 127 / 277\n",
      "elapsed time 12709.248460531235\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3574 - accuracy: 0.8701\n",
      "batch loss: 0.35741427540779114\n",
      "batch accuracy: 0.8701171875\n",
      "doing 128 / 277\n",
      "elapsed time 12905.440091609955\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2791 - accuracy: 0.9082\n",
      "batch loss: 0.2791490852832794\n",
      "batch accuracy: 0.908203125\n",
      "doing 129 / 277\n",
      "elapsed time 13097.569062709808\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3364 - accuracy: 0.8799\n",
      "batch loss: 0.3364224135875702\n",
      "batch accuracy: 0.8798828125\n",
      "doing 130 / 277\n",
      "elapsed time 13302.666537284851\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3204 - accuracy: 0.8809\n",
      "batch loss: 0.3204030990600586\n",
      "batch accuracy: 0.880859375\n",
      "doing 131 / 277\n",
      "elapsed time 13500.033833265305\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3213 - accuracy: 0.8818\n",
      "batch loss: 0.3212987780570984\n",
      "batch accuracy: 0.8818359375\n",
      "doing 132 / 277\n",
      "elapsed time 13697.680709838867\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3102 - accuracy: 0.8857\n",
      "batch loss: 0.31022658944129944\n",
      "batch accuracy: 0.8857421875\n",
      "doing 133 / 277\n",
      "elapsed time 13896.588422060013\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3005 - accuracy: 0.8848\n",
      "batch loss: 0.3004918694496155\n",
      "batch accuracy: 0.884765625\n",
      "doing 134 / 277\n",
      "elapsed time 14091.427688121796\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2951 - accuracy: 0.8916\n",
      "batch loss: 0.2950597107410431\n",
      "batch accuracy: 0.8916015625\n",
      "doing 135 / 277\n",
      "elapsed time 14286.948204278946\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3145 - accuracy: 0.8838\n",
      "batch loss: 0.31447869539260864\n",
      "batch accuracy: 0.8837890625\n",
      "doing 136 / 277\n",
      "elapsed time 14483.126992702484\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2818 - accuracy: 0.9014\n",
      "batch loss: 0.2818068265914917\n",
      "batch accuracy: 0.9013671875\n",
      "doing 137 / 277\n",
      "elapsed time 14674.79463815689\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3103 - accuracy: 0.8887\n",
      "batch loss: 0.3103068470954895\n",
      "batch accuracy: 0.888671875\n",
      "doing 138 / 277\n",
      "elapsed time 14856.403943061829\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3147 - accuracy: 0.8916\n",
      "batch loss: 0.31471726298332214\n",
      "batch accuracy: 0.8916015625\n",
      "doing 139 / 277\n",
      "elapsed time 15044.390409708023\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2962 - accuracy: 0.8945\n",
      "batch loss: 0.2961961328983307\n",
      "batch accuracy: 0.89453125\n",
      "doing 140 / 277\n",
      "elapsed time 15234.540635585785\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3220 - accuracy: 0.8760\n",
      "batch loss: 0.3219512403011322\n",
      "batch accuracy: 0.8759765625\n",
      "doing 141 / 277\n",
      "elapsed time 15417.75570821762\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2913 - accuracy: 0.9004\n",
      "batch loss: 0.2912890315055847\n",
      "batch accuracy: 0.900390625\n",
      "doing 142 / 277\n",
      "elapsed time 15591.467148303986\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3390 - accuracy: 0.8818\n",
      "batch loss: 0.33896276354789734\n",
      "batch accuracy: 0.8818359375\n",
      "doing 143 / 277\n",
      "elapsed time 15787.425331115723\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2714 - accuracy: 0.9023\n",
      "batch loss: 0.2714282274246216\n",
      "batch accuracy: 0.90234375\n",
      "doing 144 / 277\n",
      "elapsed time 15970.462906837463\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2918 - accuracy: 0.9014\n",
      "batch loss: 0.2918310761451721\n",
      "batch accuracy: 0.9013671875\n",
      "doing 145 / 277\n",
      "elapsed time 16144.979580640793\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2965 - accuracy: 0.8848\n",
      "batch loss: 0.29646849632263184\n",
      "batch accuracy: 0.884765625\n",
      "doing 146 / 277\n",
      "elapsed time 16348.839135169983\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3383 - accuracy: 0.8828\n",
      "batch loss: 0.3382720947265625\n",
      "batch accuracy: 0.8828125\n",
      "doing 147 / 277\n",
      "elapsed time 16544.900009155273\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3088 - accuracy: 0.8965\n",
      "batch loss: 0.3087681531906128\n",
      "batch accuracy: 0.896484375\n",
      "doing 148 / 277\n",
      "elapsed time 16732.118700027466\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2536 - accuracy: 0.9092\n",
      "batch loss: 0.2536487877368927\n",
      "batch accuracy: 0.9091796875\n",
      "doing 149 / 277\n",
      "elapsed time 16915.32505965233\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3576 - accuracy: 0.8730\n",
      "batch loss: 0.35761314630508423\n",
      "batch accuracy: 0.873046875\n",
      "doing 150 / 277\n",
      "elapsed time 17086.85584449768\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3012 - accuracy: 0.8926\n",
      "batch loss: 0.3011978566646576\n",
      "batch accuracy: 0.892578125\n",
      "doing 151 / 277\n",
      "elapsed time 17288.34224796295\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2741 - accuracy: 0.8945\n",
      "batch loss: 0.27411752939224243\n",
      "batch accuracy: 0.89453125\n",
      "doing 152 / 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 17483.81814265251\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3164 - accuracy: 0.8926\n",
      "batch loss: 0.3163532018661499\n",
      "batch accuracy: 0.892578125\n",
      "doing 153 / 277\n",
      "elapsed time 17672.886982679367\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3252 - accuracy: 0.9014\n",
      "batch loss: 0.3252077102661133\n",
      "batch accuracy: 0.9013671875\n",
      "doing 154 / 277\n",
      "elapsed time 17849.20499229431\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3516 - accuracy: 0.8750\n",
      "batch loss: 0.35158205032348633\n",
      "batch accuracy: 0.875\n",
      "doing 155 / 277\n",
      "elapsed time 18026.71620941162\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2716 - accuracy: 0.9082\n",
      "batch loss: 0.271606981754303\n",
      "batch accuracy: 0.908203125\n",
      "doing 156 / 277\n",
      "elapsed time 18220.14300918579\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3696 - accuracy: 0.8721\n",
      "batch loss: 0.36962172389030457\n",
      "batch accuracy: 0.8720703125\n",
      "doing 157 / 277\n",
      "elapsed time 18404.70503783226\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3357 - accuracy: 0.8896\n",
      "batch loss: 0.3357231914997101\n",
      "batch accuracy: 0.8896484375\n",
      "doing 158 / 277\n",
      "elapsed time 18586.25202536583\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2858 - accuracy: 0.8926\n",
      "batch loss: 0.28576818108558655\n",
      "batch accuracy: 0.892578125\n",
      "doing 159 / 277\n",
      "elapsed time 18771.623584508896\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2959 - accuracy: 0.9023\n",
      "batch loss: 0.29587462544441223\n",
      "batch accuracy: 0.90234375\n",
      "doing 160 / 277\n",
      "elapsed time 18960.969571828842\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3032 - accuracy: 0.9062\n",
      "batch loss: 0.30318331718444824\n",
      "batch accuracy: 0.90625\n",
      "doing 161 / 277\n",
      "elapsed time 19145.545475006104\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2676 - accuracy: 0.8994\n",
      "batch loss: 0.2675762474536896\n",
      "batch accuracy: 0.8994140625\n",
      "doing 162 / 277\n",
      "elapsed time 19335.34655189514\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2837 - accuracy: 0.8955\n",
      "batch loss: 0.283736914396286\n",
      "batch accuracy: 0.8955078125\n",
      "doing 163 / 277\n",
      "elapsed time 19519.14511537552\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3067 - accuracy: 0.8877\n",
      "batch loss: 0.3067114055156708\n",
      "batch accuracy: 0.8876953125\n",
      "doing 164 / 277\n",
      "elapsed time 19691.642181158066\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3011 - accuracy: 0.8896\n",
      "batch loss: 0.3010610044002533\n",
      "batch accuracy: 0.8896484375\n",
      "doing 165 / 277\n",
      "elapsed time 19873.12852692604\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3129 - accuracy: 0.8936\n",
      "batch loss: 0.31292158365249634\n",
      "batch accuracy: 0.8935546875\n",
      "doing 166 / 277\n",
      "elapsed time 20054.81889152527\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2774 - accuracy: 0.9072\n",
      "batch loss: 0.2773740291595459\n",
      "batch accuracy: 0.9072265625\n",
      "doing 167 / 277\n",
      "elapsed time 20222.728900909424\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2399 - accuracy: 0.9131\n",
      "batch loss: 0.23990947008132935\n",
      "batch accuracy: 0.9130859375\n",
      "doing 168 / 277\n",
      "elapsed time 20388.917887210846\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3037 - accuracy: 0.8984\n",
      "batch loss: 0.3036653697490692\n",
      "batch accuracy: 0.8984375\n",
      "doing 169 / 277\n",
      "elapsed time 20557.292182683945\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3002 - accuracy: 0.8936\n",
      "batch loss: 0.30024832487106323\n",
      "batch accuracy: 0.8935546875\n",
      "doing 170 / 277\n",
      "elapsed time 20728.960736513138\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2934 - accuracy: 0.8994\n",
      "batch loss: 0.29342496395111084\n",
      "batch accuracy: 0.8994140625\n",
      "doing 171 / 277\n",
      "elapsed time 20899.70083975792\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2763 - accuracy: 0.9082\n",
      "batch loss: 0.27627062797546387\n",
      "batch accuracy: 0.908203125\n",
      "doing 172 / 277\n",
      "elapsed time 21067.725868225098\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3424 - accuracy: 0.8877\n",
      "batch loss: 0.34237420558929443\n",
      "batch accuracy: 0.8876953125\n",
      "doing 173 / 277\n",
      "elapsed time 21230.47950077057\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2646 - accuracy: 0.8975\n",
      "batch loss: 0.2645922601222992\n",
      "batch accuracy: 0.8974609375\n",
      "doing 174 / 277\n",
      "elapsed time 21395.363095998764\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3096 - accuracy: 0.8799\n",
      "batch loss: 0.30960410833358765\n",
      "batch accuracy: 0.8798828125\n",
      "doing 175 / 277\n",
      "elapsed time 21565.60402584076\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2764 - accuracy: 0.8984\n",
      "batch loss: 0.27637800574302673\n",
      "batch accuracy: 0.8984375\n",
      "doing 176 / 277\n",
      "elapsed time 21719.146332502365\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2820 - accuracy: 0.8994\n",
      "batch loss: 0.2819712460041046\n",
      "batch accuracy: 0.8994140625\n",
      "doing 177 / 277\n",
      "elapsed time 21885.63990330696\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2964 - accuracy: 0.8848\n",
      "batch loss: 0.2963751256465912\n",
      "batch accuracy: 0.884765625\n",
      "doing 178 / 277\n",
      "elapsed time 22055.933645248413\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2460 - accuracy: 0.9092\n",
      "batch loss: 0.24598246812820435\n",
      "batch accuracy: 0.9091796875\n",
      "doing 179 / 277\n",
      "elapsed time 22220.352078676224\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3138 - accuracy: 0.9014\n",
      "batch loss: 0.3138017952442169\n",
      "batch accuracy: 0.9013671875\n",
      "doing 180 / 277\n",
      "elapsed time 22366.351499080658\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3028 - accuracy: 0.8916\n",
      "batch loss: 0.30278486013412476\n",
      "batch accuracy: 0.8916015625\n",
      "doing 181 / 277\n",
      "elapsed time 22518.33811402321\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2795 - accuracy: 0.9072\n",
      "batch loss: 0.27950143814086914\n",
      "batch accuracy: 0.9072265625\n",
      "doing 182 / 277\n",
      "elapsed time 22685.84246110916\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2724 - accuracy: 0.9033\n",
      "batch loss: 0.27241554856300354\n",
      "batch accuracy: 0.9033203125\n",
      "doing 183 / 277\n",
      "elapsed time 22839.913168668747\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2790 - accuracy: 0.8945\n",
      "batch loss: 0.2790387272834778\n",
      "batch accuracy: 0.89453125\n",
      "doing 184 / 277\n",
      "elapsed time 22988.26221036911\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2788 - accuracy: 0.9023\n",
      "batch loss: 0.27877989411354065\n",
      "batch accuracy: 0.90234375\n",
      "doing 185 / 277\n",
      "elapsed time 23132.541429758072\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2416 - accuracy: 0.9209\n",
      "batch loss: 0.24157889187335968\n",
      "batch accuracy: 0.9208984375\n",
      "doing 186 / 277\n",
      "elapsed time 23282.049550533295\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3215 - accuracy: 0.8818\n",
      "batch loss: 0.32150399684906006\n",
      "batch accuracy: 0.8818359375\n",
      "doing 187 / 277\n",
      "elapsed time 23448.997590065002\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3082 - accuracy: 0.9004\n",
      "batch loss: 0.30816853046417236\n",
      "batch accuracy: 0.900390625\n",
      "doing 188 / 277\n",
      "elapsed time 23613.529925107956\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2226 - accuracy: 0.9189\n",
      "batch loss: 0.222602978348732\n",
      "batch accuracy: 0.9189453125\n",
      "doing 189 / 277\n",
      "elapsed time 23770.05631518364\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3079 - accuracy: 0.8926\n",
      "batch loss: 0.3079143166542053\n",
      "batch accuracy: 0.892578125\n",
      "doing 190 / 277\n",
      "elapsed time 23929.77614736557\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2784 - accuracy: 0.8994\n",
      "batch loss: 0.27835842967033386\n",
      "batch accuracy: 0.8994140625\n",
      "doing 191 / 277\n",
      "elapsed time 24072.356887817383\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2631 - accuracy: 0.9053\n",
      "batch loss: 0.26309776306152344\n",
      "batch accuracy: 0.9052734375\n",
      "doing 192 / 277\n",
      "elapsed time 24217.973034381866\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2736 - accuracy: 0.8984\n",
      "batch loss: 0.27357378602027893\n",
      "batch accuracy: 0.8984375\n",
      "doing 193 / 277\n",
      "elapsed time 24363.47064781189\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2803 - accuracy: 0.9004\n",
      "batch loss: 0.28032806515693665\n",
      "batch accuracy: 0.900390625\n",
      "doing 194 / 277\n",
      "elapsed time 24509.403061151505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3051 - accuracy: 0.8887\n",
      "batch loss: 0.30509576201438904\n",
      "batch accuracy: 0.888671875\n",
      "doing 195 / 277\n",
      "elapsed time 24644.279940843582\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2753 - accuracy: 0.9053\n",
      "batch loss: 0.2752588987350464\n",
      "batch accuracy: 0.9052734375\n",
      "doing 196 / 277\n",
      "elapsed time 24778.10321354866\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2703 - accuracy: 0.8975\n",
      "batch loss: 0.2702537178993225\n",
      "batch accuracy: 0.8974609375\n",
      "doing 197 / 277\n",
      "elapsed time 24910.46700501442\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2856 - accuracy: 0.9033\n",
      "batch loss: 0.2855856716632843\n",
      "batch accuracy: 0.9033203125\n",
      "doing 198 / 277\n",
      "elapsed time 25047.047575712204\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2784 - accuracy: 0.9023\n",
      "batch loss: 0.27840906381607056\n",
      "batch accuracy: 0.90234375\n",
      "doing 199 / 277\n",
      "elapsed time 25184.052731990814\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2596 - accuracy: 0.9004\n",
      "batch loss: 0.2596479058265686\n",
      "batch accuracy: 0.900390625\n",
      "doing 200 / 277\n",
      "elapsed time 25315.785135507584\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2970 - accuracy: 0.8926\n",
      "batch loss: 0.29699134826660156\n",
      "batch accuracy: 0.892578125\n",
      "doing 201 / 277\n",
      "elapsed time 25443.381739377975\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2813 - accuracy: 0.8984\n",
      "batch loss: 0.2813296616077423\n",
      "batch accuracy: 0.8984375\n",
      "doing 202 / 277\n",
      "elapsed time 25570.67111682892\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2559 - accuracy: 0.9023\n",
      "batch loss: 0.25592827796936035\n",
      "batch accuracy: 0.90234375\n",
      "doing 203 / 277\n",
      "elapsed time 25694.252743005753\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2705 - accuracy: 0.8955\n",
      "batch loss: 0.2704917788505554\n",
      "batch accuracy: 0.8955078125\n",
      "doing 204 / 277\n",
      "elapsed time 25824.611832141876\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2578 - accuracy: 0.9072\n",
      "batch loss: 0.2578139007091522\n",
      "batch accuracy: 0.9072265625\n",
      "doing 205 / 277\n",
      "elapsed time 25955.822513103485\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2509 - accuracy: 0.9189\n",
      "batch loss: 0.2508681118488312\n",
      "batch accuracy: 0.9189453125\n",
      "doing 206 / 277\n",
      "elapsed time 26089.378596782684\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2442 - accuracy: 0.9014\n",
      "batch loss: 0.24422338604927063\n",
      "batch accuracy: 0.9013671875\n",
      "doing 207 / 277\n",
      "elapsed time 26221.778946876526\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2623 - accuracy: 0.9043\n",
      "batch loss: 0.2622520327568054\n",
      "batch accuracy: 0.904296875\n",
      "doing 208 / 277\n",
      "elapsed time 26351.243639230728\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3205 - accuracy: 0.8760\n",
      "batch loss: 0.3204919099807739\n",
      "batch accuracy: 0.8759765625\n",
      "doing 209 / 277\n",
      "elapsed time 26472.55526447296\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3829 - accuracy: 0.8740\n",
      "batch loss: 0.38294827938079834\n",
      "batch accuracy: 0.8740234375\n",
      "doing 210 / 277\n",
      "elapsed time 26595.745782375336\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2575 - accuracy: 0.9131\n",
      "batch loss: 0.25745853781700134\n",
      "batch accuracy: 0.9130859375\n",
      "doing 211 / 277\n",
      "elapsed time 26715.233202934265\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3157 - accuracy: 0.8750\n",
      "batch loss: 0.315701425075531\n",
      "batch accuracy: 0.875\n",
      "doing 212 / 277\n",
      "elapsed time 26826.73128271103\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2791 - accuracy: 0.9043\n",
      "batch loss: 0.27913036942481995\n",
      "batch accuracy: 0.904296875\n",
      "doing 213 / 277\n",
      "elapsed time 26952.310851097107\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3450 - accuracy: 0.8730\n",
      "batch loss: 0.3450322151184082\n",
      "batch accuracy: 0.873046875\n",
      "doing 214 / 277\n",
      "elapsed time 27062.509068489075\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2583 - accuracy: 0.9180\n",
      "batch loss: 0.25827112793922424\n",
      "batch accuracy: 0.91796875\n",
      "doing 215 / 277\n",
      "elapsed time 27173.96263885498\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2789 - accuracy: 0.9023\n",
      "batch loss: 0.2788834571838379\n",
      "batch accuracy: 0.90234375\n",
      "doing 216 / 277\n",
      "elapsed time 27291.849502325058\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3092 - accuracy: 0.8887\n",
      "batch loss: 0.3091552257537842\n",
      "batch accuracy: 0.888671875\n",
      "doing 217 / 277\n",
      "elapsed time 27409.67443728447\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3106 - accuracy: 0.8994\n",
      "batch loss: 0.31057441234588623\n",
      "batch accuracy: 0.8994140625\n",
      "doing 218 / 277\n",
      "elapsed time 27518.623846292496\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3179 - accuracy: 0.8848\n",
      "batch loss: 0.3178800940513611\n",
      "batch accuracy: 0.884765625\n",
      "doing 219 / 277\n",
      "elapsed time 27636.972874403\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2920 - accuracy: 0.8975\n",
      "batch loss: 0.2920473515987396\n",
      "batch accuracy: 0.8974609375\n",
      "doing 220 / 277\n",
      "elapsed time 27744.503926038742\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2707 - accuracy: 0.9023\n",
      "batch loss: 0.2706998288631439\n",
      "batch accuracy: 0.90234375\n",
      "doing 221 / 277\n",
      "elapsed time 27852.20296573639\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2425 - accuracy: 0.9150\n",
      "batch loss: 0.2424601912498474\n",
      "batch accuracy: 0.9150390625\n",
      "doing 222 / 277\n",
      "elapsed time 27967.33046078682\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2963 - accuracy: 0.9014\n",
      "batch loss: 0.2962738275527954\n",
      "batch accuracy: 0.9013671875\n",
      "doing 223 / 277\n",
      "elapsed time 28085.18126821518\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2814 - accuracy: 0.8965\n",
      "batch loss: 0.28144723176956177\n",
      "batch accuracy: 0.896484375\n",
      "doing 224 / 277\n",
      "elapsed time 28202.070368528366\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.9033\n",
      "batch loss: 0.3006840944290161\n",
      "batch accuracy: 0.9033203125\n",
      "doing 225 / 277\n",
      "elapsed time 28315.966459989548\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2401 - accuracy: 0.9170\n",
      "batch loss: 0.24013105034828186\n",
      "batch accuracy: 0.9169921875\n",
      "doing 226 / 277\n",
      "elapsed time 28431.699684858322\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2456 - accuracy: 0.9180\n",
      "batch loss: 0.24560710787773132\n",
      "batch accuracy: 0.91796875\n",
      "doing 227 / 277\n",
      "elapsed time 28546.46515893936\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2499 - accuracy: 0.9141\n",
      "batch loss: 0.24990475177764893\n",
      "batch accuracy: 0.9140625\n",
      "doing 228 / 277\n",
      "elapsed time 28657.44419813156\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2603 - accuracy: 0.9004\n",
      "batch loss: 0.2602944076061249\n",
      "batch accuracy: 0.900390625\n",
      "doing 229 / 277\n",
      "elapsed time 28771.456288814545\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2418 - accuracy: 0.9121\n",
      "batch loss: 0.24181918799877167\n",
      "batch accuracy: 0.912109375\n",
      "doing 230 / 277\n",
      "elapsed time 28883.093168735504\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2827 - accuracy: 0.9082\n",
      "batch loss: 0.28272852301597595\n",
      "batch accuracy: 0.908203125\n",
      "doing 231 / 277\n",
      "elapsed time 28999.530549049377\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2397 - accuracy: 0.9160\n",
      "batch loss: 0.2396659553050995\n",
      "batch accuracy: 0.916015625\n",
      "doing 232 / 277\n",
      "elapsed time 29114.28175163269\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2100 - accuracy: 0.9209\n",
      "batch loss: 0.2100353091955185\n",
      "batch accuracy: 0.9208984375\n",
      "doing 233 / 277\n",
      "elapsed time 29224.53060221672\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2729 - accuracy: 0.9033\n",
      "batch loss: 0.2729206085205078\n",
      "batch accuracy: 0.9033203125\n",
      "doing 234 / 277\n",
      "elapsed time 29337.708246707916\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2737 - accuracy: 0.8984\n",
      "batch loss: 0.2737483084201813\n",
      "batch accuracy: 0.8984375\n",
      "doing 235 / 277\n",
      "elapsed time 29448.20262169838\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2675 - accuracy: 0.9082\n",
      "batch loss: 0.2675327956676483\n",
      "batch accuracy: 0.908203125\n",
      "doing 236 / 277\n",
      "elapsed time 29555.517695903778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2594 - accuracy: 0.9072\n",
      "batch loss: 0.259420782327652\n",
      "batch accuracy: 0.9072265625\n",
      "doing 237 / 277\n",
      "elapsed time 29666.807098150253\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2580 - accuracy: 0.9092\n",
      "batch loss: 0.2579845190048218\n",
      "batch accuracy: 0.9091796875\n",
      "doing 238 / 277\n",
      "elapsed time 29777.463146686554\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2345 - accuracy: 0.9287\n",
      "batch loss: 0.23453082144260406\n",
      "batch accuracy: 0.9287109375\n",
      "doing 239 / 277\n",
      "elapsed time 29883.804779291153\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2891 - accuracy: 0.8926\n",
      "batch loss: 0.2890929579734802\n",
      "batch accuracy: 0.892578125\n",
      "doing 240 / 277\n",
      "elapsed time 29993.364374160767\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2719 - accuracy: 0.9053\n",
      "batch loss: 0.2718700170516968\n",
      "batch accuracy: 0.9052734375\n",
      "doing 241 / 277\n",
      "elapsed time 30104.272810697556\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2491 - accuracy: 0.9150\n",
      "batch loss: 0.24914640188217163\n",
      "batch accuracy: 0.9150390625\n",
      "doing 242 / 277\n",
      "elapsed time 30214.22592163086\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2681 - accuracy: 0.9053\n",
      "batch loss: 0.26810422539711\n",
      "batch accuracy: 0.9052734375\n",
      "doing 243 / 277\n",
      "elapsed time 30322.241055488586\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2751 - accuracy: 0.9062\n",
      "batch loss: 0.2750869393348694\n",
      "batch accuracy: 0.90625\n",
      "doing 244 / 277\n",
      "elapsed time 30431.502838134766\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2297 - accuracy: 0.9209\n",
      "batch loss: 0.22970832884311676\n",
      "batch accuracy: 0.9208984375\n",
      "doing 245 / 277\n",
      "elapsed time 30536.759922742844\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3045 - accuracy: 0.9062\n",
      "batch loss: 0.30453234910964966\n",
      "batch accuracy: 0.90625\n",
      "doing 246 / 277\n",
      "elapsed time 30643.64844727516\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2552 - accuracy: 0.9180\n",
      "batch loss: 0.2551756203174591\n",
      "batch accuracy: 0.91796875\n",
      "doing 247 / 277\n",
      "elapsed time 30744.879016399384\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2457 - accuracy: 0.9111\n",
      "batch loss: 0.24567089974880219\n",
      "batch accuracy: 0.9111328125\n",
      "doing 248 / 277\n",
      "elapsed time 30845.648305892944\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2349 - accuracy: 0.9141\n",
      "batch loss: 0.23493966460227966\n",
      "batch accuracy: 0.9140625\n",
      "doing 249 / 277\n",
      "elapsed time 30950.40515065193\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2022 - accuracy: 0.9268\n",
      "batch loss: 0.20215007662773132\n",
      "batch accuracy: 0.9267578125\n",
      "doing 250 / 277\n",
      "elapsed time 31054.679941177368\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2260 - accuracy: 0.9219\n",
      "batch loss: 0.2260352075099945\n",
      "batch accuracy: 0.921875\n",
      "doing 251 / 277\n",
      "elapsed time 31158.034712791443\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2402 - accuracy: 0.9160\n",
      "batch loss: 0.24021902680397034\n",
      "batch accuracy: 0.916015625\n",
      "doing 252 / 277\n",
      "elapsed time 31266.58581137657\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2414 - accuracy: 0.9111\n",
      "batch loss: 0.24138101935386658\n",
      "batch accuracy: 0.9111328125\n",
      "doing 253 / 277\n",
      "elapsed time 31370.623881578445\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2525 - accuracy: 0.9014\n",
      "batch loss: 0.25250673294067383\n",
      "batch accuracy: 0.9013671875\n",
      "doing 254 / 277\n",
      "elapsed time 31470.919884204865\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2162 - accuracy: 0.9248\n",
      "batch loss: 0.21620242297649384\n",
      "batch accuracy: 0.9248046875\n",
      "doing 255 / 277\n",
      "elapsed time 31570.79523062706\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2614 - accuracy: 0.9199\n",
      "batch loss: 0.26142942905426025\n",
      "batch accuracy: 0.919921875\n",
      "doing 256 / 277\n",
      "elapsed time 31668.157603740692\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2663 - accuracy: 0.9004\n",
      "batch loss: 0.2662610709667206\n",
      "batch accuracy: 0.900390625\n",
      "doing 257 / 277\n",
      "elapsed time 31764.97927069664\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2498 - accuracy: 0.9082\n",
      "batch loss: 0.24980276823043823\n",
      "batch accuracy: 0.908203125\n",
      "doing 258 / 277\n",
      "elapsed time 31861.275281906128\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2859 - accuracy: 0.9053\n",
      "batch loss: 0.2859172523021698\n",
      "batch accuracy: 0.9052734375\n",
      "doing 259 / 277\n",
      "elapsed time 31960.85680603981\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2399 - accuracy: 0.9238\n",
      "batch loss: 0.2399131804704666\n",
      "batch accuracy: 0.923828125\n",
      "doing 260 / 277\n",
      "elapsed time 32052.108303785324\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2329 - accuracy: 0.9229\n",
      "batch loss: 0.23293840885162354\n",
      "batch accuracy: 0.9228515625\n",
      "doing 261 / 277\n",
      "elapsed time 32158.46558046341\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2439 - accuracy: 0.9092\n",
      "batch loss: 0.2438795119524002\n",
      "batch accuracy: 0.9091796875\n",
      "doing 262 / 277\n",
      "elapsed time 32258.032564640045\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2057 - accuracy: 0.9287\n",
      "batch loss: 0.20571519434452057\n",
      "batch accuracy: 0.9287109375\n",
      "doing 263 / 277\n",
      "elapsed time 32355.531898975372\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2082 - accuracy: 0.9277\n",
      "batch loss: 0.20820632576942444\n",
      "batch accuracy: 0.927734375\n",
      "doing 264 / 277\n",
      "elapsed time 32450.613399505615\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2218 - accuracy: 0.9199\n",
      "batch loss: 0.22176891565322876\n",
      "batch accuracy: 0.919921875\n",
      "doing 265 / 277\n",
      "elapsed time 32539.233395814896\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2284 - accuracy: 0.9229\n",
      "batch loss: 0.22840465605258942\n",
      "batch accuracy: 0.9228515625\n",
      "doing 266 / 277\n",
      "elapsed time 32634.8223259449\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2073 - accuracy: 0.9209\n",
      "batch loss: 0.20728805661201477\n",
      "batch accuracy: 0.9208984375\n",
      "doing 267 / 277\n",
      "elapsed time 32728.53255224228\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2613 - accuracy: 0.9014\n",
      "batch loss: 0.261281281709671\n",
      "batch accuracy: 0.9013671875\n",
      "doing 268 / 277\n",
      "elapsed time 32823.742105960846\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2139 - accuracy: 0.9287\n",
      "batch loss: 0.21387159824371338\n",
      "batch accuracy: 0.9287109375\n",
      "doing 269 / 277\n",
      "elapsed time 32935.05540943146\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2073 - accuracy: 0.9287\n",
      "batch loss: 0.20732825994491577\n",
      "batch accuracy: 0.9287109375\n",
      "doing 270 / 277\n",
      "elapsed time 33033.19062542915\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2508 - accuracy: 0.9160\n",
      "batch loss: 0.2508274018764496\n",
      "batch accuracy: 0.916015625\n",
      "doing 271 / 277\n",
      "elapsed time 33125.52641606331\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2089 - accuracy: 0.9248\n",
      "batch loss: 0.2089325487613678\n",
      "batch accuracy: 0.9248046875\n",
      "doing 272 / 277\n",
      "elapsed time 33227.42530345917\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2285 - accuracy: 0.9189\n",
      "batch loss: 0.22851675748825073\n",
      "batch accuracy: 0.9189453125\n",
      "doing 273 / 277\n",
      "elapsed time 33321.30481123924\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2272 - accuracy: 0.9277\n",
      "batch loss: 0.22724807262420654\n",
      "batch accuracy: 0.927734375\n",
      "doing 274 / 277\n",
      "elapsed time 33419.72485232353\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2256 - accuracy: 0.9277\n",
      "batch loss: 0.2255975902080536\n",
      "batch accuracy: 0.927734375\n",
      "doing 275 / 277\n",
      "elapsed time 33517.62132000923\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2087 - accuracy: 0.9297\n",
      "batch loss: 0.2087039202451706\n",
      "batch accuracy: 0.9296875\n",
      "doing 276 / 277\n",
      "elapsed time 33576.39313411713\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.1801 - accuracy: 0.9452\n",
      "batch loss: 0.18014104664325714\n",
      "batch accuracy: 0.9451553821563721\n",
      "Train loss 0.3237332080890986\n",
      "Train accuracy 0.8854736825619364\n",
      "141/141 [==============================] - 2s 13ms/step - loss: 0.2104 - accuracy: 0.9362\n",
      "Validation loss: 0.21042878925800323\n",
      "Validation accuracy: 0.9362221956253052\n",
      "==================================================\n",
      "3 / 10\n",
      "doing 0 / 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 65.19519090652466\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2400 - accuracy: 0.9141\n",
      "batch loss: 0.24004679918289185\n",
      "batch accuracy: 0.9140625\n",
      "doing 1 / 277\n",
      "elapsed time 130.90342116355896\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2111 - accuracy: 0.9170\n",
      "batch loss: 0.2111361175775528\n",
      "batch accuracy: 0.9169921875\n",
      "doing 2 / 277\n",
      "elapsed time 209.2765097618103\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2119 - accuracy: 0.9268\n",
      "batch loss: 0.2118736058473587\n",
      "batch accuracy: 0.9267578125\n",
      "doing 3 / 277\n",
      "elapsed time 273.71437644958496\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2029 - accuracy: 0.9199\n",
      "batch loss: 0.20288941264152527\n",
      "batch accuracy: 0.919921875\n",
      "doing 4 / 277\n",
      "elapsed time 337.8205044269562\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2142 - accuracy: 0.9209\n",
      "batch loss: 0.2141680121421814\n",
      "batch accuracy: 0.9208984375\n",
      "doing 5 / 277\n",
      "elapsed time 408.93670320510864\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2665 - accuracy: 0.9004\n",
      "batch loss: 0.2665395736694336\n",
      "batch accuracy: 0.900390625\n",
      "doing 6 / 277\n",
      "elapsed time 482.92899656295776\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2409 - accuracy: 0.9092\n",
      "batch loss: 0.24090132117271423\n",
      "batch accuracy: 0.9091796875\n",
      "doing 7 / 277\n",
      "elapsed time 552.9688739776611\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2358 - accuracy: 0.9160\n",
      "batch loss: 0.23582309484481812\n",
      "batch accuracy: 0.916015625\n",
      "doing 8 / 277\n",
      "elapsed time 610.8901777267456\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2474 - accuracy: 0.9199\n",
      "batch loss: 0.24735887348651886\n",
      "batch accuracy: 0.919921875\n",
      "doing 9 / 277\n",
      "elapsed time 680.9102518558502\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2453 - accuracy: 0.9131\n",
      "batch loss: 0.2453482449054718\n",
      "batch accuracy: 0.9130859375\n",
      "doing 10 / 277\n",
      "elapsed time 755.5590617656708\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2303 - accuracy: 0.9170\n",
      "batch loss: 0.2303016036748886\n",
      "batch accuracy: 0.9169921875\n",
      "doing 11 / 277\n",
      "elapsed time 828.0678083896637\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2284 - accuracy: 0.9268\n",
      "batch loss: 0.2284134030342102\n",
      "batch accuracy: 0.9267578125\n",
      "doing 12 / 277\n",
      "elapsed time 899.9797110557556\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2044 - accuracy: 0.9307\n",
      "batch loss: 0.2044335901737213\n",
      "batch accuracy: 0.9306640625\n",
      "doing 13 / 277\n",
      "elapsed time 959.435544013977\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2232 - accuracy: 0.9307\n",
      "batch loss: 0.22319725155830383\n",
      "batch accuracy: 0.9306640625\n",
      "doing 14 / 277\n",
      "elapsed time 1028.1766803264618\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2326 - accuracy: 0.9170\n",
      "batch loss: 0.23258507251739502\n",
      "batch accuracy: 0.9169921875\n",
      "doing 15 / 277\n",
      "elapsed time 1091.085047006607\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2125 - accuracy: 0.9297\n",
      "batch loss: 0.21253837645053864\n",
      "batch accuracy: 0.9296875\n",
      "doing 16 / 277\n",
      "elapsed time 1154.2214033603668\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2162 - accuracy: 0.9209\n",
      "batch loss: 0.21616172790527344\n",
      "batch accuracy: 0.9208984375\n",
      "doing 17 / 277\n",
      "elapsed time 1218.7765896320343\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2462 - accuracy: 0.9082\n",
      "batch loss: 0.24621060490608215\n",
      "batch accuracy: 0.908203125\n",
      "doing 18 / 277\n",
      "elapsed time 1291.1978907585144\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2209 - accuracy: 0.9297\n",
      "batch loss: 0.22094807028770447\n",
      "batch accuracy: 0.9296875\n",
      "doing 19 / 277\n",
      "elapsed time 1360.4846720695496\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2006 - accuracy: 0.9268\n",
      "batch loss: 0.20064052939414978\n",
      "batch accuracy: 0.9267578125\n",
      "doing 20 / 277\n",
      "elapsed time 1426.8662226200104\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2038 - accuracy: 0.9189\n",
      "batch loss: 0.20377148687839508\n",
      "batch accuracy: 0.9189453125\n",
      "doing 21 / 277\n",
      "elapsed time 1486.685269355774\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2224 - accuracy: 0.9141\n",
      "batch loss: 0.22241315245628357\n",
      "batch accuracy: 0.9140625\n",
      "doing 22 / 277\n",
      "elapsed time 1550.0818979740143\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2305 - accuracy: 0.9209\n",
      "batch loss: 0.23047436773777008\n",
      "batch accuracy: 0.9208984375\n",
      "doing 23 / 277\n",
      "elapsed time 1615.9993751049042\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2372 - accuracy: 0.9092\n",
      "batch loss: 0.2372264862060547\n",
      "batch accuracy: 0.9091796875\n",
      "doing 24 / 277\n",
      "elapsed time 1683.3045353889465\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2375 - accuracy: 0.9189\n",
      "batch loss: 0.2374996691942215\n",
      "batch accuracy: 0.9189453125\n",
      "doing 25 / 277\n",
      "elapsed time 1742.789127588272\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2148 - accuracy: 0.9209\n",
      "batch loss: 0.2147582769393921\n",
      "batch accuracy: 0.9208984375\n",
      "doing 26 / 277\n",
      "elapsed time 1804.5491771697998\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1849 - accuracy: 0.9346\n",
      "batch loss: 0.18487723171710968\n",
      "batch accuracy: 0.9345703125\n",
      "doing 27 / 277\n",
      "elapsed time 1871.508332490921\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2025 - accuracy: 0.9248\n",
      "batch loss: 0.2024647295475006\n",
      "batch accuracy: 0.9248046875\n",
      "doing 28 / 277\n",
      "elapsed time 1932.7009346485138\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2192 - accuracy: 0.9209\n",
      "batch loss: 0.21924853324890137\n",
      "batch accuracy: 0.9208984375\n",
      "doing 29 / 277\n",
      "elapsed time 1991.9902033805847\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2040 - accuracy: 0.9268\n",
      "batch loss: 0.20396965742111206\n",
      "batch accuracy: 0.9267578125\n",
      "doing 30 / 277\n",
      "elapsed time 2047.2548513412476\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2163 - accuracy: 0.9229\n",
      "batch loss: 0.21629832684993744\n",
      "batch accuracy: 0.9228515625\n",
      "doing 31 / 277\n",
      "elapsed time 2114.639145374298\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1881 - accuracy: 0.9316\n",
      "batch loss: 0.18807664513587952\n",
      "batch accuracy: 0.931640625\n",
      "doing 32 / 277\n",
      "elapsed time 2169.8494296073914\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2034 - accuracy: 0.9248\n",
      "batch loss: 0.2033969908952713\n",
      "batch accuracy: 0.9248046875\n",
      "doing 33 / 277\n",
      "elapsed time 2222.7838020324707\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1976 - accuracy: 0.9287\n",
      "batch loss: 0.19759276509284973\n",
      "batch accuracy: 0.9287109375\n",
      "doing 34 / 277\n",
      "elapsed time 2284.9191012382507\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2139 - accuracy: 0.9307\n",
      "batch loss: 0.21393457055091858\n",
      "batch accuracy: 0.9306640625\n",
      "doing 35 / 277\n",
      "elapsed time 2346.0957231521606\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2032 - accuracy: 0.9268\n",
      "batch loss: 0.20316976308822632\n",
      "batch accuracy: 0.9267578125\n",
      "doing 36 / 277\n",
      "elapsed time 2403.6099264621735\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1838 - accuracy: 0.9307\n",
      "batch loss: 0.18375733494758606\n",
      "batch accuracy: 0.9306640625\n",
      "doing 37 / 277\n",
      "elapsed time 2461.756331682205\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1829 - accuracy: 0.9365\n",
      "batch loss: 0.1829114705324173\n",
      "batch accuracy: 0.9365234375\n",
      "doing 38 / 277\n",
      "elapsed time 2534.7820608615875\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2010 - accuracy: 0.9365\n",
      "batch loss: 0.20102685689926147\n",
      "batch accuracy: 0.9365234375\n",
      "doing 39 / 277\n",
      "elapsed time 2597.214672803879\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1571 - accuracy: 0.9531\n",
      "batch loss: 0.1570742130279541\n",
      "batch accuracy: 0.953125\n",
      "doing 40 / 277\n",
      "elapsed time 2657.6820845603943\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2166 - accuracy: 0.9258\n",
      "batch loss: 0.21663139760494232\n",
      "batch accuracy: 0.92578125\n",
      "doing 41 / 277\n",
      "elapsed time 2715.119704723358\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2085 - accuracy: 0.9277\n",
      "batch loss: 0.20847967267036438\n",
      "batch accuracy: 0.927734375\n",
      "doing 42 / 277\n",
      "elapsed time 2772.8812963962555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1992 - accuracy: 0.9355\n",
      "batch loss: 0.1991737186908722\n",
      "batch accuracy: 0.935546875\n",
      "doing 43 / 277\n",
      "elapsed time 2838.0797486305237\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1664 - accuracy: 0.9473\n",
      "batch loss: 0.1663539558649063\n",
      "batch accuracy: 0.947265625\n",
      "doing 44 / 277\n",
      "elapsed time 2907.1759593486786\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2107 - accuracy: 0.9316\n",
      "batch loss: 0.21067729592323303\n",
      "batch accuracy: 0.931640625\n",
      "doing 45 / 277\n",
      "elapsed time 2959.785177707672\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2149 - accuracy: 0.9180\n",
      "batch loss: 0.21489490568637848\n",
      "batch accuracy: 0.91796875\n",
      "doing 46 / 277\n",
      "elapsed time 3010.983692884445\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1927 - accuracy: 0.9336\n",
      "batch loss: 0.19274833798408508\n",
      "batch accuracy: 0.93359375\n",
      "doing 47 / 277\n",
      "elapsed time 3077.905838727951\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2186 - accuracy: 0.9346\n",
      "batch loss: 0.21861526370048523\n",
      "batch accuracy: 0.9345703125\n",
      "doing 48 / 277\n",
      "elapsed time 3141.6923067569733\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1929 - accuracy: 0.9434\n",
      "batch loss: 0.19288475811481476\n",
      "batch accuracy: 0.943359375\n",
      "doing 49 / 277\n",
      "elapsed time 3201.40763092041\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2257 - accuracy: 0.9248\n",
      "batch loss: 0.22572988271713257\n",
      "batch accuracy: 0.9248046875\n",
      "doing 50 / 277\n",
      "elapsed time 3268.532300710678\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1699 - accuracy: 0.9453\n",
      "batch loss: 0.1698877066373825\n",
      "batch accuracy: 0.9453125\n",
      "doing 51 / 277\n",
      "elapsed time 3328.5567824840546\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1615 - accuracy: 0.9473\n",
      "batch loss: 0.1615161895751953\n",
      "batch accuracy: 0.947265625\n",
      "doing 52 / 277\n",
      "elapsed time 3395.7000794410706\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2127 - accuracy: 0.9170\n",
      "batch loss: 0.2126871794462204\n",
      "batch accuracy: 0.9169921875\n",
      "doing 53 / 277\n",
      "elapsed time 3453.391369819641\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1772 - accuracy: 0.9346\n",
      "batch loss: 0.17720454931259155\n",
      "batch accuracy: 0.9345703125\n",
      "doing 54 / 277\n",
      "elapsed time 3516.525540113449\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1929 - accuracy: 0.9336\n",
      "batch loss: 0.19293993711471558\n",
      "batch accuracy: 0.93359375\n",
      "doing 55 / 277\n",
      "elapsed time 3579.265390396118\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1949 - accuracy: 0.9346\n",
      "batch loss: 0.19486591219902039\n",
      "batch accuracy: 0.9345703125\n",
      "doing 56 / 277\n",
      "elapsed time 3647.084498643875\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1927 - accuracy: 0.9316\n",
      "batch loss: 0.1926981657743454\n",
      "batch accuracy: 0.931640625\n",
      "doing 57 / 277\n",
      "elapsed time 3714.7435433864594\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1994 - accuracy: 0.9277\n",
      "batch loss: 0.19942206144332886\n",
      "batch accuracy: 0.927734375\n",
      "doing 58 / 277\n",
      "elapsed time 3784.0564498901367\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2200 - accuracy: 0.9170\n",
      "batch loss: 0.2200177013874054\n",
      "batch accuracy: 0.9169921875\n",
      "doing 59 / 277\n",
      "elapsed time 3849.663864135742\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1683 - accuracy: 0.9355\n",
      "batch loss: 0.1683286428451538\n",
      "batch accuracy: 0.935546875\n",
      "doing 60 / 277\n",
      "elapsed time 3902.6733179092407\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2124 - accuracy: 0.9160\n",
      "batch loss: 0.21242021024227142\n",
      "batch accuracy: 0.916015625\n",
      "doing 61 / 277\n",
      "elapsed time 3961.172115802765\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1770 - accuracy: 0.9336\n",
      "batch loss: 0.17699772119522095\n",
      "batch accuracy: 0.93359375\n",
      "doing 62 / 277\n",
      "elapsed time 4030.1274421215057\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1741 - accuracy: 0.9336\n",
      "batch loss: 0.17409811913967133\n",
      "batch accuracy: 0.93359375\n",
      "doing 63 / 277\n",
      "elapsed time 4091.525204181671\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2549 - accuracy: 0.9180\n",
      "batch loss: 0.254852294921875\n",
      "batch accuracy: 0.91796875\n",
      "doing 64 / 277\n",
      "elapsed time 4164.683272361755\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1994 - accuracy: 0.9268\n",
      "batch loss: 0.1994098573923111\n",
      "batch accuracy: 0.9267578125\n",
      "doing 65 / 277\n",
      "elapsed time 4227.028333187103\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1673 - accuracy: 0.9443\n",
      "batch loss: 0.16725043952465057\n",
      "batch accuracy: 0.9443359375\n",
      "doing 66 / 277\n",
      "elapsed time 4287.061100721359\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1938 - accuracy: 0.9307\n",
      "batch loss: 0.1937723457813263\n",
      "batch accuracy: 0.9306640625\n",
      "doing 67 / 277\n",
      "elapsed time 4344.818955183029\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1939 - accuracy: 0.9316\n",
      "batch loss: 0.19392737746238708\n",
      "batch accuracy: 0.931640625\n",
      "doing 68 / 277\n",
      "elapsed time 4396.687463760376\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1863 - accuracy: 0.9375\n",
      "batch loss: 0.18631520867347717\n",
      "batch accuracy: 0.9375\n",
      "doing 69 / 277\n",
      "elapsed time 4463.829922199249\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1907 - accuracy: 0.9346\n",
      "batch loss: 0.19071123003959656\n",
      "batch accuracy: 0.9345703125\n",
      "doing 70 / 277\n",
      "elapsed time 4529.326986074448\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1737 - accuracy: 0.9346\n",
      "batch loss: 0.1736813634634018\n",
      "batch accuracy: 0.9345703125\n",
      "doing 71 / 277\n",
      "elapsed time 4593.707694530487\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1934 - accuracy: 0.9268\n",
      "batch loss: 0.19344577193260193\n",
      "batch accuracy: 0.9267578125\n",
      "doing 72 / 277\n",
      "elapsed time 4656.735162973404\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1956 - accuracy: 0.9199\n",
      "batch loss: 0.19560326635837555\n",
      "batch accuracy: 0.919921875\n",
      "doing 73 / 277\n",
      "elapsed time 4718.061002492905\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1788 - accuracy: 0.9443\n",
      "batch loss: 0.17875510454177856\n",
      "batch accuracy: 0.9443359375\n",
      "doing 74 / 277\n",
      "elapsed time 4774.076318979263\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2100 - accuracy: 0.9219\n",
      "batch loss: 0.21004411578178406\n",
      "batch accuracy: 0.921875\n",
      "doing 75 / 277\n",
      "elapsed time 4837.115561008453\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1729 - accuracy: 0.9355\n",
      "batch loss: 0.17294612526893616\n",
      "batch accuracy: 0.935546875\n",
      "doing 76 / 277\n",
      "elapsed time 4894.345768451691\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2040 - accuracy: 0.9277\n",
      "batch loss: 0.20399433374404907\n",
      "batch accuracy: 0.927734375\n",
      "doing 77 / 277\n",
      "elapsed time 4950.242871284485\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1952 - accuracy: 0.9355\n",
      "batch loss: 0.1951882243156433\n",
      "batch accuracy: 0.935546875\n",
      "doing 78 / 277\n",
      "elapsed time 5014.227934122086\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1960 - accuracy: 0.9307\n",
      "batch loss: 0.1960146725177765\n",
      "batch accuracy: 0.9306640625\n",
      "doing 79 / 277\n",
      "elapsed time 5071.543489933014\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2118 - accuracy: 0.9268\n",
      "batch loss: 0.21179494261741638\n",
      "batch accuracy: 0.9267578125\n",
      "doing 80 / 277\n",
      "elapsed time 5129.152404308319\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2062 - accuracy: 0.9365\n",
      "batch loss: 0.2062109112739563\n",
      "batch accuracy: 0.9365234375\n",
      "doing 81 / 277\n",
      "elapsed time 5182.29914188385\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2086 - accuracy: 0.9307\n",
      "batch loss: 0.20861580967903137\n",
      "batch accuracy: 0.9306640625\n",
      "doing 82 / 277\n",
      "elapsed time 5236.671653985977\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1879 - accuracy: 0.9404\n",
      "batch loss: 0.1878998726606369\n",
      "batch accuracy: 0.9404296875\n",
      "doing 83 / 277\n",
      "elapsed time 5289.7936046123505\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1805 - accuracy: 0.9395\n",
      "batch loss: 0.1804800182580948\n",
      "batch accuracy: 0.939453125\n",
      "doing 84 / 277\n",
      "elapsed time 5343.439423799515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1796 - accuracy: 0.9297\n",
      "batch loss: 0.17964650690555573\n",
      "batch accuracy: 0.9296875\n",
      "doing 85 / 277\n",
      "elapsed time 5390.082764387131\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1746 - accuracy: 0.9385\n",
      "batch loss: 0.1746464967727661\n",
      "batch accuracy: 0.9384765625\n",
      "doing 86 / 277\n",
      "elapsed time 5447.399532794952\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1685 - accuracy: 0.9385\n",
      "batch loss: 0.16851794719696045\n",
      "batch accuracy: 0.9384765625\n",
      "doing 87 / 277\n",
      "elapsed time 5504.189423799515\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1770 - accuracy: 0.9297\n",
      "batch loss: 0.17703047394752502\n",
      "batch accuracy: 0.9296875\n",
      "doing 88 / 277\n",
      "elapsed time 5552.07098031044\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1688 - accuracy: 0.9346\n",
      "batch loss: 0.16881932318210602\n",
      "batch accuracy: 0.9345703125\n",
      "doing 89 / 277\n",
      "elapsed time 5611.861701011658\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1913 - accuracy: 0.9326\n",
      "batch loss: 0.19125577807426453\n",
      "batch accuracy: 0.9326171875\n",
      "doing 90 / 277\n",
      "elapsed time 5672.67120885849\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1659 - accuracy: 0.9414\n",
      "batch loss: 0.16592374444007874\n",
      "batch accuracy: 0.94140625\n",
      "doing 91 / 277\n",
      "elapsed time 5766.086888074875\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1903 - accuracy: 0.9336\n",
      "batch loss: 0.19034108519554138\n",
      "batch accuracy: 0.93359375\n",
      "doing 92 / 277\n",
      "elapsed time 5856.77872133255\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1556 - accuracy: 0.9463\n",
      "batch loss: 0.1555807888507843\n",
      "batch accuracy: 0.9462890625\n",
      "doing 93 / 277\n",
      "elapsed time 5948.312787532806\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1733 - accuracy: 0.9355\n",
      "batch loss: 0.17327114939689636\n",
      "batch accuracy: 0.935546875\n",
      "doing 94 / 277\n",
      "elapsed time 6035.885630846024\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1576 - accuracy: 0.9521\n",
      "batch loss: 0.15763482451438904\n",
      "batch accuracy: 0.9521484375\n",
      "doing 95 / 277\n",
      "elapsed time 6134.005797147751\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1432 - accuracy: 0.9482\n",
      "batch loss: 0.1431530863046646\n",
      "batch accuracy: 0.9482421875\n",
      "doing 96 / 277\n",
      "elapsed time 6225.564040660858\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1720 - accuracy: 0.9395\n",
      "batch loss: 0.1719677448272705\n",
      "batch accuracy: 0.939453125\n",
      "doing 97 / 277\n",
      "elapsed time 6319.8448576927185\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2038 - accuracy: 0.9268\n",
      "batch loss: 0.20377808809280396\n",
      "batch accuracy: 0.9267578125\n",
      "doing 98 / 277\n",
      "elapsed time 6415.930705785751\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2214 - accuracy: 0.9209\n",
      "batch loss: 0.22136931121349335\n",
      "batch accuracy: 0.9208984375\n",
      "doing 99 / 277\n",
      "elapsed time 6515.672075271606\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2118 - accuracy: 0.9297\n",
      "batch loss: 0.21181628108024597\n",
      "batch accuracy: 0.9296875\n",
      "doing 100 / 277\n",
      "elapsed time 6596.099983215332\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2118 - accuracy: 0.9287\n",
      "batch loss: 0.21178440749645233\n",
      "batch accuracy: 0.9287109375\n",
      "doing 101 / 277\n",
      "elapsed time 6669.7289872169495\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1989 - accuracy: 0.9326\n",
      "batch loss: 0.1989288479089737\n",
      "batch accuracy: 0.9326171875\n",
      "doing 102 / 277\n",
      "elapsed time 6770.619304895401\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1698 - accuracy: 0.9404\n",
      "batch loss: 0.16984274983406067\n",
      "batch accuracy: 0.9404296875\n",
      "doing 103 / 277\n",
      "elapsed time 6877.292401790619\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1822 - accuracy: 0.9336\n",
      "batch loss: 0.18224464356899261\n",
      "batch accuracy: 0.93359375\n",
      "doing 104 / 277\n",
      "elapsed time 6976.688430070877\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1911 - accuracy: 0.9336\n",
      "batch loss: 0.1910526007413864\n",
      "batch accuracy: 0.93359375\n",
      "doing 105 / 277\n",
      "elapsed time 7074.755780220032\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2092 - accuracy: 0.9258\n",
      "batch loss: 0.20924800634384155\n",
      "batch accuracy: 0.92578125\n",
      "doing 106 / 277\n",
      "elapsed time 7185.02591252327\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1708 - accuracy: 0.9316\n",
      "batch loss: 0.17076948285102844\n",
      "batch accuracy: 0.931640625\n",
      "doing 107 / 277\n",
      "elapsed time 7294.1419994831085\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1811 - accuracy: 0.9355\n",
      "batch loss: 0.18113753199577332\n",
      "batch accuracy: 0.935546875\n",
      "doing 108 / 277\n",
      "elapsed time 7390.654662847519\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1879 - accuracy: 0.9336\n",
      "batch loss: 0.18792413175106049\n",
      "batch accuracy: 0.93359375\n",
      "doing 109 / 277\n",
      "elapsed time 7495.713778495789\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1984 - accuracy: 0.9268\n",
      "batch loss: 0.19835825264453888\n",
      "batch accuracy: 0.9267578125\n",
      "doing 110 / 277\n",
      "elapsed time 7600.911672830582\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1903 - accuracy: 0.9355\n",
      "batch loss: 0.1902766227722168\n",
      "batch accuracy: 0.935546875\n",
      "doing 111 / 277\n",
      "elapsed time 7699.013509273529\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1905 - accuracy: 0.9277\n",
      "batch loss: 0.19046960771083832\n",
      "batch accuracy: 0.927734375\n",
      "doing 112 / 277\n",
      "elapsed time 7803.2506647109985\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1676 - accuracy: 0.9424\n",
      "batch loss: 0.1676337718963623\n",
      "batch accuracy: 0.9423828125\n",
      "doing 113 / 277\n",
      "elapsed time 7901.758113861084\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2265 - accuracy: 0.9160\n",
      "batch loss: 0.22647368907928467\n",
      "batch accuracy: 0.916015625\n",
      "doing 114 / 277\n",
      "elapsed time 8006.589285135269\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1946 - accuracy: 0.9297\n",
      "batch loss: 0.19457292556762695\n",
      "batch accuracy: 0.9296875\n",
      "doing 115 / 277\n",
      "elapsed time 8101.737747192383\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1877 - accuracy: 0.9365\n",
      "batch loss: 0.18767033517360687\n",
      "batch accuracy: 0.9365234375\n",
      "doing 116 / 277\n",
      "elapsed time 8199.16421699524\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1872 - accuracy: 0.9365\n",
      "batch loss: 0.1872105896472931\n",
      "batch accuracy: 0.9365234375\n",
      "doing 117 / 277\n",
      "elapsed time 8300.255461215973\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1870 - accuracy: 0.9326\n",
      "batch loss: 0.18704164028167725\n",
      "batch accuracy: 0.9326171875\n",
      "doing 118 / 277\n",
      "elapsed time 8398.532853364944\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1601 - accuracy: 0.9434\n",
      "batch loss: 0.1600932776927948\n",
      "batch accuracy: 0.943359375\n",
      "doing 119 / 277\n",
      "elapsed time 8495.782055854797\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1582 - accuracy: 0.9453\n",
      "batch loss: 0.15815594792366028\n",
      "batch accuracy: 0.9453125\n",
      "doing 120 / 277\n",
      "elapsed time 8590.141384363174\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1456 - accuracy: 0.9521\n",
      "batch loss: 0.14560845494270325\n",
      "batch accuracy: 0.9521484375\n",
      "doing 121 / 277\n",
      "elapsed time 8693.375666856766\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1650 - accuracy: 0.9346\n",
      "batch loss: 0.16497839987277985\n",
      "batch accuracy: 0.9345703125\n",
      "doing 122 / 277\n",
      "elapsed time 8796.762085199356\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2056 - accuracy: 0.9326\n",
      "batch loss: 0.20557735860347748\n",
      "batch accuracy: 0.9326171875\n",
      "doing 123 / 277\n",
      "elapsed time 8893.337214708328\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1883 - accuracy: 0.9395\n",
      "batch loss: 0.18833118677139282\n",
      "batch accuracy: 0.939453125\n",
      "doing 124 / 277\n",
      "elapsed time 8994.800171613693\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1874 - accuracy: 0.9346\n",
      "batch loss: 0.1874309480190277\n",
      "batch accuracy: 0.9345703125\n",
      "doing 125 / 277\n",
      "elapsed time 9086.361797332764\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1814 - accuracy: 0.9385\n",
      "batch loss: 0.18141332268714905\n",
      "batch accuracy: 0.9384765625\n",
      "doing 126 / 277\n",
      "elapsed time 9180.19076538086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1604 - accuracy: 0.9453\n",
      "batch loss: 0.16035547852516174\n",
      "batch accuracy: 0.9453125\n",
      "doing 127 / 277\n",
      "elapsed time 9272.787449598312\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1488 - accuracy: 0.9443\n",
      "batch loss: 0.1487976759672165\n",
      "batch accuracy: 0.9443359375\n",
      "doing 128 / 277\n",
      "elapsed time 9361.627226829529\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1724 - accuracy: 0.9375\n",
      "batch loss: 0.17241886258125305\n",
      "batch accuracy: 0.9375\n",
      "doing 129 / 277\n",
      "elapsed time 9460.24475812912\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1729 - accuracy: 0.9365\n",
      "batch loss: 0.17292657494544983\n",
      "batch accuracy: 0.9365234375\n",
      "doing 130 / 277\n",
      "elapsed time 9556.275260686874\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1866 - accuracy: 0.9326\n",
      "batch loss: 0.186642587184906\n",
      "batch accuracy: 0.9326171875\n",
      "doing 131 / 277\n",
      "elapsed time 9655.116443634033\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1576 - accuracy: 0.9492\n",
      "batch loss: 0.15758568048477173\n",
      "batch accuracy: 0.94921875\n",
      "doing 132 / 277\n",
      "elapsed time 9746.383651018143\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1771 - accuracy: 0.9346\n",
      "batch loss: 0.17707769572734833\n",
      "batch accuracy: 0.9345703125\n",
      "doing 133 / 277\n",
      "elapsed time 9838.6836373806\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1615 - accuracy: 0.9424\n",
      "batch loss: 0.1615070253610611\n",
      "batch accuracy: 0.9423828125\n",
      "doing 134 / 277\n",
      "elapsed time 9936.2144510746\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1904 - accuracy: 0.9268\n",
      "batch loss: 0.19043105840682983\n",
      "batch accuracy: 0.9267578125\n",
      "doing 135 / 277\n",
      "elapsed time 10028.100370645523\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1676 - accuracy: 0.9424\n",
      "batch loss: 0.16756094992160797\n",
      "batch accuracy: 0.9423828125\n",
      "doing 136 / 277\n",
      "elapsed time 10122.471348762512\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1572 - accuracy: 0.9414\n",
      "batch loss: 0.1571667641401291\n",
      "batch accuracy: 0.94140625\n",
      "doing 137 / 277\n",
      "elapsed time 10212.216024160385\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2006 - accuracy: 0.9316\n",
      "batch loss: 0.20060575008392334\n",
      "batch accuracy: 0.931640625\n",
      "doing 138 / 277\n",
      "elapsed time 10302.356627464294\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1906 - accuracy: 0.9395\n",
      "batch loss: 0.19057847559452057\n",
      "batch accuracy: 0.939453125\n",
      "doing 139 / 277\n",
      "elapsed time 10397.287025928497\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1584 - accuracy: 0.9492\n",
      "batch loss: 0.15838366746902466\n",
      "batch accuracy: 0.94921875\n",
      "doing 140 / 277\n",
      "elapsed time 10486.860440731049\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1699 - accuracy: 0.9404\n",
      "batch loss: 0.1698712706565857\n",
      "batch accuracy: 0.9404296875\n",
      "doing 141 / 277\n",
      "elapsed time 10577.981081962585\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1719 - accuracy: 0.9297\n",
      "batch loss: 0.17190639674663544\n",
      "batch accuracy: 0.9296875\n",
      "doing 142 / 277\n",
      "elapsed time 10663.994424819946\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1737 - accuracy: 0.9385\n",
      "batch loss: 0.1737159788608551\n",
      "batch accuracy: 0.9384765625\n",
      "doing 143 / 277\n",
      "elapsed time 10765.243933916092\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1588 - accuracy: 0.9395\n",
      "batch loss: 0.15881529450416565\n",
      "batch accuracy: 0.939453125\n",
      "doing 144 / 277\n",
      "elapsed time 10853.030595779419\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2021 - accuracy: 0.9326\n",
      "batch loss: 0.20212210714817047\n",
      "batch accuracy: 0.9326171875\n",
      "doing 145 / 277\n",
      "elapsed time 10926.657089948654\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1641 - accuracy: 0.9404\n",
      "batch loss: 0.16406404972076416\n",
      "batch accuracy: 0.9404296875\n",
      "doing 146 / 277\n",
      "elapsed time 11018.288744449615\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1670 - accuracy: 0.9424\n",
      "batch loss: 0.16698186099529266\n",
      "batch accuracy: 0.9423828125\n",
      "doing 147 / 277\n",
      "elapsed time 11107.32326221466\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1956 - accuracy: 0.9307\n",
      "batch loss: 0.195581316947937\n",
      "batch accuracy: 0.9306640625\n",
      "doing 148 / 277\n",
      "elapsed time 11190.267534255981\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1697 - accuracy: 0.9482\n",
      "batch loss: 0.1696912795305252\n",
      "batch accuracy: 0.9482421875\n",
      "doing 149 / 277\n",
      "elapsed time 11273.35964846611\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1658 - accuracy: 0.9385\n",
      "batch loss: 0.16578499972820282\n",
      "batch accuracy: 0.9384765625\n",
      "doing 150 / 277\n",
      "elapsed time 11357.345513105392\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1608 - accuracy: 0.9492\n",
      "batch loss: 0.16079145669937134\n",
      "batch accuracy: 0.94921875\n",
      "doing 151 / 277\n",
      "elapsed time 11447.123512029648\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2014 - accuracy: 0.9395\n",
      "batch loss: 0.2013629674911499\n",
      "batch accuracy: 0.939453125\n",
      "doing 152 / 277\n",
      "elapsed time 11537.598583221436\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2097 - accuracy: 0.9268\n",
      "batch loss: 0.20971736311912537\n",
      "batch accuracy: 0.9267578125\n",
      "doing 153 / 277\n",
      "elapsed time 11621.697878599167\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1916 - accuracy: 0.9307\n",
      "batch loss: 0.19159722328186035\n",
      "batch accuracy: 0.9306640625\n",
      "doing 154 / 277\n",
      "elapsed time 11703.131876468658\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1866 - accuracy: 0.9316\n",
      "batch loss: 0.1865559220314026\n",
      "batch accuracy: 0.931640625\n",
      "doing 155 / 277\n",
      "elapsed time 11787.816812753677\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1841 - accuracy: 0.9355\n",
      "batch loss: 0.18408219516277313\n",
      "batch accuracy: 0.935546875\n",
      "doing 156 / 277\n",
      "elapsed time 11867.629633426666\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2085 - accuracy: 0.9326\n",
      "batch loss: 0.20853152871131897\n",
      "batch accuracy: 0.9326171875\n",
      "doing 157 / 277\n",
      "elapsed time 11948.7464864254\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2020 - accuracy: 0.9355\n",
      "batch loss: 0.20196589827537537\n",
      "batch accuracy: 0.935546875\n",
      "doing 158 / 277\n",
      "elapsed time 12033.175111055374\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1918 - accuracy: 0.9395\n",
      "batch loss: 0.19175326824188232\n",
      "batch accuracy: 0.939453125\n",
      "doing 159 / 277\n",
      "elapsed time 12104.700300216675\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1939 - accuracy: 0.9375\n",
      "batch loss: 0.1938696801662445\n",
      "batch accuracy: 0.9375\n",
      "doing 160 / 277\n",
      "elapsed time 12180.855967760086\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1684 - accuracy: 0.9414\n",
      "batch loss: 0.1683679074048996\n",
      "batch accuracy: 0.94140625\n",
      "doing 161 / 277\n",
      "elapsed time 12261.259574174881\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1967 - accuracy: 0.9326\n",
      "batch loss: 0.19669777154922485\n",
      "batch accuracy: 0.9326171875\n",
      "doing 162 / 277\n",
      "elapsed time 12355.214525938034\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1882 - accuracy: 0.9336\n",
      "batch loss: 0.1882392317056656\n",
      "batch accuracy: 0.93359375\n",
      "doing 163 / 277\n",
      "elapsed time 12430.588072299957\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1367 - accuracy: 0.9521\n",
      "batch loss: 0.13665184378623962\n",
      "batch accuracy: 0.9521484375\n",
      "doing 164 / 277\n",
      "elapsed time 12511.073473453522\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1750 - accuracy: 0.9395\n",
      "batch loss: 0.174963116645813\n",
      "batch accuracy: 0.939453125\n",
      "doing 165 / 277\n",
      "elapsed time 12589.148248195648\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1497 - accuracy: 0.9482\n",
      "batch loss: 0.14965781569480896\n",
      "batch accuracy: 0.9482421875\n",
      "doing 166 / 277\n",
      "elapsed time 12672.379552602768\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1796 - accuracy: 0.9355\n",
      "batch loss: 0.17961463332176208\n",
      "batch accuracy: 0.935546875\n",
      "doing 167 / 277\n",
      "elapsed time 12757.202590227127\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1881 - accuracy: 0.9346\n",
      "batch loss: 0.1880609095096588\n",
      "batch accuracy: 0.9345703125\n",
      "doing 168 / 277\n",
      "elapsed time 12830.679190397263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1812 - accuracy: 0.9395\n",
      "batch loss: 0.181169331073761\n",
      "batch accuracy: 0.939453125\n",
      "doing 169 / 277\n",
      "elapsed time 12898.545837402344\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1666 - accuracy: 0.9316\n",
      "batch loss: 0.16664421558380127\n",
      "batch accuracy: 0.931640625\n",
      "doing 170 / 277\n",
      "elapsed time 12965.380977153778\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1928 - accuracy: 0.9414\n",
      "batch loss: 0.1927720457315445\n",
      "batch accuracy: 0.94140625\n",
      "doing 171 / 277\n",
      "elapsed time 13039.689438343048\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1842 - accuracy: 0.9326\n",
      "batch loss: 0.18420256674289703\n",
      "batch accuracy: 0.9326171875\n",
      "doing 172 / 277\n",
      "elapsed time 13109.972633838654\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2062 - accuracy: 0.9404\n",
      "batch loss: 0.2061648964881897\n",
      "batch accuracy: 0.9404296875\n",
      "doing 173 / 277\n",
      "elapsed time 13183.49531006813\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1810 - accuracy: 0.9453\n",
      "batch loss: 0.18101298809051514\n",
      "batch accuracy: 0.9453125\n",
      "doing 174 / 277\n",
      "elapsed time 13258.251339673996\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1609 - accuracy: 0.9512\n",
      "batch loss: 0.16085129976272583\n",
      "batch accuracy: 0.951171875\n",
      "doing 175 / 277\n",
      "elapsed time 13333.217740535736\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1649 - accuracy: 0.9443\n",
      "batch loss: 0.1649157702922821\n",
      "batch accuracy: 0.9443359375\n",
      "doing 176 / 277\n",
      "elapsed time 13406.985486030579\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1778 - accuracy: 0.9424\n",
      "batch loss: 0.17779803276062012\n",
      "batch accuracy: 0.9423828125\n",
      "doing 177 / 277\n",
      "elapsed time 13482.372548103333\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1787 - accuracy: 0.9365\n",
      "batch loss: 0.17867107689380646\n",
      "batch accuracy: 0.9365234375\n",
      "doing 178 / 277\n",
      "elapsed time 13555.37421131134\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1417 - accuracy: 0.9531\n",
      "batch loss: 0.14166180789470673\n",
      "batch accuracy: 0.953125\n",
      "doing 179 / 277\n",
      "elapsed time 13619.614698171616\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1558 - accuracy: 0.9463\n",
      "batch loss: 0.15583814680576324\n",
      "batch accuracy: 0.9462890625\n",
      "doing 180 / 277\n",
      "elapsed time 13689.87181353569\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2129 - accuracy: 0.9189\n",
      "batch loss: 0.21289436519145966\n",
      "batch accuracy: 0.9189453125\n",
      "doing 181 / 277\n",
      "elapsed time 13759.613211631775\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1727 - accuracy: 0.9326\n",
      "batch loss: 0.1727023422718048\n",
      "batch accuracy: 0.9326171875\n",
      "doing 182 / 277\n",
      "elapsed time 13827.653069972992\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1703 - accuracy: 0.9443\n",
      "batch loss: 0.17034752666950226\n",
      "batch accuracy: 0.9443359375\n",
      "doing 183 / 277\n",
      "elapsed time 13900.140552043915\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1316 - accuracy: 0.9551\n",
      "batch loss: 0.13160601258277893\n",
      "batch accuracy: 0.955078125\n",
      "doing 184 / 277\n",
      "elapsed time 13978.94102716446\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1490 - accuracy: 0.9473\n",
      "batch loss: 0.1490023136138916\n",
      "batch accuracy: 0.947265625\n",
      "doing 185 / 277\n",
      "elapsed time 14040.387079954147\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1518 - accuracy: 0.9482\n",
      "batch loss: 0.1517995297908783\n",
      "batch accuracy: 0.9482421875\n",
      "doing 186 / 277\n",
      "elapsed time 14103.693443775177\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1862 - accuracy: 0.9424\n",
      "batch loss: 0.18616414070129395\n",
      "batch accuracy: 0.9423828125\n",
      "doing 187 / 277\n",
      "elapsed time 14173.492773532867\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1820 - accuracy: 0.9346\n",
      "batch loss: 0.18199950456619263\n",
      "batch accuracy: 0.9345703125\n",
      "doing 188 / 277\n",
      "elapsed time 14228.515612363815\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1555 - accuracy: 0.9502\n",
      "batch loss: 0.15554217994213104\n",
      "batch accuracy: 0.9501953125\n",
      "doing 189 / 277\n",
      "elapsed time 14279.319229841232\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1549 - accuracy: 0.9424\n",
      "batch loss: 0.1549403965473175\n",
      "batch accuracy: 0.9423828125\n",
      "doing 190 / 277\n",
      "elapsed time 14329.158369541168\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1527 - accuracy: 0.9463\n",
      "batch loss: 0.15271268784999847\n",
      "batch accuracy: 0.9462890625\n",
      "doing 191 / 277\n",
      "elapsed time 14378.026527404785\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1775 - accuracy: 0.9434\n",
      "batch loss: 0.17752116918563843\n",
      "batch accuracy: 0.943359375\n",
      "doing 192 / 277\n",
      "elapsed time 14437.37697839737\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1716 - accuracy: 0.9385\n",
      "batch loss: 0.17157229781150818\n",
      "batch accuracy: 0.9384765625\n",
      "doing 193 / 277\n",
      "elapsed time 14497.270977258682\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1654 - accuracy: 0.9424\n",
      "batch loss: 0.1654355227947235\n",
      "batch accuracy: 0.9423828125\n",
      "doing 194 / 277\n",
      "elapsed time 14561.493582248688\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1700 - accuracy: 0.9385\n",
      "batch loss: 0.17004474997520447\n",
      "batch accuracy: 0.9384765625\n",
      "doing 195 / 277\n",
      "elapsed time 14626.46361899376\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1553 - accuracy: 0.9502\n",
      "batch loss: 0.15529417991638184\n",
      "batch accuracy: 0.9501953125\n",
      "doing 196 / 277\n",
      "elapsed time 14688.016056060791\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1752 - accuracy: 0.9414\n",
      "batch loss: 0.17520660161972046\n",
      "batch accuracy: 0.94140625\n",
      "doing 197 / 277\n",
      "elapsed time 14752.11172246933\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1706 - accuracy: 0.9355\n",
      "batch loss: 0.17061686515808105\n",
      "batch accuracy: 0.935546875\n",
      "doing 198 / 277\n",
      "elapsed time 14821.650763750076\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1648 - accuracy: 0.9434\n",
      "batch loss: 0.16479554772377014\n",
      "batch accuracy: 0.943359375\n",
      "doing 199 / 277\n",
      "elapsed time 14886.81128501892\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1752 - accuracy: 0.9326\n",
      "batch loss: 0.17517662048339844\n",
      "batch accuracy: 0.9326171875\n",
      "doing 200 / 277\n",
      "elapsed time 14956.230541706085\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1717 - accuracy: 0.9414\n",
      "batch loss: 0.17168544232845306\n",
      "batch accuracy: 0.94140625\n",
      "doing 201 / 277\n",
      "elapsed time 15019.822144269943\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1686 - accuracy: 0.9443\n",
      "batch loss: 0.16859079897403717\n",
      "batch accuracy: 0.9443359375\n",
      "doing 202 / 277\n",
      "elapsed time 15086.00994849205\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1562 - accuracy: 0.9434\n",
      "batch loss: 0.15618064999580383\n",
      "batch accuracy: 0.943359375\n",
      "doing 203 / 277\n",
      "elapsed time 15151.517671585083\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2011 - accuracy: 0.9277\n",
      "batch loss: 0.2010941505432129\n",
      "batch accuracy: 0.927734375\n",
      "doing 204 / 277\n",
      "elapsed time 15220.148832082748\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1409 - accuracy: 0.9512\n",
      "batch loss: 0.1409420520067215\n",
      "batch accuracy: 0.951171875\n",
      "doing 205 / 277\n",
      "elapsed time 15289.151806354523\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1814 - accuracy: 0.9287\n",
      "batch loss: 0.181447833776474\n",
      "batch accuracy: 0.9287109375\n",
      "doing 206 / 277\n",
      "elapsed time 15354.778500080109\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1594 - accuracy: 0.9424\n",
      "batch loss: 0.15939633548259735\n",
      "batch accuracy: 0.9423828125\n",
      "doing 207 / 277\n",
      "elapsed time 15422.188403367996\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1469 - accuracy: 0.9521\n",
      "batch loss: 0.1469244807958603\n",
      "batch accuracy: 0.9521484375\n",
      "doing 208 / 277\n",
      "elapsed time 15488.098441362381\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1420 - accuracy: 0.9492\n",
      "batch loss: 0.14204862713813782\n",
      "batch accuracy: 0.94921875\n",
      "doing 209 / 277\n",
      "elapsed time 15548.385432243347\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1511 - accuracy: 0.9541\n",
      "batch loss: 0.15110629796981812\n",
      "batch accuracy: 0.9541015625\n",
      "doing 210 / 277\n",
      "elapsed time 15615.953434467316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1275 - accuracy: 0.9551\n",
      "batch loss: 0.1275320053100586\n",
      "batch accuracy: 0.955078125\n",
      "doing 211 / 277\n",
      "elapsed time 15677.156501531601\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1554 - accuracy: 0.9521\n",
      "batch loss: 0.15538813173770905\n",
      "batch accuracy: 0.9521484375\n",
      "doing 212 / 277\n",
      "elapsed time 15738.466637849808\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1442 - accuracy: 0.9463\n",
      "batch loss: 0.1441921442747116\n",
      "batch accuracy: 0.9462890625\n",
      "doing 213 / 277\n",
      "elapsed time 15800.885137796402\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1396 - accuracy: 0.9443\n",
      "batch loss: 0.1396017223596573\n",
      "batch accuracy: 0.9443359375\n",
      "doing 214 / 277\n",
      "elapsed time 15863.963795661926\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1676 - accuracy: 0.9385\n",
      "batch loss: 0.16755597293376923\n",
      "batch accuracy: 0.9384765625\n",
      "doing 215 / 277\n",
      "elapsed time 15923.281783342361\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1754 - accuracy: 0.9385\n",
      "batch loss: 0.17541980743408203\n",
      "batch accuracy: 0.9384765625\n",
      "doing 216 / 277\n",
      "elapsed time 15986.940523147583\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1620 - accuracy: 0.9404\n",
      "batch loss: 0.16200996935367584\n",
      "batch accuracy: 0.9404296875\n",
      "doing 217 / 277\n",
      "elapsed time 16050.98318529129\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1418 - accuracy: 0.9453\n",
      "batch loss: 0.14184339344501495\n",
      "batch accuracy: 0.9453125\n",
      "doing 218 / 277\n",
      "elapsed time 16114.52745461464\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1699 - accuracy: 0.9404\n",
      "batch loss: 0.16993960738182068\n",
      "batch accuracy: 0.9404296875\n",
      "doing 219 / 277\n",
      "elapsed time 16174.415974855423\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1281 - accuracy: 0.9512\n",
      "batch loss: 0.12805086374282837\n",
      "batch accuracy: 0.951171875\n",
      "doing 220 / 277\n",
      "elapsed time 16234.914842128754\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1460 - accuracy: 0.9502\n",
      "batch loss: 0.146021768450737\n",
      "batch accuracy: 0.9501953125\n",
      "doing 221 / 277\n",
      "elapsed time 16294.210316419601\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1442 - accuracy: 0.9512\n",
      "batch loss: 0.1441752165555954\n",
      "batch accuracy: 0.951171875\n",
      "doing 222 / 277\n",
      "elapsed time 16356.169597625732\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1583 - accuracy: 0.9463\n",
      "batch loss: 0.15829648077487946\n",
      "batch accuracy: 0.9462890625\n",
      "doing 223 / 277\n",
      "elapsed time 16414.209770679474\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1648 - accuracy: 0.9395\n",
      "batch loss: 0.1647668033838272\n",
      "batch accuracy: 0.939453125\n",
      "doing 224 / 277\n",
      "elapsed time 16472.171248197556\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1154 - accuracy: 0.9600\n",
      "batch loss: 0.11544044315814972\n",
      "batch accuracy: 0.9599609375\n",
      "doing 225 / 277\n",
      "elapsed time 16532.325284957886\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1541 - accuracy: 0.9551\n",
      "batch loss: 0.15407902002334595\n",
      "batch accuracy: 0.955078125\n",
      "doing 226 / 277\n",
      "elapsed time 16591.666347026825\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1556 - accuracy: 0.9541\n",
      "batch loss: 0.15562109649181366\n",
      "batch accuracy: 0.9541015625\n",
      "doing 227 / 277\n",
      "elapsed time 16648.469099521637\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1329 - accuracy: 0.9531\n",
      "batch loss: 0.13293248414993286\n",
      "batch accuracy: 0.953125\n",
      "doing 228 / 277\n",
      "elapsed time 16696.20771074295\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1260 - accuracy: 0.9482\n",
      "batch loss: 0.1260276734828949\n",
      "batch accuracy: 0.9482421875\n",
      "doing 229 / 277\n",
      "elapsed time 16745.018268346786\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1212 - accuracy: 0.9648\n",
      "batch loss: 0.12119749933481216\n",
      "batch accuracy: 0.96484375\n",
      "doing 230 / 277\n",
      "elapsed time 16798.043679714203\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1444 - accuracy: 0.9443\n",
      "batch loss: 0.14439117908477783\n",
      "batch accuracy: 0.9443359375\n",
      "doing 231 / 277\n",
      "elapsed time 16845.610380649567\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1617 - accuracy: 0.9492\n",
      "batch loss: 0.16171090304851532\n",
      "batch accuracy: 0.94921875\n",
      "doing 232 / 277\n",
      "elapsed time 16905.803901195526\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1282 - accuracy: 0.9531\n",
      "batch loss: 0.1282036304473877\n",
      "batch accuracy: 0.953125\n",
      "doing 233 / 277\n",
      "elapsed time 16959.215790510178\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1555 - accuracy: 0.9492\n",
      "batch loss: 0.15546447038650513\n",
      "batch accuracy: 0.94921875\n",
      "doing 234 / 277\n",
      "elapsed time 17015.938931703568\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1493 - accuracy: 0.9463\n",
      "batch loss: 0.14931482076644897\n",
      "batch accuracy: 0.9462890625\n",
      "doing 235 / 277\n",
      "elapsed time 17077.356674671173\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1370 - accuracy: 0.9502\n",
      "batch loss: 0.13704608380794525\n",
      "batch accuracy: 0.9501953125\n",
      "doing 236 / 277\n",
      "elapsed time 17131.74655532837\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1491 - accuracy: 0.9482\n",
      "batch loss: 0.1491059958934784\n",
      "batch accuracy: 0.9482421875\n",
      "doing 237 / 277\n",
      "elapsed time 17186.610597133636\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1383 - accuracy: 0.9531\n",
      "batch loss: 0.13828903436660767\n",
      "batch accuracy: 0.953125\n",
      "doing 238 / 277\n",
      "elapsed time 17238.254813432693\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1261 - accuracy: 0.9541\n",
      "batch loss: 0.1261361539363861\n",
      "batch accuracy: 0.9541015625\n",
      "doing 239 / 277\n",
      "elapsed time 17287.329437494278\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1467 - accuracy: 0.9385\n",
      "batch loss: 0.14672046899795532\n",
      "batch accuracy: 0.9384765625\n",
      "doing 240 / 277\n",
      "elapsed time 17331.07347893715\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1341 - accuracy: 0.9463\n",
      "batch loss: 0.13409146666526794\n",
      "batch accuracy: 0.9462890625\n",
      "doing 241 / 277\n",
      "elapsed time 17376.93761897087\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1364 - accuracy: 0.9502\n",
      "batch loss: 0.13644635677337646\n",
      "batch accuracy: 0.9501953125\n",
      "doing 242 / 277\n",
      "elapsed time 17426.13877081871\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1536 - accuracy: 0.9463\n",
      "batch loss: 0.1536398082971573\n",
      "batch accuracy: 0.9462890625\n",
      "doing 243 / 277\n",
      "elapsed time 17480.279022216797\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1308 - accuracy: 0.9551\n",
      "batch loss: 0.13075919449329376\n",
      "batch accuracy: 0.955078125\n",
      "doing 244 / 277\n",
      "elapsed time 17533.481387138367\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1316 - accuracy: 0.9521\n",
      "batch loss: 0.13160616159439087\n",
      "batch accuracy: 0.9521484375\n",
      "doing 245 / 277\n",
      "elapsed time 17587.141718626022\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1635 - accuracy: 0.9453\n",
      "batch loss: 0.16352903842926025\n",
      "batch accuracy: 0.9453125\n",
      "doing 246 / 277\n",
      "elapsed time 17637.351392507553\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1657 - accuracy: 0.9453\n",
      "batch loss: 0.16574600338935852\n",
      "batch accuracy: 0.9453125\n",
      "doing 247 / 277\n",
      "elapsed time 17689.357248306274\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1680 - accuracy: 0.9375\n",
      "batch loss: 0.16802480816841125\n",
      "batch accuracy: 0.9375\n",
      "doing 248 / 277\n",
      "elapsed time 17742.977694034576\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1503 - accuracy: 0.9473\n",
      "batch loss: 0.15030290186405182\n",
      "batch accuracy: 0.947265625\n",
      "doing 249 / 277\n",
      "elapsed time 17791.249224185944\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1647 - accuracy: 0.9424\n",
      "batch loss: 0.16470062732696533\n",
      "batch accuracy: 0.9423828125\n",
      "doing 250 / 277\n",
      "elapsed time 17840.49599146843\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1627 - accuracy: 0.9463\n",
      "batch loss: 0.1626630425453186\n",
      "batch accuracy: 0.9462890625\n",
      "doing 251 / 277\n",
      "elapsed time 17889.665657281876\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1547 - accuracy: 0.9492\n",
      "batch loss: 0.1547074168920517\n",
      "batch accuracy: 0.94921875\n",
      "doing 252 / 277\n",
      "elapsed time 17939.669625520706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1363 - accuracy: 0.9434\n",
      "batch loss: 0.1363138109445572\n",
      "batch accuracy: 0.943359375\n",
      "doing 253 / 277\n",
      "elapsed time 17987.97304725647\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1364 - accuracy: 0.9590\n",
      "batch loss: 0.1364179402589798\n",
      "batch accuracy: 0.958984375\n",
      "doing 254 / 277\n",
      "elapsed time 18039.244697332382\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1608 - accuracy: 0.9443\n",
      "batch loss: 0.16076989471912384\n",
      "batch accuracy: 0.9443359375\n",
      "doing 255 / 277\n",
      "elapsed time 18088.08646273613\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1588 - accuracy: 0.9424\n",
      "batch loss: 0.1588284820318222\n",
      "batch accuracy: 0.9423828125\n",
      "doing 256 / 277\n",
      "elapsed time 18136.00688147545\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1549 - accuracy: 0.9385\n",
      "batch loss: 0.15493834018707275\n",
      "batch accuracy: 0.9384765625\n",
      "doing 257 / 277\n",
      "elapsed time 18187.584941625595\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1373 - accuracy: 0.9561\n",
      "batch loss: 0.13729216158390045\n",
      "batch accuracy: 0.9560546875\n",
      "doing 258 / 277\n",
      "elapsed time 18235.384788274765\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1723 - accuracy: 0.9395\n",
      "batch loss: 0.17231404781341553\n",
      "batch accuracy: 0.939453125\n",
      "doing 259 / 277\n",
      "elapsed time 18283.63703942299\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1235 - accuracy: 0.9570\n",
      "batch loss: 0.12347763031721115\n",
      "batch accuracy: 0.95703125\n",
      "doing 260 / 277\n",
      "elapsed time 18330.557235717773\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1297 - accuracy: 0.9502\n",
      "batch loss: 0.12972939014434814\n",
      "batch accuracy: 0.9501953125\n",
      "doing 261 / 277\n",
      "elapsed time 18378.011939764023\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1775 - accuracy: 0.9414\n",
      "batch loss: 0.17753836512565613\n",
      "batch accuracy: 0.94140625\n",
      "doing 262 / 277\n",
      "elapsed time 18422.399696588516\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1202 - accuracy: 0.9629\n",
      "batch loss: 0.120242640376091\n",
      "batch accuracy: 0.962890625\n",
      "doing 263 / 277\n",
      "elapsed time 18468.58930826187\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1380 - accuracy: 0.9482\n",
      "batch loss: 0.13802896440029144\n",
      "batch accuracy: 0.9482421875\n",
      "doing 264 / 277\n",
      "elapsed time 18513.633714199066\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1465 - accuracy: 0.9443\n",
      "batch loss: 0.14648211002349854\n",
      "batch accuracy: 0.9443359375\n",
      "doing 265 / 277\n",
      "elapsed time 18558.285270929337\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0982 - accuracy: 0.9629\n",
      "batch loss: 0.09819366782903671\n",
      "batch accuracy: 0.962890625\n",
      "doing 266 / 277\n",
      "elapsed time 18607.928230285645\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1404 - accuracy: 0.9551\n",
      "batch loss: 0.1403849571943283\n",
      "batch accuracy: 0.955078125\n",
      "doing 267 / 277\n",
      "elapsed time 18655.189333438873\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1585 - accuracy: 0.9443\n",
      "batch loss: 0.1584641933441162\n",
      "batch accuracy: 0.9443359375\n",
      "doing 268 / 277\n",
      "elapsed time 18706.719074964523\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1252 - accuracy: 0.9521\n",
      "batch loss: 0.12524795532226562\n",
      "batch accuracy: 0.9521484375\n",
      "doing 269 / 277\n",
      "elapsed time 18753.919924497604\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1321 - accuracy: 0.9551\n",
      "batch loss: 0.1320551186800003\n",
      "batch accuracy: 0.955078125\n",
      "doing 270 / 277\n",
      "elapsed time 18801.698259592056\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1310 - accuracy: 0.9561\n",
      "batch loss: 0.13100622594356537\n",
      "batch accuracy: 0.9560546875\n",
      "doing 271 / 277\n",
      "elapsed time 18853.58780002594\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1580 - accuracy: 0.9414\n",
      "batch loss: 0.1579703539609909\n",
      "batch accuracy: 0.94140625\n",
      "doing 272 / 277\n",
      "elapsed time 18897.894274950027\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1602 - accuracy: 0.9316\n",
      "batch loss: 0.1602363884449005\n",
      "batch accuracy: 0.931640625\n",
      "doing 273 / 277\n",
      "elapsed time 18944.480535030365\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1380 - accuracy: 0.9531\n",
      "batch loss: 0.13798022270202637\n",
      "batch accuracy: 0.953125\n",
      "doing 274 / 277\n",
      "elapsed time 18990.912093639374\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1329 - accuracy: 0.9541\n",
      "batch loss: 0.13291332125663757\n",
      "batch accuracy: 0.9541015625\n",
      "doing 275 / 277\n",
      "elapsed time 19034.687642097473\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1518 - accuracy: 0.9434\n",
      "batch loss: 0.15184056758880615\n",
      "batch accuracy: 0.943359375\n",
      "doing 276 / 277\n",
      "elapsed time 19057.912895917892\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.1716 - accuracy: 0.9269\n",
      "batch loss: 0.1716105192899704\n",
      "batch accuracy: 0.9268738627433777\n",
      "Train loss 0.1776070094764878\n",
      "Train accuracy 0.9375920818600844\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 0.1651 - accuracy: 0.9482\n",
      "Validation loss: 0.16510532796382904\n",
      "Validation accuracy: 0.9482222199440002\n",
      "==================================================\n",
      "4 / 10\n",
      "doing 0 / 277\n",
      "elapsed time 25.589552879333496\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1495 - accuracy: 0.9355\n",
      "batch loss: 0.14947302639484406\n",
      "batch accuracy: 0.935546875\n",
      "doing 1 / 277\n",
      "elapsed time 58.45439839363098\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1604 - accuracy: 0.9453\n",
      "batch loss: 0.16036604344844818\n",
      "batch accuracy: 0.9453125\n",
      "doing 2 / 277\n",
      "elapsed time 84.85763192176819\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1300 - accuracy: 0.9531\n",
      "batch loss: 0.13001304864883423\n",
      "batch accuracy: 0.953125\n",
      "doing 3 / 277\n",
      "elapsed time 111.18961381912231\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1318 - accuracy: 0.9473\n",
      "batch loss: 0.13175581395626068\n",
      "batch accuracy: 0.947265625\n",
      "doing 4 / 277\n",
      "elapsed time 146.81358218193054\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1556 - accuracy: 0.9434\n",
      "batch loss: 0.15564996004104614\n",
      "batch accuracy: 0.943359375\n",
      "doing 5 / 277\n",
      "elapsed time 173.35867476463318\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1464 - accuracy: 0.9482\n",
      "batch loss: 0.14638032019138336\n",
      "batch accuracy: 0.9482421875\n",
      "doing 6 / 277\n",
      "elapsed time 204.87804913520813\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1798 - accuracy: 0.9482\n",
      "batch loss: 0.17975744605064392\n",
      "batch accuracy: 0.9482421875\n",
      "doing 7 / 277\n",
      "elapsed time 230.88651180267334\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1508 - accuracy: 0.9453\n",
      "batch loss: 0.15082445740699768\n",
      "batch accuracy: 0.9453125\n",
      "doing 8 / 277\n",
      "elapsed time 254.59712100028992\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1353 - accuracy: 0.9482\n",
      "batch loss: 0.1353350132703781\n",
      "batch accuracy: 0.9482421875\n",
      "doing 9 / 277\n",
      "elapsed time 282.0575749874115\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1481 - accuracy: 0.9414\n",
      "batch loss: 0.14813083410263062\n",
      "batch accuracy: 0.94140625\n",
      "doing 10 / 277\n",
      "elapsed time 307.10347175598145\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1341 - accuracy: 0.9570\n",
      "batch loss: 0.1341356784105301\n",
      "batch accuracy: 0.95703125\n",
      "doing 11 / 277\n",
      "elapsed time 336.4475338459015\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1416 - accuracy: 0.9492\n",
      "batch loss: 0.1415635347366333\n",
      "batch accuracy: 0.94921875\n",
      "doing 12 / 277\n",
      "elapsed time 366.20389580726624\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1736 - accuracy: 0.9365\n",
      "batch loss: 0.1736201047897339\n",
      "batch accuracy: 0.9365234375\n",
      "doing 13 / 277\n",
      "elapsed time 388.5756995677948\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1202 - accuracy: 0.9609\n",
      "batch loss: 0.12023317068815231\n",
      "batch accuracy: 0.9609375\n",
      "doing 14 / 277\n",
      "elapsed time 421.78528690338135\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1472 - accuracy: 0.9531\n",
      "batch loss: 0.14717963337898254\n",
      "batch accuracy: 0.953125\n",
      "doing 15 / 277\n",
      "elapsed time 445.3976683616638\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1330 - accuracy: 0.9561\n",
      "batch loss: 0.1330396831035614\n",
      "batch accuracy: 0.9560546875\n",
      "doing 16 / 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 468.32370805740356\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1584 - accuracy: 0.9473\n",
      "batch loss: 0.15842348337173462\n",
      "batch accuracy: 0.947265625\n",
      "doing 17 / 277\n",
      "elapsed time 504.67826294898987\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1500 - accuracy: 0.9443\n",
      "batch loss: 0.150007963180542\n",
      "batch accuracy: 0.9443359375\n",
      "doing 18 / 277\n",
      "elapsed time 538.8054299354553\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1196 - accuracy: 0.9590\n",
      "batch loss: 0.1196419894695282\n",
      "batch accuracy: 0.958984375\n",
      "doing 19 / 277\n",
      "elapsed time 565.9835360050201\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1133 - accuracy: 0.9600\n",
      "batch loss: 0.11331550031900406\n",
      "batch accuracy: 0.9599609375\n",
      "doing 20 / 277\n",
      "elapsed time 596.2814252376556\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1242 - accuracy: 0.9492\n",
      "batch loss: 0.12416733801364899\n",
      "batch accuracy: 0.94921875\n",
      "doing 21 / 277\n",
      "elapsed time 620.0541305541992\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1302 - accuracy: 0.9512\n",
      "batch loss: 0.13017697632312775\n",
      "batch accuracy: 0.951171875\n",
      "doing 22 / 277\n",
      "elapsed time 651.7779939174652\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0990 - accuracy: 0.9629\n",
      "batch loss: 0.09901570528745651\n",
      "batch accuracy: 0.962890625\n",
      "doing 23 / 277\n",
      "elapsed time 687.8416764736176\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1319 - accuracy: 0.9561\n",
      "batch loss: 0.13189437985420227\n",
      "batch accuracy: 0.9560546875\n",
      "doing 24 / 277\n",
      "elapsed time 715.0405249595642\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1356 - accuracy: 0.9570\n",
      "batch loss: 0.13559836149215698\n",
      "batch accuracy: 0.95703125\n",
      "doing 25 / 277\n",
      "elapsed time 747.7030568122864\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1281 - accuracy: 0.9570\n",
      "batch loss: 0.12807586789131165\n",
      "batch accuracy: 0.95703125\n",
      "doing 26 / 277\n",
      "elapsed time 782.7794444561005\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1340 - accuracy: 0.9590\n",
      "batch loss: 0.1340223103761673\n",
      "batch accuracy: 0.958984375\n",
      "doing 27 / 277\n",
      "elapsed time 812.4315629005432\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1510 - accuracy: 0.9521\n",
      "batch loss: 0.15102240443229675\n",
      "batch accuracy: 0.9521484375\n",
      "doing 28 / 277\n",
      "elapsed time 849.0586969852448\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1399 - accuracy: 0.9453\n",
      "batch loss: 0.13987331092357635\n",
      "batch accuracy: 0.9453125\n",
      "doing 29 / 277\n",
      "elapsed time 882.8521733283997\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1222 - accuracy: 0.9521\n",
      "batch loss: 0.1222163736820221\n",
      "batch accuracy: 0.9521484375\n",
      "doing 30 / 277\n",
      "elapsed time 904.3249578475952\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1156 - accuracy: 0.9619\n",
      "batch loss: 0.1156311184167862\n",
      "batch accuracy: 0.9619140625\n",
      "doing 31 / 277\n",
      "elapsed time 939.8283934593201\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1024 - accuracy: 0.9697\n",
      "batch loss: 0.10241012275218964\n",
      "batch accuracy: 0.9697265625\n",
      "doing 32 / 277\n",
      "elapsed time 964.1782336235046\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1187 - accuracy: 0.9629\n",
      "batch loss: 0.11874120682477951\n",
      "batch accuracy: 0.962890625\n",
      "doing 33 / 277\n",
      "elapsed time 997.920120716095\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1524 - accuracy: 0.9561\n",
      "batch loss: 0.15235386788845062\n",
      "batch accuracy: 0.9560546875\n",
      "doing 34 / 277\n",
      "elapsed time 1032.4285151958466\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1572 - accuracy: 0.9443\n",
      "batch loss: 0.1571585088968277\n",
      "batch accuracy: 0.9443359375\n",
      "doing 35 / 277\n",
      "elapsed time 1055.4274821281433\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1323 - accuracy: 0.9590\n",
      "batch loss: 0.13234543800354004\n",
      "batch accuracy: 0.958984375\n",
      "doing 36 / 277\n",
      "elapsed time 1094.1790750026703\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1115 - accuracy: 0.9561\n",
      "batch loss: 0.11147268116474152\n",
      "batch accuracy: 0.9560546875\n",
      "doing 37 / 277\n",
      "elapsed time 1126.7668426036835\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0958 - accuracy: 0.9688\n",
      "batch loss: 0.09580212831497192\n",
      "batch accuracy: 0.96875\n",
      "doing 38 / 277\n",
      "elapsed time 1158.7661862373352\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1270 - accuracy: 0.9502\n",
      "batch loss: 0.1270238161087036\n",
      "batch accuracy: 0.9501953125\n",
      "doing 39 / 277\n",
      "elapsed time 1189.3630962371826\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1066 - accuracy: 0.9609\n",
      "batch loss: 0.10659107565879822\n",
      "batch accuracy: 0.9609375\n",
      "doing 40 / 277\n",
      "elapsed time 1219.7996380329132\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1369 - accuracy: 0.9531\n",
      "batch loss: 0.13690418004989624\n",
      "batch accuracy: 0.953125\n",
      "doing 41 / 277\n",
      "elapsed time 1247.623260974884\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1511 - accuracy: 0.9453\n",
      "batch loss: 0.1510956734418869\n",
      "batch accuracy: 0.9453125\n",
      "doing 42 / 277\n",
      "elapsed time 1278.7923793792725\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1530 - accuracy: 0.9385\n",
      "batch loss: 0.15298430621623993\n",
      "batch accuracy: 0.9384765625\n",
      "doing 43 / 277\n",
      "elapsed time 1310.3688333034515\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1631 - accuracy: 0.9492\n",
      "batch loss: 0.16309230029582977\n",
      "batch accuracy: 0.94921875\n",
      "doing 44 / 277\n",
      "elapsed time 1338.0258061885834\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1141 - accuracy: 0.9580\n",
      "batch loss: 0.11412252485752106\n",
      "batch accuracy: 0.9580078125\n",
      "doing 45 / 277\n",
      "elapsed time 1371.0219390392303\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1267 - accuracy: 0.9502\n",
      "batch loss: 0.1267414540052414\n",
      "batch accuracy: 0.9501953125\n",
      "doing 46 / 277\n",
      "elapsed time 1400.8568501472473\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1199 - accuracy: 0.9580\n",
      "batch loss: 0.11989988386631012\n",
      "batch accuracy: 0.9580078125\n",
      "doing 47 / 277\n",
      "elapsed time 1423.6657629013062\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1475 - accuracy: 0.9463\n",
      "batch loss: 0.14745308458805084\n",
      "batch accuracy: 0.9462890625\n",
      "doing 48 / 277\n",
      "elapsed time 1456.8050112724304\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1545 - accuracy: 0.9473\n",
      "batch loss: 0.15452931821346283\n",
      "batch accuracy: 0.947265625\n",
      "doing 49 / 277\n",
      "elapsed time 1484.438447713852\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1410 - accuracy: 0.9551\n",
      "batch loss: 0.1410152018070221\n",
      "batch accuracy: 0.955078125\n",
      "doing 50 / 277\n",
      "elapsed time 1508.3980898857117\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1386 - accuracy: 0.9463\n",
      "batch loss: 0.13861161470413208\n",
      "batch accuracy: 0.9462890625\n",
      "doing 51 / 277\n",
      "elapsed time 1536.1366999149323\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1109 - accuracy: 0.9609\n",
      "batch loss: 0.11089615523815155\n",
      "batch accuracy: 0.9609375\n",
      "doing 52 / 277\n",
      "elapsed time 1558.289521932602\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1396 - accuracy: 0.9551\n",
      "batch loss: 0.13961750268936157\n",
      "batch accuracy: 0.955078125\n",
      "doing 53 / 277\n",
      "elapsed time 1591.8121254444122\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1410 - accuracy: 0.9482\n",
      "batch loss: 0.14097096025943756\n",
      "batch accuracy: 0.9482421875\n",
      "doing 54 / 277\n",
      "elapsed time 1616.8980159759521\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1322 - accuracy: 0.9521\n",
      "batch loss: 0.13217219710350037\n",
      "batch accuracy: 0.9521484375\n",
      "doing 55 / 277\n",
      "elapsed time 1647.863225698471\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0862 - accuracy: 0.9697\n",
      "batch loss: 0.08622433245182037\n",
      "batch accuracy: 0.9697265625\n",
      "doing 56 / 277\n",
      "elapsed time 1676.0576963424683\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1288 - accuracy: 0.9482\n",
      "batch loss: 0.12880879640579224\n",
      "batch accuracy: 0.9482421875\n",
      "doing 57 / 277\n",
      "elapsed time 1698.3741297721863\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1395 - accuracy: 0.9502\n",
      "batch loss: 0.13951024413108826\n",
      "batch accuracy: 0.9501953125\n",
      "doing 58 / 277\n",
      "elapsed time 1731.7293643951416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1563 - accuracy: 0.9453\n",
      "batch loss: 0.15628942847251892\n",
      "batch accuracy: 0.9453125\n",
      "doing 59 / 277\n",
      "elapsed time 1753.8231976032257\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1439 - accuracy: 0.9580\n",
      "batch loss: 0.1439429074525833\n",
      "batch accuracy: 0.9580078125\n",
      "doing 60 / 277\n",
      "elapsed time 1783.2553799152374\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1348 - accuracy: 0.9473\n",
      "batch loss: 0.13477860391139984\n",
      "batch accuracy: 0.947265625\n",
      "doing 61 / 277\n",
      "elapsed time 1817.0989696979523\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1435 - accuracy: 0.9541\n",
      "batch loss: 0.14346370100975037\n",
      "batch accuracy: 0.9541015625\n",
      "doing 62 / 277\n",
      "elapsed time 1839.7934403419495\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1261 - accuracy: 0.9639\n",
      "batch loss: 0.1260533183813095\n",
      "batch accuracy: 0.9638671875\n",
      "doing 63 / 277\n",
      "elapsed time 1867.4230916500092\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1323 - accuracy: 0.9561\n",
      "batch loss: 0.1322784125804901\n",
      "batch accuracy: 0.9560546875\n",
      "doing 64 / 277\n",
      "elapsed time 1899.9792439937592\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1390 - accuracy: 0.9512\n",
      "batch loss: 0.13898812234401703\n",
      "batch accuracy: 0.951171875\n",
      "doing 65 / 277\n",
      "elapsed time 1920.0661005973816\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1135 - accuracy: 0.9648\n",
      "batch loss: 0.11347615718841553\n",
      "batch accuracy: 0.96484375\n",
      "doing 66 / 277\n",
      "elapsed time 1950.4810972213745\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1117 - accuracy: 0.9580\n",
      "batch loss: 0.11171415448188782\n",
      "batch accuracy: 0.9580078125\n",
      "doing 67 / 277\n",
      "elapsed time 1978.696536540985\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1503 - accuracy: 0.9463\n",
      "batch loss: 0.150263711810112\n",
      "batch accuracy: 0.9462890625\n",
      "doing 68 / 277\n",
      "elapsed time 1997.8634660243988\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1088 - accuracy: 0.9590\n",
      "batch loss: 0.10877566784620285\n",
      "batch accuracy: 0.958984375\n",
      "doing 69 / 277\n",
      "elapsed time 2028.8404264450073\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1199 - accuracy: 0.9570\n",
      "batch loss: 0.11988668888807297\n",
      "batch accuracy: 0.95703125\n",
      "doing 70 / 277\n",
      "elapsed time 2053.472456932068\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1157 - accuracy: 0.9551\n",
      "batch loss: 0.11568312346935272\n",
      "batch accuracy: 0.955078125\n",
      "doing 71 / 277\n",
      "elapsed time 2078.8893547058105\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1075 - accuracy: 0.9570\n",
      "batch loss: 0.10747647285461426\n",
      "batch accuracy: 0.95703125\n",
      "doing 72 / 277\n",
      "elapsed time 2109.3090600967407\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1165 - accuracy: 0.9570\n",
      "batch loss: 0.11654786765575409\n",
      "batch accuracy: 0.95703125\n",
      "doing 73 / 277\n",
      "elapsed time 2135.271324157715\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1441 - accuracy: 0.9482\n",
      "batch loss: 0.1441483050584793\n",
      "batch accuracy: 0.9482421875\n",
      "doing 74 / 277\n",
      "elapsed time 2158.9887425899506\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1407 - accuracy: 0.9502\n",
      "batch loss: 0.14071635901927948\n",
      "batch accuracy: 0.9501953125\n",
      "doing 75 / 277\n",
      "elapsed time 2189.60085105896\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1467 - accuracy: 0.9580\n",
      "batch loss: 0.14668570458889008\n",
      "batch accuracy: 0.9580078125\n",
      "doing 76 / 277\n",
      "elapsed time 2242.3499097824097\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1374 - accuracy: 0.9512\n",
      "batch loss: 0.13741475343704224\n",
      "batch accuracy: 0.951171875\n",
      "doing 77 / 277\n",
      "elapsed time 2311.515263080597\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1487 - accuracy: 0.9482\n",
      "batch loss: 0.1486847996711731\n",
      "batch accuracy: 0.9482421875\n",
      "doing 78 / 277\n",
      "elapsed time 2371.31151676178\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1200 - accuracy: 0.9590\n",
      "batch loss: 0.11998746544122696\n",
      "batch accuracy: 0.958984375\n",
      "doing 79 / 277\n",
      "elapsed time 2431.867453813553\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1252 - accuracy: 0.9531\n",
      "batch loss: 0.1251784861087799\n",
      "batch accuracy: 0.953125\n",
      "doing 80 / 277\n",
      "elapsed time 2492.955579996109\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1017 - accuracy: 0.9639\n",
      "batch loss: 0.10172176361083984\n",
      "batch accuracy: 0.9638671875\n",
      "doing 81 / 277\n",
      "elapsed time 2559.851704597473\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1439 - accuracy: 0.9512\n",
      "batch loss: 0.14394156634807587\n",
      "batch accuracy: 0.951171875\n",
      "doing 82 / 277\n",
      "elapsed time 2628.3973639011383\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1068 - accuracy: 0.9668\n",
      "batch loss: 0.1068274974822998\n",
      "batch accuracy: 0.966796875\n",
      "doing 83 / 277\n",
      "elapsed time 2697.297220468521\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1226 - accuracy: 0.9600\n",
      "batch loss: 0.12257950752973557\n",
      "batch accuracy: 0.9599609375\n",
      "doing 84 / 277\n",
      "elapsed time 2785.944613456726\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1210 - accuracy: 0.9531\n",
      "batch loss: 0.12103681266307831\n",
      "batch accuracy: 0.953125\n",
      "doing 85 / 277\n",
      "elapsed time 2903.7802844047546\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1041 - accuracy: 0.9609\n",
      "batch loss: 0.10406890511512756\n",
      "batch accuracy: 0.9609375\n",
      "doing 86 / 277\n",
      "elapsed time 3016.989200592041\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1455 - accuracy: 0.9482\n",
      "batch loss: 0.14546969532966614\n",
      "batch accuracy: 0.9482421875\n",
      "doing 87 / 277\n",
      "elapsed time 3133.3798887729645\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1337 - accuracy: 0.9502\n",
      "batch loss: 0.13373781740665436\n",
      "batch accuracy: 0.9501953125\n",
      "doing 88 / 277\n",
      "elapsed time 3261.370977640152\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1126 - accuracy: 0.9658\n",
      "batch loss: 0.1125514805316925\n",
      "batch accuracy: 0.9658203125\n",
      "doing 89 / 277\n",
      "elapsed time 3395.6487572193146\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1469 - accuracy: 0.9512\n",
      "batch loss: 0.14685054123401642\n",
      "batch accuracy: 0.951171875\n",
      "doing 90 / 277\n",
      "elapsed time 3525.8006222248077\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1259 - accuracy: 0.9590\n",
      "batch loss: 0.12588191032409668\n",
      "batch accuracy: 0.958984375\n",
      "doing 91 / 277\n",
      "elapsed time 3656.336340904236\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0968 - accuracy: 0.9668\n",
      "batch loss: 0.09681659936904907\n",
      "batch accuracy: 0.966796875\n",
      "doing 92 / 277\n",
      "elapsed time 3786.914209842682\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1130 - accuracy: 0.9639\n",
      "batch loss: 0.11303122341632843\n",
      "batch accuracy: 0.9638671875\n",
      "doing 93 / 277\n",
      "elapsed time 3917.96515417099\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1459 - accuracy: 0.9414\n",
      "batch loss: 0.14586594700813293\n",
      "batch accuracy: 0.94140625\n",
      "doing 94 / 277\n",
      "elapsed time 4044.383176803589\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0956 - accuracy: 0.9648\n",
      "batch loss: 0.09556685388088226\n",
      "batch accuracy: 0.96484375\n",
      "doing 95 / 277\n",
      "elapsed time 4165.105435371399\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1175 - accuracy: 0.9502\n",
      "batch loss: 0.11751899868249893\n",
      "batch accuracy: 0.9501953125\n",
      "doing 96 / 277\n",
      "elapsed time 4291.833343267441\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1417 - accuracy: 0.9492\n",
      "batch loss: 0.1416776031255722\n",
      "batch accuracy: 0.94921875\n",
      "doing 97 / 277\n",
      "elapsed time 4413.966065406799\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1025 - accuracy: 0.9668\n",
      "batch loss: 0.10246196389198303\n",
      "batch accuracy: 0.966796875\n",
      "doing 98 / 277\n",
      "elapsed time 4540.0701816082\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1220 - accuracy: 0.9580\n",
      "batch loss: 0.12195909023284912\n",
      "batch accuracy: 0.9580078125\n",
      "doing 99 / 277\n",
      "elapsed time 4668.764433145523\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1159 - accuracy: 0.9639\n",
      "batch loss: 0.11591530591249466\n",
      "batch accuracy: 0.9638671875\n",
      "doing 100 / 277\n",
      "elapsed time 4789.230596780777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1601 - accuracy: 0.9453\n",
      "batch loss: 0.16009968519210815\n",
      "batch accuracy: 0.9453125\n",
      "doing 101 / 277\n",
      "elapsed time 4899.366019964218\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1252 - accuracy: 0.9512\n",
      "batch loss: 0.12524867057800293\n",
      "batch accuracy: 0.951171875\n",
      "doing 102 / 277\n",
      "elapsed time 5018.024402856827\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1222 - accuracy: 0.9590\n",
      "batch loss: 0.12218937277793884\n",
      "batch accuracy: 0.958984375\n",
      "doing 103 / 277\n",
      "elapsed time 5131.315201044083\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1213 - accuracy: 0.9561\n",
      "batch loss: 0.12131571769714355\n",
      "batch accuracy: 0.9560546875\n",
      "doing 104 / 277\n",
      "elapsed time 5256.865937232971\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1494 - accuracy: 0.9512\n",
      "batch loss: 0.1494196057319641\n",
      "batch accuracy: 0.951171875\n",
      "doing 105 / 277\n",
      "elapsed time 5375.532459974289\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1306 - accuracy: 0.9561\n",
      "batch loss: 0.13063524663448334\n",
      "batch accuracy: 0.9560546875\n",
      "doing 106 / 277\n",
      "elapsed time 5492.010552883148\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1316 - accuracy: 0.9580\n",
      "batch loss: 0.13157156109809875\n",
      "batch accuracy: 0.9580078125\n",
      "doing 107 / 277\n",
      "elapsed time 5601.72797703743\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1334 - accuracy: 0.9492\n",
      "batch loss: 0.13343125581741333\n",
      "batch accuracy: 0.94921875\n",
      "doing 108 / 277\n",
      "elapsed time 5710.217792749405\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1387 - accuracy: 0.9492\n",
      "batch loss: 0.13867536187171936\n",
      "batch accuracy: 0.94921875\n",
      "doing 109 / 277\n",
      "elapsed time 5833.570022583008\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1112 - accuracy: 0.9590\n",
      "batch loss: 0.11116794496774673\n",
      "batch accuracy: 0.958984375\n",
      "doing 110 / 277\n",
      "elapsed time 5955.040603876114\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1188 - accuracy: 0.9619\n",
      "batch loss: 0.11883324384689331\n",
      "batch accuracy: 0.9619140625\n",
      "doing 111 / 277\n",
      "elapsed time 6072.968577623367\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1177 - accuracy: 0.9590\n",
      "batch loss: 0.11765675246715546\n",
      "batch accuracy: 0.958984375\n",
      "doing 112 / 277\n",
      "elapsed time 6191.669713020325\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1609 - accuracy: 0.9443\n",
      "batch loss: 0.16085320711135864\n",
      "batch accuracy: 0.9443359375\n",
      "doing 113 / 277\n",
      "elapsed time 6306.9136209487915\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1211 - accuracy: 0.9580\n",
      "batch loss: 0.1210939809679985\n",
      "batch accuracy: 0.9580078125\n",
      "doing 114 / 277\n",
      "elapsed time 6416.452947378159\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1453 - accuracy: 0.9414\n",
      "batch loss: 0.1452726423740387\n",
      "batch accuracy: 0.94140625\n",
      "doing 115 / 277\n",
      "elapsed time 6520.816509485245\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1312 - accuracy: 0.9648\n",
      "batch loss: 0.13118451833724976\n",
      "batch accuracy: 0.96484375\n",
      "doing 116 / 277\n",
      "elapsed time 6630.142976760864\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1524 - accuracy: 0.9482\n",
      "batch loss: 0.15236158668994904\n",
      "batch accuracy: 0.9482421875\n",
      "doing 117 / 277\n",
      "elapsed time 6750.632466554642\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1314 - accuracy: 0.9551\n",
      "batch loss: 0.1314001828432083\n",
      "batch accuracy: 0.955078125\n",
      "doing 118 / 277\n",
      "elapsed time 6863.931879758835\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1364 - accuracy: 0.9521\n",
      "batch loss: 0.1364070028066635\n",
      "batch accuracy: 0.9521484375\n",
      "doing 119 / 277\n",
      "elapsed time 6978.119759082794\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1279 - accuracy: 0.9580\n",
      "batch loss: 0.1278689205646515\n",
      "batch accuracy: 0.9580078125\n",
      "doing 120 / 277\n",
      "elapsed time 7091.807049036026\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1462 - accuracy: 0.9414\n",
      "batch loss: 0.14618656039237976\n",
      "batch accuracy: 0.94140625\n",
      "doing 121 / 277\n",
      "elapsed time 7196.408485412598\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1525 - accuracy: 0.9434\n",
      "batch loss: 0.1524907946586609\n",
      "batch accuracy: 0.943359375\n",
      "doing 122 / 277\n",
      "elapsed time 7296.769510984421\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1596 - accuracy: 0.9434\n",
      "batch loss: 0.15961769223213196\n",
      "batch accuracy: 0.943359375\n",
      "doing 123 / 277\n",
      "elapsed time 7408.536720275879\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1245 - accuracy: 0.9570\n",
      "batch loss: 0.12453757971525192\n",
      "batch accuracy: 0.95703125\n",
      "doing 124 / 277\n",
      "elapsed time 7521.255775213242\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1124 - accuracy: 0.9648\n",
      "batch loss: 0.11235189437866211\n",
      "batch accuracy: 0.96484375\n",
      "doing 125 / 277\n",
      "elapsed time 7628.865171432495\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1207 - accuracy: 0.9639\n",
      "batch loss: 0.12072249501943588\n",
      "batch accuracy: 0.9638671875\n",
      "doing 126 / 277\n",
      "elapsed time 7740.644243717194\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1308 - accuracy: 0.9590\n",
      "batch loss: 0.13080064952373505\n",
      "batch accuracy: 0.958984375\n",
      "doing 127 / 277\n",
      "elapsed time 7849.003587245941\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1156 - accuracy: 0.9561\n",
      "batch loss: 0.11561869829893112\n",
      "batch accuracy: 0.9560546875\n",
      "doing 128 / 277\n",
      "elapsed time 7954.544639110565\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1514 - accuracy: 0.9404\n",
      "batch loss: 0.15143562853336334\n",
      "batch accuracy: 0.9404296875\n",
      "doing 129 / 277\n",
      "elapsed time 8059.011950016022\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1434 - accuracy: 0.9473\n",
      "batch loss: 0.14336669445037842\n",
      "batch accuracy: 0.947265625\n",
      "doing 130 / 277\n",
      "elapsed time 8165.381976604462\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1215 - accuracy: 0.9619\n",
      "batch loss: 0.12146484851837158\n",
      "batch accuracy: 0.9619140625\n",
      "doing 131 / 277\n",
      "elapsed time 8272.938991308212\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1864 - accuracy: 0.9375\n",
      "batch loss: 0.18637453019618988\n",
      "batch accuracy: 0.9375\n",
      "doing 132 / 277\n",
      "elapsed time 8376.58679318428\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1663 - accuracy: 0.9385\n",
      "batch loss: 0.16631905734539032\n",
      "batch accuracy: 0.9384765625\n",
      "doing 133 / 277\n",
      "elapsed time 8481.01478600502\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1396 - accuracy: 0.9570\n",
      "batch loss: 0.13959884643554688\n",
      "batch accuracy: 0.95703125\n",
      "doing 134 / 277\n",
      "elapsed time 8589.841005325317\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1349 - accuracy: 0.9502\n",
      "batch loss: 0.134931743144989\n",
      "batch accuracy: 0.9501953125\n",
      "doing 135 / 277\n",
      "elapsed time 8691.97423195839\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1151 - accuracy: 0.9668\n",
      "batch loss: 0.11509071290493011\n",
      "batch accuracy: 0.966796875\n",
      "doing 136 / 277\n",
      "elapsed time 8794.942327022552\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1053 - accuracy: 0.9590\n",
      "batch loss: 0.1053040400147438\n",
      "batch accuracy: 0.958984375\n",
      "doing 137 / 277\n",
      "elapsed time 8903.2119307518\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1121 - accuracy: 0.9561\n",
      "batch loss: 0.1121259331703186\n",
      "batch accuracy: 0.9560546875\n",
      "doing 138 / 277\n",
      "elapsed time 9013.01207780838\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1488 - accuracy: 0.9424\n",
      "batch loss: 0.14878202974796295\n",
      "batch accuracy: 0.9423828125\n",
      "doing 139 / 277\n",
      "elapsed time 9116.651701927185\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1428 - accuracy: 0.9580\n",
      "batch loss: 0.14278888702392578\n",
      "batch accuracy: 0.9580078125\n",
      "doing 140 / 277\n",
      "elapsed time 9220.865671396255\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1277 - accuracy: 0.9551\n",
      "batch loss: 0.12773609161376953\n",
      "batch accuracy: 0.955078125\n",
      "doing 141 / 277\n",
      "elapsed time 9320.023045539856\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1471 - accuracy: 0.9492\n",
      "batch loss: 0.1470622718334198\n",
      "batch accuracy: 0.94921875\n",
      "doing 142 / 277\n",
      "elapsed time 9422.280218839645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1245 - accuracy: 0.9531\n",
      "batch loss: 0.124486044049263\n",
      "batch accuracy: 0.953125\n",
      "doing 143 / 277\n",
      "elapsed time 9526.367322921753\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1471 - accuracy: 0.9463\n",
      "batch loss: 0.147076815366745\n",
      "batch accuracy: 0.9462890625\n",
      "doing 144 / 277\n",
      "elapsed time 9625.489323854446\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1300 - accuracy: 0.9512\n",
      "batch loss: 0.12997925281524658\n",
      "batch accuracy: 0.951171875\n",
      "doing 145 / 277\n",
      "elapsed time 9721.10366511345\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1003 - accuracy: 0.9658\n",
      "batch loss: 0.10026729106903076\n",
      "batch accuracy: 0.9658203125\n",
      "doing 146 / 277\n",
      "elapsed time 9823.488334417343\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1296 - accuracy: 0.9531\n",
      "batch loss: 0.12959671020507812\n",
      "batch accuracy: 0.953125\n",
      "doing 147 / 277\n",
      "elapsed time 9921.665532827377\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1238 - accuracy: 0.9502\n",
      "batch loss: 0.1238311231136322\n",
      "batch accuracy: 0.9501953125\n",
      "doing 148 / 277\n",
      "elapsed time 10020.912247657776\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1225 - accuracy: 0.9531\n",
      "batch loss: 0.12252401560544968\n",
      "batch accuracy: 0.953125\n",
      "doing 149 / 277\n",
      "elapsed time 10118.573762178421\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1314 - accuracy: 0.9512\n",
      "batch loss: 0.13140346109867096\n",
      "batch accuracy: 0.951171875\n",
      "doing 150 / 277\n",
      "elapsed time 10215.471312522888\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1223 - accuracy: 0.9668\n",
      "batch loss: 0.12230534106492996\n",
      "batch accuracy: 0.966796875\n",
      "doing 151 / 277\n",
      "elapsed time 10315.012372493744\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1501 - accuracy: 0.9502\n",
      "batch loss: 0.150091290473938\n",
      "batch accuracy: 0.9501953125\n",
      "doing 152 / 277\n",
      "elapsed time 10408.74345588684\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1092 - accuracy: 0.9648\n",
      "batch loss: 0.1092270016670227\n",
      "batch accuracy: 0.96484375\n",
      "doing 153 / 277\n",
      "elapsed time 10501.832623958588\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1124 - accuracy: 0.9629\n",
      "batch loss: 0.11237981915473938\n",
      "batch accuracy: 0.962890625\n",
      "doing 154 / 277\n",
      "elapsed time 10596.259283065796\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0938 - accuracy: 0.9678\n",
      "batch loss: 0.09382499754428864\n",
      "batch accuracy: 0.9677734375\n",
      "doing 155 / 277\n",
      "elapsed time 10692.308879852295\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1335 - accuracy: 0.9570\n",
      "batch loss: 0.13352516293525696\n",
      "batch accuracy: 0.95703125\n",
      "doing 156 / 277\n",
      "elapsed time 10786.967941522598\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1157 - accuracy: 0.9668\n",
      "batch loss: 0.11573699116706848\n",
      "batch accuracy: 0.966796875\n",
      "doing 157 / 277\n",
      "elapsed time 10879.1674284935\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1299 - accuracy: 0.9512\n",
      "batch loss: 0.1299285888671875\n",
      "batch accuracy: 0.951171875\n",
      "doing 158 / 277\n",
      "elapsed time 10971.7081990242\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1330 - accuracy: 0.9531\n",
      "batch loss: 0.13295277953147888\n",
      "batch accuracy: 0.953125\n",
      "doing 159 / 277\n",
      "elapsed time 11064.505679607391\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1275 - accuracy: 0.9551\n",
      "batch loss: 0.12750805914402008\n",
      "batch accuracy: 0.955078125\n",
      "doing 160 / 277\n",
      "elapsed time 11160.103858470917\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0999 - accuracy: 0.9658\n",
      "batch loss: 0.09989021718502045\n",
      "batch accuracy: 0.9658203125\n",
      "doing 161 / 277\n",
      "elapsed time 11252.995175123215\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1058 - accuracy: 0.9658\n",
      "batch loss: 0.10582311451435089\n",
      "batch accuracy: 0.9658203125\n",
      "doing 162 / 277\n",
      "elapsed time 11341.90709733963\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1160 - accuracy: 0.9580\n",
      "batch loss: 0.11596061289310455\n",
      "batch accuracy: 0.9580078125\n",
      "doing 163 / 277\n",
      "elapsed time 11431.491893291473\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1285 - accuracy: 0.9561\n",
      "batch loss: 0.12846246361732483\n",
      "batch accuracy: 0.9560546875\n",
      "doing 164 / 277\n",
      "elapsed time 11519.390795469284\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1287 - accuracy: 0.9580\n",
      "batch loss: 0.12868210673332214\n",
      "batch accuracy: 0.9580078125\n",
      "doing 165 / 277\n",
      "elapsed time 11608.89135146141\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1172 - accuracy: 0.9570\n",
      "batch loss: 0.11720530688762665\n",
      "batch accuracy: 0.95703125\n",
      "doing 166 / 277\n",
      "elapsed time 11697.316525936127\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1035 - accuracy: 0.9707\n",
      "batch loss: 0.10350389033555984\n",
      "batch accuracy: 0.970703125\n",
      "doing 167 / 277\n",
      "elapsed time 11789.960602760315\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1039 - accuracy: 0.9668\n",
      "batch loss: 0.1038975790143013\n",
      "batch accuracy: 0.966796875\n",
      "doing 168 / 277\n",
      "elapsed time 11878.905170440674\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1132 - accuracy: 0.9600\n",
      "batch loss: 0.11323797702789307\n",
      "batch accuracy: 0.9599609375\n",
      "doing 169 / 277\n",
      "elapsed time 11971.386529445648\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1112 - accuracy: 0.9600\n",
      "batch loss: 0.11115387082099915\n",
      "batch accuracy: 0.9599609375\n",
      "doing 170 / 277\n",
      "elapsed time 12054.28801035881\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1248 - accuracy: 0.9512\n",
      "batch loss: 0.12479646503925323\n",
      "batch accuracy: 0.951171875\n",
      "doing 171 / 277\n",
      "elapsed time 12151.040125131607\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1187 - accuracy: 0.9561\n",
      "batch loss: 0.11874868720769882\n",
      "batch accuracy: 0.9560546875\n",
      "doing 172 / 277\n",
      "elapsed time 12237.131952285767\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1344 - accuracy: 0.9482\n",
      "batch loss: 0.1344093680381775\n",
      "batch accuracy: 0.9482421875\n",
      "doing 173 / 277\n",
      "elapsed time 12327.61415219307\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1049 - accuracy: 0.9609\n",
      "batch loss: 0.1048906147480011\n",
      "batch accuracy: 0.9609375\n",
      "doing 174 / 277\n",
      "elapsed time 12417.933414697647\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1120 - accuracy: 0.9609\n",
      "batch loss: 0.11199377477169037\n",
      "batch accuracy: 0.9609375\n",
      "doing 175 / 277\n",
      "elapsed time 12504.412999629974\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1578 - accuracy: 0.9424\n",
      "batch loss: 0.15776227414608002\n",
      "batch accuracy: 0.9423828125\n",
      "doing 176 / 277\n",
      "elapsed time 12589.15258193016\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1241 - accuracy: 0.9580\n",
      "batch loss: 0.12408209592103958\n",
      "batch accuracy: 0.9580078125\n",
      "doing 177 / 277\n",
      "elapsed time 12673.266021728516\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1105 - accuracy: 0.9541\n",
      "batch loss: 0.11045047640800476\n",
      "batch accuracy: 0.9541015625\n",
      "doing 178 / 277\n",
      "elapsed time 12760.04335308075\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1339 - accuracy: 0.9482\n",
      "batch loss: 0.13385234773159027\n",
      "batch accuracy: 0.9482421875\n",
      "doing 179 / 277\n",
      "elapsed time 12837.495799303055\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1444 - accuracy: 0.9492\n",
      "batch loss: 0.14437192678451538\n",
      "batch accuracy: 0.94921875\n",
      "doing 180 / 277\n",
      "elapsed time 12926.942496538162\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1054 - accuracy: 0.9600\n",
      "batch loss: 0.10536181926727295\n",
      "batch accuracy: 0.9599609375\n",
      "doing 181 / 277\n",
      "elapsed time 13013.726475477219\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1320 - accuracy: 0.9502\n",
      "batch loss: 0.13198630511760712\n",
      "batch accuracy: 0.9501953125\n",
      "doing 182 / 277\n",
      "elapsed time 13101.369646787643\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1352 - accuracy: 0.9609\n",
      "batch loss: 0.13518181443214417\n",
      "batch accuracy: 0.9609375\n",
      "doing 183 / 277\n",
      "elapsed time 13180.803387403488\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1359 - accuracy: 0.9600\n",
      "batch loss: 0.13593652844429016\n",
      "batch accuracy: 0.9599609375\n",
      "doing 184 / 277\n",
      "elapsed time 13265.786468982697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1331 - accuracy: 0.9531\n",
      "batch loss: 0.13312149047851562\n",
      "batch accuracy: 0.953125\n",
      "doing 185 / 277\n",
      "elapsed time 13353.742330551147\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1400 - accuracy: 0.9521\n",
      "batch loss: 0.14003659784793854\n",
      "batch accuracy: 0.9521484375\n",
      "doing 186 / 277\n",
      "elapsed time 13438.65399312973\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1337 - accuracy: 0.9561\n",
      "batch loss: 0.13367798924446106\n",
      "batch accuracy: 0.9560546875\n",
      "doing 187 / 277\n",
      "elapsed time 13518.462774515152\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1422 - accuracy: 0.9580\n",
      "batch loss: 0.1422143280506134\n",
      "batch accuracy: 0.9580078125\n",
      "doing 188 / 277\n",
      "elapsed time 13598.881442308426\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1030 - accuracy: 0.9619\n",
      "batch loss: 0.1029762327671051\n",
      "batch accuracy: 0.9619140625\n",
      "doing 189 / 277\n",
      "elapsed time 13680.779386758804\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1123 - accuracy: 0.9570\n",
      "batch loss: 0.11234422028064728\n",
      "batch accuracy: 0.95703125\n",
      "doing 190 / 277\n",
      "elapsed time 13766.094584465027\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1357 - accuracy: 0.9570\n",
      "batch loss: 0.1356620341539383\n",
      "batch accuracy: 0.95703125\n",
      "doing 191 / 277\n",
      "elapsed time 13847.362691402435\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1105 - accuracy: 0.9658\n",
      "batch loss: 0.11045846343040466\n",
      "batch accuracy: 0.9658203125\n",
      "doing 192 / 277\n",
      "elapsed time 13926.10092830658\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1261 - accuracy: 0.9502\n",
      "batch loss: 0.1260972023010254\n",
      "batch accuracy: 0.9501953125\n",
      "doing 193 / 277\n",
      "elapsed time 14009.4773812294\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1068 - accuracy: 0.9678\n",
      "batch loss: 0.10678324848413467\n",
      "batch accuracy: 0.9677734375\n",
      "doing 194 / 277\n",
      "elapsed time 14088.09400510788\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1308 - accuracy: 0.9570\n",
      "batch loss: 0.13081857562065125\n",
      "batch accuracy: 0.95703125\n",
      "doing 195 / 277\n",
      "elapsed time 14164.476923465729\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1292 - accuracy: 0.9531\n",
      "batch loss: 0.12919436395168304\n",
      "batch accuracy: 0.953125\n",
      "doing 196 / 277\n",
      "elapsed time 14242.550159454346\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1046 - accuracy: 0.9668\n",
      "batch loss: 0.10462421178817749\n",
      "batch accuracy: 0.966796875\n",
      "doing 197 / 277\n",
      "elapsed time 14319.575249195099\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1303 - accuracy: 0.9609\n",
      "batch loss: 0.13032490015029907\n",
      "batch accuracy: 0.9609375\n",
      "doing 198 / 277\n",
      "elapsed time 14395.422322034836\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1299 - accuracy: 0.9600\n",
      "batch loss: 0.12986761331558228\n",
      "batch accuracy: 0.9599609375\n",
      "doing 199 / 277\n",
      "elapsed time 14470.079048156738\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1307 - accuracy: 0.9570\n",
      "batch loss: 0.13071542978286743\n",
      "batch accuracy: 0.95703125\n",
      "doing 200 / 277\n",
      "elapsed time 14548.926458358765\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1052 - accuracy: 0.9668\n",
      "batch loss: 0.10523712635040283\n",
      "batch accuracy: 0.966796875\n",
      "doing 201 / 277\n",
      "elapsed time 14628.720497846603\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1298 - accuracy: 0.9570\n",
      "batch loss: 0.1298295110464096\n",
      "batch accuracy: 0.95703125\n",
      "doing 202 / 277\n",
      "elapsed time 14697.835122346878\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1214 - accuracy: 0.9570\n",
      "batch loss: 0.12144073843955994\n",
      "batch accuracy: 0.95703125\n",
      "doing 203 / 277\n",
      "elapsed time 14770.721859693527\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1323 - accuracy: 0.9482\n",
      "batch loss: 0.13226081430912018\n",
      "batch accuracy: 0.9482421875\n",
      "doing 204 / 277\n",
      "elapsed time 14846.430382013321\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1473 - accuracy: 0.9482\n",
      "batch loss: 0.14731556177139282\n",
      "batch accuracy: 0.9482421875\n",
      "doing 205 / 277\n",
      "elapsed time 14930.539331197739\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1006 - accuracy: 0.9688\n",
      "batch loss: 0.10057517886161804\n",
      "batch accuracy: 0.96875\n",
      "doing 206 / 277\n",
      "elapsed time 15003.929492473602\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1271 - accuracy: 0.9561\n",
      "batch loss: 0.1271071434020996\n",
      "batch accuracy: 0.9560546875\n",
      "doing 207 / 277\n",
      "elapsed time 15076.82853937149\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1365 - accuracy: 0.9434\n",
      "batch loss: 0.13648544251918793\n",
      "batch accuracy: 0.943359375\n",
      "doing 208 / 277\n",
      "elapsed time 15143.241508722305\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1346 - accuracy: 0.9473\n",
      "batch loss: 0.13461047410964966\n",
      "batch accuracy: 0.947265625\n",
      "doing 209 / 277\n",
      "elapsed time 15214.909382343292\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1285 - accuracy: 0.9600\n",
      "batch loss: 0.128462016582489\n",
      "batch accuracy: 0.9599609375\n",
      "doing 210 / 277\n",
      "elapsed time 15282.190861463547\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1041 - accuracy: 0.9658\n",
      "batch loss: 0.10413290560245514\n",
      "batch accuracy: 0.9658203125\n",
      "doing 211 / 277\n",
      "elapsed time 15353.002836465836\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1180 - accuracy: 0.9639\n",
      "batch loss: 0.11799351871013641\n",
      "batch accuracy: 0.9638671875\n",
      "doing 212 / 277\n",
      "elapsed time 15421.309314489365\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1185 - accuracy: 0.9590\n",
      "batch loss: 0.11852538585662842\n",
      "batch accuracy: 0.958984375\n",
      "doing 213 / 277\n",
      "elapsed time 15494.274962425232\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1198 - accuracy: 0.9590\n",
      "batch loss: 0.11979296058416367\n",
      "batch accuracy: 0.958984375\n",
      "doing 214 / 277\n",
      "elapsed time 15560.537608146667\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1072 - accuracy: 0.9561\n",
      "batch loss: 0.10721893608570099\n",
      "batch accuracy: 0.9560546875\n",
      "doing 215 / 277\n",
      "elapsed time 15626.063044786453\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1075 - accuracy: 0.9619\n",
      "batch loss: 0.10750789940357208\n",
      "batch accuracy: 0.9619140625\n",
      "doing 216 / 277\n",
      "elapsed time 15671.391285896301\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0937 - accuracy: 0.9688\n",
      "batch loss: 0.09374091029167175\n",
      "batch accuracy: 0.96875\n",
      "doing 217 / 277\n",
      "elapsed time 15731.484730958939\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1228 - accuracy: 0.9482\n",
      "batch loss: 0.12278328835964203\n",
      "batch accuracy: 0.9482421875\n",
      "doing 218 / 277\n",
      "elapsed time 15771.61303639412\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1298 - accuracy: 0.9512\n",
      "batch loss: 0.12983836233615875\n",
      "batch accuracy: 0.951171875\n",
      "doing 219 / 277\n",
      "elapsed time 15843.790261030197\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1184 - accuracy: 0.9629\n",
      "batch loss: 0.11843233555555344\n",
      "batch accuracy: 0.962890625\n",
      "doing 220 / 277\n",
      "elapsed time 15903.787015676498\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1087 - accuracy: 0.9678\n",
      "batch loss: 0.10870467126369476\n",
      "batch accuracy: 0.9677734375\n",
      "doing 221 / 277\n",
      "elapsed time 15946.42076587677\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1412 - accuracy: 0.9492\n",
      "batch loss: 0.1411522477865219\n",
      "batch accuracy: 0.94921875\n",
      "doing 222 / 277\n",
      "elapsed time 15985.20311832428\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1187 - accuracy: 0.9600\n",
      "batch loss: 0.11865890026092529\n",
      "batch accuracy: 0.9599609375\n",
      "doing 223 / 277\n",
      "elapsed time 16021.438745975494\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1160 - accuracy: 0.9609\n",
      "batch loss: 0.1159917414188385\n",
      "batch accuracy: 0.9609375\n",
      "doing 224 / 277\n",
      "elapsed time 16061.485085725784\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1480 - accuracy: 0.9473\n",
      "batch loss: 0.14797362685203552\n",
      "batch accuracy: 0.947265625\n",
      "doing 225 / 277\n",
      "elapsed time 16096.793753862381\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1161 - accuracy: 0.9580\n",
      "batch loss: 0.11614060401916504\n",
      "batch accuracy: 0.9580078125\n",
      "doing 226 / 277\n",
      "elapsed time 16134.441213846207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1043 - accuracy: 0.9658\n",
      "batch loss: 0.10429461300373077\n",
      "batch accuracy: 0.9658203125\n",
      "doing 227 / 277\n",
      "elapsed time 16193.05663895607\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1107 - accuracy: 0.9658\n",
      "batch loss: 0.11068490892648697\n",
      "batch accuracy: 0.9658203125\n",
      "doing 228 / 277\n",
      "elapsed time 16259.069885015488\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1210 - accuracy: 0.9609\n",
      "batch loss: 0.12096071243286133\n",
      "batch accuracy: 0.9609375\n",
      "doing 229 / 277\n",
      "elapsed time 16333.371367931366\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1233 - accuracy: 0.9590\n",
      "batch loss: 0.12329335510730743\n",
      "batch accuracy: 0.958984375\n",
      "doing 230 / 277\n",
      "elapsed time 16402.716279268265\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0910 - accuracy: 0.9678\n",
      "batch loss: 0.09099593013525009\n",
      "batch accuracy: 0.9677734375\n",
      "doing 231 / 277\n",
      "elapsed time 16476.519793748856\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1181 - accuracy: 0.9570\n",
      "batch loss: 0.11807797849178314\n",
      "batch accuracy: 0.95703125\n",
      "doing 232 / 277\n",
      "elapsed time 16543.598394155502\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1371 - accuracy: 0.9531\n",
      "batch loss: 0.13711071014404297\n",
      "batch accuracy: 0.953125\n",
      "doing 233 / 277\n",
      "elapsed time 16610.816430091858\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1043 - accuracy: 0.9688\n",
      "batch loss: 0.10428082942962646\n",
      "batch accuracy: 0.96875\n",
      "doing 234 / 277\n",
      "elapsed time 16673.15102338791\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1049 - accuracy: 0.9668\n",
      "batch loss: 0.10493607819080353\n",
      "batch accuracy: 0.966796875\n",
      "doing 235 / 277\n",
      "elapsed time 16744.459792137146\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1355 - accuracy: 0.9600\n",
      "batch loss: 0.13549965620040894\n",
      "batch accuracy: 0.9599609375\n",
      "doing 236 / 277\n",
      "elapsed time 16809.80348110199\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1130 - accuracy: 0.9580\n",
      "batch loss: 0.11299256980419159\n",
      "batch accuracy: 0.9580078125\n",
      "doing 237 / 277\n",
      "elapsed time 16867.61997270584\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1304 - accuracy: 0.9551\n",
      "batch loss: 0.13042616844177246\n",
      "batch accuracy: 0.955078125\n",
      "doing 238 / 277\n",
      "elapsed time 16932.09726500511\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1376 - accuracy: 0.9531\n",
      "batch loss: 0.1375814825296402\n",
      "batch accuracy: 0.953125\n",
      "doing 239 / 277\n",
      "elapsed time 16999.58663749695\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1548 - accuracy: 0.9443\n",
      "batch loss: 0.15475037693977356\n",
      "batch accuracy: 0.9443359375\n",
      "doing 240 / 277\n",
      "elapsed time 17066.965867757797\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1194 - accuracy: 0.9600\n",
      "batch loss: 0.11939559131860733\n",
      "batch accuracy: 0.9599609375\n",
      "doing 241 / 277\n",
      "elapsed time 17130.32286643982\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1142 - accuracy: 0.9619\n",
      "batch loss: 0.11418372392654419\n",
      "batch accuracy: 0.9619140625\n",
      "doing 242 / 277\n",
      "elapsed time 17192.89588689804\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1198 - accuracy: 0.9580\n",
      "batch loss: 0.11983838677406311\n",
      "batch accuracy: 0.9580078125\n",
      "doing 243 / 277\n",
      "elapsed time 17248.11754345894\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1365 - accuracy: 0.9512\n",
      "batch loss: 0.13653117418289185\n",
      "batch accuracy: 0.951171875\n",
      "doing 244 / 277\n",
      "elapsed time 17312.78428053856\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1184 - accuracy: 0.9619\n",
      "batch loss: 0.11840762197971344\n",
      "batch accuracy: 0.9619140625\n",
      "doing 245 / 277\n",
      "elapsed time 17369.213676929474\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1022 - accuracy: 0.9619\n",
      "batch loss: 0.10221442580223083\n",
      "batch accuracy: 0.9619140625\n",
      "doing 246 / 277\n",
      "elapsed time 17432.332189321518\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1341 - accuracy: 0.9531\n",
      "batch loss: 0.13412228226661682\n",
      "batch accuracy: 0.953125\n",
      "doing 247 / 277\n",
      "elapsed time 17490.74565911293\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1204 - accuracy: 0.9531\n",
      "batch loss: 0.1203652173280716\n",
      "batch accuracy: 0.953125\n",
      "doing 248 / 277\n",
      "elapsed time 17546.329203367233\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1125 - accuracy: 0.9590\n",
      "batch loss: 0.11250592768192291\n",
      "batch accuracy: 0.958984375\n",
      "doing 249 / 277\n",
      "elapsed time 17601.14795088768\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1095 - accuracy: 0.9639\n",
      "batch loss: 0.10946334898471832\n",
      "batch accuracy: 0.9638671875\n",
      "doing 250 / 277\n",
      "elapsed time 17663.892258644104\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1045 - accuracy: 0.9629\n",
      "batch loss: 0.10446101427078247\n",
      "batch accuracy: 0.962890625\n",
      "doing 251 / 277\n",
      "elapsed time 17725.737316846848\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1422 - accuracy: 0.9541\n",
      "batch loss: 0.14221717417240143\n",
      "batch accuracy: 0.9541015625\n",
      "doing 252 / 277\n",
      "elapsed time 17786.25267624855\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1127 - accuracy: 0.9639\n",
      "batch loss: 0.11270265281200409\n",
      "batch accuracy: 0.9638671875\n",
      "doing 253 / 277\n",
      "elapsed time 17840.09174990654\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1066 - accuracy: 0.9609\n",
      "batch loss: 0.10656455904245377\n",
      "batch accuracy: 0.9609375\n",
      "doing 254 / 277\n",
      "elapsed time 17903.31134200096\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1212 - accuracy: 0.9639\n",
      "batch loss: 0.12123602628707886\n",
      "batch accuracy: 0.9638671875\n",
      "doing 255 / 277\n",
      "elapsed time 17950.86857318878\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1029 - accuracy: 0.9668\n",
      "batch loss: 0.1029285192489624\n",
      "batch accuracy: 0.966796875\n",
      "doing 256 / 277\n",
      "elapsed time 18006.07011938095\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1195 - accuracy: 0.9619\n",
      "batch loss: 0.11950170248746872\n",
      "batch accuracy: 0.9619140625\n",
      "doing 257 / 277\n",
      "elapsed time 18059.558188915253\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1289 - accuracy: 0.9521\n",
      "batch loss: 0.1288955807685852\n",
      "batch accuracy: 0.9521484375\n",
      "doing 258 / 277\n",
      "elapsed time 18105.975126504898\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1028 - accuracy: 0.9600\n",
      "batch loss: 0.10282492637634277\n",
      "batch accuracy: 0.9599609375\n",
      "doing 259 / 277\n",
      "elapsed time 18158.77972483635\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0918 - accuracy: 0.9678\n",
      "batch loss: 0.09178368747234344\n",
      "batch accuracy: 0.9677734375\n",
      "doing 260 / 277\n",
      "elapsed time 18215.884702682495\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1258 - accuracy: 0.9561\n",
      "batch loss: 0.12578941881656647\n",
      "batch accuracy: 0.9560546875\n",
      "doing 261 / 277\n",
      "elapsed time 18260.852996587753\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1045 - accuracy: 0.9639\n",
      "batch loss: 0.10454948246479034\n",
      "batch accuracy: 0.9638671875\n",
      "doing 262 / 277\n",
      "elapsed time 18318.553680419922\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1183 - accuracy: 0.9531\n",
      "batch loss: 0.11832159757614136\n",
      "batch accuracy: 0.953125\n",
      "doing 263 / 277\n",
      "elapsed time 18372.67833328247\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0936 - accuracy: 0.9697\n",
      "batch loss: 0.09355925023555756\n",
      "batch accuracy: 0.9697265625\n",
      "doing 264 / 277\n",
      "elapsed time 18420.014161109924\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1041 - accuracy: 0.9639\n",
      "batch loss: 0.1040722131729126\n",
      "batch accuracy: 0.9638671875\n",
      "doing 265 / 277\n",
      "elapsed time 18467.104898691177\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1084 - accuracy: 0.9639\n",
      "batch loss: 0.10840299725532532\n",
      "batch accuracy: 0.9638671875\n",
      "doing 266 / 277\n",
      "elapsed time 18512.57303929329\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1143 - accuracy: 0.9639\n",
      "batch loss: 0.1143021434545517\n",
      "batch accuracy: 0.9638671875\n",
      "doing 267 / 277\n",
      "elapsed time 18559.21543264389\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1064 - accuracy: 0.9629\n",
      "batch loss: 0.1064467653632164\n",
      "batch accuracy: 0.962890625\n",
      "doing 268 / 277\n",
      "elapsed time 18612.165333271027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1091 - accuracy: 0.9600\n",
      "batch loss: 0.10909134894609451\n",
      "batch accuracy: 0.9599609375\n",
      "doing 269 / 277\n",
      "elapsed time 18664.844767332077\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1304 - accuracy: 0.9570\n",
      "batch loss: 0.1303752064704895\n",
      "batch accuracy: 0.95703125\n",
      "doing 270 / 277\n",
      "elapsed time 18710.378718852997\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1237 - accuracy: 0.9531\n",
      "batch loss: 0.12366268038749695\n",
      "batch accuracy: 0.953125\n",
      "doing 271 / 277\n",
      "elapsed time 18752.173383951187\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0933 - accuracy: 0.9629\n",
      "batch loss: 0.09327523410320282\n",
      "batch accuracy: 0.962890625\n",
      "doing 272 / 277\n",
      "elapsed time 18796.843195915222\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1283 - accuracy: 0.9580\n",
      "batch loss: 0.12834443151950836\n",
      "batch accuracy: 0.9580078125\n",
      "doing 273 / 277\n",
      "elapsed time 18849.481447935104\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1442 - accuracy: 0.9463\n",
      "batch loss: 0.1442365050315857\n",
      "batch accuracy: 0.9462890625\n",
      "doing 274 / 277\n",
      "elapsed time 18897.39254975319\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1427 - accuracy: 0.9473\n",
      "batch loss: 0.14271852374076843\n",
      "batch accuracy: 0.947265625\n",
      "doing 275 / 277\n",
      "elapsed time 18945.83233141899\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1000 - accuracy: 0.9648\n",
      "batch loss: 0.10001660138368607\n",
      "batch accuracy: 0.96484375\n",
      "doing 276 / 277\n",
      "elapsed time 18970.49012875557\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.1378 - accuracy: 0.9543\n",
      "batch loss: 0.13775528967380524\n",
      "batch accuracy: 0.9542961716651917\n",
      "Train loss 0.12660094963837187\n",
      "Train accuracy 0.9558896917298383\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 0.1905 - accuracy: 0.9418\n",
      "Validation loss: 0.19045674800872803\n",
      "Validation accuracy: 0.941777765750885\n",
      "==================================================\n",
      "5 / 10\n",
      "doing 0 / 277\n",
      "elapsed time 16.272643327713013\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1364 - accuracy: 0.9629\n",
      "batch loss: 0.1363787204027176\n",
      "batch accuracy: 0.962890625\n",
      "doing 1 / 277\n",
      "elapsed time 36.43504738807678\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1094 - accuracy: 0.9570\n",
      "batch loss: 0.10935644060373306\n",
      "batch accuracy: 0.95703125\n",
      "doing 2 / 277\n",
      "elapsed time 53.19372487068176\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1065 - accuracy: 0.9629\n",
      "batch loss: 0.10651753842830658\n",
      "batch accuracy: 0.962890625\n",
      "doing 3 / 277\n",
      "elapsed time 65.11132621765137\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1056 - accuracy: 0.9609\n",
      "batch loss: 0.10556213557720184\n",
      "batch accuracy: 0.9609375\n",
      "doing 4 / 277\n",
      "elapsed time 85.56914448738098\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1054 - accuracy: 0.9609\n",
      "batch loss: 0.10536995530128479\n",
      "batch accuracy: 0.9609375\n",
      "doing 5 / 277\n",
      "elapsed time 99.18819952011108\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1158 - accuracy: 0.9600\n",
      "batch loss: 0.115759938955307\n",
      "batch accuracy: 0.9599609375\n",
      "doing 6 / 277\n",
      "elapsed time 116.14201951026917\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1027 - accuracy: 0.9600\n",
      "batch loss: 0.10268319398164749\n",
      "batch accuracy: 0.9599609375\n",
      "doing 7 / 277\n",
      "elapsed time 136.75490593910217\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0947 - accuracy: 0.9639\n",
      "batch loss: 0.09471045434474945\n",
      "batch accuracy: 0.9638671875\n",
      "doing 8 / 277\n",
      "elapsed time 153.15258526802063\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1233 - accuracy: 0.9570\n",
      "batch loss: 0.12327133119106293\n",
      "batch accuracy: 0.95703125\n",
      "doing 9 / 277\n",
      "elapsed time 172.04151439666748\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1183 - accuracy: 0.9590\n",
      "batch loss: 0.11826100945472717\n",
      "batch accuracy: 0.958984375\n",
      "doing 10 / 277\n",
      "elapsed time 185.41553664207458\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0756 - accuracy: 0.9766\n",
      "batch loss: 0.0755634754896164\n",
      "batch accuracy: 0.9765625\n",
      "doing 11 / 277\n",
      "elapsed time 204.24335050582886\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1060 - accuracy: 0.9648\n",
      "batch loss: 0.1060282364487648\n",
      "batch accuracy: 0.96484375\n",
      "doing 12 / 277\n",
      "elapsed time 223.06290531158447\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1021 - accuracy: 0.9609\n",
      "batch loss: 0.10205668210983276\n",
      "batch accuracy: 0.9609375\n",
      "doing 13 / 277\n",
      "elapsed time 244.37457609176636\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0944 - accuracy: 0.9678\n",
      "batch loss: 0.09435345232486725\n",
      "batch accuracy: 0.9677734375\n",
      "doing 14 / 277\n",
      "elapsed time 268.7241744995117\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0970 - accuracy: 0.9648\n",
      "batch loss: 0.09703971445560455\n",
      "batch accuracy: 0.96484375\n",
      "doing 15 / 277\n",
      "elapsed time 292.9019215106964\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0917 - accuracy: 0.9688\n",
      "batch loss: 0.09165163338184357\n",
      "batch accuracy: 0.96875\n",
      "doing 16 / 277\n",
      "elapsed time 314.20195269584656\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0830 - accuracy: 0.9746\n",
      "batch loss: 0.08303074538707733\n",
      "batch accuracy: 0.974609375\n",
      "doing 17 / 277\n",
      "elapsed time 333.5299117565155\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0872 - accuracy: 0.9697\n",
      "batch loss: 0.08716893196105957\n",
      "batch accuracy: 0.9697265625\n",
      "doing 18 / 277\n",
      "elapsed time 346.03442907333374\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0895 - accuracy: 0.9697\n",
      "batch loss: 0.08952431380748749\n",
      "batch accuracy: 0.9697265625\n",
      "doing 19 / 277\n",
      "elapsed time 367.6382694244385\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0899 - accuracy: 0.9697\n",
      "batch loss: 0.08991647511720657\n",
      "batch accuracy: 0.9697265625\n",
      "doing 20 / 277\n",
      "elapsed time 386.89769196510315\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0854 - accuracy: 0.9629\n",
      "batch loss: 0.08539778739213943\n",
      "batch accuracy: 0.962890625\n",
      "doing 21 / 277\n",
      "elapsed time 408.6692569255829\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0854 - accuracy: 0.9707\n",
      "batch loss: 0.08538800477981567\n",
      "batch accuracy: 0.970703125\n",
      "doing 22 / 277\n",
      "elapsed time 428.6099169254303\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0872 - accuracy: 0.9678\n",
      "batch loss: 0.08716461062431335\n",
      "batch accuracy: 0.9677734375\n",
      "doing 23 / 277\n",
      "elapsed time 450.11948323249817\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1025 - accuracy: 0.9648\n",
      "batch loss: 0.10250762850046158\n",
      "batch accuracy: 0.96484375\n",
      "doing 24 / 277\n",
      "elapsed time 470.8952977657318\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1072 - accuracy: 0.9580\n",
      "batch loss: 0.10721328854560852\n",
      "batch accuracy: 0.9580078125\n",
      "doing 25 / 277\n",
      "elapsed time 490.140825510025\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1087 - accuracy: 0.9648\n",
      "batch loss: 0.10868903994560242\n",
      "batch accuracy: 0.96484375\n",
      "doing 26 / 277\n",
      "elapsed time 510.19922280311584\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0819 - accuracy: 0.9727\n",
      "batch loss: 0.0819275826215744\n",
      "batch accuracy: 0.97265625\n",
      "doing 27 / 277\n",
      "elapsed time 526.2501940727234\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1057 - accuracy: 0.9619\n",
      "batch loss: 0.10571146756410599\n",
      "batch accuracy: 0.9619140625\n",
      "doing 28 / 277\n",
      "elapsed time 551.0627100467682\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0969 - accuracy: 0.9688\n",
      "batch loss: 0.09686989337205887\n",
      "batch accuracy: 0.96875\n",
      "doing 29 / 277\n",
      "elapsed time 574.5316970348358\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0988 - accuracy: 0.9619\n",
      "batch loss: 0.09881647676229477\n",
      "batch accuracy: 0.9619140625\n",
      "doing 30 / 277\n",
      "elapsed time 597.540491104126\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0858 - accuracy: 0.9668\n",
      "batch loss: 0.08584942668676376\n",
      "batch accuracy: 0.966796875\n",
      "doing 31 / 277\n",
      "elapsed time 615.616340637207\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0882 - accuracy: 0.9678\n",
      "batch loss: 0.08822248131036758\n",
      "batch accuracy: 0.9677734375\n",
      "doing 32 / 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 635.6875503063202\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0888 - accuracy: 0.9668\n",
      "batch loss: 0.08875904232263565\n",
      "batch accuracy: 0.966796875\n",
      "doing 33 / 277\n",
      "elapsed time 652.7170679569244\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1172 - accuracy: 0.9580\n",
      "batch loss: 0.11724241077899933\n",
      "batch accuracy: 0.9580078125\n",
      "doing 34 / 277\n",
      "elapsed time 674.7287909984589\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1024 - accuracy: 0.9639\n",
      "batch loss: 0.10235787183046341\n",
      "batch accuracy: 0.9638671875\n",
      "doing 35 / 277\n",
      "elapsed time 703.0968010425568\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0957 - accuracy: 0.9668\n",
      "batch loss: 0.09572161734104156\n",
      "batch accuracy: 0.966796875\n",
      "doing 36 / 277\n",
      "elapsed time 734.5878472328186\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0961 - accuracy: 0.9648\n",
      "batch loss: 0.09610740840435028\n",
      "batch accuracy: 0.96484375\n",
      "doing 37 / 277\n",
      "elapsed time 763.9176163673401\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0797 - accuracy: 0.9756\n",
      "batch loss: 0.07971525192260742\n",
      "batch accuracy: 0.9755859375\n",
      "doing 38 / 277\n",
      "elapsed time 791.8724591732025\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1006 - accuracy: 0.9648\n",
      "batch loss: 0.10061375796794891\n",
      "batch accuracy: 0.96484375\n",
      "doing 39 / 277\n",
      "elapsed time 816.1970539093018\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1048 - accuracy: 0.9590\n",
      "batch loss: 0.10476569831371307\n",
      "batch accuracy: 0.958984375\n",
      "doing 40 / 277\n",
      "elapsed time 841.0763297080994\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0782 - accuracy: 0.9756\n",
      "batch loss: 0.07818357646465302\n",
      "batch accuracy: 0.9755859375\n",
      "doing 41 / 277\n",
      "elapsed time 869.2862403392792\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0921 - accuracy: 0.9639\n",
      "batch loss: 0.09211280196905136\n",
      "batch accuracy: 0.9638671875\n",
      "doing 42 / 277\n",
      "elapsed time 898.3820679187775\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0761 - accuracy: 0.9766\n",
      "batch loss: 0.07605207711458206\n",
      "batch accuracy: 0.9765625\n",
      "doing 43 / 277\n",
      "elapsed time 925.1337387561798\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1073 - accuracy: 0.9688\n",
      "batch loss: 0.10729517042636871\n",
      "batch accuracy: 0.96875\n",
      "doing 44 / 277\n",
      "elapsed time 951.215057849884\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0801 - accuracy: 0.9775\n",
      "batch loss: 0.08005794137716293\n",
      "batch accuracy: 0.9775390625\n",
      "doing 45 / 277\n",
      "elapsed time 977.1851589679718\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0799 - accuracy: 0.9717\n",
      "batch loss: 0.07988299429416656\n",
      "batch accuracy: 0.9716796875\n",
      "doing 46 / 277\n",
      "elapsed time 1004.1319179534912\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0740 - accuracy: 0.9697\n",
      "batch loss: 0.07404173910617828\n",
      "batch accuracy: 0.9697265625\n",
      "doing 47 / 277\n",
      "elapsed time 1025.7846760749817\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1054 - accuracy: 0.9590\n",
      "batch loss: 0.10536222904920578\n",
      "batch accuracy: 0.958984375\n",
      "doing 48 / 277\n",
      "elapsed time 1049.464245557785\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0981 - accuracy: 0.9678\n",
      "batch loss: 0.09811865538358688\n",
      "batch accuracy: 0.9677734375\n",
      "doing 49 / 277\n",
      "elapsed time 1076.6557240486145\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0928 - accuracy: 0.9697\n",
      "batch loss: 0.09275729954242706\n",
      "batch accuracy: 0.9697265625\n",
      "doing 50 / 277\n",
      "elapsed time 1107.9151499271393\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0979 - accuracy: 0.9688\n",
      "batch loss: 0.09786422550678253\n",
      "batch accuracy: 0.96875\n",
      "doing 51 / 277\n",
      "elapsed time 1136.5898456573486\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0873 - accuracy: 0.9648\n",
      "batch loss: 0.08725510537624359\n",
      "batch accuracy: 0.96484375\n",
      "doing 52 / 277\n",
      "elapsed time 1167.125382900238\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1025 - accuracy: 0.9541\n",
      "batch loss: 0.10246586799621582\n",
      "batch accuracy: 0.9541015625\n",
      "doing 53 / 277\n",
      "elapsed time 1193.9539830684662\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0989 - accuracy: 0.9678\n",
      "batch loss: 0.0989113375544548\n",
      "batch accuracy: 0.9677734375\n",
      "doing 54 / 277\n",
      "elapsed time 1223.0258202552795\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0891 - accuracy: 0.9619\n",
      "batch loss: 0.08905920386314392\n",
      "batch accuracy: 0.9619140625\n",
      "doing 55 / 277\n",
      "elapsed time 1248.6716995239258\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0817 - accuracy: 0.9736\n",
      "batch loss: 0.08166482299566269\n",
      "batch accuracy: 0.9736328125\n",
      "doing 56 / 277\n",
      "elapsed time 1265.6214890480042\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0635 - accuracy: 0.9795\n",
      "batch loss: 0.06354401260614395\n",
      "batch accuracy: 0.9794921875\n",
      "doing 57 / 277\n",
      "elapsed time 1292.2018792629242\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1077 - accuracy: 0.9688\n",
      "batch loss: 0.10768978297710419\n",
      "batch accuracy: 0.96875\n",
      "doing 58 / 277\n",
      "elapsed time 1321.0837018489838\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0915 - accuracy: 0.9678\n",
      "batch loss: 0.09150537848472595\n",
      "batch accuracy: 0.9677734375\n",
      "doing 59 / 277\n",
      "elapsed time 1350.3237645626068\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0926 - accuracy: 0.9658\n",
      "batch loss: 0.0925549790263176\n",
      "batch accuracy: 0.9658203125\n",
      "doing 60 / 277\n",
      "elapsed time 1378.9992151260376\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1096 - accuracy: 0.9570\n",
      "batch loss: 0.1095682680606842\n",
      "batch accuracy: 0.95703125\n",
      "doing 61 / 277\n",
      "elapsed time 1406.4617145061493\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0720 - accuracy: 0.9746\n",
      "batch loss: 0.07201579958200455\n",
      "batch accuracy: 0.974609375\n",
      "doing 62 / 277\n",
      "elapsed time 1433.2034087181091\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1058 - accuracy: 0.9629\n",
      "batch loss: 0.10578566789627075\n",
      "batch accuracy: 0.962890625\n",
      "doing 63 / 277\n",
      "elapsed time 1458.8121213912964\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0821 - accuracy: 0.9688\n",
      "batch loss: 0.08211115747690201\n",
      "batch accuracy: 0.96875\n",
      "doing 64 / 277\n",
      "elapsed time 1481.8540861606598\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0832 - accuracy: 0.9678\n",
      "batch loss: 0.08324018865823746\n",
      "batch accuracy: 0.9677734375\n",
      "doing 65 / 277\n",
      "elapsed time 1500.0435681343079\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0948 - accuracy: 0.9697\n",
      "batch loss: 0.0948251485824585\n",
      "batch accuracy: 0.9697265625\n",
      "doing 66 / 277\n",
      "elapsed time 1527.5305843353271\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0801 - accuracy: 0.9717\n",
      "batch loss: 0.08009360730648041\n",
      "batch accuracy: 0.9716796875\n",
      "doing 67 / 277\n",
      "elapsed time 1556.2326176166534\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0953 - accuracy: 0.9668\n",
      "batch loss: 0.0953356921672821\n",
      "batch accuracy: 0.966796875\n",
      "doing 68 / 277\n",
      "elapsed time 1583.0393767356873\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1217 - accuracy: 0.9600\n",
      "batch loss: 0.12168338149785995\n",
      "batch accuracy: 0.9599609375\n",
      "doing 69 / 277\n",
      "elapsed time 1610.5003399848938\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0871 - accuracy: 0.9727\n",
      "batch loss: 0.08710230886936188\n",
      "batch accuracy: 0.97265625\n",
      "doing 70 / 277\n",
      "elapsed time 1636.9782056808472\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0870 - accuracy: 0.9668\n",
      "batch loss: 0.0869731605052948\n",
      "batch accuracy: 0.966796875\n",
      "doing 71 / 277\n",
      "elapsed time 1662.2779014110565\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0833 - accuracy: 0.9756\n",
      "batch loss: 0.08334412425756454\n",
      "batch accuracy: 0.9755859375\n",
      "doing 72 / 277\n",
      "elapsed time 1681.9712941646576\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1108 - accuracy: 0.9629\n",
      "batch loss: 0.11082395911216736\n",
      "batch accuracy: 0.962890625\n",
      "doing 73 / 277\n",
      "elapsed time 1704.247326374054\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0811 - accuracy: 0.9707\n",
      "batch loss: 0.0811060220003128\n",
      "batch accuracy: 0.970703125\n",
      "doing 74 / 277\n",
      "elapsed time 1724.0800426006317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0833 - accuracy: 0.9756\n",
      "batch loss: 0.0833098441362381\n",
      "batch accuracy: 0.9755859375\n",
      "doing 75 / 277\n",
      "elapsed time 1748.180950164795\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0796 - accuracy: 0.9688\n",
      "batch loss: 0.07961570471525192\n",
      "batch accuracy: 0.96875\n",
      "doing 76 / 277\n",
      "elapsed time 1771.0592620372772\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0868 - accuracy: 0.9727\n",
      "batch loss: 0.08676391839981079\n",
      "batch accuracy: 0.97265625\n",
      "doing 77 / 277\n",
      "elapsed time 1793.2960176467896\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0917 - accuracy: 0.9668\n",
      "batch loss: 0.09172622859477997\n",
      "batch accuracy: 0.966796875\n",
      "doing 78 / 277\n",
      "elapsed time 1814.3180561065674\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0932 - accuracy: 0.9668\n",
      "batch loss: 0.09321673214435577\n",
      "batch accuracy: 0.966796875\n",
      "doing 79 / 277\n",
      "elapsed time 1849.766937494278\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0941 - accuracy: 0.9688\n",
      "batch loss: 0.09410622715950012\n",
      "batch accuracy: 0.96875\n",
      "doing 80 / 277\n",
      "elapsed time 1887.877391576767\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1064 - accuracy: 0.9551\n",
      "batch loss: 0.1064058169722557\n",
      "batch accuracy: 0.955078125\n",
      "doing 81 / 277\n",
      "elapsed time 1932.0379610061646\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0751 - accuracy: 0.9756\n",
      "batch loss: 0.07506390661001205\n",
      "batch accuracy: 0.9755859375\n",
      "doing 82 / 277\n",
      "elapsed time 1973.8789448738098\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1157 - accuracy: 0.9570\n",
      "batch loss: 0.11568260192871094\n",
      "batch accuracy: 0.95703125\n",
      "doing 83 / 277\n",
      "elapsed time 2025.1892907619476\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1264 - accuracy: 0.9580\n",
      "batch loss: 0.12638314068317413\n",
      "batch accuracy: 0.9580078125\n",
      "doing 84 / 277\n",
      "elapsed time 2079.3481845855713\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0986 - accuracy: 0.9688\n",
      "batch loss: 0.09858700633049011\n",
      "batch accuracy: 0.96875\n",
      "doing 85 / 277\n",
      "elapsed time 2131.7205176353455\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0980 - accuracy: 0.9658\n",
      "batch loss: 0.09796322137117386\n",
      "batch accuracy: 0.9658203125\n",
      "doing 86 / 277\n",
      "elapsed time 2178.9345009326935\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1234 - accuracy: 0.9609\n",
      "batch loss: 0.12342201173305511\n",
      "batch accuracy: 0.9609375\n",
      "doing 87 / 277\n",
      "elapsed time 2225.893662214279\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1074 - accuracy: 0.9629\n",
      "batch loss: 0.10739386081695557\n",
      "batch accuracy: 0.962890625\n",
      "doing 88 / 277\n",
      "elapsed time 2275.51354432106\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1168 - accuracy: 0.9561\n",
      "batch loss: 0.11675947159528732\n",
      "batch accuracy: 0.9560546875\n",
      "doing 89 / 277\n",
      "elapsed time 2321.8205275535583\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1054 - accuracy: 0.9668\n",
      "batch loss: 0.10538595914840698\n",
      "batch accuracy: 0.966796875\n",
      "doing 90 / 277\n",
      "elapsed time 2369.3628916740417\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1233 - accuracy: 0.9561\n",
      "batch loss: 0.12334861606359482\n",
      "batch accuracy: 0.9560546875\n",
      "doing 91 / 277\n",
      "elapsed time 2420.8220551013947\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0914 - accuracy: 0.9639\n",
      "batch loss: 0.09139090031385422\n",
      "batch accuracy: 0.9638671875\n",
      "doing 92 / 277\n",
      "elapsed time 2467.472400665283\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1080 - accuracy: 0.9619\n",
      "batch loss: 0.10801447927951813\n",
      "batch accuracy: 0.9619140625\n",
      "doing 93 / 277\n",
      "elapsed time 2512.7334842681885\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1071 - accuracy: 0.9658\n",
      "batch loss: 0.10707300901412964\n",
      "batch accuracy: 0.9658203125\n",
      "doing 94 / 277\n",
      "elapsed time 2555.7224447727203\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1045 - accuracy: 0.9609\n",
      "batch loss: 0.10451166331768036\n",
      "batch accuracy: 0.9609375\n",
      "doing 95 / 277\n",
      "elapsed time 2600.3536252975464\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1081 - accuracy: 0.9619\n",
      "batch loss: 0.10807010531425476\n",
      "batch accuracy: 0.9619140625\n",
      "doing 96 / 277\n",
      "elapsed time 2647.0364685058594\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0890 - accuracy: 0.9707\n",
      "batch loss: 0.08901155740022659\n",
      "batch accuracy: 0.970703125\n",
      "doing 97 / 277\n",
      "elapsed time 2700.6801052093506\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1154 - accuracy: 0.9561\n",
      "batch loss: 0.11536050587892532\n",
      "batch accuracy: 0.9560546875\n",
      "doing 98 / 277\n",
      "elapsed time 2755.2544741630554\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0931 - accuracy: 0.9619\n",
      "batch loss: 0.09306942671537399\n",
      "batch accuracy: 0.9619140625\n",
      "doing 99 / 277\n",
      "elapsed time 2799.9523210525513\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1164 - accuracy: 0.9609\n",
      "batch loss: 0.11638184636831284\n",
      "batch accuracy: 0.9609375\n",
      "doing 100 / 277\n",
      "elapsed time 2851.019156217575\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1193 - accuracy: 0.9512\n",
      "batch loss: 0.1193295419216156\n",
      "batch accuracy: 0.951171875\n",
      "doing 101 / 277\n",
      "elapsed time 2910.5016946792603\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1238 - accuracy: 0.9600\n",
      "batch loss: 0.12384441494941711\n",
      "batch accuracy: 0.9599609375\n",
      "doing 102 / 277\n",
      "elapsed time 2987.611869096756\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1229 - accuracy: 0.9619\n",
      "batch loss: 0.12286411970853806\n",
      "batch accuracy: 0.9619140625\n",
      "doing 103 / 277\n",
      "elapsed time 3056.7846159934998\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1276 - accuracy: 0.9570\n",
      "batch loss: 0.1276315152645111\n",
      "batch accuracy: 0.95703125\n",
      "doing 104 / 277\n",
      "elapsed time 3123.2092134952545\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1365 - accuracy: 0.9541\n",
      "batch loss: 0.13654474914073944\n",
      "batch accuracy: 0.9541015625\n",
      "doing 105 / 277\n",
      "elapsed time 3187.875575065613\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1231 - accuracy: 0.9541\n",
      "batch loss: 0.12305713444948196\n",
      "batch accuracy: 0.9541015625\n",
      "doing 106 / 277\n",
      "elapsed time 3251.1911766529083\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1093 - accuracy: 0.9678\n",
      "batch loss: 0.10928045213222504\n",
      "batch accuracy: 0.9677734375\n",
      "doing 107 / 277\n",
      "elapsed time 3326.7847883701324\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1009 - accuracy: 0.9668\n",
      "batch loss: 0.10091374814510345\n",
      "batch accuracy: 0.966796875\n",
      "doing 108 / 277\n",
      "elapsed time 3402.306496858597\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1400 - accuracy: 0.9512\n",
      "batch loss: 0.13996000587940216\n",
      "batch accuracy: 0.951171875\n",
      "doing 109 / 277\n",
      "elapsed time 3473.1457040309906\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1254 - accuracy: 0.9600\n",
      "batch loss: 0.12540850043296814\n",
      "batch accuracy: 0.9599609375\n",
      "doing 110 / 277\n",
      "elapsed time 3544.9267032146454\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1195 - accuracy: 0.9590\n",
      "batch loss: 0.1194826140999794\n",
      "batch accuracy: 0.958984375\n",
      "doing 111 / 277\n",
      "elapsed time 3616.429263830185\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1089 - accuracy: 0.9639\n",
      "batch loss: 0.10894570499658585\n",
      "batch accuracy: 0.9638671875\n",
      "doing 112 / 277\n",
      "elapsed time 3690.6434965133667\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0997 - accuracy: 0.9668\n",
      "batch loss: 0.09974810481071472\n",
      "batch accuracy: 0.966796875\n",
      "doing 113 / 277\n",
      "elapsed time 3763.962234020233\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1164 - accuracy: 0.9551\n",
      "batch loss: 0.11644111573696136\n",
      "batch accuracy: 0.955078125\n",
      "doing 114 / 277\n",
      "elapsed time 3833.314252138138\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1066 - accuracy: 0.9678\n",
      "batch loss: 0.10655294358730316\n",
      "batch accuracy: 0.9677734375\n",
      "doing 115 / 277\n",
      "elapsed time 3900.930935382843\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0948 - accuracy: 0.9697\n",
      "batch loss: 0.09476233273744583\n",
      "batch accuracy: 0.9697265625\n",
      "doing 116 / 277\n",
      "elapsed time 3967.0052256584167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1419 - accuracy: 0.9502\n",
      "batch loss: 0.14193767309188843\n",
      "batch accuracy: 0.9501953125\n",
      "doing 117 / 277\n",
      "elapsed time 4039.803313970566\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1349 - accuracy: 0.9590\n",
      "batch loss: 0.13487762212753296\n",
      "batch accuracy: 0.958984375\n",
      "doing 118 / 277\n",
      "elapsed time 4109.394488096237\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0871 - accuracy: 0.9756\n",
      "batch loss: 0.08711326122283936\n",
      "batch accuracy: 0.9755859375\n",
      "doing 119 / 277\n",
      "elapsed time 4177.599209070206\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1085 - accuracy: 0.9648\n",
      "batch loss: 0.10847404599189758\n",
      "batch accuracy: 0.96484375\n",
      "doing 120 / 277\n",
      "elapsed time 4243.891267299652\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1101 - accuracy: 0.9697\n",
      "batch loss: 0.11013533920049667\n",
      "batch accuracy: 0.9697265625\n",
      "doing 121 / 277\n",
      "elapsed time 4310.766974925995\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1069 - accuracy: 0.9590\n",
      "batch loss: 0.1069239154458046\n",
      "batch accuracy: 0.958984375\n",
      "doing 122 / 277\n",
      "elapsed time 4377.995718717575\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1152 - accuracy: 0.9551\n",
      "batch loss: 0.11524543166160583\n",
      "batch accuracy: 0.955078125\n",
      "doing 123 / 277\n",
      "elapsed time 4445.424275875092\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0897 - accuracy: 0.9648\n",
      "batch loss: 0.08969192951917648\n",
      "batch accuracy: 0.96484375\n",
      "doing 124 / 277\n",
      "elapsed time 4506.822555065155\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1232 - accuracy: 0.9521\n",
      "batch loss: 0.12323261052370071\n",
      "batch accuracy: 0.9521484375\n",
      "doing 125 / 277\n",
      "elapsed time 4575.1961488723755\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1185 - accuracy: 0.9541\n",
      "batch loss: 0.11849810183048248\n",
      "batch accuracy: 0.9541015625\n",
      "doing 126 / 277\n",
      "elapsed time 4638.933037281036\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1221 - accuracy: 0.9629\n",
      "batch loss: 0.12210791558027267\n",
      "batch accuracy: 0.962890625\n",
      "doing 127 / 277\n",
      "elapsed time 4716.104523181915\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1072 - accuracy: 0.9580\n",
      "batch loss: 0.10723711550235748\n",
      "batch accuracy: 0.9580078125\n",
      "doing 128 / 277\n",
      "elapsed time 4799.514271736145\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1293 - accuracy: 0.9590\n",
      "batch loss: 0.12927603721618652\n",
      "batch accuracy: 0.958984375\n",
      "doing 129 / 277\n",
      "elapsed time 4885.132117986679\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0874 - accuracy: 0.9707\n",
      "batch loss: 0.08737897872924805\n",
      "batch accuracy: 0.970703125\n",
      "doing 130 / 277\n",
      "elapsed time 4972.862731456757\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1168 - accuracy: 0.9619\n",
      "batch loss: 0.11682569235563278\n",
      "batch accuracy: 0.9619140625\n",
      "doing 131 / 277\n",
      "elapsed time 5055.892642021179\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0958 - accuracy: 0.9600\n",
      "batch loss: 0.0958387702703476\n",
      "batch accuracy: 0.9599609375\n",
      "doing 132 / 277\n",
      "elapsed time 5141.213973283768\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0924 - accuracy: 0.9697\n",
      "batch loss: 0.09242945164442062\n",
      "batch accuracy: 0.9697265625\n",
      "doing 133 / 277\n",
      "elapsed time 5227.530160188675\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1069 - accuracy: 0.9580\n",
      "batch loss: 0.10685549676418304\n",
      "batch accuracy: 0.9580078125\n",
      "doing 134 / 277\n",
      "elapsed time 5310.800194978714\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1055 - accuracy: 0.9629\n",
      "batch loss: 0.10547027736902237\n",
      "batch accuracy: 0.962890625\n",
      "doing 135 / 277\n",
      "elapsed time 5396.107700586319\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1027 - accuracy: 0.9648\n",
      "batch loss: 0.10274197161197662\n",
      "batch accuracy: 0.96484375\n",
      "doing 136 / 277\n",
      "elapsed time 5475.448543071747\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0992 - accuracy: 0.9658\n",
      "batch loss: 0.09915600717067719\n",
      "batch accuracy: 0.9658203125\n",
      "doing 137 / 277\n",
      "elapsed time 5556.871401309967\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0993 - accuracy: 0.9668\n",
      "batch loss: 0.09931755810976028\n",
      "batch accuracy: 0.966796875\n",
      "doing 138 / 277\n",
      "elapsed time 5639.829787015915\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1304 - accuracy: 0.9580\n",
      "batch loss: 0.13037142157554626\n",
      "batch accuracy: 0.9580078125\n",
      "doing 139 / 277\n",
      "elapsed time 5717.786915540695\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0849 - accuracy: 0.9756\n",
      "batch loss: 0.08486832678318024\n",
      "batch accuracy: 0.9755859375\n",
      "doing 140 / 277\n",
      "elapsed time 5798.147256135941\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1201 - accuracy: 0.9551\n",
      "batch loss: 0.12014113366603851\n",
      "batch accuracy: 0.955078125\n",
      "doing 141 / 277\n",
      "elapsed time 5877.801008939743\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0829 - accuracy: 0.9678\n",
      "batch loss: 0.08286471664905548\n",
      "batch accuracy: 0.9677734375\n",
      "doing 142 / 277\n",
      "elapsed time 5955.511801242828\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0982 - accuracy: 0.9648\n",
      "batch loss: 0.09817929565906525\n",
      "batch accuracy: 0.96484375\n",
      "doing 143 / 277\n",
      "elapsed time 6034.792379617691\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1157 - accuracy: 0.9590\n",
      "batch loss: 0.11571179330348969\n",
      "batch accuracy: 0.958984375\n",
      "doing 144 / 277\n",
      "elapsed time 6112.520169019699\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0883 - accuracy: 0.9707\n",
      "batch loss: 0.08834649622440338\n",
      "batch accuracy: 0.970703125\n",
      "doing 145 / 277\n",
      "elapsed time 6198.896913766861\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0809 - accuracy: 0.9727\n",
      "batch loss: 0.08094678074121475\n",
      "batch accuracy: 0.97265625\n",
      "doing 146 / 277\n",
      "elapsed time 6285.632767677307\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0991 - accuracy: 0.9629\n",
      "batch loss: 0.09906005859375\n",
      "batch accuracy: 0.962890625\n",
      "doing 147 / 277\n",
      "elapsed time 6374.541535377502\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0966 - accuracy: 0.9648\n",
      "batch loss: 0.09658625721931458\n",
      "batch accuracy: 0.96484375\n",
      "doing 148 / 277\n",
      "elapsed time 6454.443608760834\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1161 - accuracy: 0.9512\n",
      "batch loss: 0.11610236763954163\n",
      "batch accuracy: 0.951171875\n",
      "doing 149 / 277\n",
      "elapsed time 6533.079921245575\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1186 - accuracy: 0.9629\n",
      "batch loss: 0.11861299723386765\n",
      "batch accuracy: 0.962890625\n",
      "doing 150 / 277\n",
      "elapsed time 6618.541826725006\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0653 - accuracy: 0.9805\n",
      "batch loss: 0.06526520848274231\n",
      "batch accuracy: 0.98046875\n",
      "doing 151 / 277\n",
      "elapsed time 6697.624248743057\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0783 - accuracy: 0.9746\n",
      "batch loss: 0.07829614728689194\n",
      "batch accuracy: 0.974609375\n",
      "doing 152 / 277\n",
      "elapsed time 6780.728269815445\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1040 - accuracy: 0.9619\n",
      "batch loss: 0.10401897132396698\n",
      "batch accuracy: 0.9619140625\n",
      "doing 153 / 277\n",
      "elapsed time 6862.70699763298\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1022 - accuracy: 0.9648\n",
      "batch loss: 0.10224997997283936\n",
      "batch accuracy: 0.96484375\n",
      "doing 154 / 277\n",
      "elapsed time 6949.188333034515\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0974 - accuracy: 0.9629\n",
      "batch loss: 0.09744954109191895\n",
      "batch accuracy: 0.962890625\n",
      "doing 155 / 277\n",
      "elapsed time 7033.27978014946\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0899 - accuracy: 0.9707\n",
      "batch loss: 0.08985807001590729\n",
      "batch accuracy: 0.970703125\n",
      "doing 156 / 277\n",
      "elapsed time 7113.913603067398\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0969 - accuracy: 0.9619\n",
      "batch loss: 0.09686943888664246\n",
      "batch accuracy: 0.9619140625\n",
      "doing 157 / 277\n",
      "elapsed time 7191.869859218597\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0986 - accuracy: 0.9639\n",
      "batch loss: 0.0985993891954422\n",
      "batch accuracy: 0.9638671875\n",
      "doing 158 / 277\n",
      "elapsed time 7268.613088607788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1029 - accuracy: 0.9619\n",
      "batch loss: 0.10289580374956131\n",
      "batch accuracy: 0.9619140625\n",
      "doing 159 / 277\n",
      "elapsed time 7346.531259536743\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0916 - accuracy: 0.9697\n",
      "batch loss: 0.09156106412410736\n",
      "batch accuracy: 0.9697265625\n",
      "doing 160 / 277\n",
      "elapsed time 7424.782891988754\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1112 - accuracy: 0.9570\n",
      "batch loss: 0.11118804663419724\n",
      "batch accuracy: 0.95703125\n",
      "doing 161 / 277\n",
      "elapsed time 7508.350391864777\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1078 - accuracy: 0.9590\n",
      "batch loss: 0.10781486332416534\n",
      "batch accuracy: 0.958984375\n",
      "doing 162 / 277\n",
      "elapsed time 7583.879342556\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1022 - accuracy: 0.9668\n",
      "batch loss: 0.10222096741199493\n",
      "batch accuracy: 0.966796875\n",
      "doing 163 / 277\n",
      "elapsed time 7663.264265537262\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0905 - accuracy: 0.9746\n",
      "batch loss: 0.0905323177576065\n",
      "batch accuracy: 0.974609375\n",
      "doing 164 / 277\n",
      "elapsed time 7750.345192432404\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0903 - accuracy: 0.9736\n",
      "batch loss: 0.09028363227844238\n",
      "batch accuracy: 0.9736328125\n",
      "doing 165 / 277\n",
      "elapsed time 7840.921075344086\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1134 - accuracy: 0.9619\n",
      "batch loss: 0.11344602704048157\n",
      "batch accuracy: 0.9619140625\n",
      "doing 166 / 277\n",
      "elapsed time 7936.18653011322\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0988 - accuracy: 0.9619\n",
      "batch loss: 0.09882034361362457\n",
      "batch accuracy: 0.9619140625\n",
      "doing 167 / 277\n",
      "elapsed time 8030.858612060547\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0837 - accuracy: 0.9707\n",
      "batch loss: 0.08365598320960999\n",
      "batch accuracy: 0.970703125\n",
      "doing 168 / 277\n",
      "elapsed time 8121.940031290054\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0959 - accuracy: 0.9639\n",
      "batch loss: 0.09590588510036469\n",
      "batch accuracy: 0.9638671875\n",
      "doing 169 / 277\n",
      "elapsed time 8210.987003803253\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1064 - accuracy: 0.9648\n",
      "batch loss: 0.10635457932949066\n",
      "batch accuracy: 0.96484375\n",
      "doing 170 / 277\n",
      "elapsed time 8306.977222204208\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0889 - accuracy: 0.9639\n",
      "batch loss: 0.08887231349945068\n",
      "batch accuracy: 0.9638671875\n",
      "doing 171 / 277\n",
      "elapsed time 8397.375295877457\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0702 - accuracy: 0.9775\n",
      "batch loss: 0.07015637308359146\n",
      "batch accuracy: 0.9775390625\n",
      "doing 172 / 277\n",
      "elapsed time 8489.563506126404\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1030 - accuracy: 0.9629\n",
      "batch loss: 0.10298396646976471\n",
      "batch accuracy: 0.962890625\n",
      "doing 173 / 277\n",
      "elapsed time 8577.381076812744\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0932 - accuracy: 0.9668\n",
      "batch loss: 0.093172587454319\n",
      "batch accuracy: 0.966796875\n",
      "doing 174 / 277\n",
      "elapsed time 8666.432040929794\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0755 - accuracy: 0.9727\n",
      "batch loss: 0.07545575499534607\n",
      "batch accuracy: 0.97265625\n",
      "doing 175 / 277\n",
      "elapsed time 8754.470393419266\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0936 - accuracy: 0.9629\n",
      "batch loss: 0.09357661008834839\n",
      "batch accuracy: 0.962890625\n",
      "doing 176 / 277\n",
      "elapsed time 8836.110387086868\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0623 - accuracy: 0.9814\n",
      "batch loss: 0.06227164715528488\n",
      "batch accuracy: 0.9814453125\n",
      "doing 177 / 277\n",
      "elapsed time 8924.081558704376\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0679 - accuracy: 0.9775\n",
      "batch loss: 0.067870132625103\n",
      "batch accuracy: 0.9775390625\n",
      "doing 178 / 277\n",
      "elapsed time 9010.358691692352\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0785 - accuracy: 0.9688\n",
      "batch loss: 0.07851599901914597\n",
      "batch accuracy: 0.96875\n",
      "doing 179 / 277\n",
      "elapsed time 9091.390904903412\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0665 - accuracy: 0.9854\n",
      "batch loss: 0.0664900690317154\n",
      "batch accuracy: 0.9853515625\n",
      "doing 180 / 277\n",
      "elapsed time 9181.266277313232\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0849 - accuracy: 0.9717\n",
      "batch loss: 0.08493492007255554\n",
      "batch accuracy: 0.9716796875\n",
      "doing 181 / 277\n",
      "elapsed time 9266.731184482574\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0896 - accuracy: 0.9639\n",
      "batch loss: 0.08958538621664047\n",
      "batch accuracy: 0.9638671875\n",
      "doing 182 / 277\n",
      "elapsed time 9348.961052417755\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1229 - accuracy: 0.9580\n",
      "batch loss: 0.12292549759149551\n",
      "batch accuracy: 0.9580078125\n",
      "doing 183 / 277\n",
      "elapsed time 9433.284821748734\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0990 - accuracy: 0.9688\n",
      "batch loss: 0.0990343764424324\n",
      "batch accuracy: 0.96875\n",
      "doing 184 / 277\n",
      "elapsed time 9516.802416324615\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0828 - accuracy: 0.9727\n",
      "batch loss: 0.08283267915248871\n",
      "batch accuracy: 0.97265625\n",
      "doing 185 / 277\n",
      "elapsed time 9597.90711760521\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0837 - accuracy: 0.9756\n",
      "batch loss: 0.08371832966804504\n",
      "batch accuracy: 0.9755859375\n",
      "doing 186 / 277\n",
      "elapsed time 9674.66076016426\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0818 - accuracy: 0.9678\n",
      "batch loss: 0.08180981874465942\n",
      "batch accuracy: 0.9677734375\n",
      "doing 187 / 277\n",
      "elapsed time 9758.586511850357\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0910 - accuracy: 0.9668\n",
      "batch loss: 0.09101179242134094\n",
      "batch accuracy: 0.966796875\n",
      "doing 188 / 277\n",
      "elapsed time 9848.332970142365\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1043 - accuracy: 0.9648\n",
      "batch loss: 0.10433071106672287\n",
      "batch accuracy: 0.96484375\n",
      "doing 189 / 277\n",
      "elapsed time 9934.691348791122\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0900 - accuracy: 0.9697\n",
      "batch loss: 0.0900215208530426\n",
      "batch accuracy: 0.9697265625\n",
      "doing 190 / 277\n",
      "elapsed time 10019.150453567505\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0854 - accuracy: 0.9668\n",
      "batch loss: 0.08536204695701599\n",
      "batch accuracy: 0.966796875\n",
      "doing 191 / 277\n",
      "elapsed time 10102.983476638794\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0947 - accuracy: 0.9619\n",
      "batch loss: 0.09468373656272888\n",
      "batch accuracy: 0.9619140625\n",
      "doing 192 / 277\n",
      "elapsed time 10185.399138212204\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1191 - accuracy: 0.9561\n",
      "batch loss: 0.11910277605056763\n",
      "batch accuracy: 0.9560546875\n",
      "doing 193 / 277\n",
      "elapsed time 10263.997103452682\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0930 - accuracy: 0.9629\n",
      "batch loss: 0.09302359819412231\n",
      "batch accuracy: 0.962890625\n",
      "doing 194 / 277\n",
      "elapsed time 10348.404122591019\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0999 - accuracy: 0.9648\n",
      "batch loss: 0.0999128594994545\n",
      "batch accuracy: 0.96484375\n",
      "doing 195 / 277\n",
      "elapsed time 10428.619199514389\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0903 - accuracy: 0.9688\n",
      "batch loss: 0.09034186601638794\n",
      "batch accuracy: 0.96875\n",
      "doing 196 / 277\n",
      "elapsed time 10509.125673770905\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0988 - accuracy: 0.9678\n",
      "batch loss: 0.09876041114330292\n",
      "batch accuracy: 0.9677734375\n",
      "doing 197 / 277\n",
      "elapsed time 10593.265276193619\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0892 - accuracy: 0.9688\n",
      "batch loss: 0.08917403221130371\n",
      "batch accuracy: 0.96875\n",
      "doing 198 / 277\n",
      "elapsed time 10675.854204893112\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1004 - accuracy: 0.9668\n",
      "batch loss: 0.10041871666908264\n",
      "batch accuracy: 0.966796875\n",
      "doing 199 / 277\n",
      "elapsed time 10737.757987737656\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0688 - accuracy: 0.9736\n",
      "batch loss: 0.0687941163778305\n",
      "batch accuracy: 0.9736328125\n",
      "doing 200 / 277\n",
      "elapsed time 10781.941749095917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0856 - accuracy: 0.9727\n",
      "batch loss: 0.08563365042209625\n",
      "batch accuracy: 0.97265625\n",
      "doing 201 / 277\n",
      "elapsed time 10860.936695098877\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0968 - accuracy: 0.9688\n",
      "batch loss: 0.0967857763171196\n",
      "batch accuracy: 0.96875\n",
      "doing 202 / 277\n",
      "elapsed time 10941.39482164383\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1093 - accuracy: 0.9639\n",
      "batch loss: 0.10928914695978165\n",
      "batch accuracy: 0.9638671875\n",
      "doing 203 / 277\n",
      "elapsed time 11018.994050264359\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1011 - accuracy: 0.9668\n",
      "batch loss: 0.10114307701587677\n",
      "batch accuracy: 0.966796875\n",
      "doing 204 / 277\n",
      "elapsed time 11103.253786802292\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0819 - accuracy: 0.9609\n",
      "batch loss: 0.0818597823381424\n",
      "batch accuracy: 0.9609375\n",
      "doing 205 / 277\n",
      "elapsed time 11174.640578746796\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0880 - accuracy: 0.9688\n",
      "batch loss: 0.08803962916135788\n",
      "batch accuracy: 0.96875\n",
      "doing 206 / 277\n",
      "elapsed time 11251.495155096054\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0886 - accuracy: 0.9678\n",
      "batch loss: 0.08860882371664047\n",
      "batch accuracy: 0.9677734375\n",
      "doing 207 / 277\n",
      "elapsed time 11326.234296560287\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0878 - accuracy: 0.9717\n",
      "batch loss: 0.087834432721138\n",
      "batch accuracy: 0.9716796875\n",
      "doing 208 / 277\n",
      "elapsed time 11398.071778774261\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1024 - accuracy: 0.9600\n",
      "batch loss: 0.10240691900253296\n",
      "batch accuracy: 0.9599609375\n",
      "doing 209 / 277\n",
      "elapsed time 11478.351728439331\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0633 - accuracy: 0.9766\n",
      "batch loss: 0.06333737820386887\n",
      "batch accuracy: 0.9765625\n",
      "doing 210 / 277\n",
      "elapsed time 11558.558835983276\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0938 - accuracy: 0.9688\n",
      "batch loss: 0.09380652010440826\n",
      "batch accuracy: 0.96875\n",
      "doing 211 / 277\n",
      "elapsed time 11630.792832136154\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0639 - accuracy: 0.9766\n",
      "batch loss: 0.06385479867458344\n",
      "batch accuracy: 0.9765625\n",
      "doing 212 / 277\n",
      "elapsed time 11708.477315664291\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0985 - accuracy: 0.9678\n",
      "batch loss: 0.09854377061128616\n",
      "batch accuracy: 0.9677734375\n",
      "doing 213 / 277\n",
      "elapsed time 11773.30682682991\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0925 - accuracy: 0.9717\n",
      "batch loss: 0.09250649064779282\n",
      "batch accuracy: 0.9716796875\n",
      "doing 214 / 277\n",
      "elapsed time 11857.248075962067\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1051 - accuracy: 0.9551\n",
      "batch loss: 0.1051417738199234\n",
      "batch accuracy: 0.955078125\n",
      "doing 215 / 277\n",
      "elapsed time 11932.864775180817\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0928 - accuracy: 0.9639\n",
      "batch loss: 0.09277511388063431\n",
      "batch accuracy: 0.9638671875\n",
      "doing 216 / 277\n",
      "elapsed time 12015.367720365524\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0877 - accuracy: 0.9658\n",
      "batch loss: 0.08766872435808182\n",
      "batch accuracy: 0.9658203125\n",
      "doing 217 / 277\n",
      "elapsed time 12091.12253832817\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1015 - accuracy: 0.9609\n",
      "batch loss: 0.10150059312582016\n",
      "batch accuracy: 0.9609375\n",
      "doing 218 / 277\n",
      "elapsed time 12158.963969707489\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0748 - accuracy: 0.9707\n",
      "batch loss: 0.07484165579080582\n",
      "batch accuracy: 0.970703125\n",
      "doing 219 / 277\n",
      "elapsed time 12225.108462572098\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0820 - accuracy: 0.9746\n",
      "batch loss: 0.08201903849840164\n",
      "batch accuracy: 0.974609375\n",
      "doing 220 / 277\n",
      "elapsed time 12304.952945232391\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1137 - accuracy: 0.9561\n",
      "batch loss: 0.11373507976531982\n",
      "batch accuracy: 0.9560546875\n",
      "doing 221 / 277\n",
      "elapsed time 12377.047967672348\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0877 - accuracy: 0.9697\n",
      "batch loss: 0.08768463134765625\n",
      "batch accuracy: 0.9697265625\n",
      "doing 222 / 277\n",
      "elapsed time 12439.851900339127\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0914 - accuracy: 0.9678\n",
      "batch loss: 0.09143240749835968\n",
      "batch accuracy: 0.9677734375\n",
      "doing 223 / 277\n",
      "elapsed time 12516.677015542984\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0798 - accuracy: 0.9717\n",
      "batch loss: 0.07979068160057068\n",
      "batch accuracy: 0.9716796875\n",
      "doing 224 / 277\n",
      "elapsed time 12593.665053844452\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0926 - accuracy: 0.9727\n",
      "batch loss: 0.09258592873811722\n",
      "batch accuracy: 0.97265625\n",
      "doing 225 / 277\n",
      "elapsed time 12666.279058218002\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0976 - accuracy: 0.9658\n",
      "batch loss: 0.09760359674692154\n",
      "batch accuracy: 0.9658203125\n",
      "doing 226 / 277\n",
      "elapsed time 12734.493859291077\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0760 - accuracy: 0.9707\n",
      "batch loss: 0.07595717906951904\n",
      "batch accuracy: 0.970703125\n",
      "doing 227 / 277\n",
      "elapsed time 12807.004073143005\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0957 - accuracy: 0.9658\n",
      "batch loss: 0.09570655226707458\n",
      "batch accuracy: 0.9658203125\n",
      "doing 228 / 277\n",
      "elapsed time 12875.80870294571\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0896 - accuracy: 0.9648\n",
      "batch loss: 0.08963309973478317\n",
      "batch accuracy: 0.96484375\n",
      "doing 229 / 277\n",
      "elapsed time 12946.54957151413\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1017 - accuracy: 0.9639\n",
      "batch loss: 0.1016702875494957\n",
      "batch accuracy: 0.9638671875\n",
      "doing 230 / 277\n",
      "elapsed time 13019.890351057053\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0965 - accuracy: 0.9688\n",
      "batch loss: 0.09653190523386002\n",
      "batch accuracy: 0.96875\n",
      "doing 231 / 277\n",
      "elapsed time 13089.884407281876\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1059 - accuracy: 0.9551\n",
      "batch loss: 0.10588455200195312\n",
      "batch accuracy: 0.955078125\n",
      "doing 232 / 277\n",
      "elapsed time 13164.005593776703\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0977 - accuracy: 0.9697\n",
      "batch loss: 0.09774556756019592\n",
      "batch accuracy: 0.9697265625\n",
      "doing 233 / 277\n",
      "elapsed time 13232.491768836975\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0941 - accuracy: 0.9648\n",
      "batch loss: 0.0940883532166481\n",
      "batch accuracy: 0.96484375\n",
      "doing 234 / 277\n",
      "elapsed time 13302.831803321838\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0987 - accuracy: 0.9609\n",
      "batch loss: 0.09872235357761383\n",
      "batch accuracy: 0.9609375\n",
      "doing 235 / 277\n",
      "elapsed time 13372.820239543915\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1114 - accuracy: 0.9609\n",
      "batch loss: 0.11137454211711884\n",
      "batch accuracy: 0.9609375\n",
      "doing 236 / 277\n",
      "elapsed time 13443.482826709747\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0887 - accuracy: 0.9707\n",
      "batch loss: 0.08872798085212708\n",
      "batch accuracy: 0.970703125\n",
      "doing 237 / 277\n",
      "elapsed time 13514.72279047966\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0967 - accuracy: 0.9727\n",
      "batch loss: 0.0966564491391182\n",
      "batch accuracy: 0.97265625\n",
      "doing 238 / 277\n",
      "elapsed time 13588.550565719604\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0955 - accuracy: 0.9629\n",
      "batch loss: 0.09545206278562546\n",
      "batch accuracy: 0.962890625\n",
      "doing 239 / 277\n",
      "elapsed time 13657.047199249268\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1066 - accuracy: 0.9551\n",
      "batch loss: 0.10659998655319214\n",
      "batch accuracy: 0.955078125\n",
      "doing 240 / 277\n",
      "elapsed time 13724.275204181671\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1255 - accuracy: 0.9551\n",
      "batch loss: 0.12545007467269897\n",
      "batch accuracy: 0.955078125\n",
      "doing 241 / 277\n",
      "elapsed time 13792.07002568245\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0742 - accuracy: 0.9766\n",
      "batch loss: 0.07420022785663605\n",
      "batch accuracy: 0.9765625\n",
      "doing 242 / 277\n",
      "elapsed time 13865.939483165741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1027 - accuracy: 0.9678\n",
      "batch loss: 0.102747842669487\n",
      "batch accuracy: 0.9677734375\n",
      "doing 243 / 277\n",
      "elapsed time 13934.7687895298\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1018 - accuracy: 0.9619\n",
      "batch loss: 0.10177745670080185\n",
      "batch accuracy: 0.9619140625\n",
      "doing 244 / 277\n",
      "elapsed time 13998.78017950058\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0971 - accuracy: 0.9619\n",
      "batch loss: 0.09712447226047516\n",
      "batch accuracy: 0.9619140625\n",
      "doing 245 / 277\n",
      "elapsed time 14069.784326314926\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0697 - accuracy: 0.9814\n",
      "batch loss: 0.06966964900493622\n",
      "batch accuracy: 0.9814453125\n",
      "doing 246 / 277\n",
      "elapsed time 14135.266212940216\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1186 - accuracy: 0.9570\n",
      "batch loss: 0.11855397373437881\n",
      "batch accuracy: 0.95703125\n",
      "doing 247 / 277\n",
      "elapsed time 14200.562927246094\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0834 - accuracy: 0.9688\n",
      "batch loss: 0.08342248201370239\n",
      "batch accuracy: 0.96875\n",
      "doing 248 / 277\n",
      "elapsed time 14265.267070770264\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0952 - accuracy: 0.9639\n",
      "batch loss: 0.09515724331140518\n",
      "batch accuracy: 0.9638671875\n",
      "doing 249 / 277\n",
      "elapsed time 14328.876067638397\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0725 - accuracy: 0.9785\n",
      "batch loss: 0.07250764220952988\n",
      "batch accuracy: 0.978515625\n",
      "doing 250 / 277\n",
      "elapsed time 14393.875671386719\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0887 - accuracy: 0.9736\n",
      "batch loss: 0.08867260813713074\n",
      "batch accuracy: 0.9736328125\n",
      "doing 251 / 277\n",
      "elapsed time 14460.087186574936\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0817 - accuracy: 0.9727\n",
      "batch loss: 0.08166873455047607\n",
      "batch accuracy: 0.97265625\n",
      "doing 252 / 277\n",
      "elapsed time 14519.149120092392\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0985 - accuracy: 0.9629\n",
      "batch loss: 0.09849674999713898\n",
      "batch accuracy: 0.962890625\n",
      "doing 253 / 277\n",
      "elapsed time 14584.758865833282\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0604 - accuracy: 0.9785\n",
      "batch loss: 0.060366082936525345\n",
      "batch accuracy: 0.978515625\n",
      "doing 254 / 277\n",
      "elapsed time 14652.214527845383\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0920 - accuracy: 0.9678\n",
      "batch loss: 0.09198668599128723\n",
      "batch accuracy: 0.9677734375\n",
      "doing 255 / 277\n",
      "elapsed time 14718.767456769943\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0978 - accuracy: 0.9697\n",
      "batch loss: 0.09783151745796204\n",
      "batch accuracy: 0.9697265625\n",
      "doing 256 / 277\n",
      "elapsed time 14801.5422976017\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0966 - accuracy: 0.9678\n",
      "batch loss: 0.0966198667883873\n",
      "batch accuracy: 0.9677734375\n",
      "doing 257 / 277\n",
      "elapsed time 14886.977777957916\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0980 - accuracy: 0.9639\n",
      "batch loss: 0.0980459600687027\n",
      "batch accuracy: 0.9638671875\n",
      "doing 258 / 277\n",
      "elapsed time 14975.137761116028\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1018 - accuracy: 0.9658\n",
      "batch loss: 0.10177574306726456\n",
      "batch accuracy: 0.9658203125\n",
      "doing 259 / 277\n",
      "elapsed time 15060.616933345795\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0717 - accuracy: 0.9736\n",
      "batch loss: 0.07167982310056686\n",
      "batch accuracy: 0.9736328125\n",
      "doing 260 / 277\n",
      "elapsed time 15149.276553869247\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0870 - accuracy: 0.9707\n",
      "batch loss: 0.08695460855960846\n",
      "batch accuracy: 0.970703125\n",
      "doing 261 / 277\n",
      "elapsed time 15235.860115766525\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0923 - accuracy: 0.9717\n",
      "batch loss: 0.09234301000833511\n",
      "batch accuracy: 0.9716796875\n",
      "doing 262 / 277\n",
      "elapsed time 15318.194407701492\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0827 - accuracy: 0.9727\n",
      "batch loss: 0.08265511691570282\n",
      "batch accuracy: 0.97265625\n",
      "doing 263 / 277\n",
      "elapsed time 15405.287879943848\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0762 - accuracy: 0.9746\n",
      "batch loss: 0.0762064978480339\n",
      "batch accuracy: 0.974609375\n",
      "doing 264 / 277\n",
      "elapsed time 15487.115273952484\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0761 - accuracy: 0.9766\n",
      "batch loss: 0.07607537508010864\n",
      "batch accuracy: 0.9765625\n",
      "doing 265 / 277\n",
      "elapsed time 15572.991345405579\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0949 - accuracy: 0.9658\n",
      "batch loss: 0.09485599398612976\n",
      "batch accuracy: 0.9658203125\n",
      "doing 266 / 277\n",
      "elapsed time 15664.899723291397\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0733 - accuracy: 0.9785\n",
      "batch loss: 0.07334941625595093\n",
      "batch accuracy: 0.978515625\n",
      "doing 267 / 277\n",
      "elapsed time 15759.281798362732\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0810 - accuracy: 0.9668\n",
      "batch loss: 0.08104805648326874\n",
      "batch accuracy: 0.966796875\n",
      "doing 268 / 277\n",
      "elapsed time 15850.931902647018\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0686 - accuracy: 0.9756\n",
      "batch loss: 0.06859476864337921\n",
      "batch accuracy: 0.9755859375\n",
      "doing 269 / 277\n",
      "elapsed time 15947.13070011139\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0902 - accuracy: 0.9678\n",
      "batch loss: 0.09018541872501373\n",
      "batch accuracy: 0.9677734375\n",
      "doing 270 / 277\n",
      "elapsed time 16037.99104475975\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0759 - accuracy: 0.9707\n",
      "batch loss: 0.07593472301959991\n",
      "batch accuracy: 0.970703125\n",
      "doing 271 / 277\n",
      "elapsed time 16129.730188369751\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0756 - accuracy: 0.9736\n",
      "batch loss: 0.0755559653043747\n",
      "batch accuracy: 0.9736328125\n",
      "doing 272 / 277\n",
      "elapsed time 16223.036902189255\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0884 - accuracy: 0.9736\n",
      "batch loss: 0.08836667984724045\n",
      "batch accuracy: 0.9736328125\n",
      "doing 273 / 277\n",
      "elapsed time 16316.157615184784\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0998 - accuracy: 0.9697\n",
      "batch loss: 0.09983079880475998\n",
      "batch accuracy: 0.9697265625\n",
      "doing 274 / 277\n",
      "elapsed time 16403.154328107834\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0659 - accuracy: 0.9775\n",
      "batch loss: 0.06588590145111084\n",
      "batch accuracy: 0.9775390625\n",
      "doing 275 / 277\n",
      "elapsed time 16487.964883089066\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0789 - accuracy: 0.9756\n",
      "batch loss: 0.07886724174022675\n",
      "batch accuracy: 0.9755859375\n",
      "doing 276 / 277\n",
      "elapsed time 16530.93881869316\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0740 - accuracy: 0.9707\n",
      "batch loss: 0.07398302853107452\n",
      "batch accuracy: 0.97074955701828\n",
      "Train loss 0.09649470417561944\n",
      "Train accuracy 0.9661906572455533\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 0.1832 - accuracy: 0.9433\n",
      "Validation loss: 0.18324853479862213\n",
      "Validation accuracy: 0.9433333277702332\n",
      "==================================================\n",
      "6 / 10\n",
      "doing 0 / 277\n",
      "elapsed time 65.33184313774109\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0754 - accuracy: 0.9746\n",
      "batch loss: 0.075431689620018\n",
      "batch accuracy: 0.974609375\n",
      "doing 1 / 277\n",
      "elapsed time 137.31175303459167\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0740 - accuracy: 0.9756\n",
      "batch loss: 0.0739847719669342\n",
      "batch accuracy: 0.9755859375\n",
      "doing 2 / 277\n",
      "elapsed time 209.98689532279968\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0654 - accuracy: 0.9756\n",
      "batch loss: 0.06544873118400574\n",
      "batch accuracy: 0.9755859375\n",
      "doing 3 / 277\n",
      "elapsed time 280.5131456851959\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0740 - accuracy: 0.9697\n",
      "batch loss: 0.07404084503650665\n",
      "batch accuracy: 0.9697265625\n",
      "doing 4 / 277\n",
      "elapsed time 349.0939030647278\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0980 - accuracy: 0.9688\n",
      "batch loss: 0.09795508533716202\n",
      "batch accuracy: 0.96875\n",
      "doing 5 / 277\n",
      "elapsed time 416.68095779418945\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0793 - accuracy: 0.9688\n",
      "batch loss: 0.07927395403385162\n",
      "batch accuracy: 0.96875\n",
      "doing 6 / 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 497.08362913131714\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0767 - accuracy: 0.9707\n",
      "batch loss: 0.07665082812309265\n",
      "batch accuracy: 0.970703125\n",
      "doing 7 / 277\n",
      "elapsed time 574.8439540863037\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0866 - accuracy: 0.9668\n",
      "batch loss: 0.08663264662027359\n",
      "batch accuracy: 0.966796875\n",
      "doing 8 / 277\n",
      "elapsed time 649.9977643489838\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0873 - accuracy: 0.9688\n",
      "batch loss: 0.0872771292924881\n",
      "batch accuracy: 0.96875\n",
      "doing 9 / 277\n",
      "elapsed time 732.8326661586761\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0938 - accuracy: 0.9629\n",
      "batch loss: 0.09377311915159225\n",
      "batch accuracy: 0.962890625\n",
      "doing 10 / 277\n",
      "elapsed time 807.5593433380127\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0867 - accuracy: 0.9717\n",
      "batch loss: 0.08668626099824905\n",
      "batch accuracy: 0.9716796875\n",
      "doing 11 / 277\n",
      "elapsed time 888.6441707611084\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0855 - accuracy: 0.9678\n",
      "batch loss: 0.08545900136232376\n",
      "batch accuracy: 0.9677734375\n",
      "doing 12 / 277\n",
      "elapsed time 973.833359003067\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0903 - accuracy: 0.9717\n",
      "batch loss: 0.09028930962085724\n",
      "batch accuracy: 0.9716796875\n",
      "doing 13 / 277\n",
      "elapsed time 1053.1500244140625\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0923 - accuracy: 0.9697\n",
      "batch loss: 0.09232065081596375\n",
      "batch accuracy: 0.9697265625\n",
      "doing 14 / 277\n",
      "elapsed time 1136.0124444961548\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1066 - accuracy: 0.9609\n",
      "batch loss: 0.10655833780765533\n",
      "batch accuracy: 0.9609375\n",
      "doing 15 / 277\n",
      "elapsed time 1211.7134113311768\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0904 - accuracy: 0.9717\n",
      "batch loss: 0.09037380665540695\n",
      "batch accuracy: 0.9716796875\n",
      "doing 16 / 277\n",
      "elapsed time 1291.3118772506714\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0943 - accuracy: 0.9658\n",
      "batch loss: 0.09425461292266846\n",
      "batch accuracy: 0.9658203125\n",
      "doing 17 / 277\n",
      "elapsed time 1380.9778153896332\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0717 - accuracy: 0.9766\n",
      "batch loss: 0.07165087759494781\n",
      "batch accuracy: 0.9765625\n",
      "doing 18 / 277\n",
      "elapsed time 1475.048496723175\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0628 - accuracy: 0.9785\n",
      "batch loss: 0.06276500225067139\n",
      "batch accuracy: 0.978515625\n",
      "doing 19 / 277\n",
      "elapsed time 1567.6958072185516\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0600 - accuracy: 0.9805\n",
      "batch loss: 0.05997505411505699\n",
      "batch accuracy: 0.98046875\n",
      "doing 20 / 277\n",
      "elapsed time 1656.409390926361\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0817 - accuracy: 0.9688\n",
      "batch loss: 0.08167186379432678\n",
      "batch accuracy: 0.96875\n",
      "doing 21 / 277\n",
      "elapsed time 1747.0063858032227\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0728 - accuracy: 0.9727\n",
      "batch loss: 0.07278305292129517\n",
      "batch accuracy: 0.97265625\n",
      "doing 22 / 277\n",
      "elapsed time 1844.3788893222809\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0975 - accuracy: 0.9658\n",
      "batch loss: 0.0975380539894104\n",
      "batch accuracy: 0.9658203125\n",
      "doing 23 / 277\n",
      "elapsed time 1948.7859406471252\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0777 - accuracy: 0.9727\n",
      "batch loss: 0.07768033444881439\n",
      "batch accuracy: 0.97265625\n",
      "doing 24 / 277\n",
      "elapsed time 2049.765391588211\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0841 - accuracy: 0.9717\n",
      "batch loss: 0.0841272622346878\n",
      "batch accuracy: 0.9716796875\n",
      "doing 25 / 277\n",
      "elapsed time 2143.064052581787\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1052 - accuracy: 0.9629\n",
      "batch loss: 0.10519880056381226\n",
      "batch accuracy: 0.962890625\n",
      "doing 26 / 277\n",
      "elapsed time 2234.7952406406403\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0692 - accuracy: 0.9746\n",
      "batch loss: 0.06916987150907516\n",
      "batch accuracy: 0.974609375\n",
      "doing 27 / 277\n",
      "elapsed time 2330.723310947418\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0884 - accuracy: 0.9639\n",
      "batch loss: 0.08837468922138214\n",
      "batch accuracy: 0.9638671875\n",
      "doing 28 / 277\n",
      "elapsed time 2426.4062898159027\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0986 - accuracy: 0.9609\n",
      "batch loss: 0.0986056923866272\n",
      "batch accuracy: 0.9609375\n",
      "doing 29 / 277\n",
      "elapsed time 2533.6063072681427\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0989 - accuracy: 0.9678\n",
      "batch loss: 0.09891524910926819\n",
      "batch accuracy: 0.9677734375\n",
      "doing 30 / 277\n",
      "elapsed time 2636.5097875595093\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0898 - accuracy: 0.9639\n",
      "batch loss: 0.08983413875102997\n",
      "batch accuracy: 0.9638671875\n",
      "doing 31 / 277\n",
      "elapsed time 2738.7684667110443\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1013 - accuracy: 0.9688\n",
      "batch loss: 0.10128091275691986\n",
      "batch accuracy: 0.96875\n",
      "doing 32 / 277\n",
      "elapsed time 2841.7146530151367\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0968 - accuracy: 0.9648\n",
      "batch loss: 0.09683921188116074\n",
      "batch accuracy: 0.96484375\n",
      "doing 33 / 277\n",
      "elapsed time 2942.3094000816345\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1023 - accuracy: 0.9697\n",
      "batch loss: 0.10226604342460632\n",
      "batch accuracy: 0.9697265625\n",
      "doing 34 / 277\n",
      "elapsed time 3043.2068107128143\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1149 - accuracy: 0.9580\n",
      "batch loss: 0.11494126170873642\n",
      "batch accuracy: 0.9580078125\n",
      "doing 35 / 277\n",
      "elapsed time 3153.2453286647797\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0994 - accuracy: 0.9658\n",
      "batch loss: 0.09936411678791046\n",
      "batch accuracy: 0.9658203125\n",
      "doing 36 / 277\n",
      "elapsed time 3253.0880043506622\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0850 - accuracy: 0.9668\n",
      "batch loss: 0.08504194766283035\n",
      "batch accuracy: 0.966796875\n",
      "doing 37 / 277\n",
      "elapsed time 3355.7178962230682\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0688 - accuracy: 0.9785\n",
      "batch loss: 0.06883835792541504\n",
      "batch accuracy: 0.978515625\n",
      "doing 38 / 277\n",
      "elapsed time 3464.344207048416\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0843 - accuracy: 0.9678\n",
      "batch loss: 0.08429571986198425\n",
      "batch accuracy: 0.9677734375\n",
      "doing 39 / 277\n",
      "elapsed time 3577.5391755104065\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0741 - accuracy: 0.9746\n",
      "batch loss: 0.07409626245498657\n",
      "batch accuracy: 0.974609375\n",
      "doing 40 / 277\n",
      "elapsed time 3701.353753089905\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0689 - accuracy: 0.9736\n",
      "batch loss: 0.06892051547765732\n",
      "batch accuracy: 0.9736328125\n",
      "doing 41 / 277\n",
      "elapsed time 3823.238503217697\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1096 - accuracy: 0.9658\n",
      "batch loss: 0.10956767946481705\n",
      "batch accuracy: 0.9658203125\n",
      "doing 42 / 277\n",
      "elapsed time 3943.534191608429\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0793 - accuracy: 0.9717\n",
      "batch loss: 0.079342782497406\n",
      "batch accuracy: 0.9716796875\n",
      "doing 43 / 277\n",
      "elapsed time 4075.428366422653\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0870 - accuracy: 0.9727\n",
      "batch loss: 0.08695010840892792\n",
      "batch accuracy: 0.97265625\n",
      "doing 44 / 277\n",
      "elapsed time 4197.552774190903\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0832 - accuracy: 0.9697\n",
      "batch loss: 0.08324187994003296\n",
      "batch accuracy: 0.9697265625\n",
      "doing 45 / 277\n",
      "elapsed time 4324.3059911727905\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0834 - accuracy: 0.9678\n",
      "batch loss: 0.08338408917188644\n",
      "batch accuracy: 0.9677734375\n",
      "doing 46 / 277\n",
      "elapsed time 4446.4813668727875\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0941 - accuracy: 0.9697\n",
      "batch loss: 0.09413068741559982\n",
      "batch accuracy: 0.9697265625\n",
      "doing 47 / 277\n",
      "elapsed time 4572.853407859802\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1074 - accuracy: 0.9629\n",
      "batch loss: 0.10736972093582153\n",
      "batch accuracy: 0.962890625\n",
      "doing 48 / 277\n",
      "elapsed time 4704.954785346985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0821 - accuracy: 0.9727\n",
      "batch loss: 0.08205389976501465\n",
      "batch accuracy: 0.97265625\n",
      "doing 49 / 277\n",
      "elapsed time 4831.066637039185\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0767 - accuracy: 0.9736\n",
      "batch loss: 0.07673439383506775\n",
      "batch accuracy: 0.9736328125\n",
      "doing 50 / 277\n",
      "elapsed time 4961.530906915665\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0658 - accuracy: 0.9756\n",
      "batch loss: 0.06577451527118683\n",
      "batch accuracy: 0.9755859375\n",
      "doing 51 / 277\n",
      "elapsed time 5084.990415811539\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0906 - accuracy: 0.9639\n",
      "batch loss: 0.09060025215148926\n",
      "batch accuracy: 0.9638671875\n",
      "doing 52 / 277\n",
      "elapsed time 5212.256181001663\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1067 - accuracy: 0.9658\n",
      "batch loss: 0.10674843937158585\n",
      "batch accuracy: 0.9658203125\n",
      "doing 53 / 277\n",
      "elapsed time 5339.595037221909\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0779 - accuracy: 0.9736\n",
      "batch loss: 0.07789932936429977\n",
      "batch accuracy: 0.9736328125\n",
      "doing 54 / 277\n",
      "elapsed time 5466.198812007904\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0821 - accuracy: 0.9727\n",
      "batch loss: 0.0820593312382698\n",
      "batch accuracy: 0.97265625\n",
      "doing 55 / 277\n",
      "elapsed time 5590.924808740616\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0832 - accuracy: 0.9707\n",
      "batch loss: 0.08318699151277542\n",
      "batch accuracy: 0.970703125\n",
      "doing 56 / 277\n",
      "elapsed time 5723.949208021164\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0811 - accuracy: 0.9756\n",
      "batch loss: 0.08105917274951935\n",
      "batch accuracy: 0.9755859375\n",
      "doing 57 / 277\n",
      "elapsed time 5857.845609664917\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0888 - accuracy: 0.9668\n",
      "batch loss: 0.08877326548099518\n",
      "batch accuracy: 0.966796875\n",
      "doing 58 / 277\n",
      "elapsed time 5991.343168973923\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0633 - accuracy: 0.9805\n",
      "batch loss: 0.06327522546052933\n",
      "batch accuracy: 0.98046875\n",
      "doing 59 / 277\n",
      "elapsed time 6122.750235795975\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0581 - accuracy: 0.9775\n",
      "batch loss: 0.058122701942920685\n",
      "batch accuracy: 0.9775390625\n",
      "doing 60 / 277\n",
      "elapsed time 6254.811160802841\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0844 - accuracy: 0.9697\n",
      "batch loss: 0.08435512334108353\n",
      "batch accuracy: 0.9697265625\n",
      "doing 61 / 277\n",
      "elapsed time 6386.477497816086\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0789 - accuracy: 0.9736\n",
      "batch loss: 0.07892612367868423\n",
      "batch accuracy: 0.9736328125\n",
      "doing 62 / 277\n",
      "elapsed time 6515.28420996666\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0775 - accuracy: 0.9736\n",
      "batch loss: 0.07746926695108414\n",
      "batch accuracy: 0.9736328125\n",
      "doing 63 / 277\n",
      "elapsed time 6645.614974498749\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9746\n",
      "batch loss: 0.08262261748313904\n",
      "batch accuracy: 0.974609375\n",
      "doing 64 / 277\n",
      "elapsed time 6785.0285449028015\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0749 - accuracy: 0.9727\n",
      "batch loss: 0.07492789626121521\n",
      "batch accuracy: 0.97265625\n",
      "doing 65 / 277\n",
      "elapsed time 6920.345883846283\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0799 - accuracy: 0.9697\n",
      "batch loss: 0.07992243766784668\n",
      "batch accuracy: 0.9697265625\n",
      "doing 66 / 277\n",
      "elapsed time 7056.419006109238\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0898 - accuracy: 0.9746\n",
      "batch loss: 0.08978234976530075\n",
      "batch accuracy: 0.974609375\n",
      "doing 67 / 277\n",
      "elapsed time 7180.642095565796\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0844 - accuracy: 0.9697\n",
      "batch loss: 0.0844423770904541\n",
      "batch accuracy: 0.9697265625\n",
      "doing 68 / 277\n",
      "elapsed time 7317.3607404232025\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0915 - accuracy: 0.9668\n",
      "batch loss: 0.09152968972921371\n",
      "batch accuracy: 0.966796875\n",
      "doing 69 / 277\n",
      "elapsed time 7459.609503746033\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0921 - accuracy: 0.9697\n",
      "batch loss: 0.09208741784095764\n",
      "batch accuracy: 0.9697265625\n",
      "doing 70 / 277\n",
      "elapsed time 7596.871157407761\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0985 - accuracy: 0.9639\n",
      "batch loss: 0.09848104417324066\n",
      "batch accuracy: 0.9638671875\n",
      "doing 71 / 277\n",
      "elapsed time 7734.018059968948\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0632 - accuracy: 0.9766\n",
      "batch loss: 0.06323572248220444\n",
      "batch accuracy: 0.9765625\n",
      "doing 72 / 277\n",
      "elapsed time 7870.37114405632\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0617 - accuracy: 0.9854\n",
      "batch loss: 0.061711039394140244\n",
      "batch accuracy: 0.9853515625\n",
      "doing 73 / 277\n",
      "elapsed time 8011.487990140915\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0907 - accuracy: 0.9600\n",
      "batch loss: 0.09074956178665161\n",
      "batch accuracy: 0.9599609375\n",
      "doing 74 / 277\n",
      "elapsed time 8144.415816545486\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1015 - accuracy: 0.9629\n",
      "batch loss: 0.10153482109308243\n",
      "batch accuracy: 0.962890625\n",
      "doing 75 / 277\n",
      "elapsed time 8284.254716396332\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0856 - accuracy: 0.9697\n",
      "batch loss: 0.08557536453008652\n",
      "batch accuracy: 0.9697265625\n",
      "doing 76 / 277\n",
      "elapsed time 8423.015179634094\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0899 - accuracy: 0.9619\n",
      "batch loss: 0.08988204598426819\n",
      "batch accuracy: 0.9619140625\n",
      "doing 77 / 277\n",
      "elapsed time 8562.57256937027\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0796 - accuracy: 0.9727\n",
      "batch loss: 0.07959329336881638\n",
      "batch accuracy: 0.97265625\n",
      "doing 78 / 277\n",
      "elapsed time 8699.514861106873\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1092 - accuracy: 0.9580\n",
      "batch loss: 0.1091623455286026\n",
      "batch accuracy: 0.9580078125\n",
      "doing 79 / 277\n",
      "elapsed time 8836.96993803978\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0773 - accuracy: 0.9775\n",
      "batch loss: 0.07731413841247559\n",
      "batch accuracy: 0.9775390625\n",
      "doing 80 / 277\n",
      "elapsed time 8972.969968795776\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0877 - accuracy: 0.9688\n",
      "batch loss: 0.08771167695522308\n",
      "batch accuracy: 0.96875\n",
      "doing 81 / 277\n",
      "elapsed time 9109.961701154709\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0923 - accuracy: 0.9727\n",
      "batch loss: 0.09228183329105377\n",
      "batch accuracy: 0.97265625\n",
      "doing 82 / 277\n",
      "elapsed time 9251.392377614975\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0972 - accuracy: 0.9629\n",
      "batch loss: 0.09715847671031952\n",
      "batch accuracy: 0.962890625\n",
      "doing 83 / 277\n",
      "elapsed time 9387.876289606094\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1005 - accuracy: 0.9600\n",
      "batch loss: 0.1004728302359581\n",
      "batch accuracy: 0.9599609375\n",
      "doing 84 / 277\n",
      "elapsed time 9534.69906258583\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0787 - accuracy: 0.9736\n",
      "batch loss: 0.07866978645324707\n",
      "batch accuracy: 0.9736328125\n",
      "doing 85 / 277\n",
      "elapsed time 9678.88583612442\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0776 - accuracy: 0.9707\n",
      "batch loss: 0.0776355117559433\n",
      "batch accuracy: 0.970703125\n",
      "doing 86 / 277\n",
      "elapsed time 9827.322851896286\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0731 - accuracy: 0.9717\n",
      "batch loss: 0.073051817715168\n",
      "batch accuracy: 0.9716796875\n",
      "doing 87 / 277\n",
      "elapsed time 9970.602150201797\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0647 - accuracy: 0.9756\n",
      "batch loss: 0.06473639607429504\n",
      "batch accuracy: 0.9755859375\n",
      "doing 88 / 277\n",
      "elapsed time 10106.135041236877\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0815 - accuracy: 0.9766\n",
      "batch loss: 0.08152960240840912\n",
      "batch accuracy: 0.9765625\n",
      "doing 89 / 277\n",
      "elapsed time 10245.393991947174\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0731 - accuracy: 0.9766\n",
      "batch loss: 0.07307013869285583\n",
      "batch accuracy: 0.9765625\n",
      "doing 90 / 277\n",
      "elapsed time 10375.512027025223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0741 - accuracy: 0.9746\n",
      "batch loss: 0.0740761086344719\n",
      "batch accuracy: 0.974609375\n",
      "doing 91 / 277\n",
      "elapsed time 10508.978458881378\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0765 - accuracy: 0.9707\n",
      "batch loss: 0.07651419192552567\n",
      "batch accuracy: 0.970703125\n",
      "doing 92 / 277\n",
      "elapsed time 10645.139827489853\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0960 - accuracy: 0.9717\n",
      "batch loss: 0.09600967168807983\n",
      "batch accuracy: 0.9716796875\n",
      "doing 93 / 277\n",
      "elapsed time 10780.998097658157\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0960 - accuracy: 0.9648\n",
      "batch loss: 0.09602198004722595\n",
      "batch accuracy: 0.96484375\n",
      "doing 94 / 277\n",
      "elapsed time 10920.824974298477\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0565 - accuracy: 0.9814\n",
      "batch loss: 0.056470394134521484\n",
      "batch accuracy: 0.9814453125\n",
      "doing 95 / 277\n",
      "elapsed time 11054.357619524002\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0711 - accuracy: 0.9736\n",
      "batch loss: 0.07108648121356964\n",
      "batch accuracy: 0.9736328125\n",
      "doing 96 / 277\n",
      "elapsed time 11193.722663640976\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0739 - accuracy: 0.9688\n",
      "batch loss: 0.07391730695962906\n",
      "batch accuracy: 0.96875\n",
      "doing 97 / 277\n",
      "elapsed time 11329.118333101273\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0698 - accuracy: 0.9707\n",
      "batch loss: 0.06977453827857971\n",
      "batch accuracy: 0.970703125\n",
      "doing 98 / 277\n",
      "elapsed time 11463.223320484161\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0643 - accuracy: 0.9746\n",
      "batch loss: 0.06430147588253021\n",
      "batch accuracy: 0.974609375\n",
      "doing 99 / 277\n",
      "elapsed time 11595.940176010132\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0741 - accuracy: 0.9727\n",
      "batch loss: 0.07406040281057358\n",
      "batch accuracy: 0.97265625\n",
      "doing 100 / 277\n",
      "elapsed time 11728.749793291092\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0771 - accuracy: 0.9756\n",
      "batch loss: 0.07714851200580597\n",
      "batch accuracy: 0.9755859375\n",
      "doing 101 / 277\n",
      "elapsed time 11860.890657186508\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0937 - accuracy: 0.9688\n",
      "batch loss: 0.093747079372406\n",
      "batch accuracy: 0.96875\n",
      "doing 102 / 277\n",
      "elapsed time 11989.946633577347\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0683 - accuracy: 0.9756\n",
      "batch loss: 0.06828311085700989\n",
      "batch accuracy: 0.9755859375\n",
      "doing 103 / 277\n",
      "elapsed time 12117.546825885773\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0795 - accuracy: 0.9727\n",
      "batch loss: 0.07947554439306259\n",
      "batch accuracy: 0.97265625\n",
      "doing 104 / 277\n",
      "elapsed time 12247.97549366951\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0718 - accuracy: 0.9697\n",
      "batch loss: 0.07182250171899796\n",
      "batch accuracy: 0.9697265625\n",
      "doing 105 / 277\n",
      "elapsed time 12379.289829015732\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0692 - accuracy: 0.9736\n",
      "batch loss: 0.06918865442276001\n",
      "batch accuracy: 0.9736328125\n",
      "doing 106 / 277\n",
      "elapsed time 12501.676996707916\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0656 - accuracy: 0.9766\n",
      "batch loss: 0.06560592353343964\n",
      "batch accuracy: 0.9765625\n",
      "doing 107 / 277\n",
      "elapsed time 12636.411435842514\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0912 - accuracy: 0.9717\n",
      "batch loss: 0.09124995023012161\n",
      "batch accuracy: 0.9716796875\n",
      "doing 108 / 277\n",
      "elapsed time 12768.7376434803\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0712 - accuracy: 0.9775\n",
      "batch loss: 0.07120907306671143\n",
      "batch accuracy: 0.9775390625\n",
      "doing 109 / 277\n",
      "elapsed time 12896.976597547531\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0739 - accuracy: 0.9766\n",
      "batch loss: 0.0738702192902565\n",
      "batch accuracy: 0.9765625\n",
      "doing 110 / 277\n",
      "elapsed time 13025.5713057518\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0718 - accuracy: 0.9795\n",
      "batch loss: 0.07182417064905167\n",
      "batch accuracy: 0.9794921875\n",
      "doing 111 / 277\n",
      "elapsed time 13157.286264419556\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0759 - accuracy: 0.9717\n",
      "batch loss: 0.07590428739786148\n",
      "batch accuracy: 0.9716796875\n",
      "doing 112 / 277\n",
      "elapsed time 13287.98715353012\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 0.9678\n",
      "batch loss: 0.08224264532327652\n",
      "batch accuracy: 0.9677734375\n",
      "doing 113 / 277\n",
      "elapsed time 13417.268646717072\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0629 - accuracy: 0.9795\n",
      "batch loss: 0.06294462084770203\n",
      "batch accuracy: 0.9794921875\n",
      "doing 114 / 277\n",
      "elapsed time 13542.614116668701\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0834 - accuracy: 0.9707\n",
      "batch loss: 0.08335890620946884\n",
      "batch accuracy: 0.970703125\n",
      "doing 115 / 277\n",
      "elapsed time 13670.483541727066\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0800 - accuracy: 0.9756\n",
      "batch loss: 0.07995930314064026\n",
      "batch accuracy: 0.9755859375\n",
      "doing 116 / 277\n",
      "elapsed time 13796.76315832138\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0655 - accuracy: 0.9746\n",
      "batch loss: 0.0654963031411171\n",
      "batch accuracy: 0.974609375\n",
      "doing 117 / 277\n",
      "elapsed time 13926.238839626312\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0757 - accuracy: 0.9727\n",
      "batch loss: 0.07566221058368683\n",
      "batch accuracy: 0.97265625\n",
      "doing 118 / 277\n",
      "elapsed time 14060.11215877533\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0848 - accuracy: 0.9688\n",
      "batch loss: 0.08479523658752441\n",
      "batch accuracy: 0.96875\n",
      "doing 119 / 277\n",
      "elapsed time 14195.299783468246\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0842 - accuracy: 0.9746\n",
      "batch loss: 0.08422768861055374\n",
      "batch accuracy: 0.974609375\n",
      "doing 120 / 277\n",
      "elapsed time 14332.061194896698\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0697 - accuracy: 0.9805\n",
      "batch loss: 0.06970375031232834\n",
      "batch accuracy: 0.98046875\n",
      "doing 121 / 277\n",
      "elapsed time 14470.740055799484\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0822 - accuracy: 0.9707\n",
      "batch loss: 0.08223827928304672\n",
      "batch accuracy: 0.970703125\n",
      "doing 122 / 277\n",
      "elapsed time 14603.92558002472\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0809 - accuracy: 0.9756\n",
      "batch loss: 0.08086708188056946\n",
      "batch accuracy: 0.9755859375\n",
      "doing 123 / 277\n",
      "elapsed time 14742.283952951431\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0984 - accuracy: 0.9668\n",
      "batch loss: 0.09838847070932388\n",
      "batch accuracy: 0.966796875\n",
      "doing 124 / 277\n",
      "elapsed time 14884.315470933914\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0715 - accuracy: 0.9756\n",
      "batch loss: 0.07149884849786758\n",
      "batch accuracy: 0.9755859375\n",
      "doing 125 / 277\n",
      "elapsed time 15026.86705327034\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0646 - accuracy: 0.9727\n",
      "batch loss: 0.06457215547561646\n",
      "batch accuracy: 0.97265625\n",
      "doing 126 / 277\n",
      "elapsed time 15162.309478759766\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0895 - accuracy: 0.9717\n",
      "batch loss: 0.0895436480641365\n",
      "batch accuracy: 0.9716796875\n",
      "doing 127 / 277\n",
      "elapsed time 15298.96979880333\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0794 - accuracy: 0.9717\n",
      "batch loss: 0.07942026108503342\n",
      "batch accuracy: 0.9716796875\n",
      "doing 128 / 277\n",
      "elapsed time 15436.796153068542\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0620 - accuracy: 0.9746\n",
      "batch loss: 0.061983153223991394\n",
      "batch accuracy: 0.974609375\n",
      "doing 129 / 277\n",
      "elapsed time 15573.266375303268\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0881 - accuracy: 0.9639\n",
      "batch loss: 0.0880565345287323\n",
      "batch accuracy: 0.9638671875\n",
      "doing 130 / 277\n",
      "elapsed time 15707.185297727585\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0795 - accuracy: 0.9736\n",
      "batch loss: 0.0794573724269867\n",
      "batch accuracy: 0.9736328125\n",
      "doing 131 / 277\n",
      "elapsed time 15841.946939706802\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0670 - accuracy: 0.9766\n",
      "batch loss: 0.06704875826835632\n",
      "batch accuracy: 0.9765625\n",
      "doing 132 / 277\n",
      "elapsed time 15979.430993795395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0624 - accuracy: 0.9795\n",
      "batch loss: 0.062377989292144775\n",
      "batch accuracy: 0.9794921875\n",
      "doing 133 / 277\n",
      "elapsed time 16115.820767641068\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0690 - accuracy: 0.9736\n",
      "batch loss: 0.06900661438703537\n",
      "batch accuracy: 0.9736328125\n",
      "doing 134 / 277\n",
      "elapsed time 16244.553183794022\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0701 - accuracy: 0.9717\n",
      "batch loss: 0.07014936953783035\n",
      "batch accuracy: 0.9716796875\n",
      "doing 135 / 277\n",
      "elapsed time 16371.200263023376\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0666 - accuracy: 0.9775\n",
      "batch loss: 0.06660842150449753\n",
      "batch accuracy: 0.9775390625\n",
      "doing 136 / 277\n",
      "elapsed time 16509.927223443985\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0917 - accuracy: 0.9639\n",
      "batch loss: 0.09168633818626404\n",
      "batch accuracy: 0.9638671875\n",
      "doing 137 / 277\n",
      "elapsed time 16639.54759168625\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0643 - accuracy: 0.9844\n",
      "batch loss: 0.06426016986370087\n",
      "batch accuracy: 0.984375\n",
      "doing 138 / 277\n",
      "elapsed time 16772.21813225746\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0761 - accuracy: 0.9658\n",
      "batch loss: 0.07614403963088989\n",
      "batch accuracy: 0.9658203125\n",
      "doing 139 / 277\n",
      "elapsed time 16900.66349339485\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0864 - accuracy: 0.9707\n",
      "batch loss: 0.08640031516551971\n",
      "batch accuracy: 0.970703125\n",
      "doing 140 / 277\n",
      "elapsed time 17040.067446947098\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0638 - accuracy: 0.9756\n",
      "batch loss: 0.06377820670604706\n",
      "batch accuracy: 0.9755859375\n",
      "doing 141 / 277\n",
      "elapsed time 17178.00888967514\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0717 - accuracy: 0.9785\n",
      "batch loss: 0.07173071056604385\n",
      "batch accuracy: 0.978515625\n",
      "doing 142 / 277\n",
      "elapsed time 17304.957464694977\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0752 - accuracy: 0.9785\n",
      "batch loss: 0.07521072030067444\n",
      "batch accuracy: 0.978515625\n",
      "doing 143 / 277\n",
      "elapsed time 17442.598380327225\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0931 - accuracy: 0.9639\n",
      "batch loss: 0.0931471437215805\n",
      "batch accuracy: 0.9638671875\n",
      "doing 144 / 277\n",
      "elapsed time 17570.427177667618\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0655 - accuracy: 0.9775\n",
      "batch loss: 0.0655045360326767\n",
      "batch accuracy: 0.9775390625\n",
      "doing 145 / 277\n",
      "elapsed time 17707.377363443375\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0743 - accuracy: 0.9756\n",
      "batch loss: 0.07431715726852417\n",
      "batch accuracy: 0.9755859375\n",
      "doing 146 / 277\n",
      "elapsed time 17836.873008728027\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0779 - accuracy: 0.9736\n",
      "batch loss: 0.07794453948736191\n",
      "batch accuracy: 0.9736328125\n",
      "doing 147 / 277\n",
      "elapsed time 17963.67245054245\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0786 - accuracy: 0.9678\n",
      "batch loss: 0.07863451540470123\n",
      "batch accuracy: 0.9677734375\n",
      "doing 148 / 277\n",
      "elapsed time 18085.150872707367\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0866 - accuracy: 0.9736\n",
      "batch loss: 0.08656419813632965\n",
      "batch accuracy: 0.9736328125\n",
      "doing 149 / 277\n",
      "elapsed time 18210.759728193283\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0807 - accuracy: 0.9717\n",
      "batch loss: 0.08065983653068542\n",
      "batch accuracy: 0.9716796875\n",
      "doing 150 / 277\n",
      "elapsed time 18340.153939008713\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0772 - accuracy: 0.9795\n",
      "batch loss: 0.07719201594591141\n",
      "batch accuracy: 0.9794921875\n",
      "doing 151 / 277\n",
      "elapsed time 18470.749064445496\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0980 - accuracy: 0.9717\n",
      "batch loss: 0.09803466498851776\n",
      "batch accuracy: 0.9716796875\n",
      "doing 152 / 277\n",
      "elapsed time 18587.12036371231\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0703 - accuracy: 0.9766\n",
      "batch loss: 0.07027745991945267\n",
      "batch accuracy: 0.9765625\n",
      "doing 153 / 277\n",
      "elapsed time 18705.866203308105\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1027 - accuracy: 0.9600\n",
      "batch loss: 0.10266014188528061\n",
      "batch accuracy: 0.9599609375\n",
      "doing 154 / 277\n",
      "elapsed time 18835.57299399376\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0751 - accuracy: 0.9766\n",
      "batch loss: 0.07506106793880463\n",
      "batch accuracy: 0.9765625\n",
      "doing 155 / 277\n",
      "elapsed time 18962.576592445374\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0748 - accuracy: 0.9727\n",
      "batch loss: 0.07479461282491684\n",
      "batch accuracy: 0.97265625\n",
      "doing 156 / 277\n",
      "elapsed time 19088.83930492401\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0801 - accuracy: 0.9717\n",
      "batch loss: 0.08010958880186081\n",
      "batch accuracy: 0.9716796875\n",
      "doing 157 / 277\n",
      "elapsed time 19216.02437376976\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0692 - accuracy: 0.9775\n",
      "batch loss: 0.06922315806150436\n",
      "batch accuracy: 0.9775390625\n",
      "doing 158 / 277\n",
      "elapsed time 19343.464109659195\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0572 - accuracy: 0.9795\n",
      "batch loss: 0.05716175585985184\n",
      "batch accuracy: 0.9794921875\n",
      "doing 159 / 277\n",
      "elapsed time 19468.27180457115\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0774 - accuracy: 0.9775\n",
      "batch loss: 0.077435702085495\n",
      "batch accuracy: 0.9775390625\n",
      "doing 160 / 277\n",
      "elapsed time 19600.26801609993\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0653 - accuracy: 0.9746\n",
      "batch loss: 0.06534408777952194\n",
      "batch accuracy: 0.974609375\n",
      "doing 161 / 277\n",
      "elapsed time 19725.19928431511\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0569 - accuracy: 0.9746\n",
      "batch loss: 0.05689851939678192\n",
      "batch accuracy: 0.974609375\n",
      "doing 162 / 277\n",
      "elapsed time 19850.680028676987\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0604 - accuracy: 0.9775\n",
      "batch loss: 0.0603896826505661\n",
      "batch accuracy: 0.9775390625\n",
      "doing 163 / 277\n",
      "elapsed time 19977.588963747025\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0661 - accuracy: 0.9746\n",
      "batch loss: 0.0661458894610405\n",
      "batch accuracy: 0.974609375\n",
      "doing 164 / 277\n",
      "elapsed time 20104.555802822113\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0765 - accuracy: 0.9707\n",
      "batch loss: 0.07649598270654678\n",
      "batch accuracy: 0.970703125\n",
      "doing 165 / 277\n",
      "elapsed time 20228.014069080353\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0732 - accuracy: 0.9736\n",
      "batch loss: 0.07323092222213745\n",
      "batch accuracy: 0.9736328125\n",
      "doing 166 / 277\n",
      "elapsed time 20352.294176101685\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0803 - accuracy: 0.9678\n",
      "batch loss: 0.0803489238023758\n",
      "batch accuracy: 0.9677734375\n",
      "doing 167 / 277\n",
      "elapsed time 20477.190993785858\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0803 - accuracy: 0.9727\n",
      "batch loss: 0.0803261399269104\n",
      "batch accuracy: 0.97265625\n",
      "doing 168 / 277\n",
      "elapsed time 20600.648963928223\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0925 - accuracy: 0.9717\n",
      "batch loss: 0.09248563647270203\n",
      "batch accuracy: 0.9716796875\n",
      "doing 169 / 277\n",
      "elapsed time 20721.453007936478\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0859 - accuracy: 0.9736\n",
      "batch loss: 0.08591209352016449\n",
      "batch accuracy: 0.9736328125\n",
      "doing 170 / 277\n",
      "elapsed time 20844.26242351532\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0810 - accuracy: 0.9746\n",
      "batch loss: 0.08102759718894958\n",
      "batch accuracy: 0.974609375\n",
      "doing 171 / 277\n",
      "elapsed time 20966.107021331787\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0796 - accuracy: 0.9717\n",
      "batch loss: 0.0796118974685669\n",
      "batch accuracy: 0.9716796875\n",
      "doing 172 / 277\n",
      "elapsed time 21086.768484830856\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0750 - accuracy: 0.9766\n",
      "batch loss: 0.07503491640090942\n",
      "batch accuracy: 0.9765625\n",
      "doing 173 / 277\n",
      "elapsed time 21210.10338497162\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0828 - accuracy: 0.9648\n",
      "batch loss: 0.08277085423469543\n",
      "batch accuracy: 0.96484375\n",
      "doing 174 / 277\n",
      "elapsed time 21329.45511817932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0864 - accuracy: 0.9688\n",
      "batch loss: 0.08638699352741241\n",
      "batch accuracy: 0.96875\n",
      "doing 175 / 277\n",
      "elapsed time 21446.038470506668\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0856 - accuracy: 0.9678\n",
      "batch loss: 0.0856047198176384\n",
      "batch accuracy: 0.9677734375\n",
      "doing 176 / 277\n",
      "elapsed time 21563.12752199173\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0694 - accuracy: 0.9766\n",
      "batch loss: 0.06936574727296829\n",
      "batch accuracy: 0.9765625\n",
      "doing 177 / 277\n",
      "elapsed time 21682.236800670624\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0891 - accuracy: 0.9736\n",
      "batch loss: 0.08913415670394897\n",
      "batch accuracy: 0.9736328125\n",
      "doing 178 / 277\n",
      "elapsed time 21803.44748854637\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0629 - accuracy: 0.9844\n",
      "batch loss: 0.06293968111276627\n",
      "batch accuracy: 0.984375\n",
      "doing 179 / 277\n",
      "elapsed time 21921.47527527809\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0933 - accuracy: 0.9639\n",
      "batch loss: 0.09331561625003815\n",
      "batch accuracy: 0.9638671875\n",
      "doing 180 / 277\n",
      "elapsed time 22037.45180106163\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0716 - accuracy: 0.9736\n",
      "batch loss: 0.07158541679382324\n",
      "batch accuracy: 0.9736328125\n",
      "doing 181 / 277\n",
      "elapsed time 22149.34060359001\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0727 - accuracy: 0.9756\n",
      "batch loss: 0.07267776876688004\n",
      "batch accuracy: 0.9755859375\n",
      "doing 182 / 277\n",
      "elapsed time 22263.36659502983\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0840 - accuracy: 0.9717\n",
      "batch loss: 0.08395745605230331\n",
      "batch accuracy: 0.9716796875\n",
      "doing 183 / 277\n",
      "elapsed time 22379.842910528183\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0754 - accuracy: 0.9746\n",
      "batch loss: 0.0753559023141861\n",
      "batch accuracy: 0.974609375\n",
      "doing 184 / 277\n",
      "elapsed time 22493.16476416588\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0865 - accuracy: 0.9756\n",
      "batch loss: 0.08648531883955002\n",
      "batch accuracy: 0.9755859375\n",
      "doing 185 / 277\n",
      "elapsed time 22609.3834900856\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0605 - accuracy: 0.9795\n",
      "batch loss: 0.06051357090473175\n",
      "batch accuracy: 0.9794921875\n",
      "doing 186 / 277\n",
      "elapsed time 22722.851825475693\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0780 - accuracy: 0.9697\n",
      "batch loss: 0.0780239924788475\n",
      "batch accuracy: 0.9697265625\n",
      "doing 187 / 277\n",
      "elapsed time 22833.122004270554\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0637 - accuracy: 0.9814\n",
      "batch loss: 0.06368981301784515\n",
      "batch accuracy: 0.9814453125\n",
      "doing 188 / 277\n",
      "elapsed time 22941.93132352829\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0669 - accuracy: 0.9766\n",
      "batch loss: 0.06690852344036102\n",
      "batch accuracy: 0.9765625\n",
      "doing 189 / 277\n",
      "elapsed time 23058.94276213646\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0634 - accuracy: 0.9844\n",
      "batch loss: 0.06335008144378662\n",
      "batch accuracy: 0.984375\n",
      "doing 190 / 277\n",
      "elapsed time 23172.355660915375\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0649 - accuracy: 0.9785\n",
      "batch loss: 0.06494327634572983\n",
      "batch accuracy: 0.978515625\n",
      "doing 191 / 277\n",
      "elapsed time 23289.766340970993\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0857 - accuracy: 0.9736\n",
      "batch loss: 0.0856582522392273\n",
      "batch accuracy: 0.9736328125\n",
      "doing 192 / 277\n",
      "elapsed time 23407.267298460007\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0665 - accuracy: 0.9736\n",
      "batch loss: 0.06650011241436005\n",
      "batch accuracy: 0.9736328125\n",
      "doing 193 / 277\n",
      "elapsed time 23523.517892360687\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0669 - accuracy: 0.9766\n",
      "batch loss: 0.0669173002243042\n",
      "batch accuracy: 0.9765625\n",
      "doing 194 / 277\n",
      "elapsed time 23636.10534262657\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0579 - accuracy: 0.9805\n",
      "batch loss: 0.05793827772140503\n",
      "batch accuracy: 0.98046875\n",
      "doing 195 / 277\n",
      "elapsed time 23735.436841011047\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0631 - accuracy: 0.9795\n",
      "batch loss: 0.0631379783153534\n",
      "batch accuracy: 0.9794921875\n",
      "doing 196 / 277\n",
      "elapsed time 23846.931951999664\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0800 - accuracy: 0.9707\n",
      "batch loss: 0.07999677956104279\n",
      "batch accuracy: 0.970703125\n",
      "doing 197 / 277\n",
      "elapsed time 23959.12104678154\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0704 - accuracy: 0.9775\n",
      "batch loss: 0.07042445242404938\n",
      "batch accuracy: 0.9775390625\n",
      "doing 198 / 277\n",
      "elapsed time 24065.068969249725\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9756\n",
      "batch loss: 0.08260354399681091\n",
      "batch accuracy: 0.9755859375\n",
      "doing 199 / 277\n",
      "elapsed time 24172.034550905228\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0692 - accuracy: 0.9717\n",
      "batch loss: 0.0692121759057045\n",
      "batch accuracy: 0.9716796875\n",
      "doing 200 / 277\n",
      "elapsed time 24275.460817575455\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0477 - accuracy: 0.9814\n",
      "batch loss: 0.04772914946079254\n",
      "batch accuracy: 0.9814453125\n",
      "doing 201 / 277\n",
      "elapsed time 24389.23634815216\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0743 - accuracy: 0.9717\n",
      "batch loss: 0.0742712914943695\n",
      "batch accuracy: 0.9716796875\n",
      "doing 202 / 277\n",
      "elapsed time 24500.927676677704\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0686 - accuracy: 0.9707\n",
      "batch loss: 0.0686192736029625\n",
      "batch accuracy: 0.970703125\n",
      "doing 203 / 277\n",
      "elapsed time 24601.66029024124\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0692 - accuracy: 0.9736\n",
      "batch loss: 0.06915349513292313\n",
      "batch accuracy: 0.9736328125\n",
      "doing 204 / 277\n",
      "elapsed time 24706.6023709774\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0714 - accuracy: 0.9707\n",
      "batch loss: 0.07137776911258698\n",
      "batch accuracy: 0.970703125\n",
      "doing 205 / 277\n",
      "elapsed time 24818.908113718033\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0763 - accuracy: 0.9727\n",
      "batch loss: 0.07633866369724274\n",
      "batch accuracy: 0.97265625\n",
      "doing 206 / 277\n",
      "elapsed time 24925.553916692734\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0656 - accuracy: 0.9746\n",
      "batch loss: 0.06561107188463211\n",
      "batch accuracy: 0.974609375\n",
      "doing 207 / 277\n",
      "elapsed time 25026.933892965317\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0796 - accuracy: 0.9736\n",
      "batch loss: 0.0796382948756218\n",
      "batch accuracy: 0.9736328125\n",
      "doing 208 / 277\n",
      "elapsed time 25137.47009062767\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0770 - accuracy: 0.9727\n",
      "batch loss: 0.07700757682323456\n",
      "batch accuracy: 0.97265625\n",
      "doing 209 / 277\n",
      "elapsed time 25242.209507226944\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0832 - accuracy: 0.9756\n",
      "batch loss: 0.08316121250391006\n",
      "batch accuracy: 0.9755859375\n",
      "doing 210 / 277\n",
      "elapsed time 25335.0588991642\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0539 - accuracy: 0.9805\n",
      "batch loss: 0.05387207120656967\n",
      "batch accuracy: 0.98046875\n",
      "doing 211 / 277\n",
      "elapsed time 25423.098103046417\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0728 - accuracy: 0.9727\n",
      "batch loss: 0.07282358407974243\n",
      "batch accuracy: 0.97265625\n",
      "doing 212 / 277\n",
      "elapsed time 25515.984491109848\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0819 - accuracy: 0.9717\n",
      "batch loss: 0.08192744851112366\n",
      "batch accuracy: 0.9716796875\n",
      "doing 213 / 277\n",
      "elapsed time 25603.965159893036\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0762 - accuracy: 0.9746\n",
      "batch loss: 0.07620538771152496\n",
      "batch accuracy: 0.974609375\n",
      "doing 214 / 277\n",
      "elapsed time 25681.79251384735\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0809 - accuracy: 0.9727\n",
      "batch loss: 0.08085428178310394\n",
      "batch accuracy: 0.97265625\n",
      "doing 215 / 277\n",
      "elapsed time 25778.00087094307\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0541 - accuracy: 0.9775\n",
      "batch loss: 0.05408836156129837\n",
      "batch accuracy: 0.9775390625\n",
      "doing 216 / 277\n",
      "elapsed time 25867.922959566116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1061 - accuracy: 0.9629\n",
      "batch loss: 0.10610230267047882\n",
      "batch accuracy: 0.962890625\n",
      "doing 217 / 277\n",
      "elapsed time 25962.432809591293\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0462 - accuracy: 0.9805\n",
      "batch loss: 0.04619068652391434\n",
      "batch accuracy: 0.98046875\n",
      "doing 218 / 277\n",
      "elapsed time 26051.647755861282\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0780 - accuracy: 0.9688\n",
      "batch loss: 0.07797744870185852\n",
      "batch accuracy: 0.96875\n",
      "doing 219 / 277\n",
      "elapsed time 26140.770676374435\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0892 - accuracy: 0.9727\n",
      "batch loss: 0.08923829346895218\n",
      "batch accuracy: 0.97265625\n",
      "doing 220 / 277\n",
      "elapsed time 26229.634375572205\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0599 - accuracy: 0.9805\n",
      "batch loss: 0.05986198037862778\n",
      "batch accuracy: 0.98046875\n",
      "doing 221 / 277\n",
      "elapsed time 26317.710027456284\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0710 - accuracy: 0.9766\n",
      "batch loss: 0.07098205387592316\n",
      "batch accuracy: 0.9765625\n",
      "doing 222 / 277\n",
      "elapsed time 26409.21524500847\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0754 - accuracy: 0.9668\n",
      "batch loss: 0.07544826716184616\n",
      "batch accuracy: 0.966796875\n",
      "doing 223 / 277\n",
      "elapsed time 26497.096219539642\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0813 - accuracy: 0.9707\n",
      "batch loss: 0.08132655918598175\n",
      "batch accuracy: 0.970703125\n",
      "doing 224 / 277\n",
      "elapsed time 26586.0839138031\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0774 - accuracy: 0.9736\n",
      "batch loss: 0.07744969427585602\n",
      "batch accuracy: 0.9736328125\n",
      "doing 225 / 277\n",
      "elapsed time 26673.37031507492\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1138 - accuracy: 0.9561\n",
      "batch loss: 0.11382126808166504\n",
      "batch accuracy: 0.9560546875\n",
      "doing 226 / 277\n",
      "elapsed time 26763.63162469864\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0904 - accuracy: 0.9697\n",
      "batch loss: 0.09040133655071259\n",
      "batch accuracy: 0.9697265625\n",
      "doing 227 / 277\n",
      "elapsed time 26850.35202407837\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0798 - accuracy: 0.9736\n",
      "batch loss: 0.07981489598751068\n",
      "batch accuracy: 0.9736328125\n",
      "doing 228 / 277\n",
      "elapsed time 26937.2620677948\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1103 - accuracy: 0.9580\n",
      "batch loss: 0.11027931421995163\n",
      "batch accuracy: 0.9580078125\n",
      "doing 229 / 277\n",
      "elapsed time 27026.235051631927\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0920 - accuracy: 0.9648\n",
      "batch loss: 0.09203086793422699\n",
      "batch accuracy: 0.96484375\n",
      "doing 230 / 277\n",
      "elapsed time 27112.601476192474\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1005 - accuracy: 0.9658\n",
      "batch loss: 0.10050105303525925\n",
      "batch accuracy: 0.9658203125\n",
      "doing 231 / 277\n",
      "elapsed time 27204.61430287361\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0954 - accuracy: 0.9717\n",
      "batch loss: 0.09542267769575119\n",
      "batch accuracy: 0.9716796875\n",
      "doing 232 / 277\n",
      "elapsed time 27286.770364522934\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0825 - accuracy: 0.9707\n",
      "batch loss: 0.0824502483010292\n",
      "batch accuracy: 0.970703125\n",
      "doing 233 / 277\n",
      "elapsed time 27366.24613261223\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0684 - accuracy: 0.9756\n",
      "batch loss: 0.06836821138858795\n",
      "batch accuracy: 0.9755859375\n",
      "doing 234 / 277\n",
      "elapsed time 27448.62012195587\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0829 - accuracy: 0.9727\n",
      "batch loss: 0.0828891173005104\n",
      "batch accuracy: 0.97265625\n",
      "doing 235 / 277\n",
      "elapsed time 27540.17599964142\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0919 - accuracy: 0.9678\n",
      "batch loss: 0.09186627715826035\n",
      "batch accuracy: 0.9677734375\n",
      "doing 236 / 277\n",
      "elapsed time 27629.70329785347\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0683 - accuracy: 0.9805\n",
      "batch loss: 0.06831617653369904\n",
      "batch accuracy: 0.98046875\n",
      "doing 237 / 277\n",
      "elapsed time 27714.627301216125\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0825 - accuracy: 0.9697\n",
      "batch loss: 0.08249634504318237\n",
      "batch accuracy: 0.9697265625\n",
      "doing 238 / 277\n",
      "elapsed time 27806.81951570511\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0653 - accuracy: 0.9795\n",
      "batch loss: 0.06531596183776855\n",
      "batch accuracy: 0.9794921875\n",
      "doing 239 / 277\n",
      "elapsed time 27888.709707975388\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0737 - accuracy: 0.9756\n",
      "batch loss: 0.07368488609790802\n",
      "batch accuracy: 0.9755859375\n",
      "doing 240 / 277\n",
      "elapsed time 27978.395689487457\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0674 - accuracy: 0.9795\n",
      "batch loss: 0.06740780919790268\n",
      "batch accuracy: 0.9794921875\n",
      "doing 241 / 277\n",
      "elapsed time 28065.70787668228\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0549 - accuracy: 0.9854\n",
      "batch loss: 0.054911933839321136\n",
      "batch accuracy: 0.9853515625\n",
      "doing 242 / 277\n",
      "elapsed time 28151.57830429077\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0616 - accuracy: 0.9795\n",
      "batch loss: 0.06157255917787552\n",
      "batch accuracy: 0.9794921875\n",
      "doing 243 / 277\n",
      "elapsed time 28235.113953590393\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0695 - accuracy: 0.9805\n",
      "batch loss: 0.0695427656173706\n",
      "batch accuracy: 0.98046875\n",
      "doing 244 / 277\n",
      "elapsed time 28320.84130692482\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0619 - accuracy: 0.9775\n",
      "batch loss: 0.061945997178554535\n",
      "batch accuracy: 0.9775390625\n",
      "doing 245 / 277\n",
      "elapsed time 28408.050347328186\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0779 - accuracy: 0.9775\n",
      "batch loss: 0.07794983685016632\n",
      "batch accuracy: 0.9775390625\n",
      "doing 246 / 277\n",
      "elapsed time 28488.27303338051\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0675 - accuracy: 0.9746\n",
      "batch loss: 0.0675431415438652\n",
      "batch accuracy: 0.974609375\n",
      "doing 247 / 277\n",
      "elapsed time 28577.42137145996\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0797 - accuracy: 0.9736\n",
      "batch loss: 0.07972652465105057\n",
      "batch accuracy: 0.9736328125\n",
      "doing 248 / 277\n",
      "elapsed time 28659.758382081985\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0603 - accuracy: 0.9805\n",
      "batch loss: 0.060344673693180084\n",
      "batch accuracy: 0.98046875\n",
      "doing 249 / 277\n",
      "elapsed time 28739.55847454071\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0690 - accuracy: 0.9736\n",
      "batch loss: 0.06901352852582932\n",
      "batch accuracy: 0.9736328125\n",
      "doing 250 / 277\n",
      "elapsed time 28823.56011915207\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0654 - accuracy: 0.9814\n",
      "batch loss: 0.06536046415567398\n",
      "batch accuracy: 0.9814453125\n",
      "doing 251 / 277\n",
      "elapsed time 28908.008858203888\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0653 - accuracy: 0.9775\n",
      "batch loss: 0.06534729897975922\n",
      "batch accuracy: 0.9775390625\n",
      "doing 252 / 277\n",
      "elapsed time 28989.808505773544\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0852 - accuracy: 0.9717\n",
      "batch loss: 0.08521336317062378\n",
      "batch accuracy: 0.9716796875\n",
      "doing 253 / 277\n",
      "elapsed time 29074.998789787292\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0958 - accuracy: 0.9609\n",
      "batch loss: 0.09582598507404327\n",
      "batch accuracy: 0.9609375\n",
      "doing 254 / 277\n",
      "elapsed time 29153.528243541718\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0678 - accuracy: 0.9805\n",
      "batch loss: 0.0678107738494873\n",
      "batch accuracy: 0.98046875\n",
      "doing 255 / 277\n",
      "elapsed time 29233.8457198143\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1057 - accuracy: 0.9600\n",
      "batch loss: 0.10569534450769424\n",
      "batch accuracy: 0.9599609375\n",
      "doing 256 / 277\n",
      "elapsed time 29317.70976781845\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0608 - accuracy: 0.9766\n",
      "batch loss: 0.0607689693570137\n",
      "batch accuracy: 0.9765625\n",
      "doing 257 / 277\n",
      "elapsed time 29399.961501836777\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0938 - accuracy: 0.9629\n",
      "batch loss: 0.0938166156411171\n",
      "batch accuracy: 0.962890625\n",
      "doing 258 / 277\n",
      "elapsed time 29482.578190088272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0680 - accuracy: 0.9775\n",
      "batch loss: 0.0680113434791565\n",
      "batch accuracy: 0.9775390625\n",
      "doing 259 / 277\n",
      "elapsed time 29567.35593700409\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0775 - accuracy: 0.9688\n",
      "batch loss: 0.07751350104808807\n",
      "batch accuracy: 0.96875\n",
      "doing 260 / 277\n",
      "elapsed time 29658.765058517456\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0681 - accuracy: 0.9795\n",
      "batch loss: 0.06809333711862564\n",
      "batch accuracy: 0.9794921875\n",
      "doing 261 / 277\n",
      "elapsed time 29748.920870780945\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0610 - accuracy: 0.9805\n",
      "batch loss: 0.06099343299865723\n",
      "batch accuracy: 0.98046875\n",
      "doing 262 / 277\n",
      "elapsed time 29841.61333322525\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0746 - accuracy: 0.9746\n",
      "batch loss: 0.07458079606294632\n",
      "batch accuracy: 0.974609375\n",
      "doing 263 / 277\n",
      "elapsed time 29934.994047880173\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0575 - accuracy: 0.9805\n",
      "batch loss: 0.05754004046320915\n",
      "batch accuracy: 0.98046875\n",
      "doing 264 / 277\n",
      "elapsed time 30022.5002617836\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0588 - accuracy: 0.9756\n",
      "batch loss: 0.05879874527454376\n",
      "batch accuracy: 0.9755859375\n",
      "doing 265 / 277\n",
      "elapsed time 30110.682084560394\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0649 - accuracy: 0.9795\n",
      "batch loss: 0.06489460915327072\n",
      "batch accuracy: 0.9794921875\n",
      "doing 266 / 277\n",
      "elapsed time 30199.890144109726\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0791 - accuracy: 0.9756\n",
      "batch loss: 0.07910767197608948\n",
      "batch accuracy: 0.9755859375\n",
      "doing 267 / 277\n",
      "elapsed time 30290.686464309692\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0650 - accuracy: 0.9795\n",
      "batch loss: 0.06496044993400574\n",
      "batch accuracy: 0.9794921875\n",
      "doing 268 / 277\n",
      "elapsed time 30380.487454891205\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0790 - accuracy: 0.9678\n",
      "batch loss: 0.07898710668087006\n",
      "batch accuracy: 0.9677734375\n",
      "doing 269 / 277\n",
      "elapsed time 30466.821619033813\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0657 - accuracy: 0.9766\n",
      "batch loss: 0.0657026395201683\n",
      "batch accuracy: 0.9765625\n",
      "doing 270 / 277\n",
      "elapsed time 30554.12787461281\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0614 - accuracy: 0.9805\n",
      "batch loss: 0.061418164521455765\n",
      "batch accuracy: 0.98046875\n",
      "doing 271 / 277\n",
      "elapsed time 30642.846697568893\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0701 - accuracy: 0.9766\n",
      "batch loss: 0.07012458145618439\n",
      "batch accuracy: 0.9765625\n",
      "doing 272 / 277\n",
      "elapsed time 30730.629111289978\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0859 - accuracy: 0.9668\n",
      "batch loss: 0.0859140008687973\n",
      "batch accuracy: 0.966796875\n",
      "doing 273 / 277\n",
      "elapsed time 30823.093985557556\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0678 - accuracy: 0.9756\n",
      "batch loss: 0.0678120106458664\n",
      "batch accuracy: 0.9755859375\n",
      "doing 274 / 277\n",
      "elapsed time 30915.34744811058\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0663 - accuracy: 0.9727\n",
      "batch loss: 0.06627503037452698\n",
      "batch accuracy: 0.97265625\n",
      "doing 275 / 277\n",
      "elapsed time 31002.96740245819\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0846 - accuracy: 0.9707\n",
      "batch loss: 0.08463579416275024\n",
      "batch accuracy: 0.970703125\n",
      "doing 276 / 277\n",
      "elapsed time 31058.466407060623\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0418 - accuracy: 0.9835\n",
      "batch loss: 0.04183926060795784\n",
      "batch accuracy: 0.9835466146469116\n",
      "Train loss 0.07824602560392356\n",
      "Train accuracy 0.9726074279860899\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 0.1504 - accuracy: 0.9558\n",
      "Validation loss: 0.15038862824440002\n",
      "Validation accuracy: 0.9557777643203735\n",
      "==================================================\n",
      "7 / 10\n",
      "doing 0 / 277\n",
      "elapsed time 66.29464817047119\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0777 - accuracy: 0.9775\n",
      "batch loss: 0.0776592418551445\n",
      "batch accuracy: 0.9775390625\n",
      "doing 1 / 277\n",
      "elapsed time 127.98952078819275\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0956 - accuracy: 0.9658\n",
      "batch loss: 0.09558328241109848\n",
      "batch accuracy: 0.9658203125\n",
      "doing 2 / 277\n",
      "elapsed time 198.47758984565735\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0693 - accuracy: 0.9785\n",
      "batch loss: 0.06932050734758377\n",
      "batch accuracy: 0.978515625\n",
      "doing 3 / 277\n",
      "elapsed time 265.55189180374146\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0737 - accuracy: 0.9717\n",
      "batch loss: 0.07370801270008087\n",
      "batch accuracy: 0.9716796875\n",
      "doing 4 / 277\n",
      "elapsed time 329.03870010375977\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0603 - accuracy: 0.9844\n",
      "batch loss: 0.06025927886366844\n",
      "batch accuracy: 0.984375\n",
      "doing 5 / 277\n",
      "elapsed time 396.9489974975586\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0930 - accuracy: 0.9668\n",
      "batch loss: 0.09298872947692871\n",
      "batch accuracy: 0.966796875\n",
      "doing 6 / 277\n",
      "elapsed time 472.9999210834503\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0799 - accuracy: 0.9717\n",
      "batch loss: 0.07988155633211136\n",
      "batch accuracy: 0.9716796875\n",
      "doing 7 / 277\n",
      "elapsed time 543.9455592632294\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0785 - accuracy: 0.9717\n",
      "batch loss: 0.07852169871330261\n",
      "batch accuracy: 0.9716796875\n",
      "doing 8 / 277\n",
      "elapsed time 611.4896287918091\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0764 - accuracy: 0.9697\n",
      "batch loss: 0.07640334963798523\n",
      "batch accuracy: 0.9697265625\n",
      "doing 9 / 277\n",
      "elapsed time 674.1579566001892\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0614 - accuracy: 0.9746\n",
      "batch loss: 0.06137165427207947\n",
      "batch accuracy: 0.974609375\n",
      "doing 10 / 277\n",
      "elapsed time 742.6880376338959\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0725 - accuracy: 0.9785\n",
      "batch loss: 0.07254642248153687\n",
      "batch accuracy: 0.978515625\n",
      "doing 11 / 277\n",
      "elapsed time 807.3556141853333\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0739 - accuracy: 0.9707\n",
      "batch loss: 0.07385656982660294\n",
      "batch accuracy: 0.970703125\n",
      "doing 12 / 277\n",
      "elapsed time 869.3039531707764\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0501 - accuracy: 0.9814\n",
      "batch loss: 0.050123270601034164\n",
      "batch accuracy: 0.9814453125\n",
      "doing 13 / 277\n",
      "elapsed time 928.451578617096\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0960 - accuracy: 0.9609\n",
      "batch loss: 0.09600431472063065\n",
      "batch accuracy: 0.9609375\n",
      "doing 14 / 277\n",
      "elapsed time 1003.222953081131\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0762 - accuracy: 0.9775\n",
      "batch loss: 0.07621892541646957\n",
      "batch accuracy: 0.9775390625\n",
      "doing 15 / 277\n",
      "elapsed time 1065.9249515533447\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0744 - accuracy: 0.9746\n",
      "batch loss: 0.07443784177303314\n",
      "batch accuracy: 0.974609375\n",
      "doing 16 / 277\n",
      "elapsed time 1131.2904872894287\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0955 - accuracy: 0.9629\n",
      "batch loss: 0.09552048146724701\n",
      "batch accuracy: 0.962890625\n",
      "doing 17 / 277\n",
      "elapsed time 1194.2423357963562\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0575 - accuracy: 0.9814\n",
      "batch loss: 0.057471685111522675\n",
      "batch accuracy: 0.9814453125\n",
      "doing 18 / 277\n",
      "elapsed time 1259.2107558250427\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0567 - accuracy: 0.9834\n",
      "batch loss: 0.05674290284514427\n",
      "batch accuracy: 0.9833984375\n",
      "doing 19 / 277\n",
      "elapsed time 1328.315706729889\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0847 - accuracy: 0.9697\n",
      "batch loss: 0.08470621705055237\n",
      "batch accuracy: 0.9697265625\n",
      "doing 20 / 277\n",
      "elapsed time 1390.2329308986664\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0743 - accuracy: 0.9736\n",
      "batch loss: 0.07425092160701752\n",
      "batch accuracy: 0.9736328125\n",
      "doing 21 / 277\n",
      "elapsed time 1461.6503727436066\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0620 - accuracy: 0.9824\n",
      "batch loss: 0.062000688165426254\n",
      "batch accuracy: 0.982421875\n",
      "doing 22 / 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 1528.5378403663635\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0558 - accuracy: 0.9727\n",
      "batch loss: 0.05577341839671135\n",
      "batch accuracy: 0.97265625\n",
      "doing 23 / 277\n",
      "elapsed time 1587.0192527770996\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0754 - accuracy: 0.9697\n",
      "batch loss: 0.07535907626152039\n",
      "batch accuracy: 0.9697265625\n",
      "doing 24 / 277\n",
      "elapsed time 1642.3047676086426\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0681 - accuracy: 0.9756\n",
      "batch loss: 0.06805499643087387\n",
      "batch accuracy: 0.9755859375\n",
      "doing 25 / 277\n",
      "elapsed time 1716.3852534294128\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0602 - accuracy: 0.9805\n",
      "batch loss: 0.060174159705638885\n",
      "batch accuracy: 0.98046875\n",
      "doing 26 / 277\n",
      "elapsed time 1780.8117427825928\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0678 - accuracy: 0.9824\n",
      "batch loss: 0.06775668263435364\n",
      "batch accuracy: 0.982421875\n",
      "doing 27 / 277\n",
      "elapsed time 1835.0051696300507\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0544 - accuracy: 0.9824\n",
      "batch loss: 0.054353900253772736\n",
      "batch accuracy: 0.982421875\n",
      "doing 28 / 277\n",
      "elapsed time 1898.2671296596527\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0600 - accuracy: 0.9814\n",
      "batch loss: 0.05998380109667778\n",
      "batch accuracy: 0.9814453125\n",
      "doing 29 / 277\n",
      "elapsed time 1965.7174999713898\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0735 - accuracy: 0.9736\n",
      "batch loss: 0.07352006435394287\n",
      "batch accuracy: 0.9736328125\n",
      "doing 30 / 277\n",
      "elapsed time 2036.1997549533844\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0609 - accuracy: 0.9785\n",
      "batch loss: 0.060879115015268326\n",
      "batch accuracy: 0.978515625\n",
      "doing 31 / 277\n",
      "elapsed time 2097.0517394542694\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0445 - accuracy: 0.9863\n",
      "batch loss: 0.04453511908650398\n",
      "batch accuracy: 0.986328125\n",
      "doing 32 / 277\n",
      "elapsed time 2152.787487745285\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0611 - accuracy: 0.9795\n",
      "batch loss: 0.06114795804023743\n",
      "batch accuracy: 0.9794921875\n",
      "doing 33 / 277\n",
      "elapsed time 2215.7032606601715\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0622 - accuracy: 0.9766\n",
      "batch loss: 0.06222105771303177\n",
      "batch accuracy: 0.9765625\n",
      "doing 34 / 277\n",
      "elapsed time 2278.2446603775024\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0593 - accuracy: 0.9834\n",
      "batch loss: 0.05930813401937485\n",
      "batch accuracy: 0.9833984375\n",
      "doing 35 / 277\n",
      "elapsed time 2340.4589779376984\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0653 - accuracy: 0.9775\n",
      "batch loss: 0.06530800461769104\n",
      "batch accuracy: 0.9775390625\n",
      "doing 36 / 277\n",
      "elapsed time 2404.494820833206\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0713 - accuracy: 0.9736\n",
      "batch loss: 0.07126938551664352\n",
      "batch accuracy: 0.9736328125\n",
      "doing 37 / 277\n",
      "elapsed time 2462.126143217087\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0693 - accuracy: 0.9707\n",
      "batch loss: 0.06927971541881561\n",
      "batch accuracy: 0.970703125\n",
      "doing 38 / 277\n",
      "elapsed time 2528.0283122062683\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0681 - accuracy: 0.9736\n",
      "batch loss: 0.06814345717430115\n",
      "batch accuracy: 0.9736328125\n",
      "doing 39 / 277\n",
      "elapsed time 2587.0132246017456\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0416 - accuracy: 0.9873\n",
      "batch loss: 0.041584476828575134\n",
      "batch accuracy: 0.9873046875\n",
      "doing 40 / 277\n",
      "elapsed time 2642.3003396987915\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0533 - accuracy: 0.9795\n",
      "batch loss: 0.05334877222776413\n",
      "batch accuracy: 0.9794921875\n",
      "doing 41 / 277\n",
      "elapsed time 2702.4201209545135\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0573 - accuracy: 0.9775\n",
      "batch loss: 0.05727827548980713\n",
      "batch accuracy: 0.9775390625\n",
      "doing 42 / 277\n",
      "elapsed time 2763.722826719284\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0501 - accuracy: 0.9863\n",
      "batch loss: 0.05010751634836197\n",
      "batch accuracy: 0.986328125\n",
      "doing 43 / 277\n",
      "elapsed time 2819.837730884552\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0573 - accuracy: 0.9785\n",
      "batch loss: 0.05732693895697594\n",
      "batch accuracy: 0.978515625\n",
      "doing 44 / 277\n",
      "elapsed time 2882.2244625091553\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0595 - accuracy: 0.9766\n",
      "batch loss: 0.059544678777456284\n",
      "batch accuracy: 0.9765625\n",
      "doing 45 / 277\n",
      "elapsed time 2937.426193714142\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0510 - accuracy: 0.9863\n",
      "batch loss: 0.051017217338085175\n",
      "batch accuracy: 0.986328125\n",
      "doing 46 / 277\n",
      "elapsed time 3001.2473175525665\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0653 - accuracy: 0.9844\n",
      "batch loss: 0.06533613801002502\n",
      "batch accuracy: 0.984375\n",
      "doing 47 / 277\n",
      "elapsed time 3052.042943716049\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0652 - accuracy: 0.9795\n",
      "batch loss: 0.06522636860609055\n",
      "batch accuracy: 0.9794921875\n",
      "doing 48 / 277\n",
      "elapsed time 3106.7679398059845\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0511 - accuracy: 0.9824\n",
      "batch loss: 0.051091499626636505\n",
      "batch accuracy: 0.982421875\n",
      "doing 49 / 277\n",
      "elapsed time 3172.634254217148\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0612 - accuracy: 0.9795\n",
      "batch loss: 0.06122232973575592\n",
      "batch accuracy: 0.9794921875\n",
      "doing 50 / 277\n",
      "elapsed time 3241.6949672698975\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0570 - accuracy: 0.9824\n",
      "batch loss: 0.05695732310414314\n",
      "batch accuracy: 0.982421875\n",
      "doing 51 / 277\n",
      "elapsed time 3294.0740356445312\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0591 - accuracy: 0.9785\n",
      "batch loss: 0.059072114527225494\n",
      "batch accuracy: 0.978515625\n",
      "doing 52 / 277\n",
      "elapsed time 3349.9886474609375\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0518 - accuracy: 0.9795\n",
      "batch loss: 0.05178678780794144\n",
      "batch accuracy: 0.9794921875\n",
      "doing 53 / 277\n",
      "elapsed time 3406.6644508838654\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0719 - accuracy: 0.9775\n",
      "batch loss: 0.0718526691198349\n",
      "batch accuracy: 0.9775390625\n",
      "doing 54 / 277\n",
      "elapsed time 3472.4662098884583\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0411 - accuracy: 0.9883\n",
      "batch loss: 0.041065044701099396\n",
      "batch accuracy: 0.98828125\n",
      "doing 55 / 277\n",
      "elapsed time 3536.3926858901978\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0499 - accuracy: 0.9824\n",
      "batch loss: 0.04987429082393646\n",
      "batch accuracy: 0.982421875\n",
      "doing 56 / 277\n",
      "elapsed time 3600.6818385124207\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0623 - accuracy: 0.9824\n",
      "batch loss: 0.062258534133434296\n",
      "batch accuracy: 0.982421875\n",
      "doing 57 / 277\n",
      "elapsed time 3660.985897541046\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0438 - accuracy: 0.9824\n",
      "batch loss: 0.04381665214896202\n",
      "batch accuracy: 0.982421875\n",
      "doing 58 / 277\n",
      "elapsed time 3717.9224202632904\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0601 - accuracy: 0.9785\n",
      "batch loss: 0.060131534934043884\n",
      "batch accuracy: 0.978515625\n",
      "doing 59 / 277\n",
      "elapsed time 3770.5188903808594\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0542 - accuracy: 0.9834\n",
      "batch loss: 0.05417988449335098\n",
      "batch accuracy: 0.9833984375\n",
      "doing 60 / 277\n",
      "elapsed time 3830.542538881302\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0692 - accuracy: 0.9746\n",
      "batch loss: 0.06924350559711456\n",
      "batch accuracy: 0.974609375\n",
      "doing 61 / 277\n",
      "elapsed time 3889.558697462082\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0582 - accuracy: 0.9766\n",
      "batch loss: 0.058225810527801514\n",
      "batch accuracy: 0.9765625\n",
      "doing 62 / 277\n",
      "elapsed time 3939.9198200702667\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0675 - accuracy: 0.9746\n",
      "batch loss: 0.06754977256059647\n",
      "batch accuracy: 0.974609375\n",
      "doing 63 / 277\n",
      "elapsed time 3990.858074903488\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0817 - accuracy: 0.9756\n",
      "batch loss: 0.08169825375080109\n",
      "batch accuracy: 0.9755859375\n",
      "doing 64 / 277\n",
      "elapsed time 4053.6543769836426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0533 - accuracy: 0.9844\n",
      "batch loss: 0.0532769076526165\n",
      "batch accuracy: 0.984375\n",
      "doing 65 / 277\n",
      "elapsed time 4102.543935537338\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0757 - accuracy: 0.9736\n",
      "batch loss: 0.0756668895483017\n",
      "batch accuracy: 0.9736328125\n",
      "doing 66 / 277\n",
      "elapsed time 4151.260101079941\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0585 - accuracy: 0.9795\n",
      "batch loss: 0.0584648959338665\n",
      "batch accuracy: 0.9794921875\n",
      "doing 67 / 277\n",
      "elapsed time 4206.610944032669\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0445 - accuracy: 0.9854\n",
      "batch loss: 0.04452850669622421\n",
      "batch accuracy: 0.9853515625\n",
      "doing 68 / 277\n",
      "elapsed time 4263.405614376068\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0622 - accuracy: 0.9795\n",
      "batch loss: 0.0621940903365612\n",
      "batch accuracy: 0.9794921875\n",
      "doing 69 / 277\n",
      "elapsed time 4316.2545046806335\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0547 - accuracy: 0.9785\n",
      "batch loss: 0.054651595652103424\n",
      "batch accuracy: 0.978515625\n",
      "doing 70 / 277\n",
      "elapsed time 4361.852734327316\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0659 - accuracy: 0.9707\n",
      "batch loss: 0.06594225764274597\n",
      "batch accuracy: 0.970703125\n",
      "doing 71 / 277\n",
      "elapsed time 4420.988874197006\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0817 - accuracy: 0.9678\n",
      "batch loss: 0.08168350160121918\n",
      "batch accuracy: 0.9677734375\n",
      "doing 72 / 277\n",
      "elapsed time 4474.378981113434\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0709 - accuracy: 0.9766\n",
      "batch loss: 0.07088764011859894\n",
      "batch accuracy: 0.9765625\n",
      "doing 73 / 277\n",
      "elapsed time 4526.985223054886\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0854 - accuracy: 0.9727\n",
      "batch loss: 0.08537213504314423\n",
      "batch accuracy: 0.97265625\n",
      "doing 74 / 277\n",
      "elapsed time 4577.297029495239\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0594 - accuracy: 0.9824\n",
      "batch loss: 0.05944555997848511\n",
      "batch accuracy: 0.982421875\n",
      "doing 75 / 277\n",
      "elapsed time 4635.652227401733\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0518 - accuracy: 0.9805\n",
      "batch loss: 0.05177096277475357\n",
      "batch accuracy: 0.98046875\n",
      "doing 76 / 277\n",
      "elapsed time 4688.407182455063\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0663 - accuracy: 0.9775\n",
      "batch loss: 0.06632521003484726\n",
      "batch accuracy: 0.9775390625\n",
      "doing 77 / 277\n",
      "elapsed time 4732.6001489162445\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0458 - accuracy: 0.9863\n",
      "batch loss: 0.045787349343299866\n",
      "batch accuracy: 0.986328125\n",
      "doing 78 / 277\n",
      "elapsed time 4784.220102071762\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0693 - accuracy: 0.9736\n",
      "batch loss: 0.06925714015960693\n",
      "batch accuracy: 0.9736328125\n",
      "doing 79 / 277\n",
      "elapsed time 4839.301089048386\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0636 - accuracy: 0.9805\n",
      "batch loss: 0.06361426413059235\n",
      "batch accuracy: 0.98046875\n",
      "doing 80 / 277\n",
      "elapsed time 4891.835230588913\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0460 - accuracy: 0.9863\n",
      "batch loss: 0.046039387583732605\n",
      "batch accuracy: 0.986328125\n",
      "doing 81 / 277\n",
      "elapsed time 4941.503151655197\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0738 - accuracy: 0.9756\n",
      "batch loss: 0.07382487505674362\n",
      "batch accuracy: 0.9755859375\n",
      "doing 82 / 277\n",
      "elapsed time 4994.942823410034\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0546 - accuracy: 0.9814\n",
      "batch loss: 0.05462278425693512\n",
      "batch accuracy: 0.9814453125\n",
      "doing 83 / 277\n",
      "elapsed time 5044.68638086319\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0487 - accuracy: 0.9775\n",
      "batch loss: 0.048717595636844635\n",
      "batch accuracy: 0.9775390625\n",
      "doing 84 / 277\n",
      "elapsed time 5106.57760310173\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0543 - accuracy: 0.9844\n",
      "batch loss: 0.054329466074705124\n",
      "batch accuracy: 0.984375\n",
      "doing 85 / 277\n",
      "elapsed time 5161.086800098419\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0598 - accuracy: 0.9775\n",
      "batch loss: 0.05981893837451935\n",
      "batch accuracy: 0.9775390625\n",
      "doing 86 / 277\n",
      "elapsed time 5215.083290815353\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0450 - accuracy: 0.9873\n",
      "batch loss: 0.045011553913354874\n",
      "batch accuracy: 0.9873046875\n",
      "doing 87 / 277\n",
      "elapsed time 5265.123834848404\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0495 - accuracy: 0.9844\n",
      "batch loss: 0.04948235675692558\n",
      "batch accuracy: 0.984375\n",
      "doing 88 / 277\n",
      "elapsed time 5313.366716384888\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0701 - accuracy: 0.9736\n",
      "batch loss: 0.07005741447210312\n",
      "batch accuracy: 0.9736328125\n",
      "doing 89 / 277\n",
      "elapsed time 5363.895966291428\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0747 - accuracy: 0.9727\n",
      "batch loss: 0.07465855777263641\n",
      "batch accuracy: 0.97265625\n",
      "doing 90 / 277\n",
      "elapsed time 5417.774738073349\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0702 - accuracy: 0.9775\n",
      "batch loss: 0.0702345222234726\n",
      "batch accuracy: 0.9775390625\n",
      "doing 91 / 277\n",
      "elapsed time 5474.15499830246\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0521 - accuracy: 0.9814\n",
      "batch loss: 0.05210022255778313\n",
      "batch accuracy: 0.9814453125\n",
      "doing 92 / 277\n",
      "elapsed time 5519.409060955048\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0585 - accuracy: 0.9736\n",
      "batch loss: 0.058540452271699905\n",
      "batch accuracy: 0.9736328125\n",
      "doing 93 / 277\n",
      "elapsed time 5568.985756158829\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0519 - accuracy: 0.9775\n",
      "batch loss: 0.0518990196287632\n",
      "batch accuracy: 0.9775390625\n",
      "doing 94 / 277\n",
      "elapsed time 5611.794860124588\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0873 - accuracy: 0.9658\n",
      "batch loss: 0.08725088089704514\n",
      "batch accuracy: 0.9658203125\n",
      "doing 95 / 277\n",
      "elapsed time 5662.1752576828\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0749 - accuracy: 0.9697\n",
      "batch loss: 0.07489833235740662\n",
      "batch accuracy: 0.9697265625\n",
      "doing 96 / 277\n",
      "elapsed time 5703.32647895813\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0541 - accuracy: 0.9805\n",
      "batch loss: 0.054123494774103165\n",
      "batch accuracy: 0.98046875\n",
      "doing 97 / 277\n",
      "elapsed time 5742.309349775314\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0637 - accuracy: 0.9766\n",
      "batch loss: 0.06372405588626862\n",
      "batch accuracy: 0.9765625\n",
      "doing 98 / 277\n",
      "elapsed time 5794.222382545471\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0470 - accuracy: 0.9844\n",
      "batch loss: 0.04697674885392189\n",
      "batch accuracy: 0.984375\n",
      "doing 99 / 277\n",
      "elapsed time 5841.381153106689\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0659 - accuracy: 0.9805\n",
      "batch loss: 0.06590477377176285\n",
      "batch accuracy: 0.98046875\n",
      "doing 100 / 277\n",
      "elapsed time 5886.7228236198425\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0548 - accuracy: 0.9824\n",
      "batch loss: 0.054839201271533966\n",
      "batch accuracy: 0.982421875\n",
      "doing 101 / 277\n",
      "elapsed time 5926.9781222343445\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0441 - accuracy: 0.9873\n",
      "batch loss: 0.044063467532396317\n",
      "batch accuracy: 0.9873046875\n",
      "doing 102 / 277\n",
      "elapsed time 5978.970178365707\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0530 - accuracy: 0.9805\n",
      "batch loss: 0.053018517792224884\n",
      "batch accuracy: 0.98046875\n",
      "doing 103 / 277\n",
      "elapsed time 6035.272715806961\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0412 - accuracy: 0.9873\n",
      "batch loss: 0.0412316769361496\n",
      "batch accuracy: 0.9873046875\n",
      "doing 104 / 277\n",
      "elapsed time 6084.665151596069\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0768 - accuracy: 0.9756\n",
      "batch loss: 0.07679975777864456\n",
      "batch accuracy: 0.9755859375\n",
      "doing 105 / 277\n",
      "elapsed time 6126.533697128296\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0545 - accuracy: 0.9805\n",
      "batch loss: 0.05453991889953613\n",
      "batch accuracy: 0.98046875\n",
      "doing 106 / 277\n",
      "elapsed time 6163.971968889236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0634 - accuracy: 0.9766\n",
      "batch loss: 0.06339047104120255\n",
      "batch accuracy: 0.9765625\n",
      "doing 107 / 277\n",
      "elapsed time 6216.780542135239\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0580 - accuracy: 0.9756\n",
      "batch loss: 0.058046624064445496\n",
      "batch accuracy: 0.9755859375\n",
      "doing 108 / 277\n",
      "elapsed time 6265.441453456879\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0533 - accuracy: 0.9844\n",
      "batch loss: 0.05327871814370155\n",
      "batch accuracy: 0.984375\n",
      "doing 109 / 277\n",
      "elapsed time 6310.831867456436\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0458 - accuracy: 0.9854\n",
      "batch loss: 0.04578942805528641\n",
      "batch accuracy: 0.9853515625\n",
      "doing 110 / 277\n",
      "elapsed time 6349.597529888153\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0636 - accuracy: 0.9795\n",
      "batch loss: 0.06357245147228241\n",
      "batch accuracy: 0.9794921875\n",
      "doing 111 / 277\n",
      "elapsed time 6406.011935710907\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0502 - accuracy: 0.9863\n",
      "batch loss: 0.05021768808364868\n",
      "batch accuracy: 0.986328125\n",
      "doing 112 / 277\n",
      "elapsed time 6459.536458015442\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0494 - accuracy: 0.9844\n",
      "batch loss: 0.04940685257315636\n",
      "batch accuracy: 0.984375\n",
      "doing 113 / 277\n",
      "elapsed time 6505.072222232819\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0610 - accuracy: 0.9795\n",
      "batch loss: 0.06104907765984535\n",
      "batch accuracy: 0.9794921875\n",
      "doing 114 / 277\n",
      "elapsed time 6551.018146276474\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0583 - accuracy: 0.9785\n",
      "batch loss: 0.0583210326731205\n",
      "batch accuracy: 0.978515625\n",
      "doing 115 / 277\n",
      "elapsed time 6596.997678995132\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0645 - accuracy: 0.9766\n",
      "batch loss: 0.06453555077314377\n",
      "batch accuracy: 0.9765625\n",
      "doing 116 / 277\n",
      "elapsed time 6645.365073680878\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0529 - accuracy: 0.9844\n",
      "batch loss: 0.052932191640138626\n",
      "batch accuracy: 0.984375\n",
      "doing 117 / 277\n",
      "elapsed time 6699.097784519196\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0552 - accuracy: 0.9814\n",
      "batch loss: 0.0552280992269516\n",
      "batch accuracy: 0.9814453125\n",
      "doing 118 / 277\n",
      "elapsed time 6749.184568405151\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0686 - accuracy: 0.9746\n",
      "batch loss: 0.06860827654600143\n",
      "batch accuracy: 0.974609375\n",
      "doing 119 / 277\n",
      "elapsed time 6794.145416259766\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0519 - accuracy: 0.9805\n",
      "batch loss: 0.05190489813685417\n",
      "batch accuracy: 0.98046875\n",
      "doing 120 / 277\n",
      "elapsed time 6835.3964376449585\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0754 - accuracy: 0.9697\n",
      "batch loss: 0.07542391121387482\n",
      "batch accuracy: 0.9697265625\n",
      "doing 121 / 277\n",
      "elapsed time 6885.847700834274\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0647 - accuracy: 0.9785\n",
      "batch loss: 0.064748615026474\n",
      "batch accuracy: 0.978515625\n",
      "doing 122 / 277\n",
      "elapsed time 6929.780939340591\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0493 - accuracy: 0.9824\n",
      "batch loss: 0.04929044097661972\n",
      "batch accuracy: 0.982421875\n",
      "doing 123 / 277\n",
      "elapsed time 6986.29536986351\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0521 - accuracy: 0.9854\n",
      "batch loss: 0.052056632936000824\n",
      "batch accuracy: 0.9853515625\n",
      "doing 124 / 277\n",
      "elapsed time 7042.59693646431\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0756 - accuracy: 0.9756\n",
      "batch loss: 0.0756499245762825\n",
      "batch accuracy: 0.9755859375\n",
      "doing 125 / 277\n",
      "elapsed time 7095.681555271149\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0560 - accuracy: 0.9775\n",
      "batch loss: 0.05596409738063812\n",
      "batch accuracy: 0.9775390625\n",
      "doing 126 / 277\n",
      "elapsed time 7150.750922679901\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0556 - accuracy: 0.9834\n",
      "batch loss: 0.055603474378585815\n",
      "batch accuracy: 0.9833984375\n",
      "doing 127 / 277\n",
      "elapsed time 7201.590626001358\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0524 - accuracy: 0.9834\n",
      "batch loss: 0.05242452770471573\n",
      "batch accuracy: 0.9833984375\n",
      "doing 128 / 277\n",
      "elapsed time 7263.522746562958\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0639 - accuracy: 0.9756\n",
      "batch loss: 0.06389185041189194\n",
      "batch accuracy: 0.9755859375\n",
      "doing 129 / 277\n",
      "elapsed time 7323.3611562252045\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0673 - accuracy: 0.9707\n",
      "batch loss: 0.06729517132043839\n",
      "batch accuracy: 0.970703125\n",
      "doing 130 / 277\n",
      "elapsed time 7374.69725394249\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0640 - accuracy: 0.9775\n",
      "batch loss: 0.06396320462226868\n",
      "batch accuracy: 0.9775390625\n",
      "doing 131 / 277\n",
      "elapsed time 7424.497272014618\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0493 - accuracy: 0.9824\n",
      "batch loss: 0.04933889955282211\n",
      "batch accuracy: 0.982421875\n",
      "doing 132 / 277\n",
      "elapsed time 7483.101744413376\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0676 - accuracy: 0.9795\n",
      "batch loss: 0.06764163821935654\n",
      "batch accuracy: 0.9794921875\n",
      "doing 133 / 277\n",
      "elapsed time 7534.842528104782\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0455 - accuracy: 0.9844\n",
      "batch loss: 0.04548799991607666\n",
      "batch accuracy: 0.984375\n",
      "doing 134 / 277\n",
      "elapsed time 7583.778351068497\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0539 - accuracy: 0.9805\n",
      "batch loss: 0.05391509085893631\n",
      "batch accuracy: 0.98046875\n",
      "doing 135 / 277\n",
      "elapsed time 7640.975903511047\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0543 - accuracy: 0.9824\n",
      "batch loss: 0.054272785782814026\n",
      "batch accuracy: 0.982421875\n",
      "doing 136 / 277\n",
      "elapsed time 7695.716742038727\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0544 - accuracy: 0.9795\n",
      "batch loss: 0.054440878331661224\n",
      "batch accuracy: 0.9794921875\n",
      "doing 137 / 277\n",
      "elapsed time 7750.375219583511\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0500 - accuracy: 0.9854\n",
      "batch loss: 0.04998660087585449\n",
      "batch accuracy: 0.9853515625\n",
      "doing 138 / 277\n",
      "elapsed time 7806.896419286728\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0592 - accuracy: 0.9854\n",
      "batch loss: 0.05918678641319275\n",
      "batch accuracy: 0.9853515625\n",
      "doing 139 / 277\n",
      "elapsed time 7861.581638097763\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0619 - accuracy: 0.9814\n",
      "batch loss: 0.06192302703857422\n",
      "batch accuracy: 0.9814453125\n",
      "doing 140 / 277\n",
      "elapsed time 7917.085695505142\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0509 - accuracy: 0.9805\n",
      "batch loss: 0.05090203136205673\n",
      "batch accuracy: 0.98046875\n",
      "doing 141 / 277\n",
      "elapsed time 7973.315524816513\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0719 - accuracy: 0.9766\n",
      "batch loss: 0.07189926505088806\n",
      "batch accuracy: 0.9765625\n",
      "doing 142 / 277\n",
      "elapsed time 8032.75316119194\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0486 - accuracy: 0.9824\n",
      "batch loss: 0.04855581745505333\n",
      "batch accuracy: 0.982421875\n",
      "doing 143 / 277\n",
      "elapsed time 8086.9720804691315\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0559 - accuracy: 0.9805\n",
      "batch loss: 0.0558633990585804\n",
      "batch accuracy: 0.98046875\n",
      "doing 144 / 277\n",
      "elapsed time 8143.204749584198\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0722 - accuracy: 0.9727\n",
      "batch loss: 0.07223627716302872\n",
      "batch accuracy: 0.97265625\n",
      "doing 145 / 277\n",
      "elapsed time 8198.508633375168\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0422 - accuracy: 0.9873\n",
      "batch loss: 0.04222097992897034\n",
      "batch accuracy: 0.9873046875\n",
      "doing 146 / 277\n",
      "elapsed time 8254.843447446823\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0421 - accuracy: 0.9844\n",
      "batch loss: 0.04205526039004326\n",
      "batch accuracy: 0.984375\n",
      "doing 147 / 277\n",
      "elapsed time 8308.94866657257\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0698 - accuracy: 0.9697\n",
      "batch loss: 0.0698028951883316\n",
      "batch accuracy: 0.9697265625\n",
      "doing 148 / 277\n",
      "elapsed time 8360.662667512894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0661 - accuracy: 0.9805\n",
      "batch loss: 0.06612985581159592\n",
      "batch accuracy: 0.98046875\n",
      "doing 149 / 277\n",
      "elapsed time 8415.997824192047\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0497 - accuracy: 0.9854\n",
      "batch loss: 0.049725256860256195\n",
      "batch accuracy: 0.9853515625\n",
      "doing 150 / 277\n",
      "elapsed time 8476.338870048523\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0491 - accuracy: 0.9844\n",
      "batch loss: 0.0491202250123024\n",
      "batch accuracy: 0.984375\n",
      "doing 151 / 277\n",
      "elapsed time 8535.313790082932\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0634 - accuracy: 0.9756\n",
      "batch loss: 0.06336870789527893\n",
      "batch accuracy: 0.9755859375\n",
      "doing 152 / 277\n",
      "elapsed time 8596.631169557571\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0551 - accuracy: 0.9814\n",
      "batch loss: 0.05509384721517563\n",
      "batch accuracy: 0.9814453125\n",
      "doing 153 / 277\n",
      "elapsed time 8653.797863483429\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0719 - accuracy: 0.9756\n",
      "batch loss: 0.07192336767911911\n",
      "batch accuracy: 0.9755859375\n",
      "doing 154 / 277\n",
      "elapsed time 8709.680081367493\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0465 - accuracy: 0.9834\n",
      "batch loss: 0.0465439148247242\n",
      "batch accuracy: 0.9833984375\n",
      "doing 155 / 277\n",
      "elapsed time 8769.42267870903\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0455 - accuracy: 0.9893\n",
      "batch loss: 0.04549693688750267\n",
      "batch accuracy: 0.9892578125\n",
      "doing 156 / 277\n",
      "elapsed time 8827.928707361221\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0563 - accuracy: 0.9795\n",
      "batch loss: 0.056252773851156235\n",
      "batch accuracy: 0.9794921875\n",
      "doing 157 / 277\n",
      "elapsed time 8885.41600894928\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0710 - accuracy: 0.9775\n",
      "batch loss: 0.07097963243722916\n",
      "batch accuracy: 0.9775390625\n",
      "doing 158 / 277\n",
      "elapsed time 8940.811048269272\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0529 - accuracy: 0.9844\n",
      "batch loss: 0.05289987847208977\n",
      "batch accuracy: 0.984375\n",
      "doing 159 / 277\n",
      "elapsed time 8995.760694026947\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0527 - accuracy: 0.9834\n",
      "batch loss: 0.05269145220518112\n",
      "batch accuracy: 0.9833984375\n",
      "doing 160 / 277\n",
      "elapsed time 9056.447192192078\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0503 - accuracy: 0.9814\n",
      "batch loss: 0.05027109384536743\n",
      "batch accuracy: 0.9814453125\n",
      "doing 161 / 277\n",
      "elapsed time 9113.718133449554\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0761 - accuracy: 0.9727\n",
      "batch loss: 0.07607577741146088\n",
      "batch accuracy: 0.97265625\n",
      "doing 162 / 277\n",
      "elapsed time 9175.445385932922\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0558 - accuracy: 0.9795\n",
      "batch loss: 0.055826857686042786\n",
      "batch accuracy: 0.9794921875\n",
      "doing 163 / 277\n",
      "elapsed time 9235.181424617767\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0666 - accuracy: 0.9775\n",
      "batch loss: 0.06658391654491425\n",
      "batch accuracy: 0.9775390625\n",
      "doing 164 / 277\n",
      "elapsed time 9302.255779027939\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0712 - accuracy: 0.9756\n",
      "batch loss: 0.07119057327508926\n",
      "batch accuracy: 0.9755859375\n",
      "doing 165 / 277\n",
      "elapsed time 9364.665235042572\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0612 - accuracy: 0.9756\n",
      "batch loss: 0.06120429188013077\n",
      "batch accuracy: 0.9755859375\n",
      "doing 166 / 277\n",
      "elapsed time 9427.58423614502\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0510 - accuracy: 0.9854\n",
      "batch loss: 0.05101681500673294\n",
      "batch accuracy: 0.9853515625\n",
      "doing 167 / 277\n",
      "elapsed time 9487.94018292427\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0686 - accuracy: 0.9736\n",
      "batch loss: 0.06860880553722382\n",
      "batch accuracy: 0.9736328125\n",
      "doing 168 / 277\n",
      "elapsed time 9546.63710141182\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0521 - accuracy: 0.9814\n",
      "batch loss: 0.052059758454561234\n",
      "batch accuracy: 0.9814453125\n",
      "doing 169 / 277\n",
      "elapsed time 9608.941464662552\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0566 - accuracy: 0.9814\n",
      "batch loss: 0.05658472329378128\n",
      "batch accuracy: 0.9814453125\n",
      "doing 170 / 277\n",
      "elapsed time 9669.862127542496\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0626 - accuracy: 0.9795\n",
      "batch loss: 0.06256570667028427\n",
      "batch accuracy: 0.9794921875\n",
      "doing 171 / 277\n",
      "elapsed time 9729.728365898132\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0584 - accuracy: 0.9805\n",
      "batch loss: 0.058381013572216034\n",
      "batch accuracy: 0.98046875\n",
      "doing 172 / 277\n",
      "elapsed time 9788.128337144852\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0547 - accuracy: 0.9805\n",
      "batch loss: 0.05470246076583862\n",
      "batch accuracy: 0.98046875\n",
      "doing 173 / 277\n",
      "elapsed time 9841.141585588455\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0623 - accuracy: 0.9814\n",
      "batch loss: 0.062250178307294846\n",
      "batch accuracy: 0.9814453125\n",
      "doing 174 / 277\n",
      "elapsed time 9899.456148862839\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0473 - accuracy: 0.9824\n",
      "batch loss: 0.04727238789200783\n",
      "batch accuracy: 0.982421875\n",
      "doing 175 / 277\n",
      "elapsed time 9956.44997382164\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0509 - accuracy: 0.9795\n",
      "batch loss: 0.05087510496377945\n",
      "batch accuracy: 0.9794921875\n",
      "doing 176 / 277\n",
      "elapsed time 10018.165292024612\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0688 - accuracy: 0.9814\n",
      "batch loss: 0.06882467865943909\n",
      "batch accuracy: 0.9814453125\n",
      "doing 177 / 277\n",
      "elapsed time 10075.050223827362\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0622 - accuracy: 0.9756\n",
      "batch loss: 0.06216328591108322\n",
      "batch accuracy: 0.9755859375\n",
      "doing 178 / 277\n",
      "elapsed time 10130.278752326965\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0677 - accuracy: 0.9756\n",
      "batch loss: 0.06768076866865158\n",
      "batch accuracy: 0.9755859375\n",
      "doing 179 / 277\n",
      "elapsed time 10187.494704246521\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0519 - accuracy: 0.9805\n",
      "batch loss: 0.051854342222213745\n",
      "batch accuracy: 0.98046875\n",
      "doing 180 / 277\n",
      "elapsed time 10239.587451219559\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0518 - accuracy: 0.9805\n",
      "batch loss: 0.05183521285653114\n",
      "batch accuracy: 0.98046875\n",
      "doing 181 / 277\n",
      "elapsed time 10296.196649312973\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0604 - accuracy: 0.9824\n",
      "batch loss: 0.06035853922367096\n",
      "batch accuracy: 0.982421875\n",
      "doing 182 / 277\n",
      "elapsed time 10347.81272816658\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0715 - accuracy: 0.9736\n",
      "batch loss: 0.07148268073797226\n",
      "batch accuracy: 0.9736328125\n",
      "doing 183 / 277\n",
      "elapsed time 10405.061382293701\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0576 - accuracy: 0.9785\n",
      "batch loss: 0.05755390226840973\n",
      "batch accuracy: 0.978515625\n",
      "doing 184 / 277\n",
      "elapsed time 10461.372711896896\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0557 - accuracy: 0.9824\n",
      "batch loss: 0.05565588176250458\n",
      "batch accuracy: 0.982421875\n",
      "doing 185 / 277\n",
      "elapsed time 10515.931692361832\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0685 - accuracy: 0.9736\n",
      "batch loss: 0.06845127791166306\n",
      "batch accuracy: 0.9736328125\n",
      "doing 186 / 277\n",
      "elapsed time 10570.722572565079\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0679 - accuracy: 0.9766\n",
      "batch loss: 0.06793814897537231\n",
      "batch accuracy: 0.9765625\n",
      "doing 187 / 277\n",
      "elapsed time 10626.675950050354\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0479 - accuracy: 0.9844\n",
      "batch loss: 0.04793774336576462\n",
      "batch accuracy: 0.984375\n",
      "doing 188 / 277\n",
      "elapsed time 10678.203241348267\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0798 - accuracy: 0.9775\n",
      "batch loss: 0.07975044846534729\n",
      "batch accuracy: 0.9775390625\n",
      "doing 189 / 277\n",
      "elapsed time 10730.382843255997\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0588 - accuracy: 0.9814\n",
      "batch loss: 0.058817051351070404\n",
      "batch accuracy: 0.9814453125\n",
      "doing 190 / 277\n",
      "elapsed time 10785.041805267334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0647 - accuracy: 0.9785\n",
      "batch loss: 0.064673513174057\n",
      "batch accuracy: 0.978515625\n",
      "doing 191 / 277\n",
      "elapsed time 10837.98215675354\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0772 - accuracy: 0.9697\n",
      "batch loss: 0.07715998589992523\n",
      "batch accuracy: 0.9697265625\n",
      "doing 192 / 277\n",
      "elapsed time 10893.95055603981\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0713 - accuracy: 0.9727\n",
      "batch loss: 0.071258544921875\n",
      "batch accuracy: 0.97265625\n",
      "doing 193 / 277\n",
      "elapsed time 10942.940055847168\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0716 - accuracy: 0.9775\n",
      "batch loss: 0.07155705988407135\n",
      "batch accuracy: 0.9775390625\n",
      "doing 194 / 277\n",
      "elapsed time 10993.93756699562\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0600 - accuracy: 0.9805\n",
      "batch loss: 0.059994760900735855\n",
      "batch accuracy: 0.98046875\n",
      "doing 195 / 277\n",
      "elapsed time 11045.405659914017\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0631 - accuracy: 0.9775\n",
      "batch loss: 0.063055120408535\n",
      "batch accuracy: 0.9775390625\n",
      "doing 196 / 277\n",
      "elapsed time 11098.574792146683\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0723 - accuracy: 0.9775\n",
      "batch loss: 0.07229552417993546\n",
      "batch accuracy: 0.9775390625\n",
      "doing 197 / 277\n",
      "elapsed time 11146.075824975967\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0478 - accuracy: 0.9824\n",
      "batch loss: 0.0478142574429512\n",
      "batch accuracy: 0.982421875\n",
      "doing 198 / 277\n",
      "elapsed time 11197.284764766693\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0533 - accuracy: 0.9834\n",
      "batch loss: 0.05326282978057861\n",
      "batch accuracy: 0.9833984375\n",
      "doing 199 / 277\n",
      "elapsed time 11245.155622959137\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0711 - accuracy: 0.9775\n",
      "batch loss: 0.07110684365034103\n",
      "batch accuracy: 0.9775390625\n",
      "doing 200 / 277\n",
      "elapsed time 11290.96939253807\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0529 - accuracy: 0.9834\n",
      "batch loss: 0.05294761806726456\n",
      "batch accuracy: 0.9833984375\n",
      "doing 201 / 277\n",
      "elapsed time 11337.22539114952\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0488 - accuracy: 0.9844\n",
      "batch loss: 0.04884553700685501\n",
      "batch accuracy: 0.984375\n",
      "doing 202 / 277\n",
      "elapsed time 11382.130873918533\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0396 - accuracy: 0.9883\n",
      "batch loss: 0.039568349719047546\n",
      "batch accuracy: 0.98828125\n",
      "doing 203 / 277\n",
      "elapsed time 11429.018349647522\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0674 - accuracy: 0.9795\n",
      "batch loss: 0.06739407777786255\n",
      "batch accuracy: 0.9794921875\n",
      "doing 204 / 277\n",
      "elapsed time 11474.763245344162\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0483 - accuracy: 0.9834\n",
      "batch loss: 0.04826844111084938\n",
      "batch accuracy: 0.9833984375\n",
      "doing 205 / 277\n",
      "elapsed time 11517.475068569183\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0692 - accuracy: 0.9717\n",
      "batch loss: 0.06923287361860275\n",
      "batch accuracy: 0.9716796875\n",
      "doing 206 / 277\n",
      "elapsed time 11560.825155258179\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0411 - accuracy: 0.9854\n",
      "batch loss: 0.04105670005083084\n",
      "batch accuracy: 0.9853515625\n",
      "doing 207 / 277\n",
      "elapsed time 11607.594414234161\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0572 - accuracy: 0.9766\n",
      "batch loss: 0.0572047233581543\n",
      "batch accuracy: 0.9765625\n",
      "doing 208 / 277\n",
      "elapsed time 11657.649002075195\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0515 - accuracy: 0.9834\n",
      "batch loss: 0.05145570635795593\n",
      "batch accuracy: 0.9833984375\n",
      "doing 209 / 277\n",
      "elapsed time 11700.641909837723\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0549 - accuracy: 0.9795\n",
      "batch loss: 0.054856251925230026\n",
      "batch accuracy: 0.9794921875\n",
      "doing 210 / 277\n",
      "elapsed time 11745.92510676384\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0612 - accuracy: 0.9824\n",
      "batch loss: 0.06117662787437439\n",
      "batch accuracy: 0.982421875\n",
      "doing 211 / 277\n",
      "elapsed time 11789.690846204758\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0432 - accuracy: 0.9863\n",
      "batch loss: 0.04322527348995209\n",
      "batch accuracy: 0.986328125\n",
      "doing 212 / 277\n",
      "elapsed time 11834.126965284348\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0557 - accuracy: 0.9805\n",
      "batch loss: 0.05566157400608063\n",
      "batch accuracy: 0.98046875\n",
      "doing 213 / 277\n",
      "elapsed time 11874.900037527084\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0384 - accuracy: 0.9814\n",
      "batch loss: 0.03839516639709473\n",
      "batch accuracy: 0.9814453125\n",
      "doing 214 / 277\n",
      "elapsed time 11914.848885297775\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0481 - accuracy: 0.9775\n",
      "batch loss: 0.04814017564058304\n",
      "batch accuracy: 0.9775390625\n",
      "doing 215 / 277\n",
      "elapsed time 11954.430732250214\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0539 - accuracy: 0.9814\n",
      "batch loss: 0.05388354882597923\n",
      "batch accuracy: 0.9814453125\n",
      "doing 216 / 277\n",
      "elapsed time 11994.657569646835\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0524 - accuracy: 0.9873\n",
      "batch loss: 0.05241449922323227\n",
      "batch accuracy: 0.9873046875\n",
      "doing 217 / 277\n",
      "elapsed time 12029.307648897171\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0566 - accuracy: 0.9785\n",
      "batch loss: 0.056580960750579834\n",
      "batch accuracy: 0.978515625\n",
      "doing 218 / 277\n",
      "elapsed time 12072.730424404144\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0433 - accuracy: 0.9814\n",
      "batch loss: 0.0432552769780159\n",
      "batch accuracy: 0.9814453125\n",
      "doing 219 / 277\n",
      "elapsed time 12112.932022809982\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0600 - accuracy: 0.9805\n",
      "batch loss: 0.0600208044052124\n",
      "batch accuracy: 0.98046875\n",
      "doing 220 / 277\n",
      "elapsed time 12152.126367330551\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0502 - accuracy: 0.9805\n",
      "batch loss: 0.05016287788748741\n",
      "batch accuracy: 0.98046875\n",
      "doing 221 / 277\n",
      "elapsed time 12192.28382229805\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0717 - accuracy: 0.9775\n",
      "batch loss: 0.07174932956695557\n",
      "batch accuracy: 0.9775390625\n",
      "doing 222 / 277\n",
      "elapsed time 12230.396116733551\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0629 - accuracy: 0.9805\n",
      "batch loss: 0.06289391964673996\n",
      "batch accuracy: 0.98046875\n",
      "doing 223 / 277\n",
      "elapsed time 12268.002313613892\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0570 - accuracy: 0.9844\n",
      "batch loss: 0.05697273835539818\n",
      "batch accuracy: 0.984375\n",
      "doing 224 / 277\n",
      "elapsed time 12305.486287355423\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0739 - accuracy: 0.9707\n",
      "batch loss: 0.07389381527900696\n",
      "batch accuracy: 0.970703125\n",
      "doing 225 / 277\n",
      "elapsed time 12344.617114543915\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0683 - accuracy: 0.9775\n",
      "batch loss: 0.06829726696014404\n",
      "batch accuracy: 0.9775390625\n",
      "doing 226 / 277\n",
      "elapsed time 12387.988029956818\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0683 - accuracy: 0.9766\n",
      "batch loss: 0.06834343075752258\n",
      "batch accuracy: 0.9765625\n",
      "doing 227 / 277\n",
      "elapsed time 12435.347950696945\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0787 - accuracy: 0.9727\n",
      "batch loss: 0.07870365679264069\n",
      "batch accuracy: 0.97265625\n",
      "doing 228 / 277\n",
      "elapsed time 12473.290570497513\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0476 - accuracy: 0.9824\n",
      "batch loss: 0.04758138209581375\n",
      "batch accuracy: 0.982421875\n",
      "doing 229 / 277\n",
      "elapsed time 12521.047276496887\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0803 - accuracy: 0.9727\n",
      "batch loss: 0.08029817044734955\n",
      "batch accuracy: 0.97265625\n",
      "doing 230 / 277\n",
      "elapsed time 12559.037650823593\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0637 - accuracy: 0.9736\n",
      "batch loss: 0.06367756426334381\n",
      "batch accuracy: 0.9736328125\n",
      "doing 231 / 277\n",
      "elapsed time 12602.775094270706\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0686 - accuracy: 0.9795\n",
      "batch loss: 0.06860858201980591\n",
      "batch accuracy: 0.9794921875\n",
      "doing 232 / 277\n",
      "elapsed time 12637.801150798798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0647 - accuracy: 0.9814\n",
      "batch loss: 0.06466174870729446\n",
      "batch accuracy: 0.9814453125\n",
      "doing 233 / 277\n",
      "elapsed time 12675.997372865677\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0541 - accuracy: 0.9805\n",
      "batch loss: 0.054072052240371704\n",
      "batch accuracy: 0.98046875\n",
      "doing 234 / 277\n",
      "elapsed time 12717.170663356781\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0838 - accuracy: 0.9668\n",
      "batch loss: 0.08376141637563705\n",
      "batch accuracy: 0.966796875\n",
      "doing 235 / 277\n",
      "elapsed time 12752.716428756714\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0717 - accuracy: 0.9707\n",
      "batch loss: 0.07167646288871765\n",
      "batch accuracy: 0.970703125\n",
      "doing 236 / 277\n",
      "elapsed time 12794.219781160355\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0570 - accuracy: 0.9766\n",
      "batch loss: 0.05701708793640137\n",
      "batch accuracy: 0.9765625\n",
      "doing 237 / 277\n",
      "elapsed time 12834.496620416641\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0636 - accuracy: 0.9766\n",
      "batch loss: 0.06358859688043594\n",
      "batch accuracy: 0.9765625\n",
      "doing 238 / 277\n",
      "elapsed time 12870.230034351349\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0712 - accuracy: 0.9746\n",
      "batch loss: 0.07117427885532379\n",
      "batch accuracy: 0.974609375\n",
      "doing 239 / 277\n",
      "elapsed time 12910.508351802826\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0535 - accuracy: 0.9824\n",
      "batch loss: 0.05345133692026138\n",
      "batch accuracy: 0.982421875\n",
      "doing 240 / 277\n",
      "elapsed time 12949.709882259369\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0695 - accuracy: 0.9727\n",
      "batch loss: 0.06950262188911438\n",
      "batch accuracy: 0.97265625\n",
      "doing 241 / 277\n",
      "elapsed time 12982.36162352562\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0712 - accuracy: 0.9795\n",
      "batch loss: 0.07115150988101959\n",
      "batch accuracy: 0.9794921875\n",
      "doing 242 / 277\n",
      "elapsed time 13026.349857091904\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0593 - accuracy: 0.9805\n",
      "batch loss: 0.059324074536561966\n",
      "batch accuracy: 0.98046875\n",
      "doing 243 / 277\n",
      "elapsed time 13061.224394321442\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0486 - accuracy: 0.9814\n",
      "batch loss: 0.04859175905585289\n",
      "batch accuracy: 0.9814453125\n",
      "doing 244 / 277\n",
      "elapsed time 13096.571828842163\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0676 - accuracy: 0.9775\n",
      "batch loss: 0.06756007671356201\n",
      "batch accuracy: 0.9775390625\n",
      "doing 245 / 277\n",
      "elapsed time 13131.885286092758\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0565 - accuracy: 0.9834\n",
      "batch loss: 0.0564766488969326\n",
      "batch accuracy: 0.9833984375\n",
      "doing 246 / 277\n",
      "elapsed time 13168.698699235916\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0783 - accuracy: 0.9688\n",
      "batch loss: 0.07825001329183578\n",
      "batch accuracy: 0.96875\n",
      "doing 247 / 277\n",
      "elapsed time 13206.047107696533\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0618 - accuracy: 0.9766\n",
      "batch loss: 0.06184953451156616\n",
      "batch accuracy: 0.9765625\n",
      "doing 248 / 277\n",
      "elapsed time 13244.021097421646\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0619 - accuracy: 0.9805\n",
      "batch loss: 0.06190452724695206\n",
      "batch accuracy: 0.98046875\n",
      "doing 249 / 277\n",
      "elapsed time 13279.822591781616\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0604 - accuracy: 0.9805\n",
      "batch loss: 0.06041592359542847\n",
      "batch accuracy: 0.98046875\n",
      "doing 250 / 277\n",
      "elapsed time 13319.22624206543\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0594 - accuracy: 0.9795\n",
      "batch loss: 0.05944792926311493\n",
      "batch accuracy: 0.9794921875\n",
      "doing 251 / 277\n",
      "elapsed time 13361.57628440857\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0648 - accuracy: 0.9824\n",
      "batch loss: 0.0648057609796524\n",
      "batch accuracy: 0.982421875\n",
      "doing 252 / 277\n",
      "elapsed time 13403.241665840149\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0796 - accuracy: 0.9648\n",
      "batch loss: 0.07963576167821884\n",
      "batch accuracy: 0.96484375\n",
      "doing 253 / 277\n",
      "elapsed time 13437.14781165123\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0720 - accuracy: 0.9746\n",
      "batch loss: 0.07197746634483337\n",
      "batch accuracy: 0.974609375\n",
      "doing 254 / 277\n",
      "elapsed time 13469.74373292923\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0612 - accuracy: 0.9775\n",
      "batch loss: 0.061202745884656906\n",
      "batch accuracy: 0.9775390625\n",
      "doing 255 / 277\n",
      "elapsed time 13502.86787891388\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0630 - accuracy: 0.9756\n",
      "batch loss: 0.06302190572023392\n",
      "batch accuracy: 0.9755859375\n",
      "doing 256 / 277\n",
      "elapsed time 13561.206038713455\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0630 - accuracy: 0.9795\n",
      "batch loss: 0.06300722807645798\n",
      "batch accuracy: 0.9794921875\n",
      "doing 257 / 277\n",
      "elapsed time 13613.158960342407\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0607 - accuracy: 0.9775\n",
      "batch loss: 0.06067276746034622\n",
      "batch accuracy: 0.9775390625\n",
      "doing 258 / 277\n",
      "elapsed time 13667.429248809814\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0670 - accuracy: 0.9736\n",
      "batch loss: 0.06697484850883484\n",
      "batch accuracy: 0.9736328125\n",
      "doing 259 / 277\n",
      "elapsed time 13728.009120464325\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0558 - accuracy: 0.9805\n",
      "batch loss: 0.0557817667722702\n",
      "batch accuracy: 0.98046875\n",
      "doing 260 / 277\n",
      "elapsed time 13778.209768772125\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0401 - accuracy: 0.9883\n",
      "batch loss: 0.040079593658447266\n",
      "batch accuracy: 0.98828125\n",
      "doing 261 / 277\n",
      "elapsed time 13836.237604618073\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0566 - accuracy: 0.9834\n",
      "batch loss: 0.05659390240907669\n",
      "batch accuracy: 0.9833984375\n",
      "doing 262 / 277\n",
      "elapsed time 13895.25490784645\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0623 - accuracy: 0.9785\n",
      "batch loss: 0.06232422590255737\n",
      "batch accuracy: 0.978515625\n",
      "doing 263 / 277\n",
      "elapsed time 13952.728845119476\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0525 - accuracy: 0.9805\n",
      "batch loss: 0.052456919103860855\n",
      "batch accuracy: 0.98046875\n",
      "doing 264 / 277\n",
      "elapsed time 14006.625827550888\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0602 - accuracy: 0.9834\n",
      "batch loss: 0.0601571761071682\n",
      "batch accuracy: 0.9833984375\n",
      "doing 265 / 277\n",
      "elapsed time 14062.096321821213\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0577 - accuracy: 0.9766\n",
      "batch loss: 0.057670898735523224\n",
      "batch accuracy: 0.9765625\n",
      "doing 266 / 277\n",
      "elapsed time 14125.213911533356\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0628 - accuracy: 0.9746\n",
      "batch loss: 0.06276357173919678\n",
      "batch accuracy: 0.974609375\n",
      "doing 267 / 277\n",
      "elapsed time 14171.511826515198\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0457 - accuracy: 0.9863\n",
      "batch loss: 0.04565700143575668\n",
      "batch accuracy: 0.986328125\n",
      "doing 268 / 277\n",
      "elapsed time 14226.182261705399\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0586 - accuracy: 0.9834\n",
      "batch loss: 0.05856183171272278\n",
      "batch accuracy: 0.9833984375\n",
      "doing 269 / 277\n",
      "elapsed time 14299.47419333458\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0348 - accuracy: 0.9902\n",
      "batch loss: 0.034818995743989944\n",
      "batch accuracy: 0.990234375\n",
      "doing 270 / 277\n",
      "elapsed time 14367.178962230682\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0531 - accuracy: 0.9873\n",
      "batch loss: 0.0531158447265625\n",
      "batch accuracy: 0.9873046875\n",
      "doing 271 / 277\n",
      "elapsed time 14440.81504535675\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0523 - accuracy: 0.9863\n",
      "batch loss: 0.05231630802154541\n",
      "batch accuracy: 0.986328125\n",
      "doing 272 / 277\n",
      "elapsed time 14511.664719343185\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0706 - accuracy: 0.9746\n",
      "batch loss: 0.07060949504375458\n",
      "batch accuracy: 0.974609375\n",
      "doing 273 / 277\n",
      "elapsed time 14582.65914273262\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0524 - accuracy: 0.9814\n",
      "batch loss: 0.052391037344932556\n",
      "batch accuracy: 0.9814453125\n",
      "doing 274 / 277\n",
      "elapsed time 14652.778276205063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0542 - accuracy: 0.9814\n",
      "batch loss: 0.054182231426239014\n",
      "batch accuracy: 0.9814453125\n",
      "doing 275 / 277\n",
      "elapsed time 14729.670491218567\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0385 - accuracy: 0.9883\n",
      "batch loss: 0.038489628583192825\n",
      "batch accuracy: 0.98828125\n",
      "doing 276 / 277\n",
      "elapsed time 14771.800425767899\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.0504 - accuracy: 0.9835\n",
      "batch loss: 0.05040338635444641\n",
      "batch accuracy: 0.9835466146469116\n",
      "Train loss 0.06065644855049543\n",
      "Train accuracy 0.9790308824084726\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 0.1680 - accuracy: 0.9469\n",
      "Validation loss: 0.16801276803016663\n",
      "Validation accuracy: 0.9468888640403748\n",
      "==================================================\n",
      "8 / 10\n",
      "doing 0 / 277\n",
      "elapsed time 55.5587956905365\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0634 - accuracy: 0.9795\n",
      "batch loss: 0.06337151676416397\n",
      "batch accuracy: 0.9794921875\n",
      "doing 1 / 277\n",
      "elapsed time 110.34800887107849\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0351 - accuracy: 0.9883\n",
      "batch loss: 0.03511327877640724\n",
      "batch accuracy: 0.98828125\n",
      "doing 2 / 277\n",
      "elapsed time 171.48280668258667\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0432 - accuracy: 0.9814\n",
      "batch loss: 0.04316532984375954\n",
      "batch accuracy: 0.9814453125\n",
      "doing 3 / 277\n",
      "elapsed time 242.2960388660431\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0347 - accuracy: 0.9854\n",
      "batch loss: 0.03471801429986954\n",
      "batch accuracy: 0.9853515625\n",
      "doing 4 / 277\n",
      "elapsed time 317.68173146247864\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0421 - accuracy: 0.9844\n",
      "batch loss: 0.0420711413025856\n",
      "batch accuracy: 0.984375\n",
      "doing 5 / 277\n",
      "elapsed time 382.51244831085205\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0363 - accuracy: 0.9854\n",
      "batch loss: 0.03625071048736572\n",
      "batch accuracy: 0.9853515625\n",
      "doing 6 / 277\n",
      "elapsed time 450.7329204082489\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0580 - accuracy: 0.9795\n",
      "batch loss: 0.05799444019794464\n",
      "batch accuracy: 0.9794921875\n",
      "doing 7 / 277\n",
      "elapsed time 513.1550104618073\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0357 - accuracy: 0.9902\n",
      "batch loss: 0.035691410303115845\n",
      "batch accuracy: 0.990234375\n",
      "doing 8 / 277\n",
      "elapsed time 573.2333798408508\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0368 - accuracy: 0.9863\n",
      "batch loss: 0.03682372346520424\n",
      "batch accuracy: 0.986328125\n",
      "doing 9 / 277\n",
      "elapsed time 650.4661123752594\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0340 - accuracy: 0.9893\n",
      "batch loss: 0.034000154584646225\n",
      "batch accuracy: 0.9892578125\n",
      "doing 10 / 277\n",
      "elapsed time 724.1311860084534\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0542 - accuracy: 0.9795\n",
      "batch loss: 0.05423804372549057\n",
      "batch accuracy: 0.9794921875\n",
      "doing 11 / 277\n",
      "elapsed time 792.0325529575348\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0649 - accuracy: 0.9785\n",
      "batch loss: 0.0648777112364769\n",
      "batch accuracy: 0.978515625\n",
      "doing 12 / 277\n",
      "elapsed time 858.7484376430511\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0572 - accuracy: 0.9795\n",
      "batch loss: 0.05720235034823418\n",
      "batch accuracy: 0.9794921875\n",
      "doing 13 / 277\n",
      "elapsed time 922.4892718791962\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0425 - accuracy: 0.9824\n",
      "batch loss: 0.04245400056242943\n",
      "batch accuracy: 0.982421875\n",
      "doing 14 / 277\n",
      "elapsed time 998.6209132671356\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0298 - accuracy: 0.9902\n",
      "batch loss: 0.029819294810295105\n",
      "batch accuracy: 0.990234375\n",
      "doing 15 / 277\n",
      "elapsed time 1073.72638630867\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0314 - accuracy: 0.9902\n",
      "batch loss: 0.03139425814151764\n",
      "batch accuracy: 0.990234375\n",
      "doing 16 / 277\n",
      "elapsed time 1149.2056231498718\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0488 - accuracy: 0.9805\n",
      "batch loss: 0.04884077608585358\n",
      "batch accuracy: 0.98046875\n",
      "doing 17 / 277\n",
      "elapsed time 1223.0968787670135\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0581 - accuracy: 0.9805\n",
      "batch loss: 0.05807022750377655\n",
      "batch accuracy: 0.98046875\n",
      "doing 18 / 277\n",
      "elapsed time 1294.8763802051544\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0444 - accuracy: 0.9805\n",
      "batch loss: 0.04437790811061859\n",
      "batch accuracy: 0.98046875\n",
      "doing 19 / 277\n",
      "elapsed time 1367.1118428707123\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0574 - accuracy: 0.9775\n",
      "batch loss: 0.0573853924870491\n",
      "batch accuracy: 0.9775390625\n",
      "doing 20 / 277\n",
      "elapsed time 1439.439829826355\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0433 - accuracy: 0.9873\n",
      "batch loss: 0.043315447866916656\n",
      "batch accuracy: 0.9873046875\n",
      "doing 21 / 277\n",
      "elapsed time 1507.715648174286\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0566 - accuracy: 0.9814\n",
      "batch loss: 0.05660640448331833\n",
      "batch accuracy: 0.9814453125\n",
      "doing 22 / 277\n",
      "elapsed time 1577.2206559181213\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0404 - accuracy: 0.9873\n",
      "batch loss: 0.04037026688456535\n",
      "batch accuracy: 0.9873046875\n",
      "doing 23 / 277\n",
      "elapsed time 1642.768919467926\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0466 - accuracy: 0.9805\n",
      "batch loss: 0.04660361632704735\n",
      "batch accuracy: 0.98046875\n",
      "doing 24 / 277\n",
      "elapsed time 1705.2809419631958\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0840 - accuracy: 0.9697\n",
      "batch loss: 0.08399106562137604\n",
      "batch accuracy: 0.9697265625\n",
      "doing 25 / 277\n",
      "elapsed time 1780.4678852558136\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0478 - accuracy: 0.9834\n",
      "batch loss: 0.04775024950504303\n",
      "batch accuracy: 0.9833984375\n",
      "doing 26 / 277\n",
      "elapsed time 1857.7294104099274\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0526 - accuracy: 0.9814\n",
      "batch loss: 0.05257989466190338\n",
      "batch accuracy: 0.9814453125\n",
      "doing 27 / 277\n",
      "elapsed time 1937.615613937378\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0990 - accuracy: 0.9648\n",
      "batch loss: 0.09899003803730011\n",
      "batch accuracy: 0.96484375\n",
      "doing 28 / 277\n",
      "elapsed time 2019.2746460437775\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1254 - accuracy: 0.9648\n",
      "batch loss: 0.1253643035888672\n",
      "batch accuracy: 0.96484375\n",
      "doing 29 / 277\n",
      "elapsed time 2099.363532781601\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2074 - accuracy: 0.9512\n",
      "batch loss: 0.20735040307044983\n",
      "batch accuracy: 0.951171875\n",
      "doing 30 / 277\n",
      "elapsed time 2176.7940793037415\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0977 - accuracy: 0.9629\n",
      "batch loss: 0.09772180020809174\n",
      "batch accuracy: 0.962890625\n",
      "doing 31 / 277\n",
      "elapsed time 2243.139139652252\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1220 - accuracy: 0.9580\n",
      "batch loss: 0.12195847928524017\n",
      "batch accuracy: 0.9580078125\n",
      "doing 32 / 277\n",
      "elapsed time 2310.425856590271\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1146 - accuracy: 0.9551\n",
      "batch loss: 0.11455702781677246\n",
      "batch accuracy: 0.955078125\n",
      "doing 33 / 277\n",
      "elapsed time 2381.7500982284546\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1055 - accuracy: 0.9570\n",
      "batch loss: 0.10546115785837173\n",
      "batch accuracy: 0.95703125\n",
      "doing 34 / 277\n",
      "elapsed time 2450.4216859340668\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0958 - accuracy: 0.9688\n",
      "batch loss: 0.09575214982032776\n",
      "batch accuracy: 0.96875\n",
      "doing 35 / 277\n",
      "elapsed time 2513.908673286438\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0928 - accuracy: 0.9658\n",
      "batch loss: 0.09281475841999054\n",
      "batch accuracy: 0.9658203125\n",
      "doing 36 / 277\n",
      "elapsed time 2588.4179406166077\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0835 - accuracy: 0.9658\n",
      "batch loss: 0.083492211997509\n",
      "batch accuracy: 0.9658203125\n",
      "doing 37 / 277\n",
      "elapsed time 2655.501277446747\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0853 - accuracy: 0.9678\n",
      "batch loss: 0.08526531606912613\n",
      "batch accuracy: 0.9677734375\n",
      "doing 38 / 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 2724.1099820137024\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0695 - accuracy: 0.9795\n",
      "batch loss: 0.0694962665438652\n",
      "batch accuracy: 0.9794921875\n",
      "doing 39 / 277\n",
      "elapsed time 2796.5089631080627\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0635 - accuracy: 0.9766\n",
      "batch loss: 0.06348417699337006\n",
      "batch accuracy: 0.9765625\n",
      "doing 40 / 277\n",
      "elapsed time 2870.5986387729645\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1043 - accuracy: 0.9629\n",
      "batch loss: 0.10428968071937561\n",
      "batch accuracy: 0.962890625\n",
      "doing 41 / 277\n",
      "elapsed time 2942.379101753235\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0878 - accuracy: 0.9766\n",
      "batch loss: 0.0877622589468956\n",
      "batch accuracy: 0.9765625\n",
      "doing 42 / 277\n",
      "elapsed time 3006.4605860710144\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0797 - accuracy: 0.9766\n",
      "batch loss: 0.07973938435316086\n",
      "batch accuracy: 0.9765625\n",
      "doing 43 / 277\n",
      "elapsed time 3079.965037584305\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0728 - accuracy: 0.9746\n",
      "batch loss: 0.07275459170341492\n",
      "batch accuracy: 0.974609375\n",
      "doing 44 / 277\n",
      "elapsed time 3149.773706674576\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0880 - accuracy: 0.9688\n",
      "batch loss: 0.08804208785295486\n",
      "batch accuracy: 0.96875\n",
      "doing 45 / 277\n",
      "elapsed time 3210.993531703949\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0707 - accuracy: 0.9717\n",
      "batch loss: 0.07067307829856873\n",
      "batch accuracy: 0.9716796875\n",
      "doing 46 / 277\n",
      "elapsed time 3277.1083748340607\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0637 - accuracy: 0.9795\n",
      "batch loss: 0.06371938437223434\n",
      "batch accuracy: 0.9794921875\n",
      "doing 47 / 277\n",
      "elapsed time 3347.6598970890045\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0864 - accuracy: 0.9727\n",
      "batch loss: 0.08639629185199738\n",
      "batch accuracy: 0.97265625\n",
      "doing 48 / 277\n",
      "elapsed time 3416.955190181732\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0691 - accuracy: 0.9736\n",
      "batch loss: 0.06905284523963928\n",
      "batch accuracy: 0.9736328125\n",
      "doing 49 / 277\n",
      "elapsed time 3486.7641139030457\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0611 - accuracy: 0.9814\n",
      "batch loss: 0.06108962744474411\n",
      "batch accuracy: 0.9814453125\n",
      "doing 50 / 277\n",
      "elapsed time 3549.621188879013\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0779 - accuracy: 0.9766\n",
      "batch loss: 0.0779288187623024\n",
      "batch accuracy: 0.9765625\n",
      "doing 51 / 277\n",
      "elapsed time 3622.1739094257355\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0792 - accuracy: 0.9668\n",
      "batch loss: 0.07922200113534927\n",
      "batch accuracy: 0.966796875\n",
      "doing 52 / 277\n",
      "elapsed time 3692.330411195755\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0660 - accuracy: 0.9785\n",
      "batch loss: 0.06595213711261749\n",
      "batch accuracy: 0.978515625\n",
      "doing 53 / 277\n",
      "elapsed time 3763.128664255142\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0715 - accuracy: 0.9756\n",
      "batch loss: 0.07145312428474426\n",
      "batch accuracy: 0.9755859375\n",
      "doing 54 / 277\n",
      "elapsed time 3822.974885702133\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0565 - accuracy: 0.9775\n",
      "batch loss: 0.05649318918585777\n",
      "batch accuracy: 0.9775390625\n",
      "doing 55 / 277\n",
      "elapsed time 3887.2227494716644\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0484 - accuracy: 0.9854\n",
      "batch loss: 0.04838695377111435\n",
      "batch accuracy: 0.9853515625\n",
      "doing 56 / 277\n",
      "elapsed time 3943.043774366379\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0509 - accuracy: 0.9824\n",
      "batch loss: 0.050928592681884766\n",
      "batch accuracy: 0.982421875\n",
      "doing 57 / 277\n",
      "elapsed time 4012.389704465866\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0646 - accuracy: 0.9805\n",
      "batch loss: 0.06456267833709717\n",
      "batch accuracy: 0.98046875\n",
      "doing 58 / 277\n",
      "elapsed time 4069.9450132846832\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0438 - accuracy: 0.9863\n",
      "batch loss: 0.04383371025323868\n",
      "batch accuracy: 0.986328125\n",
      "doing 59 / 277\n",
      "elapsed time 4138.033090353012\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0599 - accuracy: 0.9756\n",
      "batch loss: 0.059878796339035034\n",
      "batch accuracy: 0.9755859375\n",
      "doing 60 / 277\n",
      "elapsed time 4207.992550611496\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0479 - accuracy: 0.9805\n",
      "batch loss: 0.04787291958928108\n",
      "batch accuracy: 0.98046875\n",
      "doing 61 / 277\n",
      "elapsed time 4271.598651170731\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0497 - accuracy: 0.9844\n",
      "batch loss: 0.04971126839518547\n",
      "batch accuracy: 0.984375\n",
      "doing 62 / 277\n",
      "elapsed time 4333.813410758972\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0448 - accuracy: 0.9844\n",
      "batch loss: 0.04484054818749428\n",
      "batch accuracy: 0.984375\n",
      "doing 63 / 277\n",
      "elapsed time 4407.314575910568\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0552 - accuracy: 0.9766\n",
      "batch loss: 0.0551946684718132\n",
      "batch accuracy: 0.9765625\n",
      "doing 64 / 277\n",
      "elapsed time 4480.037455797195\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0746 - accuracy: 0.9688\n",
      "batch loss: 0.07459190487861633\n",
      "batch accuracy: 0.96875\n",
      "doing 65 / 277\n",
      "elapsed time 4547.107350349426\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0444 - accuracy: 0.9824\n",
      "batch loss: 0.04435873404145241\n",
      "batch accuracy: 0.982421875\n",
      "doing 66 / 277\n",
      "elapsed time 4609.505967378616\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0627 - accuracy: 0.9844\n",
      "batch loss: 0.06272988766431808\n",
      "batch accuracy: 0.984375\n",
      "doing 67 / 277\n",
      "elapsed time 4669.019680261612\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0694 - accuracy: 0.9746\n",
      "batch loss: 0.06940022110939026\n",
      "batch accuracy: 0.974609375\n",
      "doing 68 / 277\n",
      "elapsed time 4735.303263664246\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0502 - accuracy: 0.9814\n",
      "batch loss: 0.050239913165569305\n",
      "batch accuracy: 0.9814453125\n",
      "doing 69 / 277\n",
      "elapsed time 4801.895544052124\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0575 - accuracy: 0.9785\n",
      "batch loss: 0.05751701444387436\n",
      "batch accuracy: 0.978515625\n",
      "doing 70 / 277\n",
      "elapsed time 4873.914015054703\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0647 - accuracy: 0.9805\n",
      "batch loss: 0.06466341763734818\n",
      "batch accuracy: 0.98046875\n",
      "doing 71 / 277\n",
      "elapsed time 4937.625325918198\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0684 - accuracy: 0.9785\n",
      "batch loss: 0.06844408810138702\n",
      "batch accuracy: 0.978515625\n",
      "doing 72 / 277\n",
      "elapsed time 5000.4746305942535\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0444 - accuracy: 0.9854\n",
      "batch loss: 0.04443776234984398\n",
      "batch accuracy: 0.9853515625\n",
      "doing 73 / 277\n",
      "elapsed time 5064.235379457474\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0378 - accuracy: 0.9844\n",
      "batch loss: 0.037767842411994934\n",
      "batch accuracy: 0.984375\n",
      "doing 74 / 277\n",
      "elapsed time 5134.126313924789\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0562 - accuracy: 0.9766\n",
      "batch loss: 0.05615324527025223\n",
      "batch accuracy: 0.9765625\n",
      "doing 75 / 277\n",
      "elapsed time 5194.985507965088\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0561 - accuracy: 0.9805\n",
      "batch loss: 0.05605560541152954\n",
      "batch accuracy: 0.98046875\n",
      "doing 76 / 277\n",
      "elapsed time 5264.075858831406\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0622 - accuracy: 0.9805\n",
      "batch loss: 0.06219583377242088\n",
      "batch accuracy: 0.98046875\n",
      "doing 77 / 277\n",
      "elapsed time 5336.6058802604675\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0608 - accuracy: 0.9775\n",
      "batch loss: 0.060799337923526764\n",
      "batch accuracy: 0.9775390625\n",
      "doing 78 / 277\n",
      "elapsed time 5408.020626068115\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0694 - accuracy: 0.9688\n",
      "batch loss: 0.06937350332736969\n",
      "batch accuracy: 0.96875\n",
      "doing 79 / 277\n",
      "elapsed time 5476.020097017288\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0483 - accuracy: 0.9814\n",
      "batch loss: 0.04830121994018555\n",
      "batch accuracy: 0.9814453125\n",
      "doing 80 / 277\n",
      "elapsed time 5541.178488969803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0448 - accuracy: 0.9814\n",
      "batch loss: 0.04478483274579048\n",
      "batch accuracy: 0.9814453125\n",
      "doing 81 / 277\n",
      "elapsed time 5599.984668731689\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0577 - accuracy: 0.9785\n",
      "batch loss: 0.057739321142435074\n",
      "batch accuracy: 0.978515625\n",
      "doing 82 / 277\n",
      "elapsed time 5659.904582977295\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0459 - accuracy: 0.9883\n",
      "batch loss: 0.04591459780931473\n",
      "batch accuracy: 0.98828125\n",
      "doing 83 / 277\n",
      "elapsed time 5727.338052988052\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0500 - accuracy: 0.9844\n",
      "batch loss: 0.05002499744296074\n",
      "batch accuracy: 0.984375\n",
      "doing 84 / 277\n",
      "elapsed time 5789.1415956020355\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0491 - accuracy: 0.9814\n",
      "batch loss: 0.049100521951913834\n",
      "batch accuracy: 0.9814453125\n",
      "doing 85 / 277\n",
      "elapsed time 5852.538169622421\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0504 - accuracy: 0.9863\n",
      "batch loss: 0.05036936700344086\n",
      "batch accuracy: 0.986328125\n",
      "doing 86 / 277\n",
      "elapsed time 5911.530203342438\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0469 - accuracy: 0.9863\n",
      "batch loss: 0.04685194045305252\n",
      "batch accuracy: 0.986328125\n",
      "doing 87 / 277\n",
      "elapsed time 5980.682410001755\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0508 - accuracy: 0.9844\n",
      "batch loss: 0.05077078193426132\n",
      "batch accuracy: 0.984375\n",
      "doing 88 / 277\n",
      "elapsed time 6043.036578178406\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0545 - accuracy: 0.9795\n",
      "batch loss: 0.05452192202210426\n",
      "batch accuracy: 0.9794921875\n",
      "doing 89 / 277\n",
      "elapsed time 6108.479872941971\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0389 - accuracy: 0.9863\n",
      "batch loss: 0.038879524916410446\n",
      "batch accuracy: 0.986328125\n",
      "doing 90 / 277\n",
      "elapsed time 6192.344214439392\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0386 - accuracy: 0.9863\n",
      "batch loss: 0.03857157379388809\n",
      "batch accuracy: 0.986328125\n",
      "doing 91 / 277\n",
      "elapsed time 6274.881727218628\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0551 - accuracy: 0.9766\n",
      "batch loss: 0.0551285520195961\n",
      "batch accuracy: 0.9765625\n",
      "doing 92 / 277\n",
      "elapsed time 6362.4964916706085\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0585 - accuracy: 0.9824\n",
      "batch loss: 0.0584566667675972\n",
      "batch accuracy: 0.982421875\n",
      "doing 93 / 277\n",
      "elapsed time 6444.611943721771\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0588 - accuracy: 0.9795\n",
      "batch loss: 0.05883870646357536\n",
      "batch accuracy: 0.9794921875\n",
      "doing 94 / 277\n",
      "elapsed time 6530.837159872055\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0498 - accuracy: 0.9873\n",
      "batch loss: 0.049821410328149796\n",
      "batch accuracy: 0.9873046875\n",
      "doing 95 / 277\n",
      "elapsed time 6615.833910703659\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0623 - accuracy: 0.9756\n",
      "batch loss: 0.06227467581629753\n",
      "batch accuracy: 0.9755859375\n",
      "doing 96 / 277\n",
      "elapsed time 6695.728943347931\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0428 - accuracy: 0.9844\n",
      "batch loss: 0.042796194553375244\n",
      "batch accuracy: 0.984375\n",
      "doing 97 / 277\n",
      "elapsed time 6778.639607429504\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0580 - accuracy: 0.9814\n",
      "batch loss: 0.05801240727305412\n",
      "batch accuracy: 0.9814453125\n",
      "doing 98 / 277\n",
      "elapsed time 6863.68386387825\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0465 - accuracy: 0.9873\n",
      "batch loss: 0.046547356992959976\n",
      "batch accuracy: 0.9873046875\n",
      "doing 99 / 277\n",
      "elapsed time 6946.809488534927\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0502 - accuracy: 0.9785\n",
      "batch loss: 0.0501554049551487\n",
      "batch accuracy: 0.978515625\n",
      "doing 100 / 277\n",
      "elapsed time 7033.177245855331\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0543 - accuracy: 0.9785\n",
      "batch loss: 0.05425383523106575\n",
      "batch accuracy: 0.978515625\n",
      "doing 101 / 277\n",
      "elapsed time 7113.469674825668\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0448 - accuracy: 0.9844\n",
      "batch loss: 0.04475053399801254\n",
      "batch accuracy: 0.984375\n",
      "doing 102 / 277\n",
      "elapsed time 7198.4686806201935\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0413 - accuracy: 0.9824\n",
      "batch loss: 0.04129153490066528\n",
      "batch accuracy: 0.982421875\n",
      "doing 103 / 277\n",
      "elapsed time 7282.835380792618\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0597 - accuracy: 0.9805\n",
      "batch loss: 0.05974029004573822\n",
      "batch accuracy: 0.98046875\n",
      "doing 104 / 277\n",
      "elapsed time 7366.78848862648\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0602 - accuracy: 0.9805\n",
      "batch loss: 0.06022128835320473\n",
      "batch accuracy: 0.98046875\n",
      "doing 105 / 277\n",
      "elapsed time 7451.94184923172\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0482 - accuracy: 0.9873\n",
      "batch loss: 0.04815271496772766\n",
      "batch accuracy: 0.9873046875\n",
      "doing 106 / 277\n",
      "elapsed time 7537.470219135284\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0509 - accuracy: 0.9814\n",
      "batch loss: 0.05091923475265503\n",
      "batch accuracy: 0.9814453125\n",
      "doing 107 / 277\n",
      "elapsed time 7616.642908811569\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0429 - accuracy: 0.9873\n",
      "batch loss: 0.04288244992494583\n",
      "batch accuracy: 0.9873046875\n",
      "doing 108 / 277\n",
      "elapsed time 7693.479207038879\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0472 - accuracy: 0.9854\n",
      "batch loss: 0.04715520143508911\n",
      "batch accuracy: 0.9853515625\n",
      "doing 109 / 277\n",
      "elapsed time 7777.598432064056\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0456 - accuracy: 0.9863\n",
      "batch loss: 0.045624829828739166\n",
      "batch accuracy: 0.986328125\n",
      "doing 110 / 277\n",
      "elapsed time 7878.577021360397\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0366 - accuracy: 0.9883\n",
      "batch loss: 0.03662560507655144\n",
      "batch accuracy: 0.98828125\n",
      "doing 111 / 277\n",
      "elapsed time 7985.694015979767\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0636 - accuracy: 0.9766\n",
      "batch loss: 0.0635853111743927\n",
      "batch accuracy: 0.9765625\n",
      "doing 112 / 277\n",
      "elapsed time 8098.5009207725525\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0590 - accuracy: 0.9824\n",
      "batch loss: 0.059034936130046844\n",
      "batch accuracy: 0.982421875\n",
      "doing 113 / 277\n",
      "elapsed time 8208.469990491867\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0392 - accuracy: 0.9863\n",
      "batch loss: 0.03916557878255844\n",
      "batch accuracy: 0.986328125\n",
      "doing 114 / 277\n",
      "elapsed time 8320.99228644371\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0555 - accuracy: 0.9834\n",
      "batch loss: 0.055516019463539124\n",
      "batch accuracy: 0.9833984375\n",
      "doing 115 / 277\n",
      "elapsed time 8430.97706770897\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0446 - accuracy: 0.9863\n",
      "batch loss: 0.04463876783847809\n",
      "batch accuracy: 0.986328125\n",
      "doing 116 / 277\n",
      "elapsed time 8560.626555204391\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0659 - accuracy: 0.9814\n",
      "batch loss: 0.06590595096349716\n",
      "batch accuracy: 0.9814453125\n",
      "doing 117 / 277\n",
      "elapsed time 8688.385256290436\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0614 - accuracy: 0.9785\n",
      "batch loss: 0.06143386662006378\n",
      "batch accuracy: 0.978515625\n",
      "doing 118 / 277\n",
      "elapsed time 8811.094863414764\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0448 - accuracy: 0.9873\n",
      "batch loss: 0.04482646659016609\n",
      "batch accuracy: 0.9873046875\n",
      "doing 119 / 277\n",
      "elapsed time 8934.990677833557\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0465 - accuracy: 0.9824\n",
      "batch loss: 0.046452563256025314\n",
      "batch accuracy: 0.982421875\n",
      "doing 120 / 277\n",
      "elapsed time 9067.315536499023\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0405 - accuracy: 0.9883\n",
      "batch loss: 0.0405195988714695\n",
      "batch accuracy: 0.98828125\n",
      "doing 121 / 277\n",
      "elapsed time 9198.370822906494\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0416 - accuracy: 0.9893\n",
      "batch loss: 0.04162806272506714\n",
      "batch accuracy: 0.9892578125\n",
      "doing 122 / 277\n",
      "elapsed time 9328.69966340065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0387 - accuracy: 0.9863\n",
      "batch loss: 0.03874877467751503\n",
      "batch accuracy: 0.986328125\n",
      "doing 123 / 277\n",
      "elapsed time 9458.054099321365\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0337 - accuracy: 0.9902\n",
      "batch loss: 0.03372668847441673\n",
      "batch accuracy: 0.990234375\n",
      "doing 124 / 277\n",
      "elapsed time 9586.943447351456\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0496 - accuracy: 0.9834\n",
      "batch loss: 0.04964982345700264\n",
      "batch accuracy: 0.9833984375\n",
      "doing 125 / 277\n",
      "elapsed time 9712.311794757843\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0377 - accuracy: 0.9873\n",
      "batch loss: 0.03765193372964859\n",
      "batch accuracy: 0.9873046875\n",
      "doing 126 / 277\n",
      "elapsed time 9837.217218875885\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0368 - accuracy: 0.9902\n",
      "batch loss: 0.03677462786436081\n",
      "batch accuracy: 0.990234375\n",
      "doing 127 / 277\n",
      "elapsed time 9956.904106378555\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0638 - accuracy: 0.9785\n",
      "batch loss: 0.06378518044948578\n",
      "batch accuracy: 0.978515625\n",
      "doing 128 / 277\n",
      "elapsed time 10079.626253843307\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0691 - accuracy: 0.9795\n",
      "batch loss: 0.06905772536993027\n",
      "batch accuracy: 0.9794921875\n",
      "doing 129 / 277\n",
      "elapsed time 10203.389980316162\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0514 - accuracy: 0.9883\n",
      "batch loss: 0.05141936242580414\n",
      "batch accuracy: 0.98828125\n",
      "doing 130 / 277\n",
      "elapsed time 10322.680207252502\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0563 - accuracy: 0.9824\n",
      "batch loss: 0.05634992569684982\n",
      "batch accuracy: 0.982421875\n",
      "doing 131 / 277\n",
      "elapsed time 10443.121784210205\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0527 - accuracy: 0.9795\n",
      "batch loss: 0.05266014114022255\n",
      "batch accuracy: 0.9794921875\n",
      "doing 132 / 277\n",
      "elapsed time 10566.194568395615\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0416 - accuracy: 0.9863\n",
      "batch loss: 0.04155706241726875\n",
      "batch accuracy: 0.986328125\n",
      "doing 133 / 277\n",
      "elapsed time 10688.694150686264\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0253 - accuracy: 0.9961\n",
      "batch loss: 0.02531561627984047\n",
      "batch accuracy: 0.99609375\n",
      "doing 134 / 277\n",
      "elapsed time 10812.554233551025\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0427 - accuracy: 0.9873\n",
      "batch loss: 0.042706072330474854\n",
      "batch accuracy: 0.9873046875\n",
      "doing 135 / 277\n",
      "elapsed time 10934.718724489212\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0466 - accuracy: 0.9854\n",
      "batch loss: 0.04658947139978409\n",
      "batch accuracy: 0.9853515625\n",
      "doing 136 / 277\n",
      "elapsed time 11055.672413825989\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0460 - accuracy: 0.9834\n",
      "batch loss: 0.045993659645318985\n",
      "batch accuracy: 0.9833984375\n",
      "doing 137 / 277\n",
      "elapsed time 11177.466724395752\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0404 - accuracy: 0.9844\n",
      "batch loss: 0.04037820175290108\n",
      "batch accuracy: 0.984375\n",
      "doing 138 / 277\n",
      "elapsed time 11294.72393655777\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0420 - accuracy: 0.9854\n",
      "batch loss: 0.04203564301133156\n",
      "batch accuracy: 0.9853515625\n",
      "doing 139 / 277\n",
      "elapsed time 11412.411430358887\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0399 - accuracy: 0.9873\n",
      "batch loss: 0.039900630712509155\n",
      "batch accuracy: 0.9873046875\n",
      "doing 140 / 277\n",
      "elapsed time 11532.30354809761\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0358 - accuracy: 0.9844\n",
      "batch loss: 0.03582914173603058\n",
      "batch accuracy: 0.984375\n",
      "doing 141 / 277\n",
      "elapsed time 11650.677366018295\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0379 - accuracy: 0.9863\n",
      "batch loss: 0.03787851706147194\n",
      "batch accuracy: 0.986328125\n",
      "doing 142 / 277\n",
      "elapsed time 11766.155987977982\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0532 - accuracy: 0.9873\n",
      "batch loss: 0.05318272113800049\n",
      "batch accuracy: 0.9873046875\n",
      "doing 143 / 277\n",
      "elapsed time 11883.757864713669\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0444 - accuracy: 0.9785\n",
      "batch loss: 0.04437102749943733\n",
      "batch accuracy: 0.978515625\n",
      "doing 144 / 277\n",
      "elapsed time 11998.182729244232\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0399 - accuracy: 0.9902\n",
      "batch loss: 0.03985172137618065\n",
      "batch accuracy: 0.990234375\n",
      "doing 145 / 277\n",
      "elapsed time 12114.563781023026\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0541 - accuracy: 0.9824\n",
      "batch loss: 0.05411345511674881\n",
      "batch accuracy: 0.982421875\n",
      "doing 146 / 277\n",
      "elapsed time 12233.871072292328\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0397 - accuracy: 0.9902\n",
      "batch loss: 0.03965179994702339\n",
      "batch accuracy: 0.990234375\n",
      "doing 147 / 277\n",
      "elapsed time 12352.287014245987\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0347 - accuracy: 0.9873\n",
      "batch loss: 0.03466307371854782\n",
      "batch accuracy: 0.9873046875\n",
      "doing 148 / 277\n",
      "elapsed time 12466.326582193375\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0515 - accuracy: 0.9785\n",
      "batch loss: 0.051508378237485886\n",
      "batch accuracy: 0.978515625\n",
      "doing 149 / 277\n",
      "elapsed time 12577.904461145401\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0439 - accuracy: 0.9844\n",
      "batch loss: 0.043876320123672485\n",
      "batch accuracy: 0.984375\n",
      "doing 150 / 277\n",
      "elapsed time 12686.736915826797\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0450 - accuracy: 0.9854\n",
      "batch loss: 0.04497949406504631\n",
      "batch accuracy: 0.9853515625\n",
      "doing 151 / 277\n",
      "elapsed time 12803.315363407135\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0362 - accuracy: 0.9902\n",
      "batch loss: 0.03616878762841225\n",
      "batch accuracy: 0.990234375\n",
      "doing 152 / 277\n",
      "elapsed time 12914.08519935608\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0536 - accuracy: 0.9824\n",
      "batch loss: 0.053600043058395386\n",
      "batch accuracy: 0.982421875\n",
      "doing 153 / 277\n",
      "elapsed time 13023.650379180908\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0427 - accuracy: 0.9844\n",
      "batch loss: 0.042687758803367615\n",
      "batch accuracy: 0.984375\n",
      "doing 154 / 277\n",
      "elapsed time 13136.897238254547\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0536 - accuracy: 0.9824\n",
      "batch loss: 0.0536491796374321\n",
      "batch accuracy: 0.982421875\n",
      "doing 155 / 277\n",
      "elapsed time 13247.215636014938\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0452 - accuracy: 0.9854\n",
      "batch loss: 0.0451715886592865\n",
      "batch accuracy: 0.9853515625\n",
      "doing 156 / 277\n",
      "elapsed time 13360.286882638931\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0383 - accuracy: 0.9834\n",
      "batch loss: 0.03831227868795395\n",
      "batch accuracy: 0.9833984375\n",
      "doing 157 / 277\n",
      "elapsed time 13473.092465400696\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0453 - accuracy: 0.9814\n",
      "batch loss: 0.04531001299619675\n",
      "batch accuracy: 0.9814453125\n",
      "doing 158 / 277\n",
      "elapsed time 13581.746233940125\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0399 - accuracy: 0.9834\n",
      "batch loss: 0.039926204830408096\n",
      "batch accuracy: 0.9833984375\n",
      "doing 159 / 277\n",
      "elapsed time 13692.999180555344\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0463 - accuracy: 0.9824\n",
      "batch loss: 0.04634708911180496\n",
      "batch accuracy: 0.982421875\n",
      "doing 160 / 277\n",
      "elapsed time 13802.193935155869\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0493 - accuracy: 0.9824\n",
      "batch loss: 0.04929668456315994\n",
      "batch accuracy: 0.982421875\n",
      "doing 161 / 277\n",
      "elapsed time 13911.102603435516\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0522 - accuracy: 0.9824\n",
      "batch loss: 0.052205007523298264\n",
      "batch accuracy: 0.982421875\n",
      "doing 162 / 277\n",
      "elapsed time 14013.650390625\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0376 - accuracy: 0.9883\n",
      "batch loss: 0.03756086155772209\n",
      "batch accuracy: 0.98828125\n",
      "doing 163 / 277\n",
      "elapsed time 14119.278025627136\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0440 - accuracy: 0.9824\n",
      "batch loss: 0.04401836171746254\n",
      "batch accuracy: 0.982421875\n",
      "doing 164 / 277\n",
      "elapsed time 14223.125301361084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0476 - accuracy: 0.9824\n",
      "batch loss: 0.04755810648202896\n",
      "batch accuracy: 0.982421875\n",
      "doing 165 / 277\n",
      "elapsed time 14330.516451835632\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0488 - accuracy: 0.9824\n",
      "batch loss: 0.04882103204727173\n",
      "batch accuracy: 0.982421875\n",
      "doing 166 / 277\n",
      "elapsed time 14440.065641880035\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0417 - accuracy: 0.9814\n",
      "batch loss: 0.0417211689054966\n",
      "batch accuracy: 0.9814453125\n",
      "doing 167 / 277\n",
      "elapsed time 14541.095168590546\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0366 - accuracy: 0.9893\n",
      "batch loss: 0.0365680456161499\n",
      "batch accuracy: 0.9892578125\n",
      "doing 168 / 277\n",
      "elapsed time 14649.752823352814\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0353 - accuracy: 0.9902\n",
      "batch loss: 0.03533822298049927\n",
      "batch accuracy: 0.990234375\n",
      "doing 169 / 277\n",
      "elapsed time 14757.829350233078\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0596 - accuracy: 0.9766\n",
      "batch loss: 0.05961140990257263\n",
      "batch accuracy: 0.9765625\n",
      "doing 170 / 277\n",
      "elapsed time 14861.516278266907\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0448 - accuracy: 0.9834\n",
      "batch loss: 0.04475531354546547\n",
      "batch accuracy: 0.9833984375\n",
      "doing 171 / 277\n",
      "elapsed time 14963.6031768322\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0484 - accuracy: 0.9844\n",
      "batch loss: 0.048428013920784\n",
      "batch accuracy: 0.984375\n",
      "doing 172 / 277\n",
      "elapsed time 15067.316806077957\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0576 - accuracy: 0.9824\n",
      "batch loss: 0.05755951255559921\n",
      "batch accuracy: 0.982421875\n",
      "doing 173 / 277\n",
      "elapsed time 15167.028774499893\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0506 - accuracy: 0.9775\n",
      "batch loss: 0.05064712092280388\n",
      "batch accuracy: 0.9775390625\n",
      "doing 174 / 277\n",
      "elapsed time 15274.086462497711\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0409 - accuracy: 0.9873\n",
      "batch loss: 0.04090461879968643\n",
      "batch accuracy: 0.9873046875\n",
      "doing 175 / 277\n",
      "elapsed time 15378.443321704865\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0528 - accuracy: 0.9775\n",
      "batch loss: 0.052763864398002625\n",
      "batch accuracy: 0.9775390625\n",
      "doing 176 / 277\n",
      "elapsed time 15474.21397805214\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0632 - accuracy: 0.9736\n",
      "batch loss: 0.06316622346639633\n",
      "batch accuracy: 0.9736328125\n",
      "doing 177 / 277\n",
      "elapsed time 15576.40454506874\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0522 - accuracy: 0.9795\n",
      "batch loss: 0.05215611308813095\n",
      "batch accuracy: 0.9794921875\n",
      "doing 178 / 277\n",
      "elapsed time 15678.16565823555\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0597 - accuracy: 0.9795\n",
      "batch loss: 0.05966382101178169\n",
      "batch accuracy: 0.9794921875\n",
      "doing 179 / 277\n",
      "elapsed time 15780.942232847214\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0493 - accuracy: 0.9834\n",
      "batch loss: 0.049326471984386444\n",
      "batch accuracy: 0.9833984375\n",
      "doing 180 / 277\n",
      "elapsed time 15883.264040231705\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0401 - accuracy: 0.9893\n",
      "batch loss: 0.04014338180422783\n",
      "batch accuracy: 0.9892578125\n",
      "doing 181 / 277\n",
      "elapsed time 15987.320861577988\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0712 - accuracy: 0.9756\n",
      "batch loss: 0.07116970419883728\n",
      "batch accuracy: 0.9755859375\n",
      "doing 182 / 277\n",
      "elapsed time 16087.947535514832\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0533 - accuracy: 0.9834\n",
      "batch loss: 0.05330232158303261\n",
      "batch accuracy: 0.9833984375\n",
      "doing 183 / 277\n",
      "elapsed time 16187.148208379745\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0673 - accuracy: 0.9805\n",
      "batch loss: 0.06730034202337265\n",
      "batch accuracy: 0.98046875\n",
      "doing 184 / 277\n",
      "elapsed time 16281.075070619583\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0599 - accuracy: 0.9834\n",
      "batch loss: 0.059917937964200974\n",
      "batch accuracy: 0.9833984375\n",
      "doing 185 / 277\n",
      "elapsed time 16376.312039613724\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0497 - accuracy: 0.9795\n",
      "batch loss: 0.0496850460767746\n",
      "batch accuracy: 0.9794921875\n",
      "doing 186 / 277\n",
      "elapsed time 16469.155077934265\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0475 - accuracy: 0.9824\n",
      "batch loss: 0.0474885031580925\n",
      "batch accuracy: 0.982421875\n",
      "doing 187 / 277\n",
      "elapsed time 16565.84282898903\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0487 - accuracy: 0.9834\n",
      "batch loss: 0.048702336847782135\n",
      "batch accuracy: 0.9833984375\n",
      "doing 188 / 277\n",
      "elapsed time 16663.811055660248\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0377 - accuracy: 0.9863\n",
      "batch loss: 0.03770701587200165\n",
      "batch accuracy: 0.986328125\n",
      "doing 189 / 277\n",
      "elapsed time 16760.258787870407\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0492 - accuracy: 0.9834\n",
      "batch loss: 0.04916359484195709\n",
      "batch accuracy: 0.9833984375\n",
      "doing 190 / 277\n",
      "elapsed time 16857.695521354675\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0527 - accuracy: 0.9805\n",
      "batch loss: 0.052727844566106796\n",
      "batch accuracy: 0.98046875\n",
      "doing 191 / 277\n",
      "elapsed time 16954.20370221138\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0602 - accuracy: 0.9814\n",
      "batch loss: 0.060152363032102585\n",
      "batch accuracy: 0.9814453125\n",
      "doing 192 / 277\n",
      "elapsed time 17050.979098320007\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0457 - accuracy: 0.9824\n",
      "batch loss: 0.04566741734743118\n",
      "batch accuracy: 0.982421875\n",
      "doing 193 / 277\n",
      "elapsed time 17143.791924715042\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0449 - accuracy: 0.9814\n",
      "batch loss: 0.04486846923828125\n",
      "batch accuracy: 0.9814453125\n",
      "doing 194 / 277\n",
      "elapsed time 17235.466609477997\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0608 - accuracy: 0.9844\n",
      "batch loss: 0.060825519263744354\n",
      "batch accuracy: 0.984375\n",
      "doing 195 / 277\n",
      "elapsed time 17326.615740776062\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0371 - accuracy: 0.9834\n",
      "batch loss: 0.03707673028111458\n",
      "batch accuracy: 0.9833984375\n",
      "doing 196 / 277\n",
      "elapsed time 17417.320529937744\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0426 - accuracy: 0.9824\n",
      "batch loss: 0.042560212314128876\n",
      "batch accuracy: 0.982421875\n",
      "doing 197 / 277\n",
      "elapsed time 17506.39905834198\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0653 - accuracy: 0.9824\n",
      "batch loss: 0.06531365215778351\n",
      "batch accuracy: 0.982421875\n",
      "doing 198 / 277\n",
      "elapsed time 17585.119095802307\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0469 - accuracy: 0.9834\n",
      "batch loss: 0.04693106561899185\n",
      "batch accuracy: 0.9833984375\n",
      "doing 199 / 277\n",
      "elapsed time 17678.5905482769\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0461 - accuracy: 0.9854\n",
      "batch loss: 0.046066638082265854\n",
      "batch accuracy: 0.9853515625\n",
      "doing 200 / 277\n",
      "elapsed time 17773.156500339508\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0652 - accuracy: 0.9785\n",
      "batch loss: 0.065172478556633\n",
      "batch accuracy: 0.978515625\n",
      "doing 201 / 277\n",
      "elapsed time 17856.2462682724\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0395 - accuracy: 0.9902\n",
      "batch loss: 0.03946441039443016\n",
      "batch accuracy: 0.990234375\n",
      "doing 202 / 277\n",
      "elapsed time 17942.744696617126\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0647 - accuracy: 0.9756\n",
      "batch loss: 0.06466647982597351\n",
      "batch accuracy: 0.9755859375\n",
      "doing 203 / 277\n",
      "elapsed time 18032.48542523384\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0431 - accuracy: 0.9844\n",
      "batch loss: 0.04307543858885765\n",
      "batch accuracy: 0.984375\n",
      "doing 204 / 277\n",
      "elapsed time 18115.121599674225\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0507 - accuracy: 0.9814\n",
      "batch loss: 0.050740256905555725\n",
      "batch accuracy: 0.9814453125\n",
      "doing 205 / 277\n",
      "elapsed time 18193.196254253387\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0566 - accuracy: 0.9766\n",
      "batch loss: 0.056565284729003906\n",
      "batch accuracy: 0.9765625\n",
      "doing 206 / 277\n",
      "elapsed time 18282.20219564438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0548 - accuracy: 0.9854\n",
      "batch loss: 0.054759591817855835\n",
      "batch accuracy: 0.9853515625\n",
      "doing 207 / 277\n",
      "elapsed time 18359.212004184723\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0620 - accuracy: 0.9824\n",
      "batch loss: 0.06197727099061012\n",
      "batch accuracy: 0.982421875\n",
      "doing 208 / 277\n",
      "elapsed time 18437.584089517593\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0389 - accuracy: 0.9893\n",
      "batch loss: 0.03885626420378685\n",
      "batch accuracy: 0.9892578125\n",
      "doing 209 / 277\n",
      "elapsed time 18520.83339190483\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0369 - accuracy: 0.9893\n",
      "batch loss: 0.036895688623189926\n",
      "batch accuracy: 0.9892578125\n",
      "doing 210 / 277\n",
      "elapsed time 18601.070247888565\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0483 - accuracy: 0.9795\n",
      "batch loss: 0.04828079789876938\n",
      "batch accuracy: 0.9794921875\n",
      "doing 211 / 277\n",
      "elapsed time 18679.39068865776\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0449 - accuracy: 0.9814\n",
      "batch loss: 0.04494562745094299\n",
      "batch accuracy: 0.9814453125\n",
      "doing 212 / 277\n",
      "elapsed time 18763.878447055817\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0384 - accuracy: 0.9854\n",
      "batch loss: 0.03836582601070404\n",
      "batch accuracy: 0.9853515625\n",
      "doing 213 / 277\n",
      "elapsed time 18850.77170085907\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0387 - accuracy: 0.9893\n",
      "batch loss: 0.03874480351805687\n",
      "batch accuracy: 0.9892578125\n",
      "doing 214 / 277\n",
      "elapsed time 18930.004984140396\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0374 - accuracy: 0.9873\n",
      "batch loss: 0.03743457794189453\n",
      "batch accuracy: 0.9873046875\n",
      "doing 215 / 277\n",
      "elapsed time 19014.557277202606\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0351 - accuracy: 0.9873\n",
      "batch loss: 0.035147737711668015\n",
      "batch accuracy: 0.9873046875\n",
      "doing 216 / 277\n",
      "elapsed time 19084.167035341263\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0446 - accuracy: 0.9834\n",
      "batch loss: 0.0446157306432724\n",
      "batch accuracy: 0.9833984375\n",
      "doing 217 / 277\n",
      "elapsed time 19168.6769657135\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0304 - accuracy: 0.9912\n",
      "batch loss: 0.030388379469513893\n",
      "batch accuracy: 0.9912109375\n",
      "doing 218 / 277\n",
      "elapsed time 19246.40968465805\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0294 - accuracy: 0.9912\n",
      "batch loss: 0.029391365125775337\n",
      "batch accuracy: 0.9912109375\n",
      "doing 219 / 277\n",
      "elapsed time 19323.10922384262\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0383 - accuracy: 0.9863\n",
      "batch loss: 0.0382751040160656\n",
      "batch accuracy: 0.986328125\n",
      "doing 220 / 277\n",
      "elapsed time 19400.323693990707\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0312 - accuracy: 0.9912\n",
      "batch loss: 0.031201021745800972\n",
      "batch accuracy: 0.9912109375\n",
      "doing 221 / 277\n",
      "elapsed time 19471.11617541313\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0391 - accuracy: 0.9824\n",
      "batch loss: 0.03908418118953705\n",
      "batch accuracy: 0.982421875\n",
      "doing 222 / 277\n",
      "elapsed time 19552.94319486618\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9902\n",
      "batch loss: 0.023699801415205002\n",
      "batch accuracy: 0.990234375\n",
      "doing 223 / 277\n",
      "elapsed time 19618.50621843338\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0285 - accuracy: 0.9932\n",
      "batch loss: 0.028481241315603256\n",
      "batch accuracy: 0.9931640625\n",
      "doing 224 / 277\n",
      "elapsed time 19693.69411969185\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0432 - accuracy: 0.9863\n",
      "batch loss: 0.043161194771528244\n",
      "batch accuracy: 0.986328125\n",
      "doing 225 / 277\n",
      "elapsed time 19771.695254325867\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0654 - accuracy: 0.9775\n",
      "batch loss: 0.06536982953548431\n",
      "batch accuracy: 0.9775390625\n",
      "doing 226 / 277\n",
      "elapsed time 19849.65184187889\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0375 - accuracy: 0.9873\n",
      "batch loss: 0.03747941553592682\n",
      "batch accuracy: 0.9873046875\n",
      "doing 227 / 277\n",
      "elapsed time 19922.406975269318\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0641 - accuracy: 0.9785\n",
      "batch loss: 0.06412734091281891\n",
      "batch accuracy: 0.978515625\n",
      "doing 228 / 277\n",
      "elapsed time 20001.518686771393\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0584 - accuracy: 0.9805\n",
      "batch loss: 0.05840460583567619\n",
      "batch accuracy: 0.98046875\n",
      "doing 229 / 277\n",
      "elapsed time 20081.221259117126\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0498 - accuracy: 0.9814\n",
      "batch loss: 0.049776867032051086\n",
      "batch accuracy: 0.9814453125\n",
      "doing 230 / 277\n",
      "elapsed time 20157.09588766098\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0409 - accuracy: 0.9893\n",
      "batch loss: 0.04087623208761215\n",
      "batch accuracy: 0.9892578125\n",
      "doing 231 / 277\n",
      "elapsed time 20225.71911072731\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0510 - accuracy: 0.9854\n",
      "batch loss: 0.05100356787443161\n",
      "batch accuracy: 0.9853515625\n",
      "doing 232 / 277\n",
      "elapsed time 20298.689734220505\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0564 - accuracy: 0.9775\n",
      "batch loss: 0.05641461908817291\n",
      "batch accuracy: 0.9775390625\n",
      "doing 233 / 277\n",
      "elapsed time 20364.210561275482\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0549 - accuracy: 0.9795\n",
      "batch loss: 0.054856110364198685\n",
      "batch accuracy: 0.9794921875\n",
      "doing 234 / 277\n",
      "elapsed time 20433.106511831284\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0448 - accuracy: 0.9854\n",
      "batch loss: 0.04484793543815613\n",
      "batch accuracy: 0.9853515625\n",
      "doing 235 / 277\n",
      "elapsed time 20499.560636758804\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0443 - accuracy: 0.9834\n",
      "batch loss: 0.04429972171783447\n",
      "batch accuracy: 0.9833984375\n",
      "doing 236 / 277\n",
      "elapsed time 20571.52777695656\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0710 - accuracy: 0.9805\n",
      "batch loss: 0.07097582519054413\n",
      "batch accuracy: 0.98046875\n",
      "doing 237 / 277\n",
      "elapsed time 20645.550654649734\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0387 - accuracy: 0.9844\n",
      "batch loss: 0.038733210414648056\n",
      "batch accuracy: 0.984375\n",
      "doing 238 / 277\n",
      "elapsed time 20709.349598884583\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0457 - accuracy: 0.9873\n",
      "batch loss: 0.04565703496336937\n",
      "batch accuracy: 0.9873046875\n",
      "doing 239 / 277\n",
      "elapsed time 20779.939935445786\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0553 - accuracy: 0.9766\n",
      "batch loss: 0.05527925863862038\n",
      "batch accuracy: 0.9765625\n",
      "doing 240 / 277\n",
      "elapsed time 20850.801998615265\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0548 - accuracy: 0.9795\n",
      "batch loss: 0.054832566529512405\n",
      "batch accuracy: 0.9794921875\n",
      "doing 241 / 277\n",
      "elapsed time 20919.644079208374\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0702 - accuracy: 0.9746\n",
      "batch loss: 0.0702207013964653\n",
      "batch accuracy: 0.974609375\n",
      "doing 242 / 277\n",
      "elapsed time 20987.387031793594\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0539 - accuracy: 0.9854\n",
      "batch loss: 0.053885385394096375\n",
      "batch accuracy: 0.9853515625\n",
      "doing 243 / 277\n",
      "elapsed time 21056.61335659027\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0643 - accuracy: 0.9805\n",
      "batch loss: 0.06431662291288376\n",
      "batch accuracy: 0.98046875\n",
      "doing 244 / 277\n",
      "elapsed time 21125.66060781479\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0512 - accuracy: 0.9834\n",
      "batch loss: 0.051206715404987335\n",
      "batch accuracy: 0.9833984375\n",
      "doing 245 / 277\n",
      "elapsed time 21193.26452255249\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0399 - accuracy: 0.9873\n",
      "batch loss: 0.03986752778291702\n",
      "batch accuracy: 0.9873046875\n",
      "doing 246 / 277\n",
      "elapsed time 21252.27787232399\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0498 - accuracy: 0.9824\n",
      "batch loss: 0.049801889806985855\n",
      "batch accuracy: 0.982421875\n",
      "doing 247 / 277\n",
      "elapsed time 21316.11409687996\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0429 - accuracy: 0.9834\n",
      "batch loss: 0.042920660227537155\n",
      "batch accuracy: 0.9833984375\n",
      "doing 248 / 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 21381.418912172318\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0547 - accuracy: 0.9844\n",
      "batch loss: 0.054738618433475494\n",
      "batch accuracy: 0.984375\n",
      "doing 249 / 277\n",
      "elapsed time 21453.55238842964\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0508 - accuracy: 0.9854\n",
      "batch loss: 0.050775688141584396\n",
      "batch accuracy: 0.9853515625\n",
      "doing 250 / 277\n",
      "elapsed time 21515.459161043167\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0475 - accuracy: 0.9795\n",
      "batch loss: 0.047528449445962906\n",
      "batch accuracy: 0.9794921875\n",
      "doing 251 / 277\n",
      "elapsed time 21571.88764357567\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0425 - accuracy: 0.9854\n",
      "batch loss: 0.04247709736227989\n",
      "batch accuracy: 0.9853515625\n",
      "doing 252 / 277\n",
      "elapsed time 21636.876580953598\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0438 - accuracy: 0.9863\n",
      "batch loss: 0.04380854219198227\n",
      "batch accuracy: 0.986328125\n",
      "doing 253 / 277\n",
      "elapsed time 21704.258499860764\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0526 - accuracy: 0.9834\n",
      "batch loss: 0.05263924598693848\n",
      "batch accuracy: 0.9833984375\n",
      "doing 254 / 277\n",
      "elapsed time 21767.86232304573\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0411 - accuracy: 0.9863\n",
      "batch loss: 0.041074346750974655\n",
      "batch accuracy: 0.986328125\n",
      "doing 255 / 277\n",
      "elapsed time 21834.837463855743\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0316 - accuracy: 0.9893\n",
      "batch loss: 0.031600940972566605\n",
      "batch accuracy: 0.9892578125\n",
      "doing 256 / 277\n",
      "elapsed time 21892.481885910034\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0419 - accuracy: 0.9883\n",
      "batch loss: 0.04194541648030281\n",
      "batch accuracy: 0.98828125\n",
      "doing 257 / 277\n",
      "elapsed time 21957.114141225815\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0517 - accuracy: 0.9863\n",
      "batch loss: 0.05171477422118187\n",
      "batch accuracy: 0.986328125\n",
      "doing 258 / 277\n",
      "elapsed time 22020.080678224564\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0377 - accuracy: 0.9883\n",
      "batch loss: 0.03770036995410919\n",
      "batch accuracy: 0.98828125\n",
      "doing 259 / 277\n",
      "elapsed time 22075.61931324005\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0414 - accuracy: 0.9893\n",
      "batch loss: 0.04144768416881561\n",
      "batch accuracy: 0.9892578125\n",
      "doing 260 / 277\n",
      "elapsed time 22130.176639318466\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0347 - accuracy: 0.9893\n",
      "batch loss: 0.03473895043134689\n",
      "batch accuracy: 0.9892578125\n",
      "doing 261 / 277\n",
      "elapsed time 22188.297024726868\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0565 - accuracy: 0.9824\n",
      "batch loss: 0.05652989447116852\n",
      "batch accuracy: 0.982421875\n",
      "doing 262 / 277\n",
      "elapsed time 22247.501348018646\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0466 - accuracy: 0.9795\n",
      "batch loss: 0.04659309983253479\n",
      "batch accuracy: 0.9794921875\n",
      "doing 263 / 277\n",
      "elapsed time 22308.82254242897\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0521 - accuracy: 0.9805\n",
      "batch loss: 0.05208135396242142\n",
      "batch accuracy: 0.98046875\n",
      "doing 264 / 277\n",
      "elapsed time 22367.036694526672\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0544 - accuracy: 0.9795\n",
      "batch loss: 0.05441908538341522\n",
      "batch accuracy: 0.9794921875\n",
      "doing 265 / 277\n",
      "elapsed time 22418.56186079979\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0341 - accuracy: 0.9893\n",
      "batch loss: 0.03405780717730522\n",
      "batch accuracy: 0.9892578125\n",
      "doing 266 / 277\n",
      "elapsed time 22475.15880703926\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0411 - accuracy: 0.9863\n",
      "batch loss: 0.04108384624123573\n",
      "batch accuracy: 0.986328125\n",
      "doing 267 / 277\n",
      "elapsed time 22538.540363788605\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0434 - accuracy: 0.9854\n",
      "batch loss: 0.04344542324542999\n",
      "batch accuracy: 0.9853515625\n",
      "doing 268 / 277\n",
      "elapsed time 22595.098274707794\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0589 - accuracy: 0.9814\n",
      "batch loss: 0.058900706470012665\n",
      "batch accuracy: 0.9814453125\n",
      "doing 269 / 277\n",
      "elapsed time 22650.561501026154\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0547 - accuracy: 0.9844\n",
      "batch loss: 0.05468088388442993\n",
      "batch accuracy: 0.984375\n",
      "doing 270 / 277\n",
      "elapsed time 22702.227895975113\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0429 - accuracy: 0.9834\n",
      "batch loss: 0.042945437133312225\n",
      "batch accuracy: 0.9833984375\n",
      "doing 271 / 277\n",
      "elapsed time 22765.963155269623\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0325 - accuracy: 0.9873\n",
      "batch loss: 0.03246501460671425\n",
      "batch accuracy: 0.9873046875\n",
      "doing 272 / 277\n",
      "elapsed time 22814.884405851364\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0490 - accuracy: 0.9814\n",
      "batch loss: 0.049049198627471924\n",
      "batch accuracy: 0.9814453125\n",
      "doing 273 / 277\n",
      "elapsed time 22871.10965013504\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0525 - accuracy: 0.9844\n",
      "batch loss: 0.052451200783252716\n",
      "batch accuracy: 0.984375\n",
      "doing 274 / 277\n",
      "elapsed time 22925.468725442886\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0359 - accuracy: 0.9863\n",
      "batch loss: 0.035885900259017944\n",
      "batch accuracy: 0.986328125\n",
      "doing 275 / 277\n",
      "elapsed time 22972.14862728119\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0449 - accuracy: 0.9873\n",
      "batch loss: 0.04493866115808487\n",
      "batch accuracy: 0.9873046875\n",
      "doing 276 / 277\n",
      "elapsed time 23005.274939775467\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.0310 - accuracy: 0.9890\n",
      "batch loss: 0.031017722561955452\n",
      "batch accuracy: 0.9890310764312744\n",
      "Train loss 0.052480061548604004\n",
      "Train accuracy 0.9820332518553475\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 0.1438 - accuracy: 0.9547\n",
      "Validation loss: 0.14378392696380615\n",
      "Validation accuracy: 0.9546666741371155\n",
      "==================================================\n",
      "9 / 10\n",
      "doing 0 / 277\n",
      "elapsed time 25.280051231384277\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0411 - accuracy: 0.9854\n",
      "batch loss: 0.041147928684949875\n",
      "batch accuracy: 0.9853515625\n",
      "doing 1 / 277\n",
      "elapsed time 50.29184174537659\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0420 - accuracy: 0.9863\n",
      "batch loss: 0.04195008426904678\n",
      "batch accuracy: 0.986328125\n",
      "doing 2 / 277\n",
      "elapsed time 70.91756319999695\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0439 - accuracy: 0.9873\n",
      "batch loss: 0.04386689141392708\n",
      "batch accuracy: 0.9873046875\n",
      "doing 3 / 277\n",
      "elapsed time 96.20702743530273\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0451 - accuracy: 0.9795\n",
      "batch loss: 0.04508255049586296\n",
      "batch accuracy: 0.9794921875\n",
      "doing 4 / 277\n",
      "elapsed time 122.84613990783691\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0372 - accuracy: 0.9873\n",
      "batch loss: 0.03723335638642311\n",
      "batch accuracy: 0.9873046875\n",
      "doing 5 / 277\n",
      "elapsed time 139.9667103290558\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0362 - accuracy: 0.9883\n",
      "batch loss: 0.03619678318500519\n",
      "batch accuracy: 0.98828125\n",
      "doing 6 / 277\n",
      "elapsed time 168.93891882896423\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0376 - accuracy: 0.9834\n",
      "batch loss: 0.03761357441544533\n",
      "batch accuracy: 0.9833984375\n",
      "doing 7 / 277\n",
      "elapsed time 198.3509349822998\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0412 - accuracy: 0.9873\n",
      "batch loss: 0.04116803780198097\n",
      "batch accuracy: 0.9873046875\n",
      "doing 8 / 277\n",
      "elapsed time 224.3723087310791\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0255 - accuracy: 0.9941\n",
      "batch loss: 0.025507720187306404\n",
      "batch accuracy: 0.994140625\n",
      "doing 9 / 277\n",
      "elapsed time 241.83997416496277\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0281 - accuracy: 0.9932\n",
      "batch loss: 0.028137018904089928\n",
      "batch accuracy: 0.9931640625\n",
      "doing 10 / 277\n",
      "elapsed time 271.33713126182556\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0342 - accuracy: 0.9893\n",
      "batch loss: 0.03419838845729828\n",
      "batch accuracy: 0.9892578125\n",
      "doing 11 / 277\n",
      "elapsed time 298.839679479599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0292 - accuracy: 0.9932\n",
      "batch loss: 0.029249776154756546\n",
      "batch accuracy: 0.9931640625\n",
      "doing 12 / 277\n",
      "elapsed time 322.67135524749756\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0316 - accuracy: 0.9854\n",
      "batch loss: 0.031596407294273376\n",
      "batch accuracy: 0.9853515625\n",
      "doing 13 / 277\n",
      "elapsed time 341.54128098487854\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0320 - accuracy: 0.9863\n",
      "batch loss: 0.032033052295446396\n",
      "batch accuracy: 0.986328125\n",
      "doing 14 / 277\n",
      "elapsed time 368.4533734321594\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.9893\n",
      "batch loss: 0.025384163483977318\n",
      "batch accuracy: 0.9892578125\n",
      "doing 15 / 277\n",
      "elapsed time 389.25467109680176\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0331 - accuracy: 0.9922\n",
      "batch loss: 0.03313133120536804\n",
      "batch accuracy: 0.9921875\n",
      "doing 16 / 277\n",
      "elapsed time 410.0287561416626\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0469 - accuracy: 0.9844\n",
      "batch loss: 0.04686405137181282\n",
      "batch accuracy: 0.984375\n",
      "doing 17 / 277\n",
      "elapsed time 430.80405163764954\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0416 - accuracy: 0.9805\n",
      "batch loss: 0.04162229970097542\n",
      "batch accuracy: 0.98046875\n",
      "doing 18 / 277\n",
      "elapsed time 449.65518450737\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0453 - accuracy: 0.9814\n",
      "batch loss: 0.045295413583517075\n",
      "batch accuracy: 0.9814453125\n",
      "doing 19 / 277\n",
      "elapsed time 475.95215487480164\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0438 - accuracy: 0.9814\n",
      "batch loss: 0.04381287842988968\n",
      "batch accuracy: 0.9814453125\n",
      "doing 20 / 277\n",
      "elapsed time 497.4875409603119\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0363 - accuracy: 0.9893\n",
      "batch loss: 0.03628508374094963\n",
      "batch accuracy: 0.9892578125\n",
      "doing 21 / 277\n",
      "elapsed time 516.7354011535645\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0353 - accuracy: 0.9863\n",
      "batch loss: 0.035294659435749054\n",
      "batch accuracy: 0.986328125\n",
      "doing 22 / 277\n",
      "elapsed time 541.2381241321564\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0312 - accuracy: 0.9883\n",
      "batch loss: 0.03119724430143833\n",
      "batch accuracy: 0.98828125\n",
      "doing 23 / 277\n",
      "elapsed time 571.2679316997528\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0403 - accuracy: 0.9863\n",
      "batch loss: 0.04030267149209976\n",
      "batch accuracy: 0.986328125\n",
      "doing 24 / 277\n",
      "elapsed time 597.3655459880829\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0367 - accuracy: 0.9883\n",
      "batch loss: 0.03674916923046112\n",
      "batch accuracy: 0.98828125\n",
      "doing 25 / 277\n",
      "elapsed time 614.9194958209991\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0274 - accuracy: 0.9922\n",
      "batch loss: 0.027423257008194923\n",
      "batch accuracy: 0.9921875\n",
      "doing 26 / 277\n",
      "elapsed time 636.3639523983002\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0297 - accuracy: 0.9873\n",
      "batch loss: 0.029692618176341057\n",
      "batch accuracy: 0.9873046875\n",
      "doing 27 / 277\n",
      "elapsed time 663.016163110733\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0453 - accuracy: 0.9834\n",
      "batch loss: 0.045330800116062164\n",
      "batch accuracy: 0.9833984375\n",
      "doing 28 / 277\n",
      "elapsed time 685.4871068000793\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0493 - accuracy: 0.9814\n",
      "batch loss: 0.04930923879146576\n",
      "batch accuracy: 0.9814453125\n",
      "doing 29 / 277\n",
      "elapsed time 702.312305688858\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0365 - accuracy: 0.9863\n",
      "batch loss: 0.03651328757405281\n",
      "batch accuracy: 0.986328125\n",
      "doing 30 / 277\n",
      "elapsed time 726.0586380958557\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0425 - accuracy: 0.9863\n",
      "batch loss: 0.04245332255959511\n",
      "batch accuracy: 0.986328125\n",
      "doing 31 / 277\n",
      "elapsed time 752.5948543548584\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0376 - accuracy: 0.9912\n",
      "batch loss: 0.03758469969034195\n",
      "batch accuracy: 0.9912109375\n",
      "doing 32 / 277\n",
      "elapsed time 777.8436367511749\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0411 - accuracy: 0.9863\n",
      "batch loss: 0.0410773940384388\n",
      "batch accuracy: 0.986328125\n",
      "doing 33 / 277\n",
      "elapsed time 796.9645502567291\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0422 - accuracy: 0.9844\n",
      "batch loss: 0.042239949107170105\n",
      "batch accuracy: 0.984375\n",
      "doing 34 / 277\n",
      "elapsed time 818.1478824615479\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0284 - accuracy: 0.9902\n",
      "batch loss: 0.028393743559718132\n",
      "batch accuracy: 0.990234375\n",
      "doing 35 / 277\n",
      "elapsed time 841.9719233512878\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0497 - accuracy: 0.9883\n",
      "batch loss: 0.0497216135263443\n",
      "batch accuracy: 0.98828125\n",
      "doing 36 / 277\n",
      "elapsed time 861.7845847606659\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0334 - accuracy: 0.9912\n",
      "batch loss: 0.03344555199146271\n",
      "batch accuracy: 0.9912109375\n",
      "doing 37 / 277\n",
      "elapsed time 878.2251093387604\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0350 - accuracy: 0.9873\n",
      "batch loss: 0.03497175872325897\n",
      "batch accuracy: 0.9873046875\n",
      "doing 38 / 277\n",
      "elapsed time 901.614940404892\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0343 - accuracy: 0.9902\n",
      "batch loss: 0.03434380143880844\n",
      "batch accuracy: 0.990234375\n",
      "doing 39 / 277\n",
      "elapsed time 923.4725782871246\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0289 - accuracy: 0.9922\n",
      "batch loss: 0.02888547256588936\n",
      "batch accuracy: 0.9921875\n",
      "doing 40 / 277\n",
      "elapsed time 941.1565475463867\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0471 - accuracy: 0.9824\n",
      "batch loss: 0.04706892371177673\n",
      "batch accuracy: 0.982421875\n",
      "doing 41 / 277\n",
      "elapsed time 968.5431475639343\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0371 - accuracy: 0.9854\n",
      "batch loss: 0.037127263844013214\n",
      "batch accuracy: 0.9853515625\n",
      "doing 42 / 277\n",
      "elapsed time 990.2065482139587\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0385 - accuracy: 0.9863\n",
      "batch loss: 0.038492601364851\n",
      "batch accuracy: 0.986328125\n",
      "doing 43 / 277\n",
      "elapsed time 1006.9639129638672\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0453 - accuracy: 0.9863\n",
      "batch loss: 0.045306961983442307\n",
      "batch accuracy: 0.986328125\n",
      "doing 44 / 277\n",
      "elapsed time 1032.8038375377655\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0390 - accuracy: 0.9873\n",
      "batch loss: 0.03900936245918274\n",
      "batch accuracy: 0.9873046875\n",
      "doing 45 / 277\n",
      "elapsed time 1051.8540003299713\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0393 - accuracy: 0.9873\n",
      "batch loss: 0.03934336453676224\n",
      "batch accuracy: 0.9873046875\n",
      "doing 46 / 277\n",
      "elapsed time 1069.1125733852386\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0299 - accuracy: 0.9902\n",
      "batch loss: 0.02986413612961769\n",
      "batch accuracy: 0.990234375\n",
      "doing 47 / 277\n",
      "elapsed time 1090.534492969513\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0322 - accuracy: 0.9883\n",
      "batch loss: 0.03220796212553978\n",
      "batch accuracy: 0.98828125\n",
      "doing 48 / 277\n",
      "elapsed time 1108.9021995067596\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0270 - accuracy: 0.9922\n",
      "batch loss: 0.027012012898921967\n",
      "batch accuracy: 0.9921875\n",
      "doing 49 / 277\n",
      "elapsed time 1127.2341964244843\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9941\n",
      "batch loss: 0.023394156247377396\n",
      "batch accuracy: 0.994140625\n",
      "doing 50 / 277\n",
      "elapsed time 1151.8993937969208\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0512 - accuracy: 0.9766\n",
      "batch loss: 0.05115633085370064\n",
      "batch accuracy: 0.9765625\n",
      "doing 51 / 277\n",
      "elapsed time 1172.6934654712677\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0343 - accuracy: 0.9873\n",
      "batch loss: 0.03434239327907562\n",
      "batch accuracy: 0.9873046875\n",
      "doing 52 / 277\n",
      "elapsed time 1188.6299018859863\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0495 - accuracy: 0.9775\n",
      "batch loss: 0.04953019320964813\n",
      "batch accuracy: 0.9775390625\n",
      "doing 53 / 277\n",
      "elapsed time 1208.8526306152344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0395 - accuracy: 0.9834\n",
      "batch loss: 0.03952556848526001\n",
      "batch accuracy: 0.9833984375\n",
      "doing 54 / 277\n",
      "elapsed time 1231.4682319164276\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0486 - accuracy: 0.9824\n",
      "batch loss: 0.048554740846157074\n",
      "batch accuracy: 0.982421875\n",
      "doing 55 / 277\n",
      "elapsed time 1250.1897389888763\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0641 - accuracy: 0.9775\n",
      "batch loss: 0.06406095623970032\n",
      "batch accuracy: 0.9775390625\n",
      "doing 56 / 277\n",
      "elapsed time 1267.3088076114655\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0509 - accuracy: 0.9805\n",
      "batch loss: 0.050940804183483124\n",
      "batch accuracy: 0.98046875\n",
      "doing 57 / 277\n",
      "elapsed time 1284.7496252059937\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0288 - accuracy: 0.9902\n",
      "batch loss: 0.028817323967814445\n",
      "batch accuracy: 0.990234375\n",
      "doing 58 / 277\n",
      "elapsed time 1305.4146754741669\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0378 - accuracy: 0.9873\n",
      "batch loss: 0.03775087743997574\n",
      "batch accuracy: 0.9873046875\n",
      "doing 59 / 277\n",
      "elapsed time 1324.5833642482758\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0281 - accuracy: 0.9902\n",
      "batch loss: 0.028064243495464325\n",
      "batch accuracy: 0.990234375\n",
      "doing 60 / 277\n",
      "elapsed time 1338.3550395965576\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0468 - accuracy: 0.9863\n",
      "batch loss: 0.04675037041306496\n",
      "batch accuracy: 0.986328125\n",
      "doing 61 / 277\n",
      "elapsed time 1359.1076457500458\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0392 - accuracy: 0.9902\n",
      "batch loss: 0.039222363382577896\n",
      "batch accuracy: 0.990234375\n",
      "doing 62 / 277\n",
      "elapsed time 1378.701544046402\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0396 - accuracy: 0.9873\n",
      "batch loss: 0.039588961750268936\n",
      "batch accuracy: 0.9873046875\n",
      "doing 63 / 277\n",
      "elapsed time 1394.1126158237457\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0395 - accuracy: 0.9873\n",
      "batch loss: 0.039464645087718964\n",
      "batch accuracy: 0.9873046875\n",
      "doing 64 / 277\n",
      "elapsed time 1415.8446402549744\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0396 - accuracy: 0.9873\n",
      "batch loss: 0.03956008702516556\n",
      "batch accuracy: 0.9873046875\n",
      "doing 65 / 277\n",
      "elapsed time 1433.5540926456451\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0402 - accuracy: 0.9883\n",
      "batch loss: 0.04015696421265602\n",
      "batch accuracy: 0.98828125\n",
      "doing 66 / 277\n",
      "elapsed time 1449.4483456611633\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0316 - accuracy: 0.9922\n",
      "batch loss: 0.03155645728111267\n",
      "batch accuracy: 0.9921875\n",
      "doing 67 / 277\n",
      "elapsed time 1468.955794095993\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0407 - accuracy: 0.9863\n",
      "batch loss: 0.040663499385118484\n",
      "batch accuracy: 0.986328125\n",
      "doing 68 / 277\n",
      "elapsed time 1481.909128189087\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0371 - accuracy: 0.9854\n",
      "batch loss: 0.03705369308590889\n",
      "batch accuracy: 0.9853515625\n",
      "doing 69 / 277\n",
      "elapsed time 1502.3270225524902\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0397 - accuracy: 0.9844\n",
      "batch loss: 0.03972703590989113\n",
      "batch accuracy: 0.984375\n",
      "doing 70 / 277\n",
      "elapsed time 1525.296264886856\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0477 - accuracy: 0.9863\n",
      "batch loss: 0.0477491170167923\n",
      "batch accuracy: 0.986328125\n",
      "doing 71 / 277\n",
      "elapsed time 1542.4162142276764\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0627 - accuracy: 0.9814\n",
      "batch loss: 0.06269992887973785\n",
      "batch accuracy: 0.9814453125\n",
      "doing 72 / 277\n",
      "elapsed time 1562.7874779701233\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0266 - accuracy: 0.9951\n",
      "batch loss: 0.02657845802605152\n",
      "batch accuracy: 0.9951171875\n",
      "doing 73 / 277\n",
      "elapsed time 1577.1168899536133\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0302 - accuracy: 0.9902\n",
      "batch loss: 0.030183108523488045\n",
      "batch accuracy: 0.990234375\n",
      "doing 74 / 277\n",
      "elapsed time 1597.2751455307007\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0441 - accuracy: 0.9805\n",
      "batch loss: 0.044107355177402496\n",
      "batch accuracy: 0.98046875\n",
      "doing 75 / 277\n",
      "elapsed time 1618.9081456661224\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0441 - accuracy: 0.9883\n",
      "batch loss: 0.044076159596443176\n",
      "batch accuracy: 0.98828125\n",
      "doing 76 / 277\n",
      "elapsed time 1636.9944896697998\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0381 - accuracy: 0.9854\n",
      "batch loss: 0.03814501687884331\n",
      "batch accuracy: 0.9853515625\n",
      "doing 77 / 277\n",
      "elapsed time 1655.3978102207184\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0415 - accuracy: 0.9854\n",
      "batch loss: 0.04151682183146477\n",
      "batch accuracy: 0.9853515625\n",
      "doing 78 / 277\n",
      "elapsed time 1673.7883133888245\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0333 - accuracy: 0.9893\n",
      "batch loss: 0.03328318893909454\n",
      "batch accuracy: 0.9892578125\n",
      "doing 79 / 277\n",
      "elapsed time 1694.906570672989\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0437 - accuracy: 0.9844\n",
      "batch loss: 0.04369868338108063\n",
      "batch accuracy: 0.984375\n",
      "doing 80 / 277\n",
      "elapsed time 1711.7380983829498\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0408 - accuracy: 0.9883\n",
      "batch loss: 0.0407557487487793\n",
      "batch accuracy: 0.98828125\n",
      "doing 81 / 277\n",
      "elapsed time 1726.5756707191467\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0462 - accuracy: 0.9854\n",
      "batch loss: 0.04623197019100189\n",
      "batch accuracy: 0.9853515625\n",
      "doing 82 / 277\n",
      "elapsed time 1744.1052298545837\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0309 - accuracy: 0.9922\n",
      "batch loss: 0.03089028410613537\n",
      "batch accuracy: 0.9921875\n",
      "doing 83 / 277\n",
      "elapsed time 1763.7833843231201\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0418 - accuracy: 0.9844\n",
      "batch loss: 0.04179057478904724\n",
      "batch accuracy: 0.984375\n",
      "doing 84 / 277\n",
      "elapsed time 1779.28799533844\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0502 - accuracy: 0.9844\n",
      "batch loss: 0.05024315416812897\n",
      "batch accuracy: 0.984375\n",
      "doing 85 / 277\n",
      "elapsed time 1794.583694934845\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0319 - accuracy: 0.9922\n",
      "batch loss: 0.031943414360284805\n",
      "batch accuracy: 0.9921875\n",
      "doing 86 / 277\n",
      "elapsed time 1812.2090196609497\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0572 - accuracy: 0.9805\n",
      "batch loss: 0.057164184749126434\n",
      "batch accuracy: 0.98046875\n",
      "doing 87 / 277\n",
      "elapsed time 1829.0156648159027\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0377 - accuracy: 0.9902\n",
      "batch loss: 0.03769347816705704\n",
      "batch accuracy: 0.990234375\n",
      "doing 88 / 277\n",
      "elapsed time 1841.0868973731995\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0382 - accuracy: 0.9854\n",
      "batch loss: 0.03822321444749832\n",
      "batch accuracy: 0.9853515625\n",
      "doing 89 / 277\n",
      "elapsed time 1858.248089313507\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0304 - accuracy: 0.9912\n",
      "batch loss: 0.030360180884599686\n",
      "batch accuracy: 0.9912109375\n",
      "doing 90 / 277\n",
      "elapsed time 1868.936928987503\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0316 - accuracy: 0.9922\n",
      "batch loss: 0.03162429481744766\n",
      "batch accuracy: 0.9921875\n",
      "doing 91 / 277\n",
      "elapsed time 1888.4353601932526\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0440 - accuracy: 0.9863\n",
      "batch loss: 0.04400698095560074\n",
      "batch accuracy: 0.986328125\n",
      "doing 92 / 277\n",
      "elapsed time 1904.273669242859\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0428 - accuracy: 0.9854\n",
      "batch loss: 0.04276631772518158\n",
      "batch accuracy: 0.9853515625\n",
      "doing 93 / 277\n",
      "elapsed time 1914.8993446826935\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0582 - accuracy: 0.9795\n",
      "batch loss: 0.058237627148628235\n",
      "batch accuracy: 0.9794921875\n",
      "doing 94 / 277\n",
      "elapsed time 1936.392948627472\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0376 - accuracy: 0.9863\n",
      "batch loss: 0.03762933984398842\n",
      "batch accuracy: 0.986328125\n",
      "doing 95 / 277\n",
      "elapsed time 1953.2493152618408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0437 - accuracy: 0.9873\n",
      "batch loss: 0.04371993988752365\n",
      "batch accuracy: 0.9873046875\n",
      "doing 96 / 277\n",
      "elapsed time 1967.4499206542969\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0340 - accuracy: 0.9873\n",
      "batch loss: 0.033968981355428696\n",
      "batch accuracy: 0.9873046875\n",
      "doing 97 / 277\n",
      "elapsed time 1983.4796838760376\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0392 - accuracy: 0.9873\n",
      "batch loss: 0.039184875786304474\n",
      "batch accuracy: 0.9873046875\n",
      "doing 98 / 277\n",
      "elapsed time 2000.5192363262177\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0414 - accuracy: 0.9883\n",
      "batch loss: 0.041449401527643204\n",
      "batch accuracy: 0.98828125\n",
      "doing 99 / 277\n",
      "elapsed time 2013.404557466507\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0272 - accuracy: 0.9961\n",
      "batch loss: 0.02724389173090458\n",
      "batch accuracy: 0.99609375\n",
      "doing 100 / 277\n",
      "elapsed time 2029.9212572574615\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0352 - accuracy: 0.9893\n",
      "batch loss: 0.035201359540224075\n",
      "batch accuracy: 0.9892578125\n",
      "doing 101 / 277\n",
      "elapsed time 2047.9757499694824\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0380 - accuracy: 0.9854\n",
      "batch loss: 0.03796599805355072\n",
      "batch accuracy: 0.9853515625\n",
      "doing 102 / 277\n",
      "elapsed time 2064.1475689411163\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0437 - accuracy: 0.9854\n",
      "batch loss: 0.04369957000017166\n",
      "batch accuracy: 0.9853515625\n",
      "doing 103 / 277\n",
      "elapsed time 2078.3926317691803\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0503 - accuracy: 0.9844\n",
      "batch loss: 0.05025320127606392\n",
      "batch accuracy: 0.984375\n",
      "doing 104 / 277\n",
      "elapsed time 2097.730347633362\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0353 - accuracy: 0.9922\n",
      "batch loss: 0.03534730523824692\n",
      "batch accuracy: 0.9921875\n",
      "doing 105 / 277\n",
      "elapsed time 2114.202836036682\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0537 - accuracy: 0.9824\n",
      "batch loss: 0.05369746312499046\n",
      "batch accuracy: 0.982421875\n",
      "doing 106 / 277\n",
      "elapsed time 2125.6895730495453\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0360 - accuracy: 0.9893\n",
      "batch loss: 0.036033082753419876\n",
      "batch accuracy: 0.9892578125\n",
      "doing 107 / 277\n",
      "elapsed time 2142.145047903061\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0385 - accuracy: 0.9912\n",
      "batch loss: 0.03851854428648949\n",
      "batch accuracy: 0.9912109375\n",
      "doing 108 / 277\n",
      "elapsed time 2158.0633656978607\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0383 - accuracy: 0.9883\n",
      "batch loss: 0.038281362503767014\n",
      "batch accuracy: 0.98828125\n",
      "doing 109 / 277\n",
      "elapsed time 2167.486508131027\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0454 - accuracy: 0.9844\n",
      "batch loss: 0.0454183965921402\n",
      "batch accuracy: 0.984375\n",
      "doing 110 / 277\n",
      "elapsed time 2187.173524618149\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0326 - accuracy: 0.9863\n",
      "batch loss: 0.032640241086483\n",
      "batch accuracy: 0.986328125\n",
      "doing 111 / 277\n",
      "elapsed time 2198.5164988040924\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0357 - accuracy: 0.9844\n",
      "batch loss: 0.03573497757315636\n",
      "batch accuracy: 0.984375\n",
      "doing 112 / 277\n",
      "elapsed time 2212.78954911232\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0477 - accuracy: 0.9824\n",
      "batch loss: 0.047741878777742386\n",
      "batch accuracy: 0.982421875\n",
      "doing 113 / 277\n",
      "elapsed time 2230.8014318943024\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0341 - accuracy: 0.9902\n",
      "batch loss: 0.03407113999128342\n",
      "batch accuracy: 0.990234375\n",
      "doing 114 / 277\n",
      "elapsed time 2247.1678550243378\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0488 - accuracy: 0.9795\n",
      "batch loss: 0.04880306124687195\n",
      "batch accuracy: 0.9794921875\n",
      "doing 115 / 277\n",
      "elapsed time 2256.457448720932\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0434 - accuracy: 0.9863\n",
      "batch loss: 0.04343395680189133\n",
      "batch accuracy: 0.986328125\n",
      "doing 116 / 277\n",
      "elapsed time 2271.9926714897156\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0324 - accuracy: 0.9883\n",
      "batch loss: 0.03236847743391991\n",
      "batch accuracy: 0.98828125\n",
      "doing 117 / 277\n",
      "elapsed time 2288.2537755966187\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0396 - accuracy: 0.9834\n",
      "batch loss: 0.039573825895786285\n",
      "batch accuracy: 0.9833984375\n",
      "doing 118 / 277\n",
      "elapsed time 2308.770719766617\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0416 - accuracy: 0.9805\n",
      "batch loss: 0.041577182710170746\n",
      "batch accuracy: 0.98046875\n",
      "doing 119 / 277\n",
      "elapsed time 2326.529940843582\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0706 - accuracy: 0.9844\n",
      "batch loss: 0.07058943063020706\n",
      "batch accuracy: 0.984375\n",
      "doing 120 / 277\n",
      "elapsed time 2341.990245580673\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0424 - accuracy: 0.9834\n",
      "batch loss: 0.04237619787454605\n",
      "batch accuracy: 0.9833984375\n",
      "doing 121 / 277\n",
      "elapsed time 2352.759735584259\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0393 - accuracy: 0.9873\n",
      "batch loss: 0.03930971771478653\n",
      "batch accuracy: 0.9873046875\n",
      "doing 122 / 277\n",
      "elapsed time 2363.96808552742\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0494 - accuracy: 0.9844\n",
      "batch loss: 0.04935315623879433\n",
      "batch accuracy: 0.984375\n",
      "doing 123 / 277\n",
      "elapsed time 2380.135331392288\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0378 - accuracy: 0.9873\n",
      "batch loss: 0.037797484546899796\n",
      "batch accuracy: 0.9873046875\n",
      "doing 124 / 277\n",
      "elapsed time 2392.4520175457\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0339 - accuracy: 0.9893\n",
      "batch loss: 0.03391876071691513\n",
      "batch accuracy: 0.9892578125\n",
      "doing 125 / 277\n",
      "elapsed time 2403.28768324852\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0443 - accuracy: 0.9883\n",
      "batch loss: 0.04433469846844673\n",
      "batch accuracy: 0.98828125\n",
      "doing 126 / 277\n",
      "elapsed time 2418.241869211197\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0521 - accuracy: 0.9814\n",
      "batch loss: 0.052124060690402985\n",
      "batch accuracy: 0.9814453125\n",
      "doing 127 / 277\n",
      "elapsed time 2432.068780183792\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0393 - accuracy: 0.9873\n",
      "batch loss: 0.03926302120089531\n",
      "batch accuracy: 0.9873046875\n",
      "doing 128 / 277\n",
      "elapsed time 2444.482321023941\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0461 - accuracy: 0.9834\n",
      "batch loss: 0.04608765244483948\n",
      "batch accuracy: 0.9833984375\n",
      "doing 129 / 277\n",
      "elapsed time 2454.0375456809998\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0414 - accuracy: 0.9854\n",
      "batch loss: 0.04142316058278084\n",
      "batch accuracy: 0.9853515625\n",
      "doing 130 / 277\n",
      "elapsed time 2469.9009234905243\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0487 - accuracy: 0.9834\n",
      "batch loss: 0.048733100295066833\n",
      "batch accuracy: 0.9833984375\n",
      "doing 131 / 277\n",
      "elapsed time 2484.218391895294\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0307 - accuracy: 0.9912\n",
      "batch loss: 0.030677184462547302\n",
      "batch accuracy: 0.9912109375\n",
      "doing 132 / 277\n",
      "elapsed time 2491.1668627262115\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0680 - accuracy: 0.9766\n",
      "batch loss: 0.06802421808242798\n",
      "batch accuracy: 0.9765625\n",
      "doing 133 / 277\n",
      "elapsed time 2502.4875206947327\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0418 - accuracy: 0.9863\n",
      "batch loss: 0.04177650436758995\n",
      "batch accuracy: 0.986328125\n",
      "doing 134 / 277\n",
      "elapsed time 2511.4882385730743\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0402 - accuracy: 0.9854\n",
      "batch loss: 0.04016938805580139\n",
      "batch accuracy: 0.9853515625\n",
      "doing 135 / 277\n",
      "elapsed time 2524.948324918747\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0533 - accuracy: 0.9775\n",
      "batch loss: 0.053254060447216034\n",
      "batch accuracy: 0.9775390625\n",
      "doing 136 / 277\n",
      "elapsed time 2537.8595535755157\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0392 - accuracy: 0.9863\n",
      "batch loss: 0.039199866354465485\n",
      "batch accuracy: 0.986328125\n",
      "doing 137 / 277\n",
      "elapsed time 2547.7744784355164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0373 - accuracy: 0.9844\n",
      "batch loss: 0.037345439195632935\n",
      "batch accuracy: 0.984375\n",
      "doing 138 / 277\n",
      "elapsed time 2563.0741028785706\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0412 - accuracy: 0.9863\n",
      "batch loss: 0.041152819991111755\n",
      "batch accuracy: 0.986328125\n",
      "doing 139 / 277\n",
      "elapsed time 2575.9968836307526\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0452 - accuracy: 0.9844\n",
      "batch loss: 0.0452447384595871\n",
      "batch accuracy: 0.984375\n",
      "doing 140 / 277\n",
      "elapsed time 2583.4320724010468\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0464 - accuracy: 0.9844\n",
      "batch loss: 0.04644569382071495\n",
      "batch accuracy: 0.984375\n",
      "doing 141 / 277\n",
      "elapsed time 2599.978196144104\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0317 - accuracy: 0.9893\n",
      "batch loss: 0.0317409373819828\n",
      "batch accuracy: 0.9892578125\n",
      "doing 142 / 277\n",
      "elapsed time 2613.9883222579956\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0418 - accuracy: 0.9854\n",
      "batch loss: 0.041783370077610016\n",
      "batch accuracy: 0.9853515625\n",
      "doing 143 / 277\n",
      "elapsed time 2627.153801679611\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0400 - accuracy: 0.9834\n",
      "batch loss: 0.04000755399465561\n",
      "batch accuracy: 0.9833984375\n",
      "doing 144 / 277\n",
      "elapsed time 2634.055715084076\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0352 - accuracy: 0.9873\n",
      "batch loss: 0.03523215651512146\n",
      "batch accuracy: 0.9873046875\n",
      "doing 145 / 277\n",
      "elapsed time 2647.1782960891724\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0328 - accuracy: 0.9844\n",
      "batch loss: 0.03282502666115761\n",
      "batch accuracy: 0.984375\n",
      "doing 146 / 277\n",
      "elapsed time 2659.4995007514954\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0342 - accuracy: 0.9893\n",
      "batch loss: 0.0342119075357914\n",
      "batch accuracy: 0.9892578125\n",
      "doing 147 / 277\n",
      "elapsed time 2666.3776161670685\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0191 - accuracy: 0.9951\n",
      "batch loss: 0.01914156973361969\n",
      "batch accuracy: 0.9951171875\n",
      "doing 148 / 277\n",
      "elapsed time 2681.2390928268433\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0394 - accuracy: 0.9834\n",
      "batch loss: 0.03939828649163246\n",
      "batch accuracy: 0.9833984375\n",
      "doing 149 / 277\n",
      "elapsed time 2696.8731367588043\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0369 - accuracy: 0.9883\n",
      "batch loss: 0.03693417087197304\n",
      "batch accuracy: 0.98828125\n",
      "doing 150 / 277\n",
      "elapsed time 2708.8130214214325\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0303 - accuracy: 0.9863\n",
      "batch loss: 0.03026825189590454\n",
      "batch accuracy: 0.986328125\n",
      "doing 151 / 277\n",
      "elapsed time 2716.007258415222\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0299 - accuracy: 0.9932\n",
      "batch loss: 0.029893701896071434\n",
      "batch accuracy: 0.9931640625\n",
      "doing 152 / 277\n",
      "elapsed time 2727.075672149658\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0384 - accuracy: 0.9863\n",
      "batch loss: 0.03837456554174423\n",
      "batch accuracy: 0.986328125\n",
      "doing 153 / 277\n",
      "elapsed time 2734.560734987259\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0337 - accuracy: 0.9873\n",
      "batch loss: 0.033665165305137634\n",
      "batch accuracy: 0.9873046875\n",
      "doing 154 / 277\n",
      "elapsed time 2748.5757257938385\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0280 - accuracy: 0.9893\n",
      "batch loss: 0.027980607002973557\n",
      "batch accuracy: 0.9892578125\n",
      "doing 155 / 277\n",
      "elapsed time 2761.457764148712\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0435 - accuracy: 0.9873\n",
      "batch loss: 0.043505508452653885\n",
      "batch accuracy: 0.9873046875\n",
      "doing 156 / 277\n",
      "elapsed time 2771.200975418091\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0359 - accuracy: 0.9893\n",
      "batch loss: 0.03594709932804108\n",
      "batch accuracy: 0.9892578125\n",
      "doing 157 / 277\n",
      "elapsed time 2781.175279378891\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0278 - accuracy: 0.9883\n",
      "batch loss: 0.027751341462135315\n",
      "batch accuracy: 0.98828125\n",
      "doing 158 / 277\n",
      "elapsed time 2791.5719034671783\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0595 - accuracy: 0.9814\n",
      "batch loss: 0.05946745723485947\n",
      "batch accuracy: 0.9814453125\n",
      "doing 159 / 277\n",
      "elapsed time 2800.5769147872925\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0431 - accuracy: 0.9854\n",
      "batch loss: 0.043121788650751114\n",
      "batch accuracy: 0.9853515625\n",
      "doing 160 / 277\n",
      "elapsed time 2809.0644018650055\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0297 - accuracy: 0.9922\n",
      "batch loss: 0.029717132449150085\n",
      "batch accuracy: 0.9921875\n",
      "doing 161 / 277\n",
      "elapsed time 2817.4074444770813\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0454 - accuracy: 0.9844\n",
      "batch loss: 0.04538004845380783\n",
      "batch accuracy: 0.984375\n",
      "doing 162 / 277\n",
      "elapsed time 2830.6991744041443\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0456 - accuracy: 0.9844\n",
      "batch loss: 0.04563351720571518\n",
      "batch accuracy: 0.984375\n",
      "doing 163 / 277\n",
      "elapsed time 2841.2539777755737\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0421 - accuracy: 0.9893\n",
      "batch loss: 0.04205569624900818\n",
      "batch accuracy: 0.9892578125\n",
      "doing 164 / 277\n",
      "elapsed time 2850.2452545166016\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0542 - accuracy: 0.9844\n",
      "batch loss: 0.05415989086031914\n",
      "batch accuracy: 0.984375\n",
      "doing 165 / 277\n",
      "elapsed time 2862.8018033504486\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0334 - accuracy: 0.9902\n",
      "batch loss: 0.03335760533809662\n",
      "batch accuracy: 0.990234375\n",
      "doing 166 / 277\n",
      "elapsed time 2873.746765613556\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0431 - accuracy: 0.9814\n",
      "batch loss: 0.043086785823106766\n",
      "batch accuracy: 0.9814453125\n",
      "doing 167 / 277\n",
      "elapsed time 2880.281240463257\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0373 - accuracy: 0.9902\n",
      "batch loss: 0.037345558404922485\n",
      "batch accuracy: 0.990234375\n",
      "doing 168 / 277\n",
      "elapsed time 2891.8186333179474\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0477 - accuracy: 0.9863\n",
      "batch loss: 0.04767439514398575\n",
      "batch accuracy: 0.986328125\n",
      "doing 169 / 277\n",
      "elapsed time 2903.5033893585205\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0420 - accuracy: 0.9873\n",
      "batch loss: 0.041964560747146606\n",
      "batch accuracy: 0.9873046875\n",
      "doing 170 / 277\n",
      "elapsed time 2915.3102509975433\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0503 - accuracy: 0.9844\n",
      "batch loss: 0.05027332156896591\n",
      "batch accuracy: 0.984375\n",
      "doing 171 / 277\n",
      "elapsed time 2924.550944328308\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0510 - accuracy: 0.9824\n",
      "batch loss: 0.05104183405637741\n",
      "batch accuracy: 0.982421875\n",
      "doing 172 / 277\n",
      "elapsed time 2932.6593635082245\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0493 - accuracy: 0.9834\n",
      "batch loss: 0.04926036298274994\n",
      "batch accuracy: 0.9833984375\n",
      "doing 173 / 277\n",
      "elapsed time 2942.6716859340668\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0391 - accuracy: 0.9854\n",
      "batch loss: 0.03905177861452103\n",
      "batch accuracy: 0.9853515625\n",
      "doing 174 / 277\n",
      "elapsed time 2953.2265932559967\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0595 - accuracy: 0.9746\n",
      "batch loss: 0.05952947586774826\n",
      "batch accuracy: 0.974609375\n",
      "doing 175 / 277\n",
      "elapsed time 2959.294953107834\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0656 - accuracy: 0.9766\n",
      "batch loss: 0.06564338505268097\n",
      "batch accuracy: 0.9765625\n",
      "doing 176 / 277\n",
      "elapsed time 2968.7525250911713\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0443 - accuracy: 0.9863\n",
      "batch loss: 0.04425531625747681\n",
      "batch accuracy: 0.986328125\n",
      "doing 177 / 277\n",
      "elapsed time 2979.6177628040314\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0416 - accuracy: 0.9854\n",
      "batch loss: 0.04158410057425499\n",
      "batch accuracy: 0.9853515625\n",
      "doing 178 / 277\n",
      "elapsed time 2989.60853600502\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0429 - accuracy: 0.9854\n",
      "batch loss: 0.04289425536990166\n",
      "batch accuracy: 0.9853515625\n",
      "doing 179 / 277\n",
      "elapsed time 2996.11664891243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0406 - accuracy: 0.9863\n",
      "batch loss: 0.040565863251686096\n",
      "batch accuracy: 0.986328125\n",
      "doing 180 / 277\n",
      "elapsed time 3004.314973115921\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0441 - accuracy: 0.9824\n",
      "batch loss: 0.044068023562431335\n",
      "batch accuracy: 0.982421875\n",
      "doing 181 / 277\n",
      "elapsed time 3012.6449966430664\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0438 - accuracy: 0.9824\n",
      "batch loss: 0.04379711672663689\n",
      "batch accuracy: 0.982421875\n",
      "doing 182 / 277\n",
      "elapsed time 3018.54581451416\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0382 - accuracy: 0.9873\n",
      "batch loss: 0.03816884011030197\n",
      "batch accuracy: 0.9873046875\n",
      "doing 183 / 277\n",
      "elapsed time 3029.9282336235046\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0347 - accuracy: 0.9854\n",
      "batch loss: 0.03466526418924332\n",
      "batch accuracy: 0.9853515625\n",
      "doing 184 / 277\n",
      "elapsed time 3035.558381795883\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0290 - accuracy: 0.9932\n",
      "batch loss: 0.028993835672736168\n",
      "batch accuracy: 0.9931640625\n",
      "doing 185 / 277\n",
      "elapsed time 3043.308869600296\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0544 - accuracy: 0.9795\n",
      "batch loss: 0.05443950742483139\n",
      "batch accuracy: 0.9794921875\n",
      "doing 186 / 277\n",
      "elapsed time 3054.0872795581818\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0499 - accuracy: 0.9814\n",
      "batch loss: 0.049866847693920135\n",
      "batch accuracy: 0.9814453125\n",
      "doing 187 / 277\n",
      "elapsed time 3062.4474210739136\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0290 - accuracy: 0.9932\n",
      "batch loss: 0.029041780158877373\n",
      "batch accuracy: 0.9931640625\n",
      "doing 188 / 277\n",
      "elapsed time 3070.10467004776\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0362 - accuracy: 0.9883\n",
      "batch loss: 0.03617846965789795\n",
      "batch accuracy: 0.98828125\n",
      "doing 189 / 277\n",
      "elapsed time 3077.6145572662354\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0294 - accuracy: 0.9922\n",
      "batch loss: 0.029392912983894348\n",
      "batch accuracy: 0.9921875\n",
      "doing 190 / 277\n",
      "elapsed time 3088.334460258484\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0362 - accuracy: 0.9863\n",
      "batch loss: 0.036154769361019135\n",
      "batch accuracy: 0.986328125\n",
      "doing 191 / 277\n",
      "elapsed time 3097.005388736725\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0324 - accuracy: 0.9893\n",
      "batch loss: 0.03244633972644806\n",
      "batch accuracy: 0.9892578125\n",
      "doing 192 / 277\n",
      "elapsed time 3102.5352444648743\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0474 - accuracy: 0.9854\n",
      "batch loss: 0.04737721383571625\n",
      "batch accuracy: 0.9853515625\n",
      "doing 193 / 277\n",
      "elapsed time 3110.6240680217743\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0405 - accuracy: 0.9883\n",
      "batch loss: 0.04046685993671417\n",
      "batch accuracy: 0.98828125\n",
      "doing 194 / 277\n",
      "elapsed time 3115.9540791511536\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0292 - accuracy: 0.9893\n",
      "batch loss: 0.02924273908138275\n",
      "batch accuracy: 0.9892578125\n",
      "doing 195 / 277\n",
      "elapsed time 3122.703688144684\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0531 - accuracy: 0.9805\n",
      "batch loss: 0.05309273302555084\n",
      "batch accuracy: 0.98046875\n",
      "doing 196 / 277\n",
      "elapsed time 3131.395509004593\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0504 - accuracy: 0.9805\n",
      "batch loss: 0.05043840408325195\n",
      "batch accuracy: 0.98046875\n",
      "doing 197 / 277\n",
      "elapsed time 3138.1926743984222\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0451 - accuracy: 0.9844\n",
      "batch loss: 0.04514677822589874\n",
      "batch accuracy: 0.984375\n",
      "doing 198 / 277\n",
      "elapsed time 3143.5848252773285\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0555 - accuracy: 0.9785\n",
      "batch loss: 0.05552778020501137\n",
      "batch accuracy: 0.978515625\n",
      "doing 199 / 277\n",
      "elapsed time 3150.574567556381\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0412 - accuracy: 0.9854\n",
      "batch loss: 0.04123202711343765\n",
      "batch accuracy: 0.9853515625\n",
      "doing 200 / 277\n",
      "elapsed time 3155.963457584381\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0594 - accuracy: 0.9785\n",
      "batch loss: 0.05941091477870941\n",
      "batch accuracy: 0.978515625\n",
      "doing 201 / 277\n",
      "elapsed time 3163.815405368805\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0393 - accuracy: 0.9854\n",
      "batch loss: 0.03931877389550209\n",
      "batch accuracy: 0.9853515625\n",
      "doing 202 / 277\n",
      "elapsed time 3169.134140729904\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0536 - accuracy: 0.9824\n",
      "batch loss: 0.05361834168434143\n",
      "batch accuracy: 0.982421875\n",
      "doing 203 / 277\n",
      "elapsed time 3175.0740196704865\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0621 - accuracy: 0.9775\n",
      "batch loss: 0.06214895099401474\n",
      "batch accuracy: 0.9775390625\n",
      "doing 204 / 277\n",
      "elapsed time 3183.874671459198\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0456 - accuracy: 0.9824\n",
      "batch loss: 0.045646898448467255\n",
      "batch accuracy: 0.982421875\n",
      "doing 205 / 277\n",
      "elapsed time 3191.1018340587616\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0514 - accuracy: 0.9834\n",
      "batch loss: 0.051379941403865814\n",
      "batch accuracy: 0.9833984375\n",
      "doing 206 / 277\n",
      "elapsed time 3198.348654985428\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0368 - accuracy: 0.9893\n",
      "batch loss: 0.03679893538355827\n",
      "batch accuracy: 0.9892578125\n",
      "doing 207 / 277\n",
      "elapsed time 3202.8446412086487\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0441 - accuracy: 0.9834\n",
      "batch loss: 0.044099047780036926\n",
      "batch accuracy: 0.9833984375\n",
      "doing 208 / 277\n",
      "elapsed time 3208.932898044586\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0486 - accuracy: 0.9814\n",
      "batch loss: 0.04855100065469742\n",
      "batch accuracy: 0.9814453125\n",
      "doing 209 / 277\n",
      "elapsed time 3217.0322518348694\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0369 - accuracy: 0.9893\n",
      "batch loss: 0.03687050938606262\n",
      "batch accuracy: 0.9892578125\n",
      "doing 210 / 277\n",
      "elapsed time 3223.633961200714\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0386 - accuracy: 0.9824\n",
      "batch loss: 0.038556814193725586\n",
      "batch accuracy: 0.982421875\n",
      "doing 211 / 277\n",
      "elapsed time 3231.21232008934\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0459 - accuracy: 0.9805\n",
      "batch loss: 0.04588036984205246\n",
      "batch accuracy: 0.98046875\n",
      "doing 212 / 277\n",
      "elapsed time 3235.537296772003\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0427 - accuracy: 0.9854\n",
      "batch loss: 0.0426950566470623\n",
      "batch accuracy: 0.9853515625\n",
      "doing 213 / 277\n",
      "elapsed time 3242.1847882270813\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0446 - accuracy: 0.9824\n",
      "batch loss: 0.04462900012731552\n",
      "batch accuracy: 0.982421875\n",
      "doing 214 / 277\n",
      "elapsed time 3248.5043618679047\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0381 - accuracy: 0.9883\n",
      "batch loss: 0.03810880333185196\n",
      "batch accuracy: 0.98828125\n",
      "doing 215 / 277\n",
      "elapsed time 3252.5053346157074\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0647 - accuracy: 0.9746\n",
      "batch loss: 0.06469599902629852\n",
      "batch accuracy: 0.974609375\n",
      "doing 216 / 277\n",
      "elapsed time 3257.6232097148895\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0426 - accuracy: 0.9834\n",
      "batch loss: 0.042611852288246155\n",
      "batch accuracy: 0.9833984375\n",
      "doing 217 / 277\n",
      "elapsed time 3261.3867247104645\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0488 - accuracy: 0.9834\n",
      "batch loss: 0.04879875108599663\n",
      "batch accuracy: 0.9833984375\n",
      "doing 218 / 277\n",
      "elapsed time 3268.3093934059143\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0570 - accuracy: 0.9785\n",
      "batch loss: 0.057029157876968384\n",
      "batch accuracy: 0.978515625\n",
      "doing 219 / 277\n",
      "elapsed time 3272.2749605178833\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0556 - accuracy: 0.9814\n",
      "batch loss: 0.05555317923426628\n",
      "batch accuracy: 0.9814453125\n",
      "doing 220 / 277\n",
      "elapsed time 3277.442244529724\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0544 - accuracy: 0.9824\n",
      "batch loss: 0.054368603974580765\n",
      "batch accuracy: 0.982421875\n",
      "doing 221 / 277\n",
      "elapsed time 3284.0645451545715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0544 - accuracy: 0.9795\n",
      "batch loss: 0.054402925074100494\n",
      "batch accuracy: 0.9794921875\n",
      "doing 222 / 277\n",
      "elapsed time 3288.045137166977\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0413 - accuracy: 0.9883\n",
      "batch loss: 0.04134061187505722\n",
      "batch accuracy: 0.98828125\n",
      "doing 223 / 277\n",
      "elapsed time 3292.537333011627\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0412 - accuracy: 0.9863\n",
      "batch loss: 0.04116808623075485\n",
      "batch accuracy: 0.986328125\n",
      "doing 224 / 277\n",
      "elapsed time 3297.2477583885193\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0456 - accuracy: 0.9854\n",
      "batch loss: 0.04564359039068222\n",
      "batch accuracy: 0.9853515625\n",
      "doing 225 / 277\n",
      "elapsed time 3300.763157606125\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0457 - accuracy: 0.9863\n",
      "batch loss: 0.04569823667407036\n",
      "batch accuracy: 0.986328125\n",
      "doing 226 / 277\n",
      "elapsed time 3306.2113242149353\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0440 - accuracy: 0.9863\n",
      "batch loss: 0.04398141801357269\n",
      "batch accuracy: 0.986328125\n",
      "doing 227 / 277\n",
      "elapsed time 3311.825113296509\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0583 - accuracy: 0.9805\n",
      "batch loss: 0.05825403332710266\n",
      "batch accuracy: 0.98046875\n",
      "doing 228 / 277\n",
      "elapsed time 3314.8570053577423\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0374 - accuracy: 0.9902\n",
      "batch loss: 0.037417516112327576\n",
      "batch accuracy: 0.990234375\n",
      "doing 229 / 277\n",
      "elapsed time 3320.3541202545166\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0468 - accuracy: 0.9814\n",
      "batch loss: 0.04676508158445358\n",
      "batch accuracy: 0.9814453125\n",
      "doing 230 / 277\n",
      "elapsed time 3324.6855931282043\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0382 - accuracy: 0.9854\n",
      "batch loss: 0.03823626786470413\n",
      "batch accuracy: 0.9853515625\n",
      "doing 231 / 277\n",
      "elapsed time 3328.801731109619\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0357 - accuracy: 0.9902\n",
      "batch loss: 0.035730890929698944\n",
      "batch accuracy: 0.990234375\n",
      "doing 232 / 277\n",
      "elapsed time 3333.8153986930847\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0387 - accuracy: 0.9863\n",
      "batch loss: 0.038696929812431335\n",
      "batch accuracy: 0.986328125\n",
      "doing 233 / 277\n",
      "elapsed time 3337.8829147815704\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0408 - accuracy: 0.9844\n",
      "batch loss: 0.04076310247182846\n",
      "batch accuracy: 0.984375\n",
      "doing 234 / 277\n",
      "elapsed time 3341.7253506183624\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0299 - accuracy: 0.9902\n",
      "batch loss: 0.029885878786444664\n",
      "batch accuracy: 0.990234375\n",
      "doing 235 / 277\n",
      "elapsed time 3348.5215718746185\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0452 - accuracy: 0.9834\n",
      "batch loss: 0.04522665590047836\n",
      "batch accuracy: 0.9833984375\n",
      "doing 236 / 277\n",
      "elapsed time 3353.454268217087\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0339 - accuracy: 0.9844\n",
      "batch loss: 0.03391312062740326\n",
      "batch accuracy: 0.984375\n",
      "doing 237 / 277\n",
      "elapsed time 3356.7660043239594\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0380 - accuracy: 0.9863\n",
      "batch loss: 0.037994593381881714\n",
      "batch accuracy: 0.986328125\n",
      "doing 238 / 277\n",
      "elapsed time 3359.813009738922\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0508 - accuracy: 0.9863\n",
      "batch loss: 0.050848476588726044\n",
      "batch accuracy: 0.986328125\n",
      "doing 239 / 277\n",
      "elapsed time 3364.4114167690277\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0348 - accuracy: 0.9854\n",
      "batch loss: 0.034790147095918655\n",
      "batch accuracy: 0.9853515625\n",
      "doing 240 / 277\n",
      "elapsed time 3368.0409531593323\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0351 - accuracy: 0.9902\n",
      "batch loss: 0.035064537078142166\n",
      "batch accuracy: 0.990234375\n",
      "doing 241 / 277\n",
      "elapsed time 3371.1150579452515\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0389 - accuracy: 0.9883\n",
      "batch loss: 0.03894960880279541\n",
      "batch accuracy: 0.98828125\n",
      "doing 242 / 277\n",
      "elapsed time 3374.7059202194214\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0389 - accuracy: 0.9873\n",
      "batch loss: 0.03885873034596443\n",
      "batch accuracy: 0.9873046875\n",
      "doing 243 / 277\n",
      "elapsed time 3378.7546529769897\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0290 - accuracy: 0.9902\n",
      "batch loss: 0.02898501604795456\n",
      "batch accuracy: 0.990234375\n",
      "doing 244 / 277\n",
      "elapsed time 3381.7495346069336\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0241 - accuracy: 0.9932\n",
      "batch loss: 0.02410554699599743\n",
      "batch accuracy: 0.9931640625\n",
      "doing 245 / 277\n",
      "elapsed time 3384.7756836414337\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0467 - accuracy: 0.9844\n",
      "batch loss: 0.046651940792798996\n",
      "batch accuracy: 0.984375\n",
      "doing 246 / 277\n",
      "elapsed time 3389.154722929001\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0489 - accuracy: 0.9795\n",
      "batch loss: 0.048917584121227264\n",
      "batch accuracy: 0.9794921875\n",
      "doing 247 / 277\n",
      "elapsed time 3391.974142551422\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0375 - accuracy: 0.9883\n",
      "batch loss: 0.03750832751393318\n",
      "batch accuracy: 0.98828125\n",
      "doing 248 / 277\n",
      "elapsed time 3394.484513282776\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0383 - accuracy: 0.9824\n",
      "batch loss: 0.03830662742257118\n",
      "batch accuracy: 0.982421875\n",
      "doing 249 / 277\n",
      "elapsed time 3398.581286907196\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0497 - accuracy: 0.9775\n",
      "batch loss: 0.04974428191781044\n",
      "batch accuracy: 0.9775390625\n",
      "doing 250 / 277\n",
      "elapsed time 3401.2056255340576\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0352 - accuracy: 0.9893\n",
      "batch loss: 0.03521795570850372\n",
      "batch accuracy: 0.9892578125\n",
      "doing 251 / 277\n",
      "elapsed time 3403.7433290481567\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0486 - accuracy: 0.9814\n",
      "batch loss: 0.048640359193086624\n",
      "batch accuracy: 0.9814453125\n",
      "doing 252 / 277\n",
      "elapsed time 3407.5446100234985\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0300 - accuracy: 0.9893\n",
      "batch loss: 0.030031709000468254\n",
      "batch accuracy: 0.9892578125\n",
      "doing 253 / 277\n",
      "elapsed time 3409.92867064476\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0408 - accuracy: 0.9873\n",
      "batch loss: 0.04083758220076561\n",
      "batch accuracy: 0.9873046875\n",
      "doing 254 / 277\n",
      "elapsed time 3412.669226169586\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0439 - accuracy: 0.9883\n",
      "batch loss: 0.043919555842876434\n",
      "batch accuracy: 0.98828125\n",
      "doing 255 / 277\n",
      "elapsed time 3415.3041684627533\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0349 - accuracy: 0.9883\n",
      "batch loss: 0.034920815378427505\n",
      "batch accuracy: 0.98828125\n",
      "doing 256 / 277\n",
      "elapsed time 3417.7896797657013\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0501 - accuracy: 0.9785\n",
      "batch loss: 0.05013944208621979\n",
      "batch accuracy: 0.978515625\n",
      "doing 257 / 277\n",
      "elapsed time 3420.0562467575073\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0283 - accuracy: 0.9902\n",
      "batch loss: 0.028308633714914322\n",
      "batch accuracy: 0.990234375\n",
      "doing 258 / 277\n",
      "elapsed time 3422.315158843994\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0399 - accuracy: 0.9873\n",
      "batch loss: 0.03994334489107132\n",
      "batch accuracy: 0.9873046875\n",
      "doing 259 / 277\n",
      "elapsed time 3424.581354379654\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0319 - accuracy: 0.9883\n",
      "batch loss: 0.03188775107264519\n",
      "batch accuracy: 0.98828125\n",
      "doing 260 / 277\n",
      "elapsed time 3427.055764436722\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0352 - accuracy: 0.9902\n",
      "batch loss: 0.035191457718610764\n",
      "batch accuracy: 0.990234375\n",
      "doing 261 / 277\n",
      "elapsed time 3429.3234457969666\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0428 - accuracy: 0.9834\n",
      "batch loss: 0.04282659292221069\n",
      "batch accuracy: 0.9833984375\n",
      "doing 262 / 277\n",
      "elapsed time 3431.8354077339172\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0271 - accuracy: 0.9932\n",
      "batch loss: 0.02706887573003769\n",
      "batch accuracy: 0.9931640625\n",
      "doing 263 / 277\n",
      "elapsed time 3434.360413312912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0405 - accuracy: 0.9863\n",
      "batch loss: 0.04049845039844513\n",
      "batch accuracy: 0.986328125\n",
      "doing 264 / 277\n",
      "elapsed time 3436.684410095215\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0450 - accuracy: 0.9834\n",
      "batch loss: 0.04499110206961632\n",
      "batch accuracy: 0.9833984375\n",
      "doing 265 / 277\n",
      "elapsed time 3438.9655158519745\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0452 - accuracy: 0.9844\n",
      "batch loss: 0.045188918709754944\n",
      "batch accuracy: 0.984375\n",
      "doing 266 / 277\n",
      "elapsed time 3441.2347240448\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0550 - accuracy: 0.9795\n",
      "batch loss: 0.055011600255966187\n",
      "batch accuracy: 0.9794921875\n",
      "doing 267 / 277\n",
      "elapsed time 3443.4834611415863\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0541 - accuracy: 0.9795\n",
      "batch loss: 0.05411761254072189\n",
      "batch accuracy: 0.9794921875\n",
      "doing 268 / 277\n",
      "elapsed time 3445.7393770217896\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0328 - accuracy: 0.9873\n",
      "batch loss: 0.03277356177568436\n",
      "batch accuracy: 0.9873046875\n",
      "doing 269 / 277\n",
      "elapsed time 3448.063709497452\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0470 - accuracy: 0.9814\n",
      "batch loss: 0.046993836760520935\n",
      "batch accuracy: 0.9814453125\n",
      "doing 270 / 277\n",
      "elapsed time 3450.382066011429\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0437 - accuracy: 0.9834\n",
      "batch loss: 0.043722737580537796\n",
      "batch accuracy: 0.9833984375\n",
      "doing 271 / 277\n",
      "elapsed time 3452.68056845665\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0288 - accuracy: 0.9912\n",
      "batch loss: 0.028805531561374664\n",
      "batch accuracy: 0.9912109375\n",
      "doing 272 / 277\n",
      "elapsed time 3454.954332113266\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0469 - accuracy: 0.9873\n",
      "batch loss: 0.046940140426158905\n",
      "batch accuracy: 0.9873046875\n",
      "doing 273 / 277\n",
      "elapsed time 3457.5247542858124\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0527 - accuracy: 0.9824\n",
      "batch loss: 0.05266360938549042\n",
      "batch accuracy: 0.982421875\n",
      "doing 274 / 277\n",
      "elapsed time 3459.8084828853607\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0348 - accuracy: 0.9912\n",
      "batch loss: 0.03481975197792053\n",
      "batch accuracy: 0.9912109375\n",
      "doing 275 / 277\n",
      "elapsed time 3462.391609430313\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0416 - accuracy: 0.9863\n",
      "batch loss: 0.041640885174274445\n",
      "batch accuracy: 0.986328125\n",
      "doing 276 / 277\n",
      "elapsed time 3464.6072199344635\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0305 - accuracy: 0.9835\n",
      "batch loss: 0.03052441217005253\n",
      "batch accuracy: 0.9835466146469116\n",
      "Train loss 0.04092223414418284\n",
      "Train accuracy 0.9859796357929491\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 0.1577 - accuracy: 0.9527\n",
      "Validation loss: 0.1576656848192215\n",
      "Validation accuracy: 0.9526666402816772\n"
     ]
    }
   ],
   "source": [
    "model = vgg_model()\n",
    "epoch_train_loss = []\n",
    "epoch_train_acc = []\n",
    "epoch_validation_loss = []\n",
    "epoch_validation_acc = []\n",
    "for ep in range(epoch):\n",
    "    print(\"=\" * 50)\n",
    "    print(ep, \"/\", epoch)\n",
    "    step_loss = []\n",
    "    step_acc = []\n",
    "    \n",
    "    # batch_size=1000でHDDからバッチを取得する\n",
    "    for X_batch, Y_batch in get_batch(batch_size):\n",
    "        model.train_on_batch(X_batch, Y_batch)\n",
    "        score = model.evaluate(X_batch, Y_batch)\n",
    "        print(\"batch loss:\", score[0])\n",
    "        print(\"batch accuracy:\", score[1])\n",
    "        step_loss.append(score[0])\n",
    "        step_acc.append(score[1])\n",
    "    print(\"Train loss\", np.mean(step_loss))\n",
    "    print(\"Train accuracy\", np.mean(step_acc))\n",
    "    score = model.evaluate(x_validation, y_validation)\n",
    "    print(\"Validation loss:\", score[0])\n",
    "    print(\"Validation accuracy:\", score[1])\n",
    "    epoch_train_loss.append(np.mean(step_loss))\n",
    "    epoch_train_acc.append(np.mean(step_acc))\n",
    "    epoch_validation_loss.append(score[0])\n",
    "    epoch_validation_acc.append(score[1])\n",
    "    \n",
    "    shuffle_indices = random.sample(list(range(len(x_train))), len(x_train))\n",
    "    x_train = [x_train[i] for i in shuffle_indices]\n",
    "    y_train = y_train[shuffle_indices]\n",
    "    \n",
    "    model.save(cnn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|            Variable Name|    Memory|\n",
      " ------------------------------------ \n",
      "|       ImageDataGenerator|      1064|\n",
      "|                       In|       200|\n",
      "|                    Input|       144|\n",
      "|                    KFold|      1064|\n",
      "|          KerasClassifier|      1064|\n",
      "|            NOTEBOOK_NAME|        97|\n",
      "|                      Out|       248|\n",
      "|                     Pool|        72|\n",
      "|                   TRAINS|   2380496|\n",
      "|              VALIDATIONS|     38224|\n",
      "|                  X_batch|       144|\n",
      "|                  Y_batch|       112|\n",
      "|                      arr|     36072|\n",
      "|               batch_size|        28|\n",
      "|                 cnn_path|       116|\n",
      "|                     copy|        88|\n",
      "|             create_model|       144|\n",
      "|          cross_val_score|       144|\n",
      "|                      csv|        88|\n",
      "|                      cv2|        88|\n",
      "|                data_size|        28|\n",
      "|                 datapath|        59|\n",
      "|                   device|        80|\n",
      "|                  dirname|        57|\n",
      "|              encord_size|        28|\n",
      "|                       ep|        28|\n",
      "|                    epoch|        28|\n",
      "|          epoch_train_acc|       200|\n",
      "|         epoch_train_loss|       200|\n",
      "|     epoch_validation_acc|       200|\n",
      "|    epoch_validation_loss|       200|\n",
      "|                     exit|        64|\n",
      "|              faulty_case|       144|\n",
      "|                 filename|        58|\n",
      "|                filenames|       104|\n",
      "|                get_batch|       144|\n",
      "|              get_ipython|        72|\n",
      "|                     glob|        88|\n",
      "|                    image|        88|\n",
      "|                   joblib|        88|\n",
      "|                     join|       144|\n",
      "|                    keras|        88|\n",
      "|                   layers|        88|\n",
      "|               load_array|       144|\n",
      "|             logical_gpus|       104|\n",
      "|                 max_size|        28|\n",
      "|                    model|        64|\n",
      "|                   models|        88|\n",
      "|                    new_y|       112|\n",
      "|                       np|        88|\n",
      "|                       os|        88|\n",
      "|                        p|        64|\n",
      "|                       pd|        88|\n",
      "|         physical_devices|       104|\n",
      "|                   pickle|        88|\n",
      "|                      plt|        88|\n",
      "|                     quit|        64|\n",
      "|                   random|        88|\n",
      "|                    score|       104|\n",
      "|          shuffle_indices|   2265440|\n",
      "|                 step_acc|      2544|\n",
      "|                step_loss|      2544|\n",
      "|                      sys|        88|\n",
      "|                       tf|        88|\n",
      "|                   tfback|        88|\n",
      "|                     time|        88|\n",
      "|           to_categorical|       144|\n",
      "|         train_test_split|       144|\n",
      "|                vgg_model|       144|\n",
      "|                 warnings|        88|\n",
      "|                  x_train|   2380496|\n",
      "|             x_validation|       144|\n",
      "|                        y|     36112|\n",
      "|                  y_train|  10194268|\n",
      "|             y_validation|       112|\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n",
    "print(\" ------------------------------------ \")\n",
    "for var_name in dir():\n",
    "    if not var_name.startswith(\"_\"):\n",
    "        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストデータで評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = joblib.load('./data/multi_' + str(max_size) + '/test/xtest.pickle')\n",
    "y_test = joblib.load('./data/multi_' + str(max_size) + '/test/ytest.pickle')\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2716 - accuracy: 0.9333\n",
      "Test loss: 0.27158695459365845\n",
      "Test accuracy: 0.9333333373069763\n",
      "Train accuracy: 0.9859796357929491\n",
      "Validation accuracy: 0.9526666402816772\n",
      "Test accuracy: 0.9333333373069763\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "# score = model.evaluate(x_validation, y_validation)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "testscore = score[1]\n",
    "trainscore = epoch_train_acc[-1]\n",
    "valiscore = epoch_validation_acc[-1]\n",
    "print(\"Train accuracy:\", trainscore)\n",
    "print(\"Validation accuracy:\", valiscore)\n",
    "print(\"Test accuracy:\", testscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = np.argmax(model.predict(x_test), axis=1)\n",
    "y_test_max = np.argmax(y_test, axis=1)\n",
    "np.sum(y_test_max == y_predict, axis=0, dtype='float') / x_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- モデルは以下．\n",
    "    - 入力層\n",
    "    - 畳み込み層3つ\n",
    "    - Flatten層（1次元に）\n",
    "    - 全結合層3つ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 100, 100, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 100, 100, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 100, 100, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 9)                 297       \n",
      "=================================================================\n",
      "Total params: 15,012,041\n",
      "Trainable params: 15,012,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- accuracyグラフ，lossグラフは以下．\n",
    "- 5epoch程度で落ち着いている．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracy plot\n",
    "fig1 = plt.figure()\n",
    "plt.plot(epoch_train_acc)\n",
    "plt.plot(epoch_validation_acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "fig1.savefig(\"multisize_accuracy.png\")\n",
    "\n",
    "# loss plot\n",
    "fig2 = plt.figure()\n",
    "plt.plot(epoch_train_loss)\n",
    "plt.plot(epoch_validation_loss)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "fig2.savefig(\"multisize_loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    fmt = '.4f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.xticks([0, 1, 2, 3, 4, 5, 6, 7 ,8], [\"Center\", \"Donut\", \"Edge-Loc\", \"Edge-Ring\", \"Loc\", \"Near-full\", \"Random\", \"Scratch\", \"None\"])\n",
    "    plt.yticks([0, 1, 2, 3, 4, 5, 6, 7 ,8], [\"Center\", \"Donut\", \"Edge-Loc\", \"Edge-Ring\", \"Loc\", \"Near-full\", \"Random\", \"Scratch\", \"None\"])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- validation confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x1080 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "y_validation_predict = np.argmax(model.predict(x_validation), axis=1)\n",
    "y_validation_max = np.argmax(y_validation, axis=1)\n",
    "cnf_matrix = confusion_matrix(y_validation_max, y_validation_predict)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "from matplotlib import gridspec\n",
    "fig = plt.figure(figsize=(8, 15)) \n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 1]) \n",
    "\n",
    "## Plot non-normalized confusion matrix\n",
    "plt.subplot(gs[0])\n",
    "plot_confusion_matrix(cnf_matrix, title='Confusion matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.subplot(gs[1])\n",
    "plot_confusion_matrix(cnf_matrix, normalize=True, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"multisize_valiconfmat.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x1080 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "y_test_predict = np.argmax(model.predict(x_test), axis=1)\n",
    "y_test_max = np.argmax(y_test, axis=1)\n",
    "cnf_matrix = confusion_matrix(y_test_max, y_test_predict)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "from matplotlib import gridspec\n",
    "fig = plt.figure(figsize=(8, 15)) \n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 1]) \n",
    "\n",
    "## Plot non-normalized confusion matrix\n",
    "plt.subplot(gs[0])\n",
    "plot_confusion_matrix(cnf_matrix, title='Confusion matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.subplot(gs[1])\n",
    "plot_confusion_matrix(cnf_matrix, normalize=True, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"multisize_testconfmat.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SSLError",
     "evalue": "HTTPSConnectionPool(host='notify-api.line.me', port=443): Max retries exceeded with url: /api/notify (Caused by SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1076)')))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_new_proxy_conn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhttp_tunnel_required\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_proxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_prepare_proxy\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtls_in_tls_required\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connect_tls_proxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhostname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0mtls_in_tls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_connect_tls_proxy\u001b[0;34m(self, hostname, conn)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mssl_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mssl_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m         )\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    428\u001b[0m         ssl_sock = _ssl_wrap_socket_impl(\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtls_in_tls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         )\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m    869\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSSLError\u001b[0m: [SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1076)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    755\u001b[0m             retries = retries.increment(\n\u001b[0;32m--> 756\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m             )\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='notify-api.line.me', port=443): Max retries exceeded with url: /api/notify (Caused by SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1076)')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e7b2220b3d63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, proxies=proxies)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mline_notify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"学習が終了しました \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;31m# line_notify(\"Shawon: \" + str(shawon) + \", rotation_num: \" + str(rotation_num) + \", inversion: \" + str(inversion) + \", trials: \" + str(trials))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mline_notify_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"正解率\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multisize_accuracy.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-e7b2220b3d63>\u001b[0m in \u001b[0;36mline_notify\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;34m'https'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'https://proxy.uec.ac.jp:8080'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     }\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, proxies=proxies)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# LINEに画像を送る関数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \"\"\"\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_SSLError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# This branch is for urllib3 v1.22 and later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSSLError\u001b[0m: HTTPSConnectionPool(host='notify-api.line.me', port=443): Max retries exceeded with url: /api/notify (Caused by SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1076)')))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# LINEの設定\n",
    "path = './lineapi.txt'\n",
    "with open(path) as f:\n",
    "    s = f.read()\n",
    "    line_token = s.rstrip('\\n')\n",
    "\n",
    "# LINEに通知する関数\n",
    "def line_notify(text):\n",
    "    url = \"https://notify-api.line.me/api/notify\"\n",
    "    data = {\"message\": text}\n",
    "    headers = {\"Authorization\": \"Bearer \" + line_token}\n",
    "    proxies = {\n",
    "        'http': 'http://proxy.uec.ac.jp:8080',\n",
    "        'https': 'https://proxy.uec.ac.jp:8080',\n",
    "    }\n",
    "    requests.post(url, headers=headers)#, proxies=proxies)\n",
    "\n",
    "# LINEに画像を送る関数\n",
    "def line_notify_img(text, imgpath):\n",
    "    url = \"https://notify-api.line.me/api/notify\"\n",
    "    data = {\"message\": text, \"notificationDisabled\": True}\n",
    "    files = {\"imageFile\": open(imgpath, \"rb\")}\n",
    "    headers = {\"Authorization\": \"Bearer \" + line_token}\n",
    "    proxies = {\n",
    "        'http': 'http://proxy.uec.ac.jp:8080',\n",
    "        'https': 'https://proxy.uec.ac.jp:8080',\n",
    "    }\n",
    "    requests.post(url, data=data, files=files, headers=headers)#, proxies=proxies)\n",
    "    \n",
    "line_notify(\"学習が終了しました \")\n",
    "# line_notify(\"Shawon: \" + str(shawon) + \", rotation_num: \" + str(rotation_num) + \", inversion: \" + str(inversion) + \", trials: \" + str(trials))\n",
    "line_notify_img(\"正解率\", \"multisize_accuracy.png\")\n",
    "line_notify_img(\"Loss\", \"multisize_loss.png\")\n",
    "line_notify_img(\"validation混同行列\", \"multisize_valiconfmat.png\")\n",
    "line_notify_img(\"test混同行列\", \"multisize_testconfmat.png\")\n",
    "line_notify(\"train:\" + str(trainscore) + \"\\nvali:\" + str(valiscore) + \"\\ntest:\" + str(testscore))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wafermap",
   "language": "python",
   "name": "wafermap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
