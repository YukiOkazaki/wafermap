{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提案手法の実験（ラベルが適切か出力）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## マルチサイズ\n",
    "- データオーギュメンテーション（鏡映，回転を追加）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import，入力データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/LSWMD.pkl\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU') memory growth: True\n",
      "PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU') memory growth: True\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU'), LogicalDevice(name='/device:GPU:1', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LSWMD.pkl']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import copy\n",
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "if len(physical_devices) > 0:\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "        print('{} memory growth: {}'.format(device, tf.config.experimental.get_memory_growth(device)))\n",
    "else:\n",
    "    print(\"Not enough GPU hardware devices available\")\n",
    "logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "print(logical_gpus)\n",
    "import keras\n",
    "from tensorflow.keras import layers, Input, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier \n",
    "import keras.backend.tensorflow_backend as tfback\n",
    "# from tf.keras.utils import multi_gpu_model\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datapath = join('data', 'wafer')\n",
    "print(os.listdir(\"../input\"))\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define\n",
    "max_size = 100\n",
    "encord_size = int(max_size / 2)\n",
    "\n",
    "NOTEBOOK_NAME = 'wafermap_multisize_train_validation_rotation'\n",
    "cnn_path = './model/cnn_' + str(max_size) + '_' + NOTEBOOK_NAME + '.h5'\n",
    "\n",
    "epoch = 30\n",
    "batch_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faulty case list : ['Center', 'Donut', 'Edge-Loc', 'Edge-Ring', 'Loc', 'Near-full', 'Random', 'Scratch', 'none']\n"
     ]
    }
   ],
   "source": [
    "faulty_case = ['Center', 'Donut', 'Edge-Loc', 'Edge-Ring', 'Loc', 'Near-full', 'Random', 'Scratch', 'none']\n",
    "print('Faulty case list : {}'.format(faulty_case))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習を行う\n",
    "- 不良ラベルを0-8の9次元のベクトルとして表現する．\n",
    "- one-hotエンコーディングを行っている．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの読み出し"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire the .npy name\n",
    "data_size = len(glob.glob('./data/multi_' + str(max_size) + '/train_rotation/' + '*.npy'))\n",
    "TRAINS = ['./data/multi_' + str(max_size) + '/train_rotation/' + str(i) + '.npy' for i in range(data_size)]\n",
    "# one-hot-encoding\n",
    "y = joblib.load('./data/multi_' + str(max_size) + '/train_rotation/y.pickle')\n",
    "new_y = to_categorical(y)\n",
    "# split test\n",
    "\n",
    "# shuffle_indices = random.sample(list(range(len(TRAINS))), 10000)\n",
    "# TRAINS = [TRAINS[i] for i in shuffle_indices]\n",
    "# new_y = new_y[shuffle_indices]\n",
    "\n",
    "x_train = TRAINS\n",
    "y_train = new_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- validaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire the .npy name\n",
    "data_size = len(glob.glob('./data/multi_' + str(max_size) + '/validation_rotation/' + '*.npy'))\n",
    "VALIDATIONS = ['./data/multi_' + str(max_size) + '/validation_rotation/' + str(i) + '.npy' for i in range(data_size)]\n",
    "# one-hot-encoding\n",
    "y = joblib.load('./data/multi_' + str(max_size) + '/validation_rotation/y.pickle')\n",
    "new_y = to_categorical(y)\n",
    "# split test\n",
    "\n",
    "# shuffle_indices = random.sample(list(range(len(TRAINS))), 10000)\n",
    "# TRAINS = [TRAINS[i] for i in shuffle_indices]\n",
    "# new_y = new_y[shuffle_indices]\n",
    "\n",
    "x_validation = VALIDATIONS\n",
    "y_validation = new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchを取得する関数\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "def load_array(file):\n",
    "    return np.load(file)\n",
    "\n",
    "def get_batch(batch_size): \n",
    "    global x_train, y_train\n",
    "    SIZE = len(x_train)\n",
    "    # n_batchs\n",
    "    n_batchs = SIZE//batch_size + 1\n",
    "    # for でyield\n",
    "    i = 0\n",
    "    start = time.time()\n",
    "    while (i < n_batchs):\n",
    "        print(\"doing\", i, \"/\", n_batchs)\n",
    "        Y_batch = y_train[(i * batch_size):((i + 1) * batch_size)]\n",
    "        \n",
    "        #あるbatchのfilenameの配列を持っておく\n",
    "        X_batch_name = x_train[(i * batch_size):((i + 1) * batch_size)]\n",
    "\n",
    "        # filenameにしたがってバッチのtensorを構築\n",
    "        with Pool() as p:\n",
    "            arr = p.map(load_array, X_batch_name)\n",
    "            \n",
    "        X_batch = np.array(arr).reshape(len(X_batch_name), max_size, max_size, 3)\n",
    "#         X_batch = np.array([np.load(file)\n",
    "#                             for file in X_batch_name]).reshape(len(X_batch_name), max_size, max_size, 3)\n",
    "        i += 1\n",
    "        print('elapsed time', time.time()-start)\n",
    "        yield X_batch, Y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 学習データとテストデータに分割する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train x : 283171, y : (283171, 9)\n",
      "Validation x: 4500, y : (4500, 9)\n"
     ]
    }
   ],
   "source": [
    "print('Train x : {}, y : {}'.format(len(x_train), y_train.shape))\n",
    "print('Validation x: {}, y : {}'.format(len(x_validation), y_validation.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading X_validation...\n"
     ]
    }
   ],
   "source": [
    "print(\"loading X_validation...\")\n",
    "with Pool() as p:\n",
    "    arr = p.map(load_array, x_validation)\n",
    "\n",
    "x_validation = np.array(arr).reshape(len(x_validation), max_size, max_size, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 学習データ246635枚，テストデータ121477枚．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- モデルの定義を行う．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    with tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"], \n",
    "#     with tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\", \"/gpu:2\", \"/gpu:3\"], \n",
    "                                        cross_device_ops = tf.distribute.HierarchicalCopyAllReduce()).scope():\n",
    "        input_shape = (max_size, max_size, 3)\n",
    "        input_tensor = Input(input_shape)\n",
    "\n",
    "        conv_1 = layers.Conv2D(8, (3,3), activation='relu', padding='same')(input_tensor)\n",
    "        conv_2 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(conv_1)\n",
    "        conv_3 = layers.Conv2D(32, (3,3), activation='relu', padding='same')(conv_2)\n",
    "\n",
    "        flat = layers.Flatten()(conv_3)\n",
    "\n",
    "        dense_1 = layers.Dense(64, activation='relu')(flat)\n",
    "        dense_2 = layers.Dense(32, activation='relu')(dense_1)\n",
    "        output_tensor = layers.Dense(9, activation='softmax')(dense_2)\n",
    "\n",
    "        model = models.Model(input_tensor, output_tensor)\n",
    "        model.compile(optimizer='Adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3-Fold Cross validationで分割して学習する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = KerasClassifier(build_fn=create_model, epochs=30, batch_size=1024, verbose=1) \n",
    "# # 3-Fold Crossvalidation\n",
    "# kfold = KFold(n_splits=3, shuffle=True, random_state=2019) \n",
    "# # results = cross_val_score(model, x_train, y_train, cv=kfold)\n",
    "# # # Check 3-fold model's mean accuracy\n",
    "# # print('Simple CNN Cross validation score : {:.4f}'.format(np.mean(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cross validiationによる精度は99.55%であった．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cross validationなしで学習する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:XLA_GPU:0')\n",
      "Number of devices: 3\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\", \"device:XLA_GPU:0\"], cross_device_ops = tf.distribute.HierarchicalCopyAllReduce())\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=5\n",
    "batch_size=1024\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "0 / 5\n",
      "doing 0 / 277\n",
      "elapsed time 72.39500617980957\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9863\n",
      "batch loss: 0.060267165303230286\n",
      "batch accuracy: 0.986328125\n",
      "doing 1 / 277\n",
      "elapsed time 145.05249500274658\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 0.9844\n",
      "batch loss: 0.05654129758477211\n",
      "batch accuracy: 0.984375\n",
      "doing 2 / 277\n",
      "elapsed time 220.9268867969513\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 0.9863\n",
      "batch loss: 0.05194913223385811\n",
      "batch accuracy: 0.986328125\n",
      "doing 3 / 277\n",
      "elapsed time 297.1925048828125\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9863\n",
      "batch loss: 0.06226062402129173\n",
      "batch accuracy: 0.986328125\n",
      "doing 4 / 277\n",
      "elapsed time 372.2093186378479\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9854\n",
      "batch loss: 0.055125292390584946\n",
      "batch accuracy: 0.9853515625\n",
      "doing 5 / 277\n",
      "elapsed time 446.1424651145935\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0750 - accuracy: 0.9883\n",
      "batch loss: 0.07499565184116364\n",
      "batch accuracy: 0.98828125\n",
      "doing 6 / 277\n",
      "elapsed time 521.2089035511017\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0539 - accuracy: 0.9883\n",
      "batch loss: 0.05393659323453903\n",
      "batch accuracy: 0.98828125\n",
      "doing 7 / 277\n",
      "elapsed time 595.9520359039307\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9844\n",
      "batch loss: 0.06216064840555191\n",
      "batch accuracy: 0.984375\n",
      "doing 8 / 277\n",
      "elapsed time 670.7344522476196\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0733 - accuracy: 0.9795\n",
      "batch loss: 0.07331177592277527\n",
      "batch accuracy: 0.9794921875\n",
      "doing 9 / 277\n",
      "elapsed time 745.7443528175354\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.9834\n",
      "batch loss: 0.0652008205652237\n",
      "batch accuracy: 0.9833984375\n",
      "doing 10 / 277\n",
      "elapsed time 822.1393926143646\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9844\n",
      "batch loss: 0.05326293781399727\n",
      "batch accuracy: 0.984375\n",
      "doing 11 / 277\n",
      "elapsed time 895.0570585727692\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.9805\n",
      "batch loss: 0.0664776861667633\n",
      "batch accuracy: 0.98046875\n",
      "doing 12 / 277\n",
      "elapsed time 970.2612080574036\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.9824\n",
      "batch loss: 0.06018175184726715\n",
      "batch accuracy: 0.982421875\n",
      "doing 13 / 277\n",
      "elapsed time 1045.562974691391\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9844\n",
      "batch loss: 0.060431841760873795\n",
      "batch accuracy: 0.984375\n",
      "doing 14 / 277\n",
      "elapsed time 1122.0577099323273\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.9746\n",
      "batch loss: 0.07031142711639404\n",
      "batch accuracy: 0.974609375\n",
      "doing 15 / 277\n",
      "elapsed time 1195.3737847805023\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0454 - accuracy: 0.9912\n",
      "batch loss: 0.04538970813155174\n",
      "batch accuracy: 0.9912109375\n",
      "doing 16 / 277\n",
      "elapsed time 1268.8988647460938\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 0.9775\n",
      "batch loss: 0.05762891098856926\n",
      "batch accuracy: 0.9775390625\n",
      "doing 17 / 277\n",
      "elapsed time 1345.1277601718903\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 0.9902\n",
      "batch loss: 0.04354563355445862\n",
      "batch accuracy: 0.990234375\n",
      "doing 18 / 277\n",
      "elapsed time 1418.7868926525116\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9873\n",
      "batch loss: 0.055894363671541214\n",
      "batch accuracy: 0.9873046875\n",
      "doing 19 / 277\n",
      "elapsed time 1496.1340477466583\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0491 - accuracy: 0.9883\n",
      "batch loss: 0.049064066261053085\n",
      "batch accuracy: 0.98828125\n",
      "doing 20 / 277\n",
      "elapsed time 1571.081217288971\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9863\n",
      "batch loss: 0.0604654923081398\n",
      "batch accuracy: 0.986328125\n",
      "doing 21 / 277\n",
      "elapsed time 1645.6857335567474\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.9863\n",
      "batch loss: 0.04993806779384613\n",
      "batch accuracy: 0.986328125\n",
      "doing 22 / 277\n",
      "elapsed time 1719.457687139511\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0515 - accuracy: 0.9873\n",
      "batch loss: 0.051471494138240814\n",
      "batch accuracy: 0.9873046875\n",
      "doing 23 / 277\n",
      "elapsed time 1793.5807361602783\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.9834\n",
      "batch loss: 0.06526355445384979\n",
      "batch accuracy: 0.9833984375\n",
      "doing 24 / 277\n",
      "elapsed time 1869.444051027298\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.9805\n",
      "batch loss: 0.059571363031864166\n",
      "batch accuracy: 0.98046875\n",
      "doing 25 / 277\n",
      "elapsed time 1944.0092084407806\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0766 - accuracy: 0.9805\n",
      "batch loss: 0.07658949494361877\n",
      "batch accuracy: 0.98046875\n",
      "doing 26 / 277\n",
      "elapsed time 2019.8764436244965\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9902\n",
      "batch loss: 0.0488915890455246\n",
      "batch accuracy: 0.990234375\n",
      "doing 27 / 277\n",
      "elapsed time 2092.6795608997345\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9814\n",
      "batch loss: 0.07117188721895218\n",
      "batch accuracy: 0.9814453125\n",
      "doing 28 / 277\n",
      "elapsed time 2168.0404975414276\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.9854\n",
      "batch loss: 0.051704250276088715\n",
      "batch accuracy: 0.9853515625\n",
      "doing 29 / 277\n",
      "elapsed time 2244.366389274597\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9863\n",
      "batch loss: 0.07021526992321014\n",
      "batch accuracy: 0.986328125\n",
      "doing 30 / 277\n",
      "elapsed time 2319.4536933898926\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.9844\n",
      "batch loss: 0.05861777067184448\n",
      "batch accuracy: 0.984375\n",
      "doing 31 / 277\n",
      "elapsed time 2392.717144012451\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 0.9863\n",
      "batch loss: 0.0508279912173748\n",
      "batch accuracy: 0.986328125\n",
      "doing 32 / 277\n",
      "elapsed time 2465.3579819202423\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0521 - accuracy: 0.9902\n",
      "batch loss: 0.05209392309188843\n",
      "batch accuracy: 0.990234375\n",
      "doing 33 / 277\n",
      "elapsed time 2540.958156108856\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.9805\n",
      "batch loss: 0.06184646487236023\n",
      "batch accuracy: 0.98046875\n",
      "doing 34 / 277\n",
      "elapsed time 2615.8917760849\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9805\n",
      "batch loss: 0.0637870505452156\n",
      "batch accuracy: 0.98046875\n",
      "doing 35 / 277\n",
      "elapsed time 2689.9668695926666\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.9873\n",
      "batch loss: 0.05167212337255478\n",
      "batch accuracy: 0.9873046875\n",
      "doing 36 / 277\n",
      "elapsed time 2764.0810515880585\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.9824\n",
      "batch loss: 0.06776800751686096\n",
      "batch accuracy: 0.982421875\n",
      "doing 37 / 277\n",
      "elapsed time 2835.6411361694336\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9902\n",
      "batch loss: 0.057546935975551605\n",
      "batch accuracy: 0.990234375\n",
      "doing 38 / 277\n",
      "elapsed time 2908.228380203247\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.9844\n",
      "batch loss: 0.06203463673591614\n",
      "batch accuracy: 0.984375\n",
      "doing 39 / 277\n",
      "elapsed time 2984.6981859207153\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9941\n",
      "batch loss: 0.044401489198207855\n",
      "batch accuracy: 0.994140625\n",
      "doing 40 / 277\n",
      "elapsed time 3058.751316547394\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9893\n",
      "batch loss: 0.050168558955192566\n",
      "batch accuracy: 0.9892578125\n",
      "doing 41 / 277\n",
      "elapsed time 3132.4310944080353\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0542 - accuracy: 0.9854\n",
      "batch loss: 0.054216742515563965\n",
      "batch accuracy: 0.9853515625\n",
      "doing 42 / 277\n",
      "elapsed time 3206.4437844753265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9873\n",
      "batch loss: 0.04306091368198395\n",
      "batch accuracy: 0.9873046875\n",
      "doing 43 / 277\n",
      "elapsed time 3280.2623674869537\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0506 - accuracy: 0.9902\n",
      "batch loss: 0.05060010030865669\n",
      "batch accuracy: 0.990234375\n",
      "doing 44 / 277\n",
      "elapsed time 3354.723263502121\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.9883\n",
      "batch loss: 0.05960754677653313\n",
      "batch accuracy: 0.98828125\n",
      "doing 45 / 277\n",
      "elapsed time 3431.0185120105743\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9951\n",
      "batch loss: 0.04400277137756348\n",
      "batch accuracy: 0.9951171875\n",
      "doing 46 / 277\n",
      "elapsed time 3504.313545703888\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9883\n",
      "batch loss: 0.047905273735523224\n",
      "batch accuracy: 0.98828125\n",
      "doing 47 / 277\n",
      "elapsed time 3580.910957336426\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0524 - accuracy: 0.9824\n",
      "batch loss: 0.052360281348228455\n",
      "batch accuracy: 0.982421875\n",
      "doing 48 / 277\n",
      "elapsed time 3657.3882184028625\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9766\n",
      "batch loss: 0.0648605227470398\n",
      "batch accuracy: 0.9765625\n",
      "doing 49 / 277\n",
      "elapsed time 3731.6377923488617\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 0.9883\n",
      "batch loss: 0.0448925718665123\n",
      "batch accuracy: 0.98828125\n",
      "doing 50 / 277\n",
      "elapsed time 3805.133654356003\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9854\n",
      "batch loss: 0.05669812113046646\n",
      "batch accuracy: 0.9853515625\n",
      "doing 51 / 277\n",
      "elapsed time 3877.6705491542816\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.9814\n",
      "batch loss: 0.05966324731707573\n",
      "batch accuracy: 0.9814453125\n",
      "doing 52 / 277\n",
      "elapsed time 3952.479430437088\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.9814\n",
      "batch loss: 0.06299708038568497\n",
      "batch accuracy: 0.9814453125\n",
      "doing 53 / 277\n",
      "elapsed time 4028.872975587845\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.9844\n",
      "batch loss: 0.05910549312829971\n",
      "batch accuracy: 0.984375\n",
      "doing 54 / 277\n",
      "elapsed time 4100.351138114929\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.9873\n",
      "batch loss: 0.04992961883544922\n",
      "batch accuracy: 0.9873046875\n",
      "doing 55 / 277\n",
      "elapsed time 4173.786096096039\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9863\n",
      "batch loss: 0.04926563799381256\n",
      "batch accuracy: 0.986328125\n",
      "doing 56 / 277\n",
      "elapsed time 4249.349996328354\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9912\n",
      "batch loss: 0.03857356309890747\n",
      "batch accuracy: 0.9912109375\n",
      "doing 57 / 277\n",
      "elapsed time 4323.164567947388\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0486 - accuracy: 0.9912\n",
      "batch loss: 0.04856487736105919\n",
      "batch accuracy: 0.9912109375\n",
      "doing 58 / 277\n",
      "elapsed time 4395.383530378342\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0511 - accuracy: 0.9873\n",
      "batch loss: 0.05110198259353638\n",
      "batch accuracy: 0.9873046875\n",
      "doing 59 / 277\n",
      "elapsed time 4468.120147705078\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.9893\n",
      "batch loss: 0.04654745012521744\n",
      "batch accuracy: 0.9892578125\n",
      "doing 60 / 277\n",
      "elapsed time 4544.286995172501\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.9873\n",
      "batch loss: 0.05159955471754074\n",
      "batch accuracy: 0.9873046875\n",
      "doing 61 / 277\n",
      "elapsed time 4616.731211900711\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0399 - accuracy: 0.9932\n",
      "batch loss: 0.03994341567158699\n",
      "batch accuracy: 0.9931640625\n",
      "doing 62 / 277\n",
      "elapsed time 4686.70987868309\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0554 - accuracy: 0.9883\n",
      "batch loss: 0.05537315830588341\n",
      "batch accuracy: 0.98828125\n",
      "doing 63 / 277\n",
      "elapsed time 4761.974617242813\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0455 - accuracy: 0.9922\n",
      "batch loss: 0.04554099217057228\n",
      "batch accuracy: 0.9921875\n",
      "doing 64 / 277\n",
      "elapsed time 4835.90088891983\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9844\n",
      "batch loss: 0.048930615186691284\n",
      "batch accuracy: 0.984375\n",
      "doing 65 / 277\n",
      "elapsed time 4909.649446249008\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0552 - accuracy: 0.9863\n",
      "batch loss: 0.05524738132953644\n",
      "batch accuracy: 0.986328125\n",
      "doing 66 / 277\n",
      "elapsed time 4985.114570617676\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9902\n",
      "batch loss: 0.0476967953145504\n",
      "batch accuracy: 0.990234375\n",
      "doing 67 / 277\n",
      "elapsed time 5060.0536942481995\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 0.9834\n",
      "batch loss: 0.052914321422576904\n",
      "batch accuracy: 0.9833984375\n",
      "doing 68 / 277\n",
      "elapsed time 5136.671376466751\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9795\n",
      "batch loss: 0.062168072909116745\n",
      "batch accuracy: 0.9794921875\n",
      "doing 69 / 277\n",
      "elapsed time 5210.963187456131\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 0.9873\n",
      "batch loss: 0.05177711695432663\n",
      "batch accuracy: 0.9873046875\n",
      "doing 70 / 277\n",
      "elapsed time 5287.829870223999\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9893\n",
      "batch loss: 0.04890504851937294\n",
      "batch accuracy: 0.9892578125\n",
      "doing 71 / 277\n",
      "elapsed time 5363.611721277237\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0537 - accuracy: 0.9854\n",
      "batch loss: 0.0537194088101387\n",
      "batch accuracy: 0.9853515625\n",
      "doing 72 / 277\n",
      "elapsed time 5439.61666560173\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0826 - accuracy: 0.9727\n",
      "batch loss: 0.08262543380260468\n",
      "batch accuracy: 0.97265625\n",
      "doing 73 / 277\n",
      "elapsed time 5513.711732149124\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0483 - accuracy: 0.9893\n",
      "batch loss: 0.048328664153814316\n",
      "batch accuracy: 0.9892578125\n",
      "doing 74 / 277\n",
      "elapsed time 5585.704081535339\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.9844\n",
      "batch loss: 0.06194548308849335\n",
      "batch accuracy: 0.984375\n",
      "doing 75 / 277\n",
      "elapsed time 5661.520631551743\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9844\n",
      "batch loss: 0.04843977838754654\n",
      "batch accuracy: 0.984375\n",
      "doing 76 / 277\n",
      "elapsed time 5734.637105464935\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9854\n",
      "batch loss: 0.05065421387553215\n",
      "batch accuracy: 0.9853515625\n",
      "doing 77 / 277\n",
      "elapsed time 5809.073253154755\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.9912\n",
      "batch loss: 0.04039398580789566\n",
      "batch accuracy: 0.9912109375\n",
      "doing 78 / 277\n",
      "elapsed time 5886.441007375717\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.9863\n",
      "batch loss: 0.05924692749977112\n",
      "batch accuracy: 0.986328125\n",
      "doing 79 / 277\n",
      "elapsed time 5961.7289164066315\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.9746\n",
      "batch loss: 0.06759225577116013\n",
      "batch accuracy: 0.974609375\n",
      "doing 80 / 277\n",
      "elapsed time 6037.31453371048\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0589 - accuracy: 0.9834\n",
      "batch loss: 0.05887865275144577\n",
      "batch accuracy: 0.9833984375\n",
      "doing 81 / 277\n",
      "elapsed time 6112.864802122116\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.9912\n",
      "batch loss: 0.04979971796274185\n",
      "batch accuracy: 0.9912109375\n",
      "doing 82 / 277\n",
      "elapsed time 6188.396385908127\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9717\n",
      "batch loss: 0.07211318612098694\n",
      "batch accuracy: 0.9716796875\n",
      "doing 83 / 277\n",
      "elapsed time 6262.753248214722\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.9795\n",
      "batch loss: 0.06833376735448837\n",
      "batch accuracy: 0.9794921875\n",
      "doing 84 / 277\n",
      "elapsed time 6338.312244415283\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9873\n",
      "batch loss: 0.057407453656196594\n",
      "batch accuracy: 0.9873046875\n",
      "doing 85 / 277\n",
      "elapsed time 6411.856568574905\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9912\n",
      "batch loss: 0.038496725261211395\n",
      "batch accuracy: 0.9912109375\n",
      "doing 86 / 277\n",
      "elapsed time 6485.673109531403\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0558 - accuracy: 0.9844\n",
      "batch loss: 0.05577206611633301\n",
      "batch accuracy: 0.984375\n",
      "doing 87 / 277\n",
      "elapsed time 6559.471894741058\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0553 - accuracy: 0.9893\n",
      "batch loss: 0.055347613990306854\n",
      "batch accuracy: 0.9892578125\n",
      "doing 88 / 277\n",
      "elapsed time 6632.749299049377\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.9824\n",
      "batch loss: 0.05691063404083252\n",
      "batch accuracy: 0.982421875\n",
      "doing 89 / 277\n",
      "elapsed time 6706.202814102173\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9795\n",
      "batch loss: 0.06375695019960403\n",
      "batch accuracy: 0.9794921875\n",
      "doing 90 / 277\n",
      "elapsed time 6778.5221536159515\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9834\n",
      "batch loss: 0.06234046444296837\n",
      "batch accuracy: 0.9833984375\n",
      "doing 91 / 277\n",
      "elapsed time 6852.558648109436\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9766\n",
      "batch loss: 0.06432396173477173\n",
      "batch accuracy: 0.9765625\n",
      "doing 92 / 277\n",
      "elapsed time 6923.518443822861\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.9824\n",
      "batch loss: 0.059632427990436554\n",
      "batch accuracy: 0.982421875\n",
      "doing 93 / 277\n",
      "elapsed time 6998.011838197708\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0589 - accuracy: 0.9854\n",
      "batch loss: 0.05886448174715042\n",
      "batch accuracy: 0.9853515625\n",
      "doing 94 / 277\n",
      "elapsed time 7069.986373186111\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9805\n",
      "batch loss: 0.05006745457649231\n",
      "batch accuracy: 0.98046875\n",
      "doing 95 / 277\n",
      "elapsed time 7143.75204706192\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.9863\n",
      "batch loss: 0.0639159232378006\n",
      "batch accuracy: 0.986328125\n",
      "doing 96 / 277\n",
      "elapsed time 7218.170248746872\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0552 - accuracy: 0.9814\n",
      "batch loss: 0.055203601717948914\n",
      "batch accuracy: 0.9814453125\n",
      "doing 97 / 277\n",
      "elapsed time 7292.033982753754\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.9834\n",
      "batch loss: 0.05706271156668663\n",
      "batch accuracy: 0.9833984375\n",
      "doing 98 / 277\n",
      "elapsed time 7368.520616531372\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9785\n",
      "batch loss: 0.060486674308776855\n",
      "batch accuracy: 0.978515625\n",
      "doing 99 / 277\n",
      "elapsed time 7443.719777584076\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.9824\n",
      "batch loss: 0.059700027108192444\n",
      "batch accuracy: 0.982421875\n",
      "doing 100 / 277\n",
      "elapsed time 7519.519644498825\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9902\n",
      "batch loss: 0.04467541351914406\n",
      "batch accuracy: 0.990234375\n",
      "doing 101 / 277\n",
      "elapsed time 7596.695418834686\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.9854\n",
      "batch loss: 0.06288736313581467\n",
      "batch accuracy: 0.9853515625\n",
      "doing 102 / 277\n",
      "elapsed time 7665.320095300674\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0754 - accuracy: 0.9795\n",
      "batch loss: 0.07541979849338531\n",
      "batch accuracy: 0.9794921875\n",
      "doing 103 / 277\n",
      "elapsed time 7742.444797754288\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 0.9805\n",
      "batch loss: 0.058745209127664566\n",
      "batch accuracy: 0.98046875\n",
      "doing 104 / 277\n",
      "elapsed time 7817.182723522186\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0835 - accuracy: 0.9756\n",
      "batch loss: 0.08353643119335175\n",
      "batch accuracy: 0.9755859375\n",
      "doing 105 / 277\n",
      "elapsed time 7892.224997282028\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0535 - accuracy: 0.9844\n",
      "batch loss: 0.05346224457025528\n",
      "batch accuracy: 0.984375\n",
      "doing 106 / 277\n",
      "elapsed time 7965.302853345871\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.9873\n",
      "batch loss: 0.051701683551073074\n",
      "batch accuracy: 0.9873046875\n",
      "doing 107 / 277\n",
      "elapsed time 8040.700912237167\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.9775\n",
      "batch loss: 0.06484577059745789\n",
      "batch accuracy: 0.9775390625\n",
      "doing 108 / 277\n",
      "elapsed time 8116.115002155304\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9834\n",
      "batch loss: 0.04739096015691757\n",
      "batch accuracy: 0.9833984375\n",
      "doing 109 / 277\n",
      "elapsed time 8191.606750249863\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.9834\n",
      "batch loss: 0.05954720079898834\n",
      "batch accuracy: 0.9833984375\n",
      "doing 110 / 277\n",
      "elapsed time 8265.834239959717\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.9844\n",
      "batch loss: 0.05779065936803818\n",
      "batch accuracy: 0.984375\n",
      "doing 111 / 277\n",
      "elapsed time 8344.340853691101\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9863\n",
      "batch loss: 0.05220041424036026\n",
      "batch accuracy: 0.986328125\n",
      "doing 112 / 277\n",
      "elapsed time 8420.254452466965\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0734 - accuracy: 0.9834\n",
      "batch loss: 0.07336287200450897\n",
      "batch accuracy: 0.9833984375\n",
      "doing 113 / 277\n",
      "elapsed time 8498.63208937645\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.9854\n",
      "batch loss: 0.05679088085889816\n",
      "batch accuracy: 0.9853515625\n",
      "doing 114 / 277\n",
      "elapsed time 8575.672590732574\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.9785\n",
      "batch loss: 0.06520750373601913\n",
      "batch accuracy: 0.978515625\n",
      "doing 115 / 277\n",
      "elapsed time 8653.449144124985\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0550 - accuracy: 0.9844\n",
      "batch loss: 0.054950129240751266\n",
      "batch accuracy: 0.984375\n",
      "doing 116 / 277\n",
      "elapsed time 8731.44120335579\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9902\n",
      "batch loss: 0.04286131262779236\n",
      "batch accuracy: 0.990234375\n",
      "doing 117 / 277\n",
      "elapsed time 8810.082207679749\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9717\n",
      "batch loss: 0.07205282151699066\n",
      "batch accuracy: 0.9716796875\n",
      "doing 118 / 277\n",
      "elapsed time 8885.463586807251\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0481 - accuracy: 0.9863\n",
      "batch loss: 0.04808341711759567\n",
      "batch accuracy: 0.986328125\n",
      "doing 119 / 277\n",
      "elapsed time 8963.370419025421\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.9775\n",
      "batch loss: 0.05912065505981445\n",
      "batch accuracy: 0.9775390625\n",
      "doing 120 / 277\n",
      "elapsed time 9038.227452754974\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.9805\n",
      "batch loss: 0.06087716668844223\n",
      "batch accuracy: 0.98046875\n",
      "doing 121 / 277\n",
      "elapsed time 9113.735969305038\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9873\n",
      "batch loss: 0.04931335151195526\n",
      "batch accuracy: 0.9873046875\n",
      "doing 122 / 277\n",
      "elapsed time 9188.385565280914\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.9795\n",
      "batch loss: 0.05797411501407623\n",
      "batch accuracy: 0.9794921875\n",
      "doing 123 / 277\n",
      "elapsed time 9269.121181488037\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9922\n",
      "batch loss: 0.047664716839790344\n",
      "batch accuracy: 0.9921875\n",
      "doing 124 / 277\n",
      "elapsed time 9345.726305246353\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0554 - accuracy: 0.9824\n",
      "batch loss: 0.05540841817855835\n",
      "batch accuracy: 0.982421875\n",
      "doing 125 / 277\n",
      "elapsed time 9422.072295665741\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.9854\n",
      "batch loss: 0.05125737935304642\n",
      "batch accuracy: 0.9853515625\n",
      "doing 126 / 277\n",
      "elapsed time 9498.51070356369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.9814\n",
      "batch loss: 0.06992369890213013\n",
      "batch accuracy: 0.9814453125\n",
      "doing 127 / 277\n",
      "elapsed time 9576.001121997833\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.9805\n",
      "batch loss: 0.062417879700660706\n",
      "batch accuracy: 0.98046875\n",
      "doing 128 / 277\n",
      "elapsed time 9653.946919679642\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0815 - accuracy: 0.9727\n",
      "batch loss: 0.0814911425113678\n",
      "batch accuracy: 0.97265625\n",
      "doing 129 / 277\n",
      "elapsed time 9732.864505052567\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 0.9854\n",
      "batch loss: 0.05184021592140198\n",
      "batch accuracy: 0.9853515625\n",
      "doing 130 / 277\n",
      "elapsed time 9812.124623060226\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0515 - accuracy: 0.9834\n",
      "batch loss: 0.051512107253074646\n",
      "batch accuracy: 0.9833984375\n",
      "doing 131 / 277\n",
      "elapsed time 9888.780188798904\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9893\n",
      "batch loss: 0.04657409340143204\n",
      "batch accuracy: 0.9892578125\n",
      "doing 132 / 277\n",
      "elapsed time 9965.00630235672\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9893\n",
      "batch loss: 0.05143212899565697\n",
      "batch accuracy: 0.9892578125\n",
      "doing 133 / 277\n",
      "elapsed time 10044.32555603981\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9746\n",
      "batch loss: 0.07235880196094513\n",
      "batch accuracy: 0.974609375\n",
      "doing 134 / 277\n",
      "elapsed time 10120.779634714127\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0537 - accuracy: 0.9834\n",
      "batch loss: 0.05365673080086708\n",
      "batch accuracy: 0.9833984375\n",
      "doing 135 / 277\n",
      "elapsed time 10200.259627103806\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9834\n",
      "batch loss: 0.06443116813898087\n",
      "batch accuracy: 0.9833984375\n",
      "doing 136 / 277\n",
      "elapsed time 10282.078588724136\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.9736\n",
      "batch loss: 0.06985026597976685\n",
      "batch accuracy: 0.9736328125\n",
      "doing 137 / 277\n",
      "elapsed time 10359.431468248367\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.9795\n",
      "batch loss: 0.06298350542783737\n",
      "batch accuracy: 0.9794921875\n",
      "doing 138 / 277\n",
      "elapsed time 10438.329764604568\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 0.9814\n",
      "batch loss: 0.05874209851026535\n",
      "batch accuracy: 0.9814453125\n",
      "doing 139 / 277\n",
      "elapsed time 10516.589337587357\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.9795\n",
      "batch loss: 0.0688171535730362\n",
      "batch accuracy: 0.9794921875\n",
      "doing 140 / 277\n",
      "elapsed time 10595.947439193726\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0772 - accuracy: 0.9844\n",
      "batch loss: 0.07717972993850708\n",
      "batch accuracy: 0.984375\n",
      "doing 141 / 277\n",
      "elapsed time 10678.307040929794\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.9814\n",
      "batch loss: 0.05711245909333229\n",
      "batch accuracy: 0.9814453125\n",
      "doing 142 / 277\n",
      "elapsed time 10757.058552503586\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.9814\n",
      "batch loss: 0.06366290152072906\n",
      "batch accuracy: 0.9814453125\n",
      "doing 143 / 277\n",
      "elapsed time 10836.886258840561\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.9814\n",
      "batch loss: 0.06014120578765869\n",
      "batch accuracy: 0.9814453125\n",
      "doing 144 / 277\n",
      "elapsed time 10917.075487852097\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 0.9863\n",
      "batch loss: 0.05279845744371414\n",
      "batch accuracy: 0.986328125\n",
      "doing 145 / 277\n",
      "elapsed time 10997.441180467606\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.9873\n",
      "batch loss: 0.05838870257139206\n",
      "batch accuracy: 0.9873046875\n",
      "doing 146 / 277\n",
      "elapsed time 11077.140078544617\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0771 - accuracy: 0.9736\n",
      "batch loss: 0.07705361396074295\n",
      "batch accuracy: 0.9736328125\n",
      "doing 147 / 277\n",
      "elapsed time 11159.513576507568\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 0.9775\n",
      "batch loss: 0.0599944069981575\n",
      "batch accuracy: 0.9775390625\n",
      "doing 148 / 277\n",
      "elapsed time 11237.810736894608\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.9834\n",
      "batch loss: 0.06509373337030411\n",
      "batch accuracy: 0.9833984375\n",
      "doing 149 / 277\n",
      "elapsed time 11316.247213602066\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0797 - accuracy: 0.9824\n",
      "batch loss: 0.07969508320093155\n",
      "batch accuracy: 0.982421875\n",
      "doing 150 / 277\n",
      "elapsed time 11397.593062639236\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.9854\n",
      "batch loss: 0.056950509548187256\n",
      "batch accuracy: 0.9853515625\n",
      "doing 151 / 277\n",
      "elapsed time 11479.5942902565\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9893\n",
      "batch loss: 0.04322775825858116\n",
      "batch accuracy: 0.9892578125\n",
      "doing 152 / 277\n",
      "elapsed time 11560.663813352585\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.9785\n",
      "batch loss: 0.06330734491348267\n",
      "batch accuracy: 0.978515625\n",
      "doing 153 / 277\n",
      "elapsed time 11640.969502687454\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9795\n",
      "batch loss: 0.06110634654760361\n",
      "batch accuracy: 0.9794921875\n",
      "doing 154 / 277\n",
      "elapsed time 11721.95835185051\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9834\n",
      "batch loss: 0.06280699372291565\n",
      "batch accuracy: 0.9833984375\n",
      "doing 155 / 277\n",
      "elapsed time 11804.356038808823\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.9727\n",
      "batch loss: 0.0677216425538063\n",
      "batch accuracy: 0.97265625\n",
      "doing 156 / 277\n",
      "elapsed time 11881.569738864899\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9893\n",
      "batch loss: 0.04903833195567131\n",
      "batch accuracy: 0.9892578125\n",
      "doing 157 / 277\n",
      "elapsed time 11960.319671154022\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0563 - accuracy: 0.9795\n",
      "batch loss: 0.05627240985631943\n",
      "batch accuracy: 0.9794921875\n",
      "doing 158 / 277\n",
      "elapsed time 12042.773655891418\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9746\n",
      "batch loss: 0.06588175892829895\n",
      "batch accuracy: 0.974609375\n",
      "doing 159 / 277\n",
      "elapsed time 12124.028308153152\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.9775\n",
      "batch loss: 0.061813630163669586\n",
      "batch accuracy: 0.9775390625\n",
      "doing 160 / 277\n",
      "elapsed time 12205.247018098831\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0754 - accuracy: 0.9824\n",
      "batch loss: 0.07542582601308823\n",
      "batch accuracy: 0.982421875\n",
      "doing 161 / 277\n",
      "elapsed time 12289.074697256088\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0772 - accuracy: 0.9814\n",
      "batch loss: 0.07723630964756012\n",
      "batch accuracy: 0.9814453125\n",
      "doing 162 / 277\n",
      "elapsed time 12372.07546710968\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.9775\n",
      "batch loss: 0.06629584729671478\n",
      "batch accuracy: 0.9775390625\n",
      "doing 163 / 277\n",
      "elapsed time 12452.347469806671\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.9766\n",
      "batch loss: 0.06623118370771408\n",
      "batch accuracy: 0.9765625\n",
      "doing 164 / 277\n",
      "elapsed time 12537.066625118256\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9863\n",
      "batch loss: 0.060614295303821564\n",
      "batch accuracy: 0.986328125\n",
      "doing 165 / 277\n",
      "elapsed time 12615.652598619461\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0725 - accuracy: 0.9785\n",
      "batch loss: 0.07250366359949112\n",
      "batch accuracy: 0.978515625\n",
      "doing 166 / 277\n",
      "elapsed time 12696.25395321846\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.9775\n",
      "batch loss: 0.06692174077033997\n",
      "batch accuracy: 0.9775390625\n",
      "doing 167 / 277\n",
      "elapsed time 12778.017516374588\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9922\n",
      "batch loss: 0.049007952213287354\n",
      "batch accuracy: 0.9921875\n",
      "doing 168 / 277\n",
      "elapsed time 12861.108929157257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.9893\n",
      "batch loss: 0.04937659204006195\n",
      "batch accuracy: 0.9892578125\n",
      "doing 169 / 277\n",
      "elapsed time 12942.663646697998\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0782 - accuracy: 0.9697\n",
      "batch loss: 0.07820864021778107\n",
      "batch accuracy: 0.9697265625\n",
      "doing 170 / 277\n",
      "elapsed time 13021.367506742477\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0554 - accuracy: 0.9873\n",
      "batch loss: 0.05541949346661568\n",
      "batch accuracy: 0.9873046875\n",
      "doing 171 / 277\n",
      "elapsed time 13100.56882596016\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0539 - accuracy: 0.9844\n",
      "batch loss: 0.0538620725274086\n",
      "batch accuracy: 0.984375\n",
      "doing 172 / 277\n",
      "elapsed time 13181.114670753479\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9854\n",
      "batch loss: 0.04848765581846237\n",
      "batch accuracy: 0.9853515625\n",
      "doing 173 / 277\n",
      "elapsed time 13261.73238992691\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.9795\n",
      "batch loss: 0.06089422106742859\n",
      "batch accuracy: 0.9794921875\n",
      "doing 174 / 277\n",
      "elapsed time 13344.533753156662\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.9785\n",
      "batch loss: 0.05989905446767807\n",
      "batch accuracy: 0.978515625\n",
      "doing 175 / 277\n",
      "elapsed time 13428.571073055267\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.9854\n",
      "batch loss: 0.06539994478225708\n",
      "batch accuracy: 0.9853515625\n",
      "doing 176 / 277\n",
      "elapsed time 13509.750814437866\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.9824\n",
      "batch loss: 0.05948936194181442\n",
      "batch accuracy: 0.982421875\n",
      "doing 177 / 277\n",
      "elapsed time 13590.126514911652\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9922\n",
      "batch loss: 0.04266298934817314\n",
      "batch accuracy: 0.9921875\n",
      "doing 178 / 277\n",
      "elapsed time 13672.41803407669\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.9844\n",
      "batch loss: 0.05607079714536667\n",
      "batch accuracy: 0.984375\n",
      "doing 179 / 277\n",
      "elapsed time 13753.547865867615\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0539 - accuracy: 0.9863\n",
      "batch loss: 0.05385979264974594\n",
      "batch accuracy: 0.986328125\n",
      "doing 180 / 277\n",
      "elapsed time 13834.37325167656\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.9912\n",
      "batch loss: 0.04501598700881004\n",
      "batch accuracy: 0.9912109375\n",
      "doing 181 / 277\n",
      "elapsed time 13915.226881980896\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.9824\n",
      "batch loss: 0.056070346385240555\n",
      "batch accuracy: 0.982421875\n",
      "doing 182 / 277\n",
      "elapsed time 13996.030350446701\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9863\n",
      "batch loss: 0.048941440880298615\n",
      "batch accuracy: 0.986328125\n",
      "doing 183 / 277\n",
      "elapsed time 14075.658598661423\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 0.9824\n",
      "batch loss: 0.05076291412115097\n",
      "batch accuracy: 0.982421875\n",
      "doing 184 / 277\n",
      "elapsed time 14157.996860742569\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 0.9854\n",
      "batch loss: 0.05177154392004013\n",
      "batch accuracy: 0.9853515625\n",
      "doing 185 / 277\n",
      "elapsed time 14244.435156345367\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0530 - accuracy: 0.9883\n",
      "batch loss: 0.052968040108680725\n",
      "batch accuracy: 0.98828125\n",
      "doing 186 / 277\n",
      "elapsed time 14331.52337694168\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.9834\n",
      "batch loss: 0.056095413863658905\n",
      "batch accuracy: 0.9833984375\n",
      "doing 187 / 277\n",
      "elapsed time 14416.157764434814\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.9863\n",
      "batch loss: 0.0516221858561039\n",
      "batch accuracy: 0.986328125\n",
      "doing 188 / 277\n",
      "elapsed time 14500.621173858643\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9863\n",
      "batch loss: 0.04660147428512573\n",
      "batch accuracy: 0.986328125\n",
      "doing 189 / 277\n",
      "elapsed time 14583.004605293274\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9873\n",
      "batch loss: 0.05482759326696396\n",
      "batch accuracy: 0.9873046875\n",
      "doing 190 / 277\n",
      "elapsed time 14669.439548015594\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0448 - accuracy: 0.9873\n",
      "batch loss: 0.0447571761906147\n",
      "batch accuracy: 0.9873046875\n",
      "doing 191 / 277\n",
      "elapsed time 14753.485306739807\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 0.9863\n",
      "batch loss: 0.05869309604167938\n",
      "batch accuracy: 0.986328125\n",
      "doing 192 / 277\n",
      "elapsed time 14837.593811273575\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.9854\n",
      "batch loss: 0.06238269805908203\n",
      "batch accuracy: 0.9853515625\n",
      "doing 193 / 277\n",
      "elapsed time 14921.553429841995\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9834\n",
      "batch loss: 0.054811425507068634\n",
      "batch accuracy: 0.9833984375\n",
      "doing 194 / 277\n",
      "elapsed time 15007.653907060623\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0430 - accuracy: 0.9883\n",
      "batch loss: 0.043003149330616\n",
      "batch accuracy: 0.98828125\n",
      "doing 195 / 277\n",
      "elapsed time 15093.531644105911\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0486 - accuracy: 0.9844\n",
      "batch loss: 0.04862704128026962\n",
      "batch accuracy: 0.984375\n",
      "doing 196 / 277\n",
      "elapsed time 15178.139076471329\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9854\n",
      "batch loss: 0.04534061253070831\n",
      "batch accuracy: 0.9853515625\n",
      "doing 197 / 277\n",
      "elapsed time 15264.600806236267\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0454 - accuracy: 0.9902\n",
      "batch loss: 0.04542416334152222\n",
      "batch accuracy: 0.990234375\n",
      "doing 198 / 277\n",
      "elapsed time 15350.002872467041\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.9814\n",
      "batch loss: 0.06466726213693619\n",
      "batch accuracy: 0.9814453125\n",
      "doing 199 / 277\n",
      "elapsed time 15435.698004722595\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0471 - accuracy: 0.9873\n",
      "batch loss: 0.047079041600227356\n",
      "batch accuracy: 0.9873046875\n",
      "doing 200 / 277\n",
      "elapsed time 15524.922156333923\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9805\n",
      "batch loss: 0.057500094175338745\n",
      "batch accuracy: 0.98046875\n",
      "doing 201 / 277\n",
      "elapsed time 15608.494403362274\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0481 - accuracy: 0.9883\n",
      "batch loss: 0.04808666184544563\n",
      "batch accuracy: 0.98828125\n",
      "doing 202 / 277\n",
      "elapsed time 15694.954258203506\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.9863\n",
      "batch loss: 0.04935307055711746\n",
      "batch accuracy: 0.986328125\n",
      "doing 203 / 277\n",
      "elapsed time 15781.926115989685\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.9844\n",
      "batch loss: 0.05169839411973953\n",
      "batch accuracy: 0.984375\n",
      "doing 204 / 277\n",
      "elapsed time 15866.643318653107\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.9854\n",
      "batch loss: 0.05937708169221878\n",
      "batch accuracy: 0.9853515625\n",
      "doing 205 / 277\n",
      "elapsed time 15952.063586711884\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9893\n",
      "batch loss: 0.04770437628030777\n",
      "batch accuracy: 0.9892578125\n",
      "doing 206 / 277\n",
      "elapsed time 16038.674045801163\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.9766\n",
      "batch loss: 0.05693893879652023\n",
      "batch accuracy: 0.9765625\n",
      "doing 207 / 277\n",
      "elapsed time 16117.146951675415\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9766\n",
      "batch loss: 0.06590371578931808\n",
      "batch accuracy: 0.9765625\n",
      "doing 208 / 277\n",
      "elapsed time 16197.79068684578\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.9883\n",
      "batch loss: 0.05157206207513809\n",
      "batch accuracy: 0.98828125\n",
      "doing 209 / 277\n",
      "elapsed time 16279.398308038712\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9863\n",
      "batch loss: 0.04056676849722862\n",
      "batch accuracy: 0.986328125\n",
      "doing 210 / 277\n",
      "elapsed time 16363.956964969635\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9785\n",
      "batch loss: 0.06042618677020073\n",
      "batch accuracy: 0.978515625\n",
      "doing 211 / 277\n",
      "elapsed time 16447.963625192642\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0512 - accuracy: 0.9863\n",
      "batch loss: 0.05115221068263054\n",
      "batch accuracy: 0.986328125\n",
      "doing 212 / 277\n",
      "elapsed time 16530.170112609863\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9863\n",
      "batch loss: 0.05101696401834488\n",
      "batch accuracy: 0.986328125\n",
      "doing 213 / 277\n",
      "elapsed time 16618.473452329636\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0472 - accuracy: 0.9893\n",
      "batch loss: 0.0472247488796711\n",
      "batch accuracy: 0.9892578125\n",
      "doing 214 / 277\n",
      "elapsed time 16707.676961660385\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0554 - accuracy: 0.9844\n",
      "batch loss: 0.05544202774763107\n",
      "batch accuracy: 0.984375\n",
      "doing 215 / 277\n",
      "elapsed time 16795.295681476593\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.9863\n",
      "batch loss: 0.057827044278383255\n",
      "batch accuracy: 0.986328125\n",
      "doing 216 / 277\n",
      "elapsed time 16887.93859052658\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.9824\n",
      "batch loss: 0.06647631525993347\n",
      "batch accuracy: 0.982421875\n",
      "doing 217 / 277\n",
      "elapsed time 16978.538469314575\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.9863\n",
      "batch loss: 0.04148846119642258\n",
      "batch accuracy: 0.986328125\n",
      "doing 218 / 277\n",
      "elapsed time 17071.725165605545\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0535 - accuracy: 0.9863\n",
      "batch loss: 0.053547851741313934\n",
      "batch accuracy: 0.986328125\n",
      "doing 219 / 277\n",
      "elapsed time 17161.027851343155\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.9766\n",
      "batch loss: 0.06303665041923523\n",
      "batch accuracy: 0.9765625\n",
      "doing 220 / 277\n",
      "elapsed time 17250.17190337181\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0505 - accuracy: 0.9863\n",
      "batch loss: 0.05045916885137558\n",
      "batch accuracy: 0.986328125\n",
      "doing 221 / 277\n",
      "elapsed time 17340.836398601532\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9854\n",
      "batch loss: 0.0501827672123909\n",
      "batch accuracy: 0.9853515625\n",
      "doing 222 / 277\n",
      "elapsed time 17427.821313619614\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9834\n",
      "batch loss: 0.05809438228607178\n",
      "batch accuracy: 0.9833984375\n",
      "doing 223 / 277\n",
      "elapsed time 17517.29569554329\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9834\n",
      "batch loss: 0.06030844897031784\n",
      "batch accuracy: 0.9833984375\n",
      "doing 224 / 277\n",
      "elapsed time 17605.610476255417\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.9883\n",
      "batch loss: 0.04751620441675186\n",
      "batch accuracy: 0.98828125\n",
      "doing 225 / 277\n",
      "elapsed time 17693.90407037735\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0525 - accuracy: 0.9824\n",
      "batch loss: 0.0525100976228714\n",
      "batch accuracy: 0.982421875\n",
      "doing 226 / 277\n",
      "elapsed time 17782.896039009094\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0492 - accuracy: 0.9902\n",
      "batch loss: 0.04917376488447189\n",
      "batch accuracy: 0.990234375\n",
      "doing 227 / 277\n",
      "elapsed time 17870.536170959473\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.9795\n",
      "batch loss: 0.05916224792599678\n",
      "batch accuracy: 0.9794921875\n",
      "doing 228 / 277\n",
      "elapsed time 17959.16275024414\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9873\n",
      "batch loss: 0.04790141433477402\n",
      "batch accuracy: 0.9873046875\n",
      "doing 229 / 277\n",
      "elapsed time 18048.217677116394\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9893\n",
      "batch loss: 0.041820891201496124\n",
      "batch accuracy: 0.9892578125\n",
      "doing 230 / 277\n",
      "elapsed time 18134.938262224197\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.9814\n",
      "batch loss: 0.0607515349984169\n",
      "batch accuracy: 0.9814453125\n",
      "doing 231 / 277\n",
      "elapsed time 18229.60963654518\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.9824\n",
      "batch loss: 0.06214473769068718\n",
      "batch accuracy: 0.982421875\n",
      "doing 232 / 277\n",
      "elapsed time 18322.15562772751\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0434 - accuracy: 0.9912\n",
      "batch loss: 0.043447889387607574\n",
      "batch accuracy: 0.9912109375\n",
      "doing 233 / 277\n",
      "elapsed time 18414.96041536331\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.9834\n",
      "batch loss: 0.059872448444366455\n",
      "batch accuracy: 0.9833984375\n",
      "doing 234 / 277\n",
      "elapsed time 18510.657292842865\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9844\n",
      "batch loss: 0.05330746993422508\n",
      "batch accuracy: 0.984375\n",
      "doing 235 / 277\n",
      "elapsed time 18603.947613716125\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0512 - accuracy: 0.9814\n",
      "batch loss: 0.05120174586772919\n",
      "batch accuracy: 0.9814453125\n",
      "doing 236 / 277\n",
      "elapsed time 18693.34903025627\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9873\n",
      "batch loss: 0.04438471049070358\n",
      "batch accuracy: 0.9873046875\n",
      "doing 237 / 277\n",
      "elapsed time 18781.18917655945\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.9883\n",
      "batch loss: 0.053597379475831985\n",
      "batch accuracy: 0.98828125\n",
      "doing 238 / 277\n",
      "elapsed time 18874.72855424881\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0370 - accuracy: 0.9922\n",
      "batch loss: 0.03703054040670395\n",
      "batch accuracy: 0.9921875\n",
      "doing 239 / 277\n",
      "elapsed time 18966.193039894104\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.9795\n",
      "batch loss: 0.06664944440126419\n",
      "batch accuracy: 0.9794921875\n",
      "doing 240 / 277\n",
      "elapsed time 19059.47648859024\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.9814\n",
      "batch loss: 0.06546717882156372\n",
      "batch accuracy: 0.9814453125\n",
      "doing 241 / 277\n",
      "elapsed time 19152.423428297043\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9854\n",
      "batch loss: 0.053223177790641785\n",
      "batch accuracy: 0.9853515625\n",
      "doing 242 / 277\n",
      "elapsed time 19244.332945108414\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.9795\n",
      "batch loss: 0.05733763426542282\n",
      "batch accuracy: 0.9794921875\n",
      "doing 243 / 277\n",
      "elapsed time 19333.029264688492\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9834\n",
      "batch loss: 0.04474722594022751\n",
      "batch accuracy: 0.9833984375\n",
      "doing 244 / 277\n",
      "elapsed time 19424.521020412445\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9902\n",
      "batch loss: 0.050308454781770706\n",
      "batch accuracy: 0.990234375\n",
      "doing 245 / 277\n",
      "elapsed time 19512.456381082535\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9854\n",
      "batch loss: 0.06028293818235397\n",
      "batch accuracy: 0.9853515625\n",
      "doing 246 / 277\n",
      "elapsed time 19602.474695682526\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0471 - accuracy: 0.9922\n",
      "batch loss: 0.047144606709480286\n",
      "batch accuracy: 0.9921875\n",
      "doing 247 / 277\n",
      "elapsed time 19693.664194107056\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9805\n",
      "batch loss: 0.05746160447597504\n",
      "batch accuracy: 0.98046875\n",
      "doing 248 / 277\n",
      "elapsed time 19782.74584698677\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.9844\n",
      "batch loss: 0.060726478695869446\n",
      "batch accuracy: 0.984375\n",
      "doing 249 / 277\n",
      "elapsed time 19870.97298359871\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9912\n",
      "batch loss: 0.03949848935008049\n",
      "batch accuracy: 0.9912109375\n",
      "doing 250 / 277\n",
      "elapsed time 19962.57122373581\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0482 - accuracy: 0.9873\n",
      "batch loss: 0.04820648580789566\n",
      "batch accuracy: 0.9873046875\n",
      "doing 251 / 277\n",
      "elapsed time 20055.430085659027\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9873\n",
      "batch loss: 0.04203532263636589\n",
      "batch accuracy: 0.9873046875\n",
      "doing 252 / 277\n",
      "elapsed time 20147.05566072464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9805\n",
      "batch loss: 0.058120422065258026\n",
      "batch accuracy: 0.98046875\n",
      "doing 253 / 277\n",
      "elapsed time 20242.88595533371\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0504 - accuracy: 0.9805\n",
      "batch loss: 0.05043572187423706\n",
      "batch accuracy: 0.98046875\n",
      "doing 254 / 277\n",
      "elapsed time 20333.300933361053\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.9902\n",
      "batch loss: 0.04044023156166077\n",
      "batch accuracy: 0.990234375\n",
      "doing 255 / 277\n",
      "elapsed time 20428.116366386414\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9854\n",
      "batch loss: 0.04948481172323227\n",
      "batch accuracy: 0.9853515625\n",
      "doing 256 / 277\n",
      "elapsed time 20523.023687839508\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 0.9834\n",
      "batch loss: 0.052944980561733246\n",
      "batch accuracy: 0.9833984375\n",
      "doing 257 / 277\n",
      "elapsed time 20611.653613567352\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.9873\n",
      "batch loss: 0.049412697553634644\n",
      "batch accuracy: 0.9873046875\n",
      "doing 258 / 277\n",
      "elapsed time 20703.446281909943\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9795\n",
      "batch loss: 0.06036103516817093\n",
      "batch accuracy: 0.9794921875\n",
      "doing 259 / 277\n",
      "elapsed time 20794.77823805809\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0512 - accuracy: 0.9844\n",
      "batch loss: 0.051178477704524994\n",
      "batch accuracy: 0.984375\n",
      "doing 260 / 277\n",
      "elapsed time 20883.50839281082\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 0.9854\n",
      "batch loss: 0.05762660875916481\n",
      "batch accuracy: 0.9853515625\n",
      "doing 261 / 277\n",
      "elapsed time 20973.25499343872\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.9863\n",
      "batch loss: 0.06011181324720383\n",
      "batch accuracy: 0.986328125\n",
      "doing 262 / 277\n",
      "elapsed time 21062.473206281662\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9873\n",
      "batch loss: 0.052670322358608246\n",
      "batch accuracy: 0.9873046875\n",
      "doing 263 / 277\n",
      "elapsed time 21158.250148296356\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0414 - accuracy: 0.9893\n",
      "batch loss: 0.04142487049102783\n",
      "batch accuracy: 0.9892578125\n",
      "doing 264 / 277\n",
      "elapsed time 21248.45374894142\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9902\n",
      "batch loss: 0.0401298962533474\n",
      "batch accuracy: 0.990234375\n",
      "doing 265 / 277\n",
      "elapsed time 21337.848274469376\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.9873\n",
      "batch loss: 0.04752074182033539\n",
      "batch accuracy: 0.9873046875\n",
      "doing 266 / 277\n",
      "elapsed time 21431.454920053482\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0546 - accuracy: 0.9814\n",
      "batch loss: 0.05459030717611313\n",
      "batch accuracy: 0.9814453125\n",
      "doing 267 / 277\n",
      "elapsed time 21527.486451387405\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0461 - accuracy: 0.9902\n",
      "batch loss: 0.04610520973801613\n",
      "batch accuracy: 0.990234375\n",
      "doing 268 / 277\n",
      "elapsed time 21620.905807495117\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 0.9854\n",
      "batch loss: 0.04582981765270233\n",
      "batch accuracy: 0.9853515625\n",
      "doing 269 / 277\n",
      "elapsed time 21714.233115196228\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9902\n",
      "batch loss: 0.048493627458810806\n",
      "batch accuracy: 0.990234375\n",
      "doing 270 / 277\n",
      "elapsed time 21809.013724565506\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0375 - accuracy: 0.9912\n",
      "batch loss: 0.03752219304442406\n",
      "batch accuracy: 0.9912109375\n",
      "doing 271 / 277\n",
      "elapsed time 21905.142512083054\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9883\n",
      "batch loss: 0.04241309314966202\n",
      "batch accuracy: 0.98828125\n",
      "doing 272 / 277\n",
      "elapsed time 21998.904284477234\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 0.9893\n",
      "batch loss: 0.03907221555709839\n",
      "batch accuracy: 0.9892578125\n",
      "doing 273 / 277\n",
      "elapsed time 22097.13660478592\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.9814\n",
      "batch loss: 0.062089703977108\n",
      "batch accuracy: 0.9814453125\n",
      "doing 274 / 277\n",
      "elapsed time 22190.774943828583\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.9883\n",
      "batch loss: 0.04026263207197189\n",
      "batch accuracy: 0.98828125\n",
      "doing 275 / 277\n",
      "elapsed time 22281.3709025383\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 0.9854\n",
      "batch loss: 0.05076270550489426\n",
      "batch accuracy: 0.9853515625\n",
      "doing 276 / 277\n",
      "elapsed time 22333.102678775787\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0415 - accuracy: 0.9927\n",
      "batch loss: 0.041467830538749695\n",
      "batch accuracy: 0.9926874041557312\n",
      "Train loss 0.05581913385473004\n",
      "Train accuracy 0.9844684676142806\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2791 - accuracy: 0.9258\n",
      "Validation loss: 0.27912819385528564\n",
      "Validation accuracy: 0.925777792930603\n",
      "==================================================\n",
      "1 / 5\n",
      "doing 0 / 277\n",
      "elapsed time 77.77232503890991\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.9951\n",
      "batch loss: 0.028993424028158188\n",
      "batch accuracy: 0.9951171875\n",
      "doing 1 / 277\n",
      "elapsed time 155.18594336509705\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 0.9951\n",
      "batch loss: 0.03269733488559723\n",
      "batch accuracy: 0.9951171875\n",
      "doing 2 / 277\n",
      "elapsed time 238.64145946502686\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0285 - accuracy: 0.9971\n",
      "batch loss: 0.028468187898397446\n",
      "batch accuracy: 0.9970703125\n",
      "doing 3 / 277\n",
      "elapsed time 316.33735704421997\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9912\n",
      "batch loss: 0.042938344180583954\n",
      "batch accuracy: 0.9912109375\n",
      "doing 4 / 277\n",
      "elapsed time 392.7164161205292\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.9922\n",
      "batch loss: 0.03512560948729515\n",
      "batch accuracy: 0.9921875\n",
      "doing 5 / 277\n",
      "elapsed time 469.9654064178467\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0355 - accuracy: 0.9922\n",
      "batch loss: 0.03551962226629257\n",
      "batch accuracy: 0.9921875\n",
      "doing 6 / 277\n",
      "elapsed time 548.7554430961609\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0311 - accuracy: 0.9951\n",
      "batch loss: 0.031076326966285706\n",
      "batch accuracy: 0.9951171875\n",
      "doing 7 / 277\n",
      "elapsed time 629.0118222236633\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 0.9971\n",
      "batch loss: 0.030602436512708664\n",
      "batch accuracy: 0.9970703125\n",
      "doing 8 / 277\n",
      "elapsed time 707.7954416275024\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 0.9951\n",
      "batch loss: 0.02839032933115959\n",
      "batch accuracy: 0.9951171875\n",
      "doing 9 / 277\n",
      "elapsed time 788.6849949359894\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9941\n",
      "batch loss: 0.03253215551376343\n",
      "batch accuracy: 0.994140625\n",
      "doing 10 / 277\n",
      "elapsed time 870.3985726833344\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.9971\n",
      "batch loss: 0.02968847192823887\n",
      "batch accuracy: 0.9970703125\n",
      "doing 11 / 277\n",
      "elapsed time 945.3051512241364\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0311 - accuracy: 0.9961\n",
      "batch loss: 0.031127676367759705\n",
      "batch accuracy: 0.99609375\n",
      "doing 12 / 277\n",
      "elapsed time 1027.3205337524414\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9941\n",
      "batch loss: 0.03520695120096207\n",
      "batch accuracy: 0.994140625\n",
      "doing 13 / 277\n",
      "elapsed time 1107.7570414543152\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9922\n",
      "batch loss: 0.03658943250775337\n",
      "batch accuracy: 0.9921875\n",
      "doing 14 / 277\n",
      "elapsed time 1186.1711475849152\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.9805\n",
      "batch loss: 0.04986494034528732\n",
      "batch accuracy: 0.98046875\n",
      "doing 15 / 277\n",
      "elapsed time 1266.2813429832458\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.9971\n",
      "batch loss: 0.02473270520567894\n",
      "batch accuracy: 0.9970703125\n",
      "doing 16 / 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 1341.5389590263367\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9961\n",
      "batch loss: 0.024637363851070404\n",
      "batch accuracy: 0.99609375\n",
      "doing 17 / 277\n",
      "elapsed time 1417.6531569957733\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9922\n",
      "batch loss: 0.027591438964009285\n",
      "batch accuracy: 0.9921875\n",
      "doing 18 / 277\n",
      "elapsed time 1498.213844537735\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9941\n",
      "batch loss: 0.03003016486763954\n",
      "batch accuracy: 0.994140625\n",
      "doing 19 / 277\n",
      "elapsed time 1580.6556143760681\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 0.9941\n",
      "batch loss: 0.033819492906332016\n",
      "batch accuracy: 0.994140625\n",
      "doing 20 / 277\n",
      "elapsed time 1668.5956451892853\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0419 - accuracy: 0.9893\n",
      "batch loss: 0.041878972202539444\n",
      "batch accuracy: 0.9892578125\n",
      "doing 21 / 277\n",
      "elapsed time 1756.3026149272919\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9971\n",
      "batch loss: 0.02643616311252117\n",
      "batch accuracy: 0.9970703125\n",
      "doing 22 / 277\n",
      "elapsed time 1847.5060839653015\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0329 - accuracy: 0.9951\n",
      "batch loss: 0.03285220265388489\n",
      "batch accuracy: 0.9951171875\n",
      "doing 23 / 277\n",
      "elapsed time 1938.55553150177\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9932\n",
      "batch loss: 0.029278699308633804\n",
      "batch accuracy: 0.9931640625\n",
      "doing 24 / 277\n",
      "elapsed time 2025.8121545314789\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.9912\n",
      "batch loss: 0.03506062552332878\n",
      "batch accuracy: 0.9912109375\n",
      "doing 25 / 277\n",
      "elapsed time 2116.3195431232452\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9854\n",
      "batch loss: 0.044704683125019073\n",
      "batch accuracy: 0.9853515625\n",
      "doing 26 / 277\n",
      "elapsed time 2203.127947330475\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0380 - accuracy: 0.9883\n",
      "batch loss: 0.03795292228460312\n",
      "batch accuracy: 0.98828125\n",
      "doing 27 / 277\n",
      "elapsed time 2294.593907356262\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0296 - accuracy: 0.9961\n",
      "batch loss: 0.029554542154073715\n",
      "batch accuracy: 0.99609375\n",
      "doing 28 / 277\n",
      "elapsed time 2380.95498251915\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0436 - accuracy: 0.9883\n",
      "batch loss: 0.04364921897649765\n",
      "batch accuracy: 0.98828125\n",
      "doing 29 / 277\n",
      "elapsed time 2467.86119055748\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9883\n",
      "batch loss: 0.04288182407617569\n",
      "batch accuracy: 0.98828125\n",
      "doing 30 / 277\n",
      "elapsed time 2555.3423812389374\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 0.9932\n",
      "batch loss: 0.029832229018211365\n",
      "batch accuracy: 0.9931640625\n",
      "doing 31 / 277\n",
      "elapsed time 2644.938864469528\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9893\n",
      "batch loss: 0.041152916848659515\n",
      "batch accuracy: 0.9892578125\n",
      "doing 32 / 277\n",
      "elapsed time 2736.057797431946\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 0.9893\n",
      "batch loss: 0.03962082043290138\n",
      "batch accuracy: 0.9892578125\n",
      "doing 33 / 277\n",
      "elapsed time 2825.695727586746\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0362 - accuracy: 0.9902\n",
      "batch loss: 0.036221008747816086\n",
      "batch accuracy: 0.990234375\n",
      "doing 34 / 277\n",
      "elapsed time 2914.0242607593536\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9902\n",
      "batch loss: 0.04241839423775673\n",
      "batch accuracy: 0.990234375\n",
      "doing 35 / 277\n",
      "elapsed time 3003.5127143859863\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0273 - accuracy: 0.9951\n",
      "batch loss: 0.027263320982456207\n",
      "batch accuracy: 0.9951171875\n",
      "doing 36 / 277\n",
      "elapsed time 3094.5565180778503\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.9902\n",
      "batch loss: 0.03678695484995842\n",
      "batch accuracy: 0.990234375\n",
      "doing 37 / 277\n",
      "elapsed time 3186.0552978515625\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0347 - accuracy: 0.9902\n",
      "batch loss: 0.034651439636945724\n",
      "batch accuracy: 0.990234375\n",
      "doing 38 / 277\n",
      "elapsed time 3275.29012966156\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 0.9961\n",
      "batch loss: 0.02799028530716896\n",
      "batch accuracy: 0.99609375\n",
      "doing 39 / 277\n",
      "elapsed time 3366.3710448741913\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.9893\n",
      "batch loss: 0.03936351463198662\n",
      "batch accuracy: 0.9892578125\n",
      "doing 40 / 277\n",
      "elapsed time 3459.186886548996\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9912\n",
      "batch loss: 0.03876707702875137\n",
      "batch accuracy: 0.9912109375\n",
      "doing 41 / 277\n",
      "elapsed time 3553.1039476394653\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.9883\n",
      "batch loss: 0.04018496721982956\n",
      "batch accuracy: 0.98828125\n",
      "doing 42 / 277\n",
      "elapsed time 3644.1544313430786\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 0.9941\n",
      "batch loss: 0.02884857729077339\n",
      "batch accuracy: 0.994140625\n",
      "doing 43 / 277\n",
      "elapsed time 3734.646208524704\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9883\n",
      "batch loss: 0.044484153389930725\n",
      "batch accuracy: 0.98828125\n",
      "doing 44 / 277\n",
      "elapsed time 3823.0509960651398\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9893\n",
      "batch loss: 0.03952297568321228\n",
      "batch accuracy: 0.9892578125\n",
      "doing 45 / 277\n",
      "elapsed time 3916.1874668598175\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0278 - accuracy: 0.9941\n",
      "batch loss: 0.02776545286178589\n",
      "batch accuracy: 0.994140625\n",
      "doing 46 / 277\n",
      "elapsed time 4003.780613899231\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0342 - accuracy: 0.9922\n",
      "batch loss: 0.03419837728142738\n",
      "batch accuracy: 0.9921875\n",
      "doing 47 / 277\n",
      "elapsed time 4089.539955854416\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 0.9932\n",
      "batch loss: 0.030248988419771194\n",
      "batch accuracy: 0.9931640625\n",
      "doing 48 / 277\n",
      "elapsed time 4178.274036407471\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9941\n",
      "batch loss: 0.033217474818229675\n",
      "batch accuracy: 0.994140625\n",
      "doing 49 / 277\n",
      "elapsed time 4273.004458189011\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 0.9941\n",
      "batch loss: 0.026617780327796936\n",
      "batch accuracy: 0.994140625\n",
      "doing 50 / 277\n",
      "elapsed time 4362.276498556137\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.9912\n",
      "batch loss: 0.024963857606053352\n",
      "batch accuracy: 0.9912109375\n",
      "doing 51 / 277\n",
      "elapsed time 4451.825078487396\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0367 - accuracy: 0.9902\n",
      "batch loss: 0.036694012582302094\n",
      "batch accuracy: 0.990234375\n",
      "doing 52 / 277\n",
      "elapsed time 4537.952644586563\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0347 - accuracy: 0.9932\n",
      "batch loss: 0.03469778969883919\n",
      "batch accuracy: 0.9931640625\n",
      "doing 53 / 277\n",
      "elapsed time 4627.802506685257\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 0.9941\n",
      "batch loss: 0.024379204958677292\n",
      "batch accuracy: 0.994140625\n",
      "doing 54 / 277\n",
      "elapsed time 4716.633586883545\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0369 - accuracy: 0.9912\n",
      "batch loss: 0.03689047321677208\n",
      "batch accuracy: 0.9912109375\n",
      "doing 55 / 277\n",
      "elapsed time 4813.006397008896\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.9902\n",
      "batch loss: 0.03512724116444588\n",
      "batch accuracy: 0.990234375\n",
      "doing 56 / 277\n",
      "elapsed time 4905.014028072357\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.9941\n",
      "batch loss: 0.031450413167476654\n",
      "batch accuracy: 0.994140625\n",
      "doing 57 / 277\n",
      "elapsed time 4993.483781337738\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 0.9912\n",
      "batch loss: 0.033753808587789536\n",
      "batch accuracy: 0.9912109375\n",
      "doing 58 / 277\n",
      "elapsed time 5081.781815290451\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.9922\n",
      "batch loss: 0.034327972680330276\n",
      "batch accuracy: 0.9921875\n",
      "doing 59 / 277\n",
      "elapsed time 5172.377472162247\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9971\n",
      "batch loss: 0.02625270001590252\n",
      "batch accuracy: 0.9970703125\n",
      "doing 60 / 277\n",
      "elapsed time 5259.638266801834\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.9961\n",
      "batch loss: 0.03041401319205761\n",
      "batch accuracy: 0.99609375\n",
      "doing 61 / 277\n",
      "elapsed time 5356.1547219753265\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.9922\n",
      "batch loss: 0.03180770203471184\n",
      "batch accuracy: 0.9921875\n",
      "doing 62 / 277\n",
      "elapsed time 5447.729680776596\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 0.9922\n",
      "batch loss: 0.05307374149560928\n",
      "batch accuracy: 0.9921875\n",
      "doing 63 / 277\n",
      "elapsed time 5537.072560548782\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 0.9912\n",
      "batch loss: 0.03453043848276138\n",
      "batch accuracy: 0.9912109375\n",
      "doing 64 / 277\n",
      "elapsed time 5627.811211109161\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 0.9912\n",
      "batch loss: 0.03385617211461067\n",
      "batch accuracy: 0.9912109375\n",
      "doing 65 / 277\n",
      "elapsed time 5718.929892778397\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0355 - accuracy: 0.9941\n",
      "batch loss: 0.03547750413417816\n",
      "batch accuracy: 0.994140625\n",
      "doing 66 / 277\n",
      "elapsed time 5808.815962791443\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9932\n",
      "batch loss: 0.036278992891311646\n",
      "batch accuracy: 0.9931640625\n",
      "doing 67 / 277\n",
      "elapsed time 5895.194629669189\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0257 - accuracy: 0.9951\n",
      "batch loss: 0.02565561607480049\n",
      "batch accuracy: 0.9951171875\n",
      "doing 68 / 277\n",
      "elapsed time 5987.33504486084\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9912\n",
      "batch loss: 0.037813007831573486\n",
      "batch accuracy: 0.9912109375\n",
      "doing 69 / 277\n",
      "elapsed time 6078.662796020508\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9932\n",
      "batch loss: 0.03663645312190056\n",
      "batch accuracy: 0.9931640625\n",
      "doing 70 / 277\n",
      "elapsed time 6168.966186285019\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9922\n",
      "batch loss: 0.035244859755039215\n",
      "batch accuracy: 0.9921875\n",
      "doing 71 / 277\n",
      "elapsed time 6261.554611682892\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9961\n",
      "batch loss: 0.023146387189626694\n",
      "batch accuracy: 0.99609375\n",
      "doing 72 / 277\n",
      "elapsed time 6349.6412880420685\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 0.9941\n",
      "batch loss: 0.024403570219874382\n",
      "batch accuracy: 0.994140625\n",
      "doing 73 / 277\n",
      "elapsed time 6438.62565946579\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.9932\n",
      "batch loss: 0.030390700325369835\n",
      "batch accuracy: 0.9931640625\n",
      "doing 74 / 277\n",
      "elapsed time 6526.734809398651\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 0.9902\n",
      "batch loss: 0.028815511614084244\n",
      "batch accuracy: 0.990234375\n",
      "doing 75 / 277\n",
      "elapsed time 6613.463197231293\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 0.9912\n",
      "batch loss: 0.030516933649778366\n",
      "batch accuracy: 0.9912109375\n",
      "doing 76 / 277\n",
      "elapsed time 6701.695290803909\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9912\n",
      "batch loss: 0.03809177875518799\n",
      "batch accuracy: 0.9912109375\n",
      "doing 77 / 277\n",
      "elapsed time 6795.7080862522125\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9922\n",
      "batch loss: 0.03662819787859917\n",
      "batch accuracy: 0.9921875\n",
      "doing 78 / 277\n",
      "elapsed time 6887.890920162201\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0370 - accuracy: 0.9883\n",
      "batch loss: 0.03695467859506607\n",
      "batch accuracy: 0.98828125\n",
      "doing 79 / 277\n",
      "elapsed time 6975.054795265198\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.9883\n",
      "batch loss: 0.04031473770737648\n",
      "batch accuracy: 0.98828125\n",
      "doing 80 / 277\n",
      "elapsed time 7066.042803287506\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9941\n",
      "batch loss: 0.024303006008267403\n",
      "batch accuracy: 0.994140625\n",
      "doing 81 / 277\n",
      "elapsed time 7153.076059579849\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0277 - accuracy: 0.9922\n",
      "batch loss: 0.027669798582792282\n",
      "batch accuracy: 0.9921875\n",
      "doing 82 / 277\n",
      "elapsed time 7244.77520108223\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9932\n",
      "batch loss: 0.03130538389086723\n",
      "batch accuracy: 0.9931640625\n",
      "doing 83 / 277\n",
      "elapsed time 7338.503586769104\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9883\n",
      "batch loss: 0.03952391445636749\n",
      "batch accuracy: 0.98828125\n",
      "doing 84 / 277\n",
      "elapsed time 7428.947248458862\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0299 - accuracy: 0.9912\n",
      "batch loss: 0.029866967350244522\n",
      "batch accuracy: 0.9912109375\n",
      "doing 85 / 277\n",
      "elapsed time 7519.259143829346\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9951\n",
      "batch loss: 0.027060652151703835\n",
      "batch accuracy: 0.9951171875\n",
      "doing 86 / 277\n",
      "elapsed time 7607.739192247391\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0314 - accuracy: 0.9951\n",
      "batch loss: 0.031364358961582184\n",
      "batch accuracy: 0.9951171875\n",
      "doing 87 / 277\n",
      "elapsed time 7696.343681335449\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9922\n",
      "batch loss: 0.029270119965076447\n",
      "batch accuracy: 0.9921875\n",
      "doing 88 / 277\n",
      "elapsed time 7787.470763921738\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9902\n",
      "batch loss: 0.047904156148433685\n",
      "batch accuracy: 0.990234375\n",
      "doing 89 / 277\n",
      "elapsed time 7875.630208492279\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.9961\n",
      "batch loss: 0.025581464171409607\n",
      "batch accuracy: 0.99609375\n",
      "doing 90 / 277\n",
      "elapsed time 7961.2278780937195\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.9971\n",
      "batch loss: 0.02671685442328453\n",
      "batch accuracy: 0.9970703125\n",
      "doing 91 / 277\n",
      "elapsed time 8052.256464719772\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9912\n",
      "batch loss: 0.029314912855625153\n",
      "batch accuracy: 0.9912109375\n",
      "doing 92 / 277\n",
      "elapsed time 8150.972187280655\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 0.9941\n",
      "batch loss: 0.029796898365020752\n",
      "batch accuracy: 0.994140625\n",
      "doing 93 / 277\n",
      "elapsed time 8254.18634724617\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9951\n",
      "batch loss: 0.02602708898484707\n",
      "batch accuracy: 0.9951171875\n",
      "doing 94 / 277\n",
      "elapsed time 8359.094076633453\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.9951\n",
      "batch loss: 0.028986133635044098\n",
      "batch accuracy: 0.9951171875\n",
      "doing 95 / 277\n",
      "elapsed time 8460.33188009262\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.9951\n",
      "batch loss: 0.025647727772593498\n",
      "batch accuracy: 0.9951171875\n",
      "doing 96 / 277\n",
      "elapsed time 8561.202490329742\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9912\n",
      "batch loss: 0.027560707181692123\n",
      "batch accuracy: 0.9912109375\n",
      "doing 97 / 277\n",
      "elapsed time 8667.49957537651\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9971\n",
      "batch loss: 0.026329664513468742\n",
      "batch accuracy: 0.9970703125\n",
      "doing 98 / 277\n",
      "elapsed time 8774.012574195862\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0272 - accuracy: 0.9941\n",
      "batch loss: 0.027216508984565735\n",
      "batch accuracy: 0.994140625\n",
      "doing 99 / 277\n",
      "elapsed time 8874.749981164932\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9932\n",
      "batch loss: 0.02433808147907257\n",
      "batch accuracy: 0.9931640625\n",
      "doing 100 / 277\n",
      "elapsed time 8975.027309894562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0324 - accuracy: 0.9932\n",
      "batch loss: 0.03241513669490814\n",
      "batch accuracy: 0.9931640625\n",
      "doing 101 / 277\n",
      "elapsed time 9082.773105621338\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.9912\n",
      "batch loss: 0.03461828827857971\n",
      "batch accuracy: 0.9912109375\n",
      "doing 102 / 277\n",
      "elapsed time 9181.58546423912\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0365 - accuracy: 0.9893\n",
      "batch loss: 0.03652992844581604\n",
      "batch accuracy: 0.9892578125\n",
      "doing 103 / 277\n",
      "elapsed time 9282.238472938538\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0299 - accuracy: 0.9922\n",
      "batch loss: 0.0299020204693079\n",
      "batch accuracy: 0.9921875\n",
      "doing 104 / 277\n",
      "elapsed time 9389.444418668747\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 0.9902\n",
      "batch loss: 0.03066261112689972\n",
      "batch accuracy: 0.990234375\n",
      "doing 105 / 277\n",
      "elapsed time 9496.697833776474\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 0.9912\n",
      "batch loss: 0.03384265676140785\n",
      "batch accuracy: 0.9912109375\n",
      "doing 106 / 277\n",
      "elapsed time 9594.729527950287\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9941\n",
      "batch loss: 0.030042029917240143\n",
      "batch accuracy: 0.994140625\n",
      "doing 107 / 277\n",
      "elapsed time 9691.529545783997\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.9873\n",
      "batch loss: 0.04040994495153427\n",
      "batch accuracy: 0.9873046875\n",
      "doing 108 / 277\n",
      "elapsed time 9801.433846235275\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0274 - accuracy: 0.9961\n",
      "batch loss: 0.027412518858909607\n",
      "batch accuracy: 0.99609375\n",
      "doing 109 / 277\n",
      "elapsed time 9906.925461292267\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9971\n",
      "batch loss: 0.021182890981435776\n",
      "batch accuracy: 0.9970703125\n",
      "doing 110 / 277\n",
      "elapsed time 10013.975451946259\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 0.9932\n",
      "batch loss: 0.032683875411748886\n",
      "batch accuracy: 0.9931640625\n",
      "doing 111 / 277\n",
      "elapsed time 10123.366813898087\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9883\n",
      "batch loss: 0.028889639303088188\n",
      "batch accuracy: 0.98828125\n",
      "doing 112 / 277\n",
      "elapsed time 10230.808440208435\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0299 - accuracy: 0.9941\n",
      "batch loss: 0.02989567443728447\n",
      "batch accuracy: 0.994140625\n",
      "doing 113 / 277\n",
      "elapsed time 10339.752043962479\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9941\n",
      "batch loss: 0.027872860431671143\n",
      "batch accuracy: 0.994140625\n",
      "doing 114 / 277\n",
      "elapsed time 10441.700583934784\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 0.9951\n",
      "batch loss: 0.03358802944421768\n",
      "batch accuracy: 0.9951171875\n",
      "doing 115 / 277\n",
      "elapsed time 10539.868077993393\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.9932\n",
      "batch loss: 0.03719562292098999\n",
      "batch accuracy: 0.9931640625\n",
      "doing 116 / 277\n",
      "elapsed time 10647.682883739471\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.9922\n",
      "batch loss: 0.03489058464765549\n",
      "batch accuracy: 0.9921875\n",
      "doing 117 / 277\n",
      "elapsed time 10745.824068069458\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9951\n",
      "batch loss: 0.0263417586684227\n",
      "batch accuracy: 0.9951171875\n",
      "doing 118 / 277\n",
      "elapsed time 10846.694108963013\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9951\n",
      "batch loss: 0.030125092715024948\n",
      "batch accuracy: 0.9951171875\n",
      "doing 119 / 277\n",
      "elapsed time 10951.936362028122\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.9922\n",
      "batch loss: 0.03721746802330017\n",
      "batch accuracy: 0.9921875\n",
      "doing 120 / 277\n",
      "elapsed time 11051.461296319962\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.9951\n",
      "batch loss: 0.02968384325504303\n",
      "batch accuracy: 0.9951171875\n",
      "doing 121 / 277\n",
      "elapsed time 11163.808464288712\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9971\n",
      "batch loss: 0.026134885847568512\n",
      "batch accuracy: 0.9970703125\n",
      "doing 122 / 277\n",
      "elapsed time 11271.408650159836\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0324 - accuracy: 0.9902\n",
      "batch loss: 0.03236781433224678\n",
      "batch accuracy: 0.990234375\n",
      "doing 123 / 277\n",
      "elapsed time 11382.468836307526\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.9883\n",
      "batch loss: 0.0422460213303566\n",
      "batch accuracy: 0.98828125\n",
      "doing 124 / 277\n",
      "elapsed time 11493.197794914246\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0299 - accuracy: 0.9951\n",
      "batch loss: 0.029860759153962135\n",
      "batch accuracy: 0.9951171875\n",
      "doing 125 / 277\n",
      "elapsed time 11601.429418563843\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9961\n",
      "batch loss: 0.03003804013133049\n",
      "batch accuracy: 0.99609375\n",
      "doing 126 / 277\n",
      "elapsed time 11707.79328584671\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9932\n",
      "batch loss: 0.04109305515885353\n",
      "batch accuracy: 0.9931640625\n",
      "doing 127 / 277\n",
      "elapsed time 11814.869854688644\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0274 - accuracy: 0.9941\n",
      "batch loss: 0.027424916625022888\n",
      "batch accuracy: 0.994140625\n",
      "doing 128 / 277\n",
      "elapsed time 11929.768288373947\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9961\n",
      "batch loss: 0.024058867245912552\n",
      "batch accuracy: 0.99609375\n",
      "doing 129 / 277\n",
      "elapsed time 12043.19654583931\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9961\n",
      "batch loss: 0.027894282713532448\n",
      "batch accuracy: 0.99609375\n",
      "doing 130 / 277\n",
      "elapsed time 12151.032788276672\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9961\n",
      "batch loss: 0.027860751375555992\n",
      "batch accuracy: 0.99609375\n",
      "doing 131 / 277\n",
      "elapsed time 12264.553448677063\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9961\n",
      "batch loss: 0.02385849505662918\n",
      "batch accuracy: 0.99609375\n",
      "doing 132 / 277\n",
      "elapsed time 12378.003215789795\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9951\n",
      "batch loss: 0.025983180850744247\n",
      "batch accuracy: 0.9951171875\n",
      "doing 133 / 277\n",
      "elapsed time 12487.630078554153\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.9951\n",
      "batch loss: 0.022329553961753845\n",
      "batch accuracy: 0.9951171875\n",
      "doing 134 / 277\n",
      "elapsed time 12598.877974510193\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 0.9941\n",
      "batch loss: 0.029247011989355087\n",
      "batch accuracy: 0.994140625\n",
      "doing 135 / 277\n",
      "elapsed time 12707.668321847916\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.9941\n",
      "batch loss: 0.026806648820638657\n",
      "batch accuracy: 0.994140625\n",
      "doing 136 / 277\n",
      "elapsed time 12819.359894514084\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0274 - accuracy: 0.9932\n",
      "batch loss: 0.027413103729486465\n",
      "batch accuracy: 0.9931640625\n",
      "doing 137 / 277\n",
      "elapsed time 12930.896868467331\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0350 - accuracy: 0.9961\n",
      "batch loss: 0.03502269461750984\n",
      "batch accuracy: 0.99609375\n",
      "doing 138 / 277\n",
      "elapsed time 13042.012900590897\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.9932\n",
      "batch loss: 0.027041565626859665\n",
      "batch accuracy: 0.9931640625\n",
      "doing 139 / 277\n",
      "elapsed time 13150.102576971054\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 0.9961\n",
      "batch loss: 0.02837531268596649\n",
      "batch accuracy: 0.99609375\n",
      "doing 140 / 277\n",
      "elapsed time 13265.625143051147\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9951\n",
      "batch loss: 0.026290852576494217\n",
      "batch accuracy: 0.9951171875\n",
      "doing 141 / 277\n",
      "elapsed time 13374.696855306625\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9961\n",
      "batch loss: 0.022011058405041695\n",
      "batch accuracy: 0.99609375\n",
      "doing 142 / 277\n",
      "elapsed time 13485.443647384644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9961\n",
      "batch loss: 0.02934756688773632\n",
      "batch accuracy: 0.99609375\n",
      "doing 143 / 277\n",
      "elapsed time 13597.669142246246\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9980\n",
      "batch loss: 0.022870313376188278\n",
      "batch accuracy: 0.998046875\n",
      "doing 144 / 277\n",
      "elapsed time 13711.916210651398\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.9902\n",
      "batch loss: 0.030372105538845062\n",
      "batch accuracy: 0.990234375\n",
      "doing 145 / 277\n",
      "elapsed time 13827.644178152084\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0303 - accuracy: 0.9922\n",
      "batch loss: 0.03026936575770378\n",
      "batch accuracy: 0.9921875\n",
      "doing 146 / 277\n",
      "elapsed time 13942.557368040085\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9961\n",
      "batch loss: 0.02425958402454853\n",
      "batch accuracy: 0.99609375\n",
      "doing 147 / 277\n",
      "elapsed time 14063.801942825317\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9951\n",
      "batch loss: 0.029108598828315735\n",
      "batch accuracy: 0.9951171875\n",
      "doing 148 / 277\n",
      "elapsed time 14179.349424600601\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0434 - accuracy: 0.9941\n",
      "batch loss: 0.04336022213101387\n",
      "batch accuracy: 0.994140625\n",
      "doing 149 / 277\n",
      "elapsed time 14297.57166981697\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9961\n",
      "batch loss: 0.026935845613479614\n",
      "batch accuracy: 0.99609375\n",
      "doing 150 / 277\n",
      "elapsed time 14415.310234069824\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9941\n",
      "batch loss: 0.02885529026389122\n",
      "batch accuracy: 0.994140625\n",
      "doing 151 / 277\n",
      "elapsed time 14526.134083747864\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.9941\n",
      "batch loss: 0.030378613620996475\n",
      "batch accuracy: 0.994140625\n",
      "doing 152 / 277\n",
      "elapsed time 14643.185447692871\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9951\n",
      "batch loss: 0.026312723755836487\n",
      "batch accuracy: 0.9951171875\n",
      "doing 153 / 277\n",
      "elapsed time 14751.734775543213\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9912\n",
      "batch loss: 0.0382620245218277\n",
      "batch accuracy: 0.9912109375\n",
      "doing 154 / 277\n",
      "elapsed time 14864.889597415924\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0225 - accuracy: 0.9951\n",
      "batch loss: 0.022484108805656433\n",
      "batch accuracy: 0.9951171875\n",
      "doing 155 / 277\n",
      "elapsed time 14970.607664585114\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 0.9951\n",
      "batch loss: 0.03308233618736267\n",
      "batch accuracy: 0.9951171875\n",
      "doing 156 / 277\n",
      "elapsed time 15080.084353208542\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9941\n",
      "batch loss: 0.026274889707565308\n",
      "batch accuracy: 0.994140625\n",
      "doing 157 / 277\n",
      "elapsed time 15196.090259313583\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.9912\n",
      "batch loss: 0.027025161311030388\n",
      "batch accuracy: 0.9912109375\n",
      "doing 158 / 277\n",
      "elapsed time 15317.983930110931\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9932\n",
      "batch loss: 0.02464834228157997\n",
      "batch accuracy: 0.9931640625\n",
      "doing 159 / 277\n",
      "elapsed time 15426.451173067093\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.9922\n",
      "batch loss: 0.03924286738038063\n",
      "batch accuracy: 0.9921875\n",
      "doing 160 / 277\n",
      "elapsed time 15538.892169475555\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0335 - accuracy: 0.9873\n",
      "batch loss: 0.0334661602973938\n",
      "batch accuracy: 0.9873046875\n",
      "doing 161 / 277\n",
      "elapsed time 15656.20223236084\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9922\n",
      "batch loss: 0.02790329046547413\n",
      "batch accuracy: 0.9921875\n",
      "doing 162 / 277\n",
      "elapsed time 15772.029131650925\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 0.9951\n",
      "batch loss: 0.032106027007102966\n",
      "batch accuracy: 0.9951171875\n",
      "doing 163 / 277\n",
      "elapsed time 15891.46086025238\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9922\n",
      "batch loss: 0.03320994973182678\n",
      "batch accuracy: 0.9921875\n",
      "doing 164 / 277\n",
      "elapsed time 16012.422983169556\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9932\n",
      "batch loss: 0.026277897879481316\n",
      "batch accuracy: 0.9931640625\n",
      "doing 165 / 277\n",
      "elapsed time 16131.215482234955\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9951\n",
      "batch loss: 0.02647530660033226\n",
      "batch accuracy: 0.9951171875\n",
      "doing 166 / 277\n",
      "elapsed time 16254.340821027756\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9961\n",
      "batch loss: 0.027555016800761223\n",
      "batch accuracy: 0.99609375\n",
      "doing 167 / 277\n",
      "elapsed time 16368.99247455597\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9902\n",
      "batch loss: 0.04235415905714035\n",
      "batch accuracy: 0.990234375\n",
      "doing 168 / 277\n",
      "elapsed time 16489.09650683403\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.9951\n",
      "batch loss: 0.02143402397632599\n",
      "batch accuracy: 0.9951171875\n",
      "doing 169 / 277\n",
      "elapsed time 16612.856495141983\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 0.9883\n",
      "batch loss: 0.03387053683400154\n",
      "batch accuracy: 0.98828125\n",
      "doing 170 / 277\n",
      "elapsed time 16737.87470459938\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9873\n",
      "batch loss: 0.04973006621003151\n",
      "batch accuracy: 0.9873046875\n",
      "doing 171 / 277\n",
      "elapsed time 16858.121187210083\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0337 - accuracy: 0.9902\n",
      "batch loss: 0.03366446867585182\n",
      "batch accuracy: 0.990234375\n",
      "doing 172 / 277\n",
      "elapsed time 16979.957800865173\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0275 - accuracy: 0.9932\n",
      "batch loss: 0.027476489543914795\n",
      "batch accuracy: 0.9931640625\n",
      "doing 173 / 277\n",
      "elapsed time 17096.131050348282\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9951\n",
      "batch loss: 0.027552029117941856\n",
      "batch accuracy: 0.9951171875\n",
      "doing 174 / 277\n",
      "elapsed time 17219.366062641144\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.9932\n",
      "batch loss: 0.02469513565301895\n",
      "batch accuracy: 0.9931640625\n",
      "doing 175 / 277\n",
      "elapsed time 17342.107380628586\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.9922\n",
      "batch loss: 0.03178275376558304\n",
      "batch accuracy: 0.9921875\n",
      "doing 176 / 277\n",
      "elapsed time 17437.650302648544\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9932\n",
      "batch loss: 0.02707788161933422\n",
      "batch accuracy: 0.9931640625\n",
      "doing 177 / 277\n",
      "elapsed time 17508.029963970184\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.9951\n",
      "batch loss: 0.030449584126472473\n",
      "batch accuracy: 0.9951171875\n",
      "doing 178 / 277\n",
      "elapsed time 17580.815759658813\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9941\n",
      "batch loss: 0.023952214047312737\n",
      "batch accuracy: 0.994140625\n",
      "doing 179 / 277\n",
      "elapsed time 17649.682512521744\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 0.9932\n",
      "batch loss: 0.02835506573319435\n",
      "batch accuracy: 0.9931640625\n",
      "doing 180 / 277\n",
      "elapsed time 17719.98922753334\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0272 - accuracy: 0.9912\n",
      "batch loss: 0.0271708182990551\n",
      "batch accuracy: 0.9912109375\n",
      "doing 181 / 277\n",
      "elapsed time 17790.60404920578\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0281 - accuracy: 0.9941\n",
      "batch loss: 0.028063733130693436\n",
      "batch accuracy: 0.994140625\n",
      "doing 182 / 277\n",
      "elapsed time 17861.104770183563\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9951\n",
      "batch loss: 0.026427842676639557\n",
      "batch accuracy: 0.9951171875\n",
      "doing 183 / 277\n",
      "elapsed time 17931.38276195526\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9932\n",
      "batch loss: 0.027866162359714508\n",
      "batch accuracy: 0.9931640625\n",
      "doing 184 / 277\n",
      "elapsed time 18002.215985298157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9951\n",
      "batch loss: 0.02602582611143589\n",
      "batch accuracy: 0.9951171875\n",
      "doing 185 / 277\n",
      "elapsed time 18074.495407104492\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9951\n",
      "batch loss: 0.02290024608373642\n",
      "batch accuracy: 0.9951171875\n",
      "doing 186 / 277\n",
      "elapsed time 18146.221568346024\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 0.9902\n",
      "batch loss: 0.029787691310048103\n",
      "batch accuracy: 0.990234375\n",
      "doing 187 / 277\n",
      "elapsed time 18217.976982593536\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9951\n",
      "batch loss: 0.020056255161762238\n",
      "batch accuracy: 0.9951171875\n",
      "doing 188 / 277\n",
      "elapsed time 18290.17113661766\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9922\n",
      "batch loss: 0.02403109520673752\n",
      "batch accuracy: 0.9921875\n",
      "doing 189 / 277\n",
      "elapsed time 18362.473117113113\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 0.9941\n",
      "batch loss: 0.02358061820268631\n",
      "batch accuracy: 0.994140625\n",
      "doing 190 / 277\n",
      "elapsed time 18431.39199757576\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0257 - accuracy: 0.9951\n",
      "batch loss: 0.02565528079867363\n",
      "batch accuracy: 0.9951171875\n",
      "doing 191 / 277\n",
      "elapsed time 18502.092746019363\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.9912\n",
      "batch loss: 0.03338202089071274\n",
      "batch accuracy: 0.9912109375\n",
      "doing 192 / 277\n",
      "elapsed time 18572.0361225605\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9980\n",
      "batch loss: 0.018354017287492752\n",
      "batch accuracy: 0.998046875\n",
      "doing 193 / 277\n",
      "elapsed time 18645.787272691727\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.9961\n",
      "batch loss: 0.02857353910803795\n",
      "batch accuracy: 0.99609375\n",
      "doing 194 / 277\n",
      "elapsed time 18718.085319280624\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9941\n",
      "batch loss: 0.021912522614002228\n",
      "batch accuracy: 0.994140625\n",
      "doing 195 / 277\n",
      "elapsed time 18790.344918489456\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0277 - accuracy: 0.9932\n",
      "batch loss: 0.02768094092607498\n",
      "batch accuracy: 0.9931640625\n",
      "doing 196 / 277\n",
      "elapsed time 18862.90553212166\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 0.9951\n",
      "batch loss: 0.02580159157514572\n",
      "batch accuracy: 0.9951171875\n",
      "doing 197 / 277\n",
      "elapsed time 18933.438987255096\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 0.9941\n",
      "batch loss: 0.02980654314160347\n",
      "batch accuracy: 0.994140625\n",
      "doing 198 / 277\n",
      "elapsed time 19003.456303596497\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0329 - accuracy: 0.9902\n",
      "batch loss: 0.032868824899196625\n",
      "batch accuracy: 0.990234375\n",
      "doing 199 / 277\n",
      "elapsed time 19074.228577375412\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 0.9922\n",
      "batch loss: 0.025771867483854294\n",
      "batch accuracy: 0.9921875\n",
      "doing 200 / 277\n",
      "elapsed time 19143.419015169144\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9912\n",
      "batch loss: 0.028935058042407036\n",
      "batch accuracy: 0.9912109375\n",
      "doing 201 / 277\n",
      "elapsed time 19217.391881227493\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9971\n",
      "batch loss: 0.016781184822320938\n",
      "batch accuracy: 0.9970703125\n",
      "doing 202 / 277\n",
      "elapsed time 19289.969728708267\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.9971\n",
      "batch loss: 0.02971600741147995\n",
      "batch accuracy: 0.9970703125\n",
      "doing 203 / 277\n",
      "elapsed time 19357.643818616867\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 0.9971\n",
      "batch loss: 0.020605433732271194\n",
      "batch accuracy: 0.9970703125\n",
      "doing 204 / 277\n",
      "elapsed time 19424.217361927032\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9912\n",
      "batch loss: 0.03246935456991196\n",
      "batch accuracy: 0.9912109375\n",
      "doing 205 / 277\n",
      "elapsed time 19495.86453795433\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 0.9951\n",
      "batch loss: 0.021487362682819366\n",
      "batch accuracy: 0.9951171875\n",
      "doing 206 / 277\n",
      "elapsed time 19568.713767051697\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.9951\n",
      "batch loss: 0.02467198856174946\n",
      "batch accuracy: 0.9951171875\n",
      "doing 207 / 277\n",
      "elapsed time 19641.8852994442\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.9922\n",
      "batch loss: 0.03903999179601669\n",
      "batch accuracy: 0.9921875\n",
      "doing 208 / 277\n",
      "elapsed time 19713.26141643524\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0282 - accuracy: 0.9932\n",
      "batch loss: 0.028245024383068085\n",
      "batch accuracy: 0.9931640625\n",
      "doing 209 / 277\n",
      "elapsed time 19783.746887922287\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9873\n",
      "batch loss: 0.047584980726242065\n",
      "batch accuracy: 0.9873046875\n",
      "doing 210 / 277\n",
      "elapsed time 19855.278652906418\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0330 - accuracy: 0.9893\n",
      "batch loss: 0.03303614258766174\n",
      "batch accuracy: 0.9892578125\n",
      "doing 211 / 277\n",
      "elapsed time 19926.353615045547\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9893\n",
      "batch loss: 0.03516680747270584\n",
      "batch accuracy: 0.9892578125\n",
      "doing 212 / 277\n",
      "elapsed time 19993.918532133102\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.9951\n",
      "batch loss: 0.029000986367464066\n",
      "batch accuracy: 0.9951171875\n",
      "doing 213 / 277\n",
      "elapsed time 20067.129732847214\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0287 - accuracy: 0.9941\n",
      "batch loss: 0.028732240200042725\n",
      "batch accuracy: 0.994140625\n",
      "doing 214 / 277\n",
      "elapsed time 20137.972784519196\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.9932\n",
      "batch loss: 0.030355919152498245\n",
      "batch accuracy: 0.9931640625\n",
      "doing 215 / 277\n",
      "elapsed time 20208.92162013054\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9951\n",
      "batch loss: 0.02518175169825554\n",
      "batch accuracy: 0.9951171875\n",
      "doing 216 / 277\n",
      "elapsed time 20277.621913671494\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 0.9932\n",
      "batch loss: 0.029777243733406067\n",
      "batch accuracy: 0.9931640625\n",
      "doing 217 / 277\n",
      "elapsed time 20352.493064641953\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9941\n",
      "batch loss: 0.024586809799075127\n",
      "batch accuracy: 0.994140625\n",
      "doing 218 / 277\n",
      "elapsed time 20425.35981941223\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.9863\n",
      "batch loss: 0.03508618474006653\n",
      "batch accuracy: 0.986328125\n",
      "doing 219 / 277\n",
      "elapsed time 20498.295685768127\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0330 - accuracy: 0.9941\n",
      "batch loss: 0.03298910707235336\n",
      "batch accuracy: 0.994140625\n",
      "doing 220 / 277\n",
      "elapsed time 20570.311859846115\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 0.9941\n",
      "batch loss: 0.02417624741792679\n",
      "batch accuracy: 0.994140625\n",
      "doing 221 / 277\n",
      "elapsed time 20641.723423480988\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9980\n",
      "batch loss: 0.023233134299516678\n",
      "batch accuracy: 0.998046875\n",
      "doing 222 / 277\n",
      "elapsed time 20715.351332187653\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0287 - accuracy: 0.9912\n",
      "batch loss: 0.028739359229803085\n",
      "batch accuracy: 0.9912109375\n",
      "doing 223 / 277\n",
      "elapsed time 20787.178265810013\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9902\n",
      "batch loss: 0.0292607881128788\n",
      "batch accuracy: 0.990234375\n",
      "doing 224 / 277\n",
      "elapsed time 20860.353125333786\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 0.9932\n",
      "batch loss: 0.024213526397943497\n",
      "batch accuracy: 0.9931640625\n",
      "doing 225 / 277\n",
      "elapsed time 20928.439863443375\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9922\n",
      "batch loss: 0.038788992911577225\n",
      "batch accuracy: 0.9921875\n",
      "doing 226 / 277\n",
      "elapsed time 21002.75533914566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9961\n",
      "batch loss: 0.02650044672191143\n",
      "batch accuracy: 0.99609375\n",
      "doing 227 / 277\n",
      "elapsed time 21075.332659244537\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.9932\n",
      "batch loss: 0.03489674627780914\n",
      "batch accuracy: 0.9931640625\n",
      "doing 228 / 277\n",
      "elapsed time 21146.171149253845\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9912\n",
      "batch loss: 0.03880835324525833\n",
      "batch accuracy: 0.9912109375\n",
      "doing 229 / 277\n",
      "elapsed time 21220.786770105362\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.9922\n",
      "batch loss: 0.026795219630002975\n",
      "batch accuracy: 0.9921875\n",
      "doing 230 / 277\n",
      "elapsed time 21293.21358513832\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9844\n",
      "batch loss: 0.04001263529062271\n",
      "batch accuracy: 0.984375\n",
      "doing 231 / 277\n",
      "elapsed time 21364.406908988953\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0294 - accuracy: 0.9922\n",
      "batch loss: 0.029356500133872032\n",
      "batch accuracy: 0.9921875\n",
      "doing 232 / 277\n",
      "elapsed time 21436.302462100983\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 0.9893\n",
      "batch loss: 0.036076925694942474\n",
      "batch accuracy: 0.9892578125\n",
      "doing 233 / 277\n",
      "elapsed time 21503.978602409363\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 0.9912\n",
      "batch loss: 0.03597906976938248\n",
      "batch accuracy: 0.9912109375\n",
      "doing 234 / 277\n",
      "elapsed time 21576.668501138687\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 0.9912\n",
      "batch loss: 0.030466124415397644\n",
      "batch accuracy: 0.9912109375\n",
      "doing 235 / 277\n",
      "elapsed time 21650.317977905273\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 0.9873\n",
      "batch loss: 0.03206585347652435\n",
      "batch accuracy: 0.9873046875\n",
      "doing 236 / 277\n",
      "elapsed time 21721.562077760696\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 0.9941\n",
      "batch loss: 0.03167325258255005\n",
      "batch accuracy: 0.994140625\n",
      "doing 237 / 277\n",
      "elapsed time 21792.820854902267\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9873\n",
      "batch loss: 0.03837347403168678\n",
      "batch accuracy: 0.9873046875\n",
      "doing 238 / 277\n",
      "elapsed time 21862.829482793808\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 0.9932\n",
      "batch loss: 0.029846543446183205\n",
      "batch accuracy: 0.9931640625\n",
      "doing 239 / 277\n",
      "elapsed time 21934.86076259613\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.9893\n",
      "batch loss: 0.031175395473837852\n",
      "batch accuracy: 0.9892578125\n",
      "doing 240 / 277\n",
      "elapsed time 22007.7433488369\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9932\n",
      "batch loss: 0.03000589832663536\n",
      "batch accuracy: 0.9931640625\n",
      "doing 241 / 277\n",
      "elapsed time 22083.954414606094\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 0.9932\n",
      "batch loss: 0.030547063797712326\n",
      "batch accuracy: 0.9931640625\n",
      "doing 242 / 277\n",
      "elapsed time 22156.192420244217\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 0.9912\n",
      "batch loss: 0.02877214178442955\n",
      "batch accuracy: 0.9912109375\n",
      "doing 243 / 277\n",
      "elapsed time 22229.113945245743\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9961\n",
      "batch loss: 0.022716160863637924\n",
      "batch accuracy: 0.99609375\n",
      "doing 244 / 277\n",
      "elapsed time 22300.710382699966\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.9932\n",
      "batch loss: 0.030410567298531532\n",
      "batch accuracy: 0.9931640625\n",
      "doing 245 / 277\n",
      "elapsed time 22372.739112377167\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 0.9912\n",
      "batch loss: 0.03166533634066582\n",
      "batch accuracy: 0.9912109375\n",
      "doing 246 / 277\n",
      "elapsed time 22447.101424455643\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 0.9951\n",
      "batch loss: 0.03362644091248512\n",
      "batch accuracy: 0.9951171875\n",
      "doing 247 / 277\n",
      "elapsed time 22521.245685338974\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9922\n",
      "batch loss: 0.04130657762289047\n",
      "batch accuracy: 0.9921875\n",
      "doing 248 / 277\n",
      "elapsed time 22592.524362564087\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9873\n",
      "batch loss: 0.04225565493106842\n",
      "batch accuracy: 0.9873046875\n",
      "doing 249 / 277\n",
      "elapsed time 22663.87290740013\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 0.9932\n",
      "batch loss: 0.02840827777981758\n",
      "batch accuracy: 0.9931640625\n",
      "doing 250 / 277\n",
      "elapsed time 22736.037554979324\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9893\n",
      "batch loss: 0.030070338398218155\n",
      "batch accuracy: 0.9892578125\n",
      "doing 251 / 277\n",
      "elapsed time 22804.20721578598\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9971\n",
      "batch loss: 0.021917052567005157\n",
      "batch accuracy: 0.9970703125\n",
      "doing 252 / 277\n",
      "elapsed time 22876.987616300583\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0277 - accuracy: 0.9922\n",
      "batch loss: 0.027711570262908936\n",
      "batch accuracy: 0.9921875\n",
      "doing 253 / 277\n",
      "elapsed time 22948.358986139297\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 0.9941\n",
      "batch loss: 0.02878156304359436\n",
      "batch accuracy: 0.994140625\n",
      "doing 254 / 277\n",
      "elapsed time 23022.10885834694\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0330 - accuracy: 0.9932\n",
      "batch loss: 0.03302381932735443\n",
      "batch accuracy: 0.9931640625\n",
      "doing 255 / 277\n",
      "elapsed time 23095.7471473217\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 0.9883\n",
      "batch loss: 0.032058265060186386\n",
      "batch accuracy: 0.98828125\n",
      "doing 256 / 277\n",
      "elapsed time 23169.54223895073\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9932\n",
      "batch loss: 0.029052596539258957\n",
      "batch accuracy: 0.9931640625\n",
      "doing 257 / 277\n",
      "elapsed time 23240.044347286224\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.9922\n",
      "batch loss: 0.03176543861627579\n",
      "batch accuracy: 0.9921875\n",
      "doing 258 / 277\n",
      "elapsed time 23315.716183900833\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 0.9902\n",
      "batch loss: 0.032345838844776154\n",
      "batch accuracy: 0.990234375\n",
      "doing 259 / 277\n",
      "elapsed time 23390.464990377426\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0283 - accuracy: 0.9932\n",
      "batch loss: 0.028285332024097443\n",
      "batch accuracy: 0.9931640625\n",
      "doing 260 / 277\n",
      "elapsed time 23461.660334587097\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9941\n",
      "batch loss: 0.025318827480077744\n",
      "batch accuracy: 0.994140625\n",
      "doing 261 / 277\n",
      "elapsed time 23536.926253318787\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.9932\n",
      "batch loss: 0.03221403807401657\n",
      "batch accuracy: 0.9931640625\n",
      "doing 262 / 277\n",
      "elapsed time 23611.78110074997\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9912\n",
      "batch loss: 0.030095091089606285\n",
      "batch accuracy: 0.9912109375\n",
      "doing 263 / 277\n",
      "elapsed time 23686.90991616249\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9922\n",
      "batch loss: 0.029059454798698425\n",
      "batch accuracy: 0.9921875\n",
      "doing 264 / 277\n",
      "elapsed time 23760.004817962646\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0380 - accuracy: 0.9863\n",
      "batch loss: 0.03800942003726959\n",
      "batch accuracy: 0.986328125\n",
      "doing 265 / 277\n",
      "elapsed time 23832.87912774086\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9932\n",
      "batch loss: 0.029118366539478302\n",
      "batch accuracy: 0.9931640625\n",
      "doing 266 / 277\n",
      "elapsed time 23906.970081329346\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0362 - accuracy: 0.9941\n",
      "batch loss: 0.03619150072336197\n",
      "batch accuracy: 0.994140625\n",
      "doing 267 / 277\n",
      "elapsed time 23983.732164144516\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9902\n",
      "batch loss: 0.036274414509534836\n",
      "batch accuracy: 0.990234375\n",
      "doing 268 / 277\n",
      "elapsed time 24058.191183805466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0512 - accuracy: 0.9863\n",
      "batch loss: 0.05122045427560806\n",
      "batch accuracy: 0.986328125\n",
      "doing 269 / 277\n",
      "elapsed time 24131.0287296772\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.9951\n",
      "batch loss: 0.028972938656806946\n",
      "batch accuracy: 0.9951171875\n",
      "doing 270 / 277\n",
      "elapsed time 24204.583241939545\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9912\n",
      "batch loss: 0.03132268786430359\n",
      "batch accuracy: 0.9912109375\n",
      "doing 271 / 277\n",
      "elapsed time 24279.201508522034\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9893\n",
      "batch loss: 0.04089405760169029\n",
      "batch accuracy: 0.9892578125\n",
      "doing 272 / 277\n",
      "elapsed time 24355.8254237175\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1141 - accuracy: 0.9707\n",
      "batch loss: 0.11412043869495392\n",
      "batch accuracy: 0.970703125\n",
      "doing 273 / 277\n",
      "elapsed time 24430.602450847626\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1009 - accuracy: 0.9688\n",
      "batch loss: 0.10089088976383209\n",
      "batch accuracy: 0.96875\n",
      "doing 274 / 277\n",
      "elapsed time 24506.076585054398\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2094 - accuracy: 0.9756\n",
      "batch loss: 0.20942965149879456\n",
      "batch accuracy: 0.9755859375\n",
      "doing 275 / 277\n",
      "elapsed time 24577.174736261368\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.9727\n",
      "batch loss: 0.05945723503828049\n",
      "batch accuracy: 0.97265625\n",
      "doing 276 / 277\n",
      "elapsed time 24619.235411405563\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0713 - accuracy: 0.9744\n",
      "batch loss: 0.0713028833270073\n",
      "batch accuracy: 0.974405825138092\n",
      "Train loss 0.03262409782339735\n",
      "Train accuracy 0.9924899578524841\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4377 - accuracy: 0.9142\n",
      "Validation loss: 0.43770670890808105\n",
      "Validation accuracy: 0.914222240447998\n",
      "==================================================\n",
      "2 / 5\n",
      "doing 0 / 277\n",
      "elapsed time 45.13599228858948\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1806 - accuracy: 0.9541\n",
      "batch loss: 0.180564284324646\n",
      "batch accuracy: 0.9541015625\n",
      "doing 1 / 277\n",
      "elapsed time 90.22589445114136\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0970 - accuracy: 0.9609\n",
      "batch loss: 0.09703174978494644\n",
      "batch accuracy: 0.9609375\n",
      "doing 2 / 277\n",
      "elapsed time 133.9502317905426\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2416 - accuracy: 0.9609\n",
      "batch loss: 0.2415989488363266\n",
      "batch accuracy: 0.9609375\n",
      "doing 3 / 277\n",
      "elapsed time 178.5348081588745\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2763 - accuracy: 0.9570\n",
      "batch loss: 0.2763410210609436\n",
      "batch accuracy: 0.95703125\n",
      "doing 4 / 277\n",
      "elapsed time 221.76354813575745\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1366 - accuracy: 0.9541\n",
      "batch loss: 0.1366465836763382\n",
      "batch accuracy: 0.9541015625\n",
      "doing 5 / 277\n",
      "elapsed time 266.64119505882263\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0891 - accuracy: 0.9697\n",
      "batch loss: 0.08912444114685059\n",
      "batch accuracy: 0.9697265625\n",
      "doing 6 / 277\n",
      "elapsed time 311.92666006088257\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1834 - accuracy: 0.9395\n",
      "batch loss: 0.1833895444869995\n",
      "batch accuracy: 0.939453125\n",
      "doing 7 / 277\n",
      "elapsed time 356.17861437797546\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0776 - accuracy: 0.9863\n",
      "batch loss: 0.07762579619884491\n",
      "batch accuracy: 0.986328125\n",
      "doing 8 / 277\n",
      "elapsed time 400.5240390300751\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0839 - accuracy: 0.9688\n",
      "batch loss: 0.08391238003969193\n",
      "batch accuracy: 0.96875\n",
      "doing 9 / 277\n",
      "elapsed time 446.07735204696655\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0918 - accuracy: 0.9668\n",
      "batch loss: 0.09184395521879196\n",
      "batch accuracy: 0.966796875\n",
      "doing 10 / 277\n",
      "elapsed time 490.20238184928894\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9805\n",
      "batch loss: 0.060568660497665405\n",
      "batch accuracy: 0.98046875\n",
      "doing 11 / 277\n",
      "elapsed time 535.4568567276001\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.9775\n",
      "batch loss: 0.060764629393815994\n",
      "batch accuracy: 0.9775390625\n",
      "doing 12 / 277\n",
      "elapsed time 580.3897533416748\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0550 - accuracy: 0.9814\n",
      "batch loss: 0.055034443736076355\n",
      "batch accuracy: 0.9814453125\n",
      "doing 13 / 277\n",
      "elapsed time 625.2736866474152\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0790 - accuracy: 0.9648\n",
      "batch loss: 0.07895320653915405\n",
      "batch accuracy: 0.96484375\n",
      "doing 14 / 277\n",
      "elapsed time 670.9576370716095\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0743 - accuracy: 0.9736\n",
      "batch loss: 0.07430043071508408\n",
      "batch accuracy: 0.9736328125\n",
      "doing 15 / 277\n",
      "elapsed time 718.8430576324463\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0745 - accuracy: 0.9863\n",
      "batch loss: 0.07453485578298569\n",
      "batch accuracy: 0.986328125\n",
      "doing 16 / 277\n",
      "elapsed time 765.2475361824036\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.9805\n",
      "batch loss: 0.0666743665933609\n",
      "batch accuracy: 0.98046875\n",
      "doing 17 / 277\n",
      "elapsed time 809.8511922359467\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9785\n",
      "batch loss: 0.056697361171245575\n",
      "batch accuracy: 0.978515625\n",
      "doing 18 / 277\n",
      "elapsed time 854.4963207244873\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9795\n",
      "batch loss: 0.05137849226593971\n",
      "batch accuracy: 0.9794921875\n",
      "doing 19 / 277\n",
      "elapsed time 902.0593414306641\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.9756\n",
      "batch loss: 0.06351841241121292\n",
      "batch accuracy: 0.9755859375\n",
      "doing 20 / 277\n",
      "elapsed time 947.7718834877014\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9785\n",
      "batch loss: 0.05511881783604622\n",
      "batch accuracy: 0.978515625\n",
      "doing 21 / 277\n",
      "elapsed time 993.25084233284\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9893\n",
      "batch loss: 0.03881346434354782\n",
      "batch accuracy: 0.9892578125\n",
      "doing 22 / 277\n",
      "elapsed time 1038.1766107082367\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.9883\n",
      "batch loss: 0.047454219311475754\n",
      "batch accuracy: 0.98828125\n",
      "doing 23 / 277\n",
      "elapsed time 1086.010576248169\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9883\n",
      "batch loss: 0.047715671360492706\n",
      "batch accuracy: 0.98828125\n",
      "doing 24 / 277\n",
      "elapsed time 1126.2669599056244\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9883\n",
      "batch loss: 0.04773275554180145\n",
      "batch accuracy: 0.98828125\n",
      "doing 25 / 277\n",
      "elapsed time 1171.067029953003\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9863\n",
      "batch loss: 0.04396305978298187\n",
      "batch accuracy: 0.986328125\n",
      "doing 26 / 277\n",
      "elapsed time 1212.0609843730927\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.9863\n",
      "batch loss: 0.040425632148981094\n",
      "batch accuracy: 0.986328125\n",
      "doing 27 / 277\n",
      "elapsed time 1255.9267857074738\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9902\n",
      "batch loss: 0.03998534381389618\n",
      "batch accuracy: 0.990234375\n",
      "doing 28 / 277\n",
      "elapsed time 1300.2748746871948\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.9932\n",
      "batch loss: 0.03332449123263359\n",
      "batch accuracy: 0.9931640625\n",
      "doing 29 / 277\n",
      "elapsed time 1347.1705448627472\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9873\n",
      "batch loss: 0.05023069679737091\n",
      "batch accuracy: 0.9873046875\n",
      "doing 30 / 277\n",
      "elapsed time 1392.3234102725983\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9912\n",
      "batch loss: 0.039470843970775604\n",
      "batch accuracy: 0.9912109375\n",
      "doing 31 / 277\n",
      "elapsed time 1435.2053699493408\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9951\n",
      "batch loss: 0.03007460944354534\n",
      "batch accuracy: 0.9951171875\n",
      "doing 32 / 277\n",
      "elapsed time 1480.821545124054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0365 - accuracy: 0.9912\n",
      "batch loss: 0.0365164689719677\n",
      "batch accuracy: 0.9912109375\n",
      "doing 33 / 277\n",
      "elapsed time 1526.073157787323\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 0.9961\n",
      "batch loss: 0.03053845465183258\n",
      "batch accuracy: 0.99609375\n",
      "doing 34 / 277\n",
      "elapsed time 1570.145943403244\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.9951\n",
      "batch loss: 0.026747863739728928\n",
      "batch accuracy: 0.9951171875\n",
      "doing 35 / 277\n",
      "elapsed time 1612.5051958560944\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9961\n",
      "batch loss: 0.02758619748055935\n",
      "batch accuracy: 0.99609375\n",
      "doing 36 / 277\n",
      "elapsed time 1658.67378616333\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9941\n",
      "batch loss: 0.026344679296016693\n",
      "batch accuracy: 0.994140625\n",
      "doing 37 / 277\n",
      "elapsed time 1703.5645678043365\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0285 - accuracy: 0.9961\n",
      "batch loss: 0.028538556769490242\n",
      "batch accuracy: 0.99609375\n",
      "doing 38 / 277\n",
      "elapsed time 1747.3998064994812\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 0.9990\n",
      "batch loss: 0.018467988818883896\n",
      "batch accuracy: 0.9990234375\n",
      "doing 39 / 277\n",
      "elapsed time 1791.9303951263428\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0314 - accuracy: 0.9951\n",
      "batch loss: 0.031411558389663696\n",
      "batch accuracy: 0.9951171875\n",
      "doing 40 / 277\n",
      "elapsed time 1835.1709213256836\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.9932\n",
      "batch loss: 0.0249948687851429\n",
      "batch accuracy: 0.9931640625\n",
      "doing 41 / 277\n",
      "elapsed time 1876.090100288391\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.9971\n",
      "batch loss: 0.026738915592432022\n",
      "batch accuracy: 0.9970703125\n",
      "doing 42 / 277\n",
      "elapsed time 1918.2045469284058\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0371 - accuracy: 0.9902\n",
      "batch loss: 0.03713630139827728\n",
      "batch accuracy: 0.990234375\n",
      "doing 43 / 277\n",
      "elapsed time 1963.9304912090302\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 0.9941\n",
      "batch loss: 0.031029552221298218\n",
      "batch accuracy: 0.994140625\n",
      "doing 44 / 277\n",
      "elapsed time 2011.9202525615692\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9941\n",
      "batch loss: 0.026923280209302902\n",
      "batch accuracy: 0.994140625\n",
      "doing 45 / 277\n",
      "elapsed time 2059.1738843917847\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0282 - accuracy: 0.9961\n",
      "batch loss: 0.02815863862633705\n",
      "batch accuracy: 0.99609375\n",
      "doing 46 / 277\n",
      "elapsed time 2104.360501766205\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9990\n",
      "batch loss: 0.025518370792269707\n",
      "batch accuracy: 0.9990234375\n",
      "doing 47 / 277\n",
      "elapsed time 2152.254247903824\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.9961\n",
      "batch loss: 0.02670248970389366\n",
      "batch accuracy: 0.99609375\n",
      "doing 48 / 277\n",
      "elapsed time 2202.250818014145\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9961\n",
      "batch loss: 0.02546371892094612\n",
      "batch accuracy: 0.99609375\n",
      "doing 49 / 277\n",
      "elapsed time 2251.1735892295837\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9951\n",
      "batch loss: 0.024030517786741257\n",
      "batch accuracy: 0.9951171875\n",
      "doing 50 / 277\n",
      "elapsed time 2299.9123797416687\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 0.9961\n",
      "batch loss: 0.023332267999649048\n",
      "batch accuracy: 0.99609375\n",
      "doing 51 / 277\n",
      "elapsed time 2350.1563675403595\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 0.9980\n",
      "batch loss: 0.023642636835575104\n",
      "batch accuracy: 0.998046875\n",
      "doing 52 / 277\n",
      "elapsed time 2397.2013924121857\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9941\n",
      "batch loss: 0.0240841843187809\n",
      "batch accuracy: 0.994140625\n",
      "doing 53 / 277\n",
      "elapsed time 2445.018969774246\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9961\n",
      "batch loss: 0.019060565158724785\n",
      "batch accuracy: 0.99609375\n",
      "doing 54 / 277\n",
      "elapsed time 2494.5768463611603\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9990\n",
      "batch loss: 0.029119528830051422\n",
      "batch accuracy: 0.9990234375\n",
      "doing 55 / 277\n",
      "elapsed time 2539.540258407593\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9990\n",
      "batch loss: 0.01887362077832222\n",
      "batch accuracy: 0.9990234375\n",
      "doing 56 / 277\n",
      "elapsed time 2589.5555696487427\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 0.9961\n",
      "batch loss: 0.023573169484734535\n",
      "batch accuracy: 0.99609375\n",
      "doing 57 / 277\n",
      "elapsed time 2635.9853751659393\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9971\n",
      "batch loss: 0.02035428397357464\n",
      "batch accuracy: 0.9970703125\n",
      "doing 58 / 277\n",
      "elapsed time 2683.059515476227\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0225 - accuracy: 0.9941\n",
      "batch loss: 0.022512443363666534\n",
      "batch accuracy: 0.994140625\n",
      "doing 59 / 277\n",
      "elapsed time 2730.9824039936066\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9990\n",
      "batch loss: 0.01631254330277443\n",
      "batch accuracy: 0.9990234375\n",
      "doing 60 / 277\n",
      "elapsed time 2776.1923184394836\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9951\n",
      "batch loss: 0.024573834612965584\n",
      "batch accuracy: 0.9951171875\n",
      "doing 61 / 277\n",
      "elapsed time 2824.149784564972\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9990\n",
      "batch loss: 0.017360778525471687\n",
      "batch accuracy: 0.9990234375\n",
      "doing 62 / 277\n",
      "elapsed time 2870.859696149826\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 0.9961\n",
      "batch loss: 0.024153172969818115\n",
      "batch accuracy: 0.99609375\n",
      "doing 63 / 277\n",
      "elapsed time 2919.5808687210083\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.9932\n",
      "batch loss: 0.024950552731752396\n",
      "batch accuracy: 0.9931640625\n",
      "doing 64 / 277\n",
      "elapsed time 2964.8922719955444\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 0.9961\n",
      "batch loss: 0.02087949402630329\n",
      "batch accuracy: 0.99609375\n",
      "doing 65 / 277\n",
      "elapsed time 3013.4015078544617\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9961\n",
      "batch loss: 0.02478303760290146\n",
      "batch accuracy: 0.99609375\n",
      "doing 66 / 277\n",
      "elapsed time 3059.862616300583\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9980\n",
      "batch loss: 0.018817156553268433\n",
      "batch accuracy: 0.998046875\n",
      "doing 67 / 277\n",
      "elapsed time 3106.7998843193054\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.9951\n",
      "batch loss: 0.02228790894150734\n",
      "batch accuracy: 0.9951171875\n",
      "doing 68 / 277\n",
      "elapsed time 3153.5808169841766\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9951\n",
      "batch loss: 0.024297956377267838\n",
      "batch accuracy: 0.9951171875\n",
      "doing 69 / 277\n",
      "elapsed time 3199.4218339920044\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9990\n",
      "batch loss: 0.02036547102034092\n",
      "batch accuracy: 0.9990234375\n",
      "doing 70 / 277\n",
      "elapsed time 3243.3570640087128\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 0.9961\n",
      "batch loss: 0.021479429677128792\n",
      "batch accuracy: 0.99609375\n",
      "doing 71 / 277\n",
      "elapsed time 3291.460177898407\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0319 - accuracy: 0.9902\n",
      "batch loss: 0.03193679451942444\n",
      "batch accuracy: 0.990234375\n",
      "doing 72 / 277\n",
      "elapsed time 3338.614596605301\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 0.9941\n",
      "batch loss: 0.02580537274479866\n",
      "batch accuracy: 0.994140625\n",
      "doing 73 / 277\n",
      "elapsed time 3389.1286959648132\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9961\n",
      "batch loss: 0.025289935991168022\n",
      "batch accuracy: 0.99609375\n",
      "doing 74 / 277\n",
      "elapsed time 3433.556018590927\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.9980\n",
      "batch loss: 0.018954336643218994\n",
      "batch accuracy: 0.998046875\n",
      "doing 75 / 277\n",
      "elapsed time 3482.3805615901947\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9941\n",
      "batch loss: 0.024798374623060226\n",
      "batch accuracy: 0.994140625\n",
      "doing 76 / 277\n",
      "elapsed time 3526.8108825683594\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9951\n",
      "batch loss: 0.02192727103829384\n",
      "batch accuracy: 0.9951171875\n",
      "doing 77 / 277\n",
      "elapsed time 3572.9865293502808\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9971\n",
      "batch loss: 0.0218748077750206\n",
      "batch accuracy: 0.9970703125\n",
      "doing 78 / 277\n",
      "elapsed time 3621.451422691345\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9902\n",
      "batch loss: 0.028911320492625237\n",
      "batch accuracy: 0.990234375\n",
      "doing 79 / 277\n",
      "elapsed time 3671.7008395195007\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9941\n",
      "batch loss: 0.024088459089398384\n",
      "batch accuracy: 0.994140625\n",
      "doing 80 / 277\n",
      "elapsed time 3719.7691230773926\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9980\n",
      "batch loss: 0.0183985847979784\n",
      "batch accuracy: 0.998046875\n",
      "doing 81 / 277\n",
      "elapsed time 3767.6742737293243\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9971\n",
      "batch loss: 0.019398147240281105\n",
      "batch accuracy: 0.9970703125\n",
      "doing 82 / 277\n",
      "elapsed time 3816.6822879314423\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9980\n",
      "batch loss: 0.024798817932605743\n",
      "batch accuracy: 0.998046875\n",
      "doing 83 / 277\n",
      "elapsed time 3865.944438457489\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 0.9971\n",
      "batch loss: 0.022243566811084747\n",
      "batch accuracy: 0.9970703125\n",
      "doing 84 / 277\n",
      "elapsed time 3915.1833386421204\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9961\n",
      "batch loss: 0.020277075469493866\n",
      "batch accuracy: 0.99609375\n",
      "doing 85 / 277\n",
      "elapsed time 3960.733363866806\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9990\n",
      "batch loss: 0.017628584057092667\n",
      "batch accuracy: 0.9990234375\n",
      "doing 86 / 277\n",
      "elapsed time 4010.736522436142\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9961\n",
      "batch loss: 0.017658650875091553\n",
      "batch accuracy: 0.99609375\n",
      "doing 87 / 277\n",
      "elapsed time 4060.5062804222107\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9951\n",
      "batch loss: 0.018370743840932846\n",
      "batch accuracy: 0.9951171875\n",
      "doing 88 / 277\n",
      "elapsed time 4111.078927993774\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 0.9961\n",
      "batch loss: 0.020650986582040787\n",
      "batch accuracy: 0.99609375\n",
      "doing 89 / 277\n",
      "elapsed time 4159.563894510269\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9990\n",
      "batch loss: 0.019753258675336838\n",
      "batch accuracy: 0.9990234375\n",
      "doing 90 / 277\n",
      "elapsed time 4208.271755456924\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 0.9961\n",
      "batch loss: 0.02089802175760269\n",
      "batch accuracy: 0.99609375\n",
      "doing 91 / 277\n",
      "elapsed time 4259.454854726791\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9990\n",
      "batch loss: 0.0182441845536232\n",
      "batch accuracy: 0.9990234375\n",
      "doing 92 / 277\n",
      "elapsed time 4309.302256822586\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9961\n",
      "batch loss: 0.018840888515114784\n",
      "batch accuracy: 0.99609375\n",
      "doing 93 / 277\n",
      "elapsed time 4359.555943965912\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9922\n",
      "batch loss: 0.0279494971036911\n",
      "batch accuracy: 0.9921875\n",
      "doing 94 / 277\n",
      "elapsed time 4414.591982841492\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.9922\n",
      "batch loss: 0.0316162109375\n",
      "batch accuracy: 0.9921875\n",
      "doing 95 / 277\n",
      "elapsed time 4464.941838264465\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9951\n",
      "batch loss: 0.02426866441965103\n",
      "batch accuracy: 0.9951171875\n",
      "doing 96 / 277\n",
      "elapsed time 4518.201225042343\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9961\n",
      "batch loss: 0.021227382123470306\n",
      "batch accuracy: 0.99609375\n",
      "doing 97 / 277\n",
      "elapsed time 4568.063789606094\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9961\n",
      "batch loss: 0.019535034894943237\n",
      "batch accuracy: 0.99609375\n",
      "doing 98 / 277\n",
      "elapsed time 4617.36080288887\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9971\n",
      "batch loss: 0.018410706892609596\n",
      "batch accuracy: 0.9970703125\n",
      "doing 99 / 277\n",
      "elapsed time 4670.0274448394775\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9971\n",
      "batch loss: 0.020110277459025383\n",
      "batch accuracy: 0.9970703125\n",
      "doing 100 / 277\n",
      "elapsed time 4719.974315166473\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.9951\n",
      "batch loss: 0.020784109830856323\n",
      "batch accuracy: 0.9951171875\n",
      "doing 101 / 277\n",
      "elapsed time 4771.126163482666\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9990\n",
      "batch loss: 0.014283467084169388\n",
      "batch accuracy: 0.9990234375\n",
      "doing 102 / 277\n",
      "elapsed time 4819.459480762482\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9961\n",
      "batch loss: 0.016700197011232376\n",
      "batch accuracy: 0.99609375\n",
      "doing 103 / 277\n",
      "elapsed time 4871.332557916641\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.9990\n",
      "batch loss: 0.018036488443613052\n",
      "batch accuracy: 0.9990234375\n",
      "doing 104 / 277\n",
      "elapsed time 4918.836824893951\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9922\n",
      "batch loss: 0.023964548483490944\n",
      "batch accuracy: 0.9921875\n",
      "doing 105 / 277\n",
      "elapsed time 4967.387843370438\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 0.9941\n",
      "batch loss: 0.021273374557495117\n",
      "batch accuracy: 0.994140625\n",
      "doing 106 / 277\n",
      "elapsed time 5017.507192134857\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9951\n",
      "batch loss: 0.02688254602253437\n",
      "batch accuracy: 0.9951171875\n",
      "doing 107 / 277\n",
      "elapsed time 5070.0253620147705\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0272 - accuracy: 0.9941\n",
      "batch loss: 0.027203459292650223\n",
      "batch accuracy: 0.994140625\n",
      "doing 108 / 277\n",
      "elapsed time 5120.602075099945\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 0.9951\n",
      "batch loss: 0.02339351549744606\n",
      "batch accuracy: 0.9951171875\n",
      "doing 109 / 277\n",
      "elapsed time 5173.422059774399\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.9922\n",
      "batch loss: 0.032169271260499954\n",
      "batch accuracy: 0.9921875\n",
      "doing 110 / 277\n",
      "elapsed time 5223.19556593895\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9951\n",
      "batch loss: 0.0252375565469265\n",
      "batch accuracy: 0.9951171875\n",
      "doing 111 / 277\n",
      "elapsed time 5275.719997406006\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9980\n",
      "batch loss: 0.020002972334623337\n",
      "batch accuracy: 0.998046875\n",
      "doing 112 / 277\n",
      "elapsed time 5327.727780580521\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.9951\n",
      "batch loss: 0.022303316742181778\n",
      "batch accuracy: 0.9951171875\n",
      "doing 113 / 277\n",
      "elapsed time 5377.735718250275\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9902\n",
      "batch loss: 0.030077572911977768\n",
      "batch accuracy: 0.990234375\n",
      "doing 114 / 277\n",
      "elapsed time 5427.174419641495\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9971\n",
      "batch loss: 0.02312852069735527\n",
      "batch accuracy: 0.9970703125\n",
      "doing 115 / 277\n",
      "elapsed time 5477.678347349167\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.9902\n",
      "batch loss: 0.028965245932340622\n",
      "batch accuracy: 0.990234375\n",
      "doing 116 / 277\n",
      "elapsed time 5526.587367773056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 0.9941\n",
      "batch loss: 0.026603378355503082\n",
      "batch accuracy: 0.994140625\n",
      "doing 117 / 277\n",
      "elapsed time 5574.682954072952\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.9932\n",
      "batch loss: 0.029700273647904396\n",
      "batch accuracy: 0.9931640625\n",
      "doing 118 / 277\n",
      "elapsed time 5620.602255344391\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9980\n",
      "batch loss: 0.017838161438703537\n",
      "batch accuracy: 0.998046875\n",
      "doing 119 / 277\n",
      "elapsed time 5671.604322195053\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9961\n",
      "batch loss: 0.021571608260273933\n",
      "batch accuracy: 0.99609375\n",
      "doing 120 / 277\n",
      "elapsed time 5724.001264810562\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 0.9922\n",
      "batch loss: 0.028049897402524948\n",
      "batch accuracy: 0.9921875\n",
      "doing 121 / 277\n",
      "elapsed time 5771.870019674301\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0237 - accuracy: 0.9951\n",
      "batch loss: 0.02365591563284397\n",
      "batch accuracy: 0.9951171875\n",
      "doing 122 / 277\n",
      "elapsed time 5831.699378490448\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0273 - accuracy: 0.9932\n",
      "batch loss: 0.027342433109879494\n",
      "batch accuracy: 0.9931640625\n",
      "doing 123 / 277\n",
      "elapsed time 5889.181767702103\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9971\n",
      "batch loss: 0.017677634954452515\n",
      "batch accuracy: 0.9970703125\n",
      "doing 124 / 277\n",
      "elapsed time 5949.810253381729\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9980\n",
      "batch loss: 0.01995188370347023\n",
      "batch accuracy: 0.998046875\n",
      "doing 125 / 277\n",
      "elapsed time 6008.842818975449\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.9980\n",
      "batch loss: 0.0214360561221838\n",
      "batch accuracy: 0.998046875\n",
      "doing 126 / 277\n",
      "elapsed time 6068.427576780319\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9990\n",
      "batch loss: 0.018364373594522476\n",
      "batch accuracy: 0.9990234375\n",
      "doing 127 / 277\n",
      "elapsed time 6129.926510334015\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9961\n",
      "batch loss: 0.026938531547784805\n",
      "batch accuracy: 0.99609375\n",
      "doing 128 / 277\n",
      "elapsed time 6193.086254119873\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9990\n",
      "batch loss: 0.016105864197015762\n",
      "batch accuracy: 0.9990234375\n",
      "doing 129 / 277\n",
      "elapsed time 6255.967448949814\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9971\n",
      "batch loss: 0.020111024379730225\n",
      "batch accuracy: 0.9970703125\n",
      "doing 130 / 277\n",
      "elapsed time 6320.656671762466\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9971\n",
      "batch loss: 0.016318148002028465\n",
      "batch accuracy: 0.9970703125\n",
      "doing 131 / 277\n",
      "elapsed time 6378.9015345573425\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 0.9971\n",
      "batch loss: 0.019265148788690567\n",
      "batch accuracy: 0.9970703125\n",
      "doing 132 / 277\n",
      "elapsed time 6439.228905916214\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 0.9980\n",
      "batch loss: 0.01929740235209465\n",
      "batch accuracy: 0.998046875\n",
      "doing 133 / 277\n",
      "elapsed time 6503.1058123111725\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9971\n",
      "batch loss: 0.01687379740178585\n",
      "batch accuracy: 0.9970703125\n",
      "doing 134 / 277\n",
      "elapsed time 6565.486530542374\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9941\n",
      "batch loss: 0.025248009711503983\n",
      "batch accuracy: 0.994140625\n",
      "doing 135 / 277\n",
      "elapsed time 6627.412808895111\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9971\n",
      "batch loss: 0.024567347019910812\n",
      "batch accuracy: 0.9970703125\n",
      "doing 136 / 277\n",
      "elapsed time 6689.4851903915405\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9961\n",
      "batch loss: 0.02011801488697529\n",
      "batch accuracy: 0.99609375\n",
      "doing 137 / 277\n",
      "elapsed time 6748.6092965602875\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 0.9971\n",
      "batch loss: 0.017112305387854576\n",
      "batch accuracy: 0.9970703125\n",
      "doing 138 / 277\n",
      "elapsed time 6811.012515306473\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9971\n",
      "batch loss: 0.01669694483280182\n",
      "batch accuracy: 0.9970703125\n",
      "doing 139 / 277\n",
      "elapsed time 6874.491966962814\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9961\n",
      "batch loss: 0.020481271669268608\n",
      "batch accuracy: 0.99609375\n",
      "doing 140 / 277\n",
      "elapsed time 6935.412699699402\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 0.9971\n",
      "batch loss: 0.015900511294603348\n",
      "batch accuracy: 0.9970703125\n",
      "doing 141 / 277\n",
      "elapsed time 6997.946948289871\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 0.9980\n",
      "batch loss: 0.019226716831326485\n",
      "batch accuracy: 0.998046875\n",
      "doing 142 / 277\n",
      "elapsed time 7056.208057165146\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9951\n",
      "batch loss: 0.025173520669341087\n",
      "batch accuracy: 0.9951171875\n",
      "doing 143 / 277\n",
      "elapsed time 7118.660146713257\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.9980\n",
      "batch loss: 0.01795455440878868\n",
      "batch accuracy: 0.998046875\n",
      "doing 144 / 277\n",
      "elapsed time 7182.432007312775\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9980\n",
      "batch loss: 0.019469425082206726\n",
      "batch accuracy: 0.998046875\n",
      "doing 145 / 277\n",
      "elapsed time 7244.613733291626\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9980\n",
      "batch loss: 0.014537913724780083\n",
      "batch accuracy: 0.998046875\n",
      "doing 146 / 277\n",
      "elapsed time 7310.87090754509\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9971\n",
      "batch loss: 0.014721713960170746\n",
      "batch accuracy: 0.9970703125\n",
      "doing 147 / 277\n",
      "elapsed time 7384.558456420898\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9932\n",
      "batch loss: 0.024297639727592468\n",
      "batch accuracy: 0.9931640625\n",
      "doing 148 / 277\n",
      "elapsed time 7457.540991783142\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9990\n",
      "batch loss: 0.01581645756959915\n",
      "batch accuracy: 0.9990234375\n",
      "doing 149 / 277\n",
      "elapsed time 7535.745017290115\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9951\n",
      "batch loss: 0.02652144245803356\n",
      "batch accuracy: 0.9951171875\n",
      "doing 150 / 277\n",
      "elapsed time 7610.537370920181\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9971\n",
      "batch loss: 0.017842145636677742\n",
      "batch accuracy: 0.9970703125\n",
      "doing 151 / 277\n",
      "elapsed time 7690.668841838837\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9990\n",
      "batch loss: 0.020252402871847153\n",
      "batch accuracy: 0.9990234375\n",
      "doing 152 / 277\n",
      "elapsed time 7766.519210100174\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9990\n",
      "batch loss: 0.013846403919160366\n",
      "batch accuracy: 0.9990234375\n",
      "doing 153 / 277\n",
      "elapsed time 7840.843050479889\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 0.9922\n",
      "batch loss: 0.03049135021865368\n",
      "batch accuracy: 0.9921875\n",
      "doing 154 / 277\n",
      "elapsed time 7915.564707517624\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9961\n",
      "batch loss: 0.02096257545053959\n",
      "batch accuracy: 0.99609375\n",
      "doing 155 / 277\n",
      "elapsed time 7987.963058948517\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9971\n",
      "batch loss: 0.019091051071882248\n",
      "batch accuracy: 0.9970703125\n",
      "doing 156 / 277\n",
      "elapsed time 8065.7334842681885\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 0.9951\n",
      "batch loss: 0.023345045745372772\n",
      "batch accuracy: 0.9951171875\n",
      "doing 157 / 277\n",
      "elapsed time 8144.529414176941\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 0.9990\n",
      "batch loss: 0.021492332220077515\n",
      "batch accuracy: 0.9990234375\n",
      "doing 158 / 277\n",
      "elapsed time 8220.078187704086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9980\n",
      "batch loss: 0.021013755351305008\n",
      "batch accuracy: 0.998046875\n",
      "doing 159 / 277\n",
      "elapsed time 8294.672966957092\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0282 - accuracy: 0.9951\n",
      "batch loss: 0.02816026285290718\n",
      "batch accuracy: 0.9951171875\n",
      "doing 160 / 277\n",
      "elapsed time 8377.607108592987\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9971\n",
      "batch loss: 0.01736888289451599\n",
      "batch accuracy: 0.9970703125\n",
      "doing 161 / 277\n",
      "elapsed time 8452.72343993187\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9971\n",
      "batch loss: 0.02190319262444973\n",
      "batch accuracy: 0.9970703125\n",
      "doing 162 / 277\n",
      "elapsed time 8523.805908441544\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9990\n",
      "batch loss: 0.015468358062207699\n",
      "batch accuracy: 0.9990234375\n",
      "doing 163 / 277\n",
      "elapsed time 8601.942846298218\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.9961\n",
      "batch loss: 0.02177492156624794\n",
      "batch accuracy: 0.99609375\n",
      "doing 164 / 277\n",
      "elapsed time 8685.486250400543\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0314 - accuracy: 0.9961\n",
      "batch loss: 0.03140197694301605\n",
      "batch accuracy: 0.99609375\n",
      "doing 165 / 277\n",
      "elapsed time 8772.815417051315\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9961\n",
      "batch loss: 0.019121911376714706\n",
      "batch accuracy: 0.99609375\n",
      "doing 166 / 277\n",
      "elapsed time 8857.358834505081\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 0.9941\n",
      "batch loss: 0.02264934591948986\n",
      "batch accuracy: 0.994140625\n",
      "doing 167 / 277\n",
      "elapsed time 8944.070146560669\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9961\n",
      "batch loss: 0.020967643707990646\n",
      "batch accuracy: 0.99609375\n",
      "doing 168 / 277\n",
      "elapsed time 9027.605909347534\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9971\n",
      "batch loss: 0.018338657915592194\n",
      "batch accuracy: 0.9970703125\n",
      "doing 169 / 277\n",
      "elapsed time 9113.46699309349\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 0.9912\n",
      "batch loss: 0.024236934259533882\n",
      "batch accuracy: 0.9912109375\n",
      "doing 170 / 277\n",
      "elapsed time 9197.380934238434\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.9980\n",
      "batch loss: 0.017514260485768318\n",
      "batch accuracy: 0.998046875\n",
      "doing 171 / 277\n",
      "elapsed time 9277.850906610489\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9971\n",
      "batch loss: 0.024131663143634796\n",
      "batch accuracy: 0.9970703125\n",
      "doing 172 / 277\n",
      "elapsed time 9358.755641460419\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.9961\n",
      "batch loss: 0.019947193562984467\n",
      "batch accuracy: 0.99609375\n",
      "doing 173 / 277\n",
      "elapsed time 9443.868381261826\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9932\n",
      "batch loss: 0.023823535069823265\n",
      "batch accuracy: 0.9931640625\n",
      "doing 174 / 277\n",
      "elapsed time 9530.162105798721\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9971\n",
      "batch loss: 0.01658598519861698\n",
      "batch accuracy: 0.9970703125\n",
      "doing 175 / 277\n",
      "elapsed time 9617.511717796326\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9961\n",
      "batch loss: 0.01881733164191246\n",
      "batch accuracy: 0.99609375\n",
      "doing 176 / 277\n",
      "elapsed time 9708.557942390442\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9922\n",
      "batch loss: 0.02461232990026474\n",
      "batch accuracy: 0.9921875\n",
      "doing 177 / 277\n",
      "elapsed time 9790.760085344315\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9932\n",
      "batch loss: 0.01961606927216053\n",
      "batch accuracy: 0.9931640625\n",
      "doing 178 / 277\n",
      "elapsed time 9874.73182797432\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9951\n",
      "batch loss: 0.022717036306858063\n",
      "batch accuracy: 0.9951171875\n",
      "doing 179 / 277\n",
      "elapsed time 9953.096388578415\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9971\n",
      "batch loss: 0.023066364228725433\n",
      "batch accuracy: 0.9970703125\n",
      "doing 180 / 277\n",
      "elapsed time 10040.088785886765\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9951\n",
      "batch loss: 0.020430490374565125\n",
      "batch accuracy: 0.9951171875\n",
      "doing 181 / 277\n",
      "elapsed time 10122.947360515594\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9971\n",
      "batch loss: 0.016701392829418182\n",
      "batch accuracy: 0.9970703125\n",
      "doing 182 / 277\n",
      "elapsed time 10208.063087701797\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9980\n",
      "batch loss: 0.016613831743597984\n",
      "batch accuracy: 0.998046875\n",
      "doing 183 / 277\n",
      "elapsed time 10291.536300182343\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9990\n",
      "batch loss: 0.018262872472405434\n",
      "batch accuracy: 0.9990234375\n",
      "doing 184 / 277\n",
      "elapsed time 10376.702067375183\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9932\n",
      "batch loss: 0.02189398743212223\n",
      "batch accuracy: 0.9931640625\n",
      "doing 185 / 277\n",
      "elapsed time 10459.973980665207\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 0.9941\n",
      "batch loss: 0.021517032757401466\n",
      "batch accuracy: 0.994140625\n",
      "doing 186 / 277\n",
      "elapsed time 10545.624474525452\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9951\n",
      "batch loss: 0.02186005190014839\n",
      "batch accuracy: 0.9951171875\n",
      "doing 187 / 277\n",
      "elapsed time 10628.872517347336\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 0.9971\n",
      "batch loss: 0.017309516668319702\n",
      "batch accuracy: 0.9970703125\n",
      "doing 188 / 277\n",
      "elapsed time 10713.110547542572\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9990\n",
      "batch loss: 0.013728154823184013\n",
      "batch accuracy: 0.9990234375\n",
      "doing 189 / 277\n",
      "elapsed time 10805.045853376389\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9980\n",
      "batch loss: 0.01453145407140255\n",
      "batch accuracy: 0.998046875\n",
      "doing 190 / 277\n",
      "elapsed time 10893.96637392044\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9980\n",
      "batch loss: 0.016583440825343132\n",
      "batch accuracy: 0.998046875\n",
      "doing 191 / 277\n",
      "elapsed time 10979.468754768372\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 0.9951\n",
      "batch loss: 0.022832542657852173\n",
      "batch accuracy: 0.9951171875\n",
      "doing 192 / 277\n",
      "elapsed time 11067.209222078323\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0150 - accuracy: 0.9990\n",
      "batch loss: 0.014959504827857018\n",
      "batch accuracy: 0.9990234375\n",
      "doing 193 / 277\n",
      "elapsed time 11153.257205247879\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9990\n",
      "batch loss: 0.014710329473018646\n",
      "batch accuracy: 0.9990234375\n",
      "doing 194 / 277\n",
      "elapsed time 11237.318578004837\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9990\n",
      "batch loss: 0.013551924377679825\n",
      "batch accuracy: 0.9990234375\n",
      "doing 195 / 277\n",
      "elapsed time 11322.729223012924\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "batch loss: 0.010901862755417824\n",
      "batch accuracy: 1.0\n",
      "doing 196 / 277\n",
      "elapsed time 11406.061779975891\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9951\n",
      "batch loss: 0.019373949617147446\n",
      "batch accuracy: 0.9951171875\n",
      "doing 197 / 277\n",
      "elapsed time 11490.715643405914\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9941\n",
      "batch loss: 0.024842439219355583\n",
      "batch accuracy: 0.994140625\n",
      "doing 198 / 277\n",
      "elapsed time 11576.715948581696\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9971\n",
      "batch loss: 0.015344296582043171\n",
      "batch accuracy: 0.9970703125\n",
      "doing 199 / 277\n",
      "elapsed time 11669.15187740326\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9951\n",
      "batch loss: 0.016652021557092667\n",
      "batch accuracy: 0.9951171875\n",
      "doing 200 / 277\n",
      "elapsed time 11757.119470357895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9980\n",
      "batch loss: 0.016858085989952087\n",
      "batch accuracy: 0.998046875\n",
      "doing 201 / 277\n",
      "elapsed time 11842.123139619827\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9980\n",
      "batch loss: 0.015178072266280651\n",
      "batch accuracy: 0.998046875\n",
      "doing 202 / 277\n",
      "elapsed time 11930.506727695465\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9971\n",
      "batch loss: 0.015512576326727867\n",
      "batch accuracy: 0.9970703125\n",
      "doing 203 / 277\n",
      "elapsed time 12014.25803565979\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9932\n",
      "batch loss: 0.02322373352944851\n",
      "batch accuracy: 0.9931640625\n",
      "doing 204 / 277\n",
      "elapsed time 12097.184949159622\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9990\n",
      "batch loss: 0.015294281765818596\n",
      "batch accuracy: 0.9990234375\n",
      "doing 205 / 277\n",
      "elapsed time 12183.483257770538\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 0.9951\n",
      "batch loss: 0.020688101649284363\n",
      "batch accuracy: 0.9951171875\n",
      "doing 206 / 277\n",
      "elapsed time 12271.123293876648\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9971\n",
      "batch loss: 0.015803450718522072\n",
      "batch accuracy: 0.9970703125\n",
      "doing 207 / 277\n",
      "elapsed time 12357.66928267479\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 0.9961\n",
      "batch loss: 0.015643244609236717\n",
      "batch accuracy: 0.99609375\n",
      "doing 208 / 277\n",
      "elapsed time 12442.785098791122\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9990\n",
      "batch loss: 0.01392035000026226\n",
      "batch accuracy: 0.9990234375\n",
      "doing 209 / 277\n",
      "elapsed time 12522.313758134842\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9961\n",
      "batch loss: 0.02014032006263733\n",
      "batch accuracy: 0.99609375\n",
      "doing 210 / 277\n",
      "elapsed time 12605.658314943314\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "batch loss: 0.01077856682240963\n",
      "batch accuracy: 1.0\n",
      "doing 211 / 277\n",
      "elapsed time 12690.924753665924\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9971\n",
      "batch loss: 0.015079800970852375\n",
      "batch accuracy: 0.9970703125\n",
      "doing 212 / 277\n",
      "elapsed time 12776.12433385849\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.9971\n",
      "batch loss: 0.018999576568603516\n",
      "batch accuracy: 0.9970703125\n",
      "doing 213 / 277\n",
      "elapsed time 12860.888970136642\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0154 - accuracy: 0.9971\n",
      "batch loss: 0.015440697781741619\n",
      "batch accuracy: 0.9970703125\n",
      "doing 214 / 277\n",
      "elapsed time 12951.505366802216\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9980\n",
      "batch loss: 0.013323955237865448\n",
      "batch accuracy: 0.998046875\n",
      "doing 215 / 277\n",
      "elapsed time 13036.875862836838\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9971\n",
      "batch loss: 0.02011311985552311\n",
      "batch accuracy: 0.9970703125\n",
      "doing 216 / 277\n",
      "elapsed time 13123.390643835068\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.9961\n",
      "batch loss: 0.021433331072330475\n",
      "batch accuracy: 0.99609375\n",
      "doing 217 / 277\n",
      "elapsed time 13208.202147006989\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "batch loss: 0.013536902144551277\n",
      "batch accuracy: 1.0\n",
      "doing 218 / 277\n",
      "elapsed time 13294.846422195435\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9961\n",
      "batch loss: 0.019075199961662292\n",
      "batch accuracy: 0.99609375\n",
      "doing 219 / 277\n",
      "elapsed time 13376.057988166809\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9971\n",
      "batch loss: 0.016848597675561905\n",
      "batch accuracy: 0.9970703125\n",
      "doing 220 / 277\n",
      "elapsed time 13454.81403183937\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9990\n",
      "batch loss: 0.016606202349066734\n",
      "batch accuracy: 0.9990234375\n",
      "doing 221 / 277\n",
      "elapsed time 13544.407611846924\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9990\n",
      "batch loss: 0.013959171250462532\n",
      "batch accuracy: 0.9990234375\n",
      "doing 222 / 277\n",
      "elapsed time 13630.500987052917\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0150 - accuracy: 0.9971\n",
      "batch loss: 0.014987429603934288\n",
      "batch accuracy: 0.9970703125\n",
      "doing 223 / 277\n",
      "elapsed time 13715.85401391983\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9951\n",
      "batch loss: 0.019816674292087555\n",
      "batch accuracy: 0.9951171875\n",
      "doing 224 / 277\n",
      "elapsed time 13804.316688537598\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0275 - accuracy: 0.9941\n",
      "batch loss: 0.027497462928295135\n",
      "batch accuracy: 0.994140625\n",
      "doing 225 / 277\n",
      "elapsed time 13893.213532686234\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0224 - accuracy: 0.9941\n",
      "batch loss: 0.02236134372651577\n",
      "batch accuracy: 0.994140625\n",
      "doing 226 / 277\n",
      "elapsed time 13976.261064767838\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9961\n",
      "batch loss: 0.015735719352960587\n",
      "batch accuracy: 0.99609375\n",
      "doing 227 / 277\n",
      "elapsed time 14061.232223033905\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9941\n",
      "batch loss: 0.01893511973321438\n",
      "batch accuracy: 0.994140625\n",
      "doing 228 / 277\n",
      "elapsed time 14146.070196151733\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 0.9941\n",
      "batch loss: 0.02328108251094818\n",
      "batch accuracy: 0.994140625\n",
      "doing 229 / 277\n",
      "elapsed time 14233.853733062744\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9932\n",
      "batch loss: 0.026410842314362526\n",
      "batch accuracy: 0.9931640625\n",
      "doing 230 / 277\n",
      "elapsed time 14311.858266115189\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 0.9990\n",
      "batch loss: 0.017284467816352844\n",
      "batch accuracy: 0.9990234375\n",
      "doing 231 / 277\n",
      "elapsed time 14373.868942022324\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0262 - accuracy: 0.9951\n",
      "batch loss: 0.026225082576274872\n",
      "batch accuracy: 0.9951171875\n",
      "doing 232 / 277\n",
      "elapsed time 14436.1062271595\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "batch loss: 0.012363128364086151\n",
      "batch accuracy: 1.0\n",
      "doing 233 / 277\n",
      "elapsed time 14503.977240562439\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 0.9971\n",
      "batch loss: 0.022990666329860687\n",
      "batch accuracy: 0.9970703125\n",
      "doing 234 / 277\n",
      "elapsed time 14574.9573636055\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 0.9990\n",
      "batch loss: 0.020695794373750687\n",
      "batch accuracy: 0.9990234375\n",
      "doing 235 / 277\n",
      "elapsed time 14642.541714429855\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 1.0000\n",
      "batch loss: 0.013903294689953327\n",
      "batch accuracy: 1.0\n",
      "doing 236 / 277\n",
      "elapsed time 14707.156950950623\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 0.9961\n",
      "batch loss: 0.020683636888861656\n",
      "batch accuracy: 0.99609375\n",
      "doing 237 / 277\n",
      "elapsed time 14772.80617070198\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9990\n",
      "batch loss: 0.011881155893206596\n",
      "batch accuracy: 0.9990234375\n",
      "doing 238 / 277\n",
      "elapsed time 14837.529787540436\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 0.9980\n",
      "batch loss: 0.017119549214839935\n",
      "batch accuracy: 0.998046875\n",
      "doing 239 / 277\n",
      "elapsed time 14905.654939889908\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9971\n",
      "batch loss: 0.016691774129867554\n",
      "batch accuracy: 0.9970703125\n",
      "doing 240 / 277\n",
      "elapsed time 14971.086344718933\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9961\n",
      "batch loss: 0.018088720738887787\n",
      "batch accuracy: 0.99609375\n",
      "doing 241 / 277\n",
      "elapsed time 15036.934540748596\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9961\n",
      "batch loss: 0.01959945634007454\n",
      "batch accuracy: 0.99609375\n",
      "doing 242 / 277\n",
      "elapsed time 15102.817969560623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9961\n",
      "batch loss: 0.02010733261704445\n",
      "batch accuracy: 0.99609375\n",
      "doing 243 / 277\n",
      "elapsed time 15168.545991659164\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9971\n",
      "batch loss: 0.017438504844903946\n",
      "batch accuracy: 0.9970703125\n",
      "doing 244 / 277\n",
      "elapsed time 15235.354828357697\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 0.9961\n",
      "batch loss: 0.019269902259111404\n",
      "batch accuracy: 0.99609375\n",
      "doing 245 / 277\n",
      "elapsed time 15305.56123828888\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9961\n",
      "batch loss: 0.01626676693558693\n",
      "batch accuracy: 0.99609375\n",
      "doing 246 / 277\n",
      "elapsed time 15375.336651563644\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "batch loss: 0.0137917660176754\n",
      "batch accuracy: 1.0\n",
      "doing 247 / 277\n",
      "elapsed time 15444.113916635513\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 0.9951\n",
      "batch loss: 0.016472995281219482\n",
      "batch accuracy: 0.9951171875\n",
      "doing 248 / 277\n",
      "elapsed time 15514.659353017807\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9980\n",
      "batch loss: 0.018397735431790352\n",
      "batch accuracy: 0.998046875\n",
      "doing 249 / 277\n",
      "elapsed time 15582.342405796051\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9961\n",
      "batch loss: 0.014879507943987846\n",
      "batch accuracy: 0.99609375\n",
      "doing 250 / 277\n",
      "elapsed time 15650.509934186935\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0150 - accuracy: 0.9990\n",
      "batch loss: 0.014989731833338737\n",
      "batch accuracy: 0.9990234375\n",
      "doing 251 / 277\n",
      "elapsed time 15723.350841283798\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0237 - accuracy: 0.9971\n",
      "batch loss: 0.02365248091518879\n",
      "batch accuracy: 0.9970703125\n",
      "doing 252 / 277\n",
      "elapsed time 15793.185090780258\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9961\n",
      "batch loss: 0.0199822336435318\n",
      "batch accuracy: 0.99609375\n",
      "doing 253 / 277\n",
      "elapsed time 15863.833379745483\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9961\n",
      "batch loss: 0.017562944442033768\n",
      "batch accuracy: 0.99609375\n",
      "doing 254 / 277\n",
      "elapsed time 15937.117773294449\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9922\n",
      "batch loss: 0.025270115584135056\n",
      "batch accuracy: 0.9921875\n",
      "doing 255 / 277\n",
      "elapsed time 16010.221796274185\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9990\n",
      "batch loss: 0.014768822118639946\n",
      "batch accuracy: 0.9990234375\n",
      "doing 256 / 277\n",
      "elapsed time 16079.58943605423\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9961\n",
      "batch loss: 0.017755836248397827\n",
      "batch accuracy: 0.99609375\n",
      "doing 257 / 277\n",
      "elapsed time 16151.790560483932\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9990\n",
      "batch loss: 0.014487149193882942\n",
      "batch accuracy: 0.9990234375\n",
      "doing 258 / 277\n",
      "elapsed time 16222.631234645844\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9980\n",
      "batch loss: 0.016391467303037643\n",
      "batch accuracy: 0.998046875\n",
      "doing 259 / 277\n",
      "elapsed time 16298.296372652054\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9990\n",
      "batch loss: 0.012568242847919464\n",
      "batch accuracy: 0.9990234375\n",
      "doing 260 / 277\n",
      "elapsed time 16369.843254804611\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9951\n",
      "batch loss: 0.016026144847273827\n",
      "batch accuracy: 0.9951171875\n",
      "doing 261 / 277\n",
      "elapsed time 16438.864887714386\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9961\n",
      "batch loss: 0.018088536337018013\n",
      "batch accuracy: 0.99609375\n",
      "doing 262 / 277\n",
      "elapsed time 16510.652807950974\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9990\n",
      "batch loss: 0.013836940750479698\n",
      "batch accuracy: 0.9990234375\n",
      "doing 263 / 277\n",
      "elapsed time 16583.360293626785\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9980\n",
      "batch loss: 0.014909913763403893\n",
      "batch accuracy: 0.998046875\n",
      "doing 264 / 277\n",
      "elapsed time 16654.702649354935\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.9951\n",
      "batch loss: 0.025869552046060562\n",
      "batch accuracy: 0.9951171875\n",
      "doing 265 / 277\n",
      "elapsed time 16726.123424768448\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9961\n",
      "batch loss: 0.018884580582380295\n",
      "batch accuracy: 0.99609375\n",
      "doing 266 / 277\n",
      "elapsed time 16796.326654672623\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9990\n",
      "batch loss: 0.013542475178837776\n",
      "batch accuracy: 0.9990234375\n",
      "doing 267 / 277\n",
      "elapsed time 16873.366389751434\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9961\n",
      "batch loss: 0.016840964555740356\n",
      "batch accuracy: 0.99609375\n",
      "doing 268 / 277\n",
      "elapsed time 16949.1279361248\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9971\n",
      "batch loss: 0.014949005097150803\n",
      "batch accuracy: 0.9970703125\n",
      "doing 269 / 277\n",
      "elapsed time 17027.645357370377\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9980\n",
      "batch loss: 0.015696991235017776\n",
      "batch accuracy: 0.998046875\n",
      "doing 270 / 277\n",
      "elapsed time 17102.07571029663\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9971\n",
      "batch loss: 0.015185073018074036\n",
      "batch accuracy: 0.9970703125\n",
      "doing 271 / 277\n",
      "elapsed time 17179.837229013443\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9990\n",
      "batch loss: 0.0157071053981781\n",
      "batch accuracy: 0.9990234375\n",
      "doing 272 / 277\n",
      "elapsed time 17255.570698022842\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9951\n",
      "batch loss: 0.02595263160765171\n",
      "batch accuracy: 0.9951171875\n",
      "doing 273 / 277\n",
      "elapsed time 17326.949430942535\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9980\n",
      "batch loss: 0.013833949342370033\n",
      "batch accuracy: 0.998046875\n",
      "doing 274 / 277\n",
      "elapsed time 17399.00046133995\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.9951\n",
      "batch loss: 0.019850119948387146\n",
      "batch accuracy: 0.9951171875\n",
      "doing 275 / 277\n",
      "elapsed time 17473.917014360428\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9980\n",
      "batch loss: 0.013789031654596329\n",
      "batch accuracy: 0.998046875\n",
      "doing 276 / 277\n",
      "elapsed time 17514.459886074066\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0189 - accuracy: 0.9982\n",
      "batch loss: 0.01890653930604458\n",
      "batch accuracy: 0.998171865940094\n",
      "Train loss 0.027649053856595975\n",
      "Train accuracy 0.9941093467633216\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3501 - accuracy: 0.9256\n",
      "Validation loss: 0.3501298427581787\n",
      "Validation accuracy: 0.9255555272102356\n",
      "==================================================\n",
      "3 / 5\n",
      "doing 0 / 277\n",
      "elapsed time 67.20409369468689\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9971\n",
      "batch loss: 0.013358918018639088\n",
      "batch accuracy: 0.9970703125\n",
      "doing 1 / 277\n",
      "elapsed time 131.20769739151\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "batch loss: 0.0074232229962944984\n",
      "batch accuracy: 1.0\n",
      "doing 2 / 277\n",
      "elapsed time 199.16809844970703\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "batch loss: 0.008775860071182251\n",
      "batch accuracy: 1.0\n",
      "doing 3 / 277\n",
      "elapsed time 261.2340168952942\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9990\n",
      "batch loss: 0.012081699445843697\n",
      "batch accuracy: 0.9990234375\n",
      "doing 4 / 277\n",
      "elapsed time 327.9284701347351\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9980\n",
      "batch loss: 0.012069793418049812\n",
      "batch accuracy: 0.998046875\n",
      "doing 5 / 277\n",
      "elapsed time 395.53809905052185\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "batch loss: 0.011432202532887459\n",
      "batch accuracy: 1.0\n",
      "doing 6 / 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 464.4984836578369\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9990\n",
      "batch loss: 0.008985967375338078\n",
      "batch accuracy: 0.9990234375\n",
      "doing 7 / 277\n",
      "elapsed time 533.1207373142242\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "batch loss: 0.008608001284301281\n",
      "batch accuracy: 1.0\n",
      "doing 8 / 277\n",
      "elapsed time 597.7745649814606\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9990\n",
      "batch loss: 0.011188298463821411\n",
      "batch accuracy: 0.9990234375\n",
      "doing 9 / 277\n",
      "elapsed time 664.18594789505\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9990\n",
      "batch loss: 0.011751951649785042\n",
      "batch accuracy: 0.9990234375\n",
      "doing 10 / 277\n",
      "elapsed time 732.027101278305\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "batch loss: 0.00962444581091404\n",
      "batch accuracy: 1.0\n",
      "doing 11 / 277\n",
      "elapsed time 801.6426255702972\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 0.9971\n",
      "batch loss: 0.017223181203007698\n",
      "batch accuracy: 0.9970703125\n",
      "doing 12 / 277\n",
      "elapsed time 869.938390493393\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9980\n",
      "batch loss: 0.010188911110162735\n",
      "batch accuracy: 0.998046875\n",
      "doing 13 / 277\n",
      "elapsed time 938.802033662796\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "batch loss: 0.007614741101861\n",
      "batch accuracy: 1.0\n",
      "doing 14 / 277\n",
      "elapsed time 1010.7717280387878\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9980\n",
      "batch loss: 0.0101003497838974\n",
      "batch accuracy: 0.998046875\n",
      "doing 15 / 277\n",
      "elapsed time 1076.3430309295654\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9990\n",
      "batch loss: 0.010950536467134953\n",
      "batch accuracy: 0.9990234375\n",
      "doing 16 / 277\n",
      "elapsed time 1142.9071288108826\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 1.0000\n",
      "batch loss: 0.011155903339385986\n",
      "batch accuracy: 1.0\n",
      "doing 17 / 277\n",
      "elapsed time 1209.917913198471\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "batch loss: 0.011668074876070023\n",
      "batch accuracy: 1.0\n",
      "doing 18 / 277\n",
      "elapsed time 1277.7691972255707\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9990\n",
      "batch loss: 0.010966788977384567\n",
      "batch accuracy: 0.9990234375\n",
      "doing 19 / 277\n",
      "elapsed time 1343.7861533164978\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9961\n",
      "batch loss: 0.020499635487794876\n",
      "batch accuracy: 0.99609375\n",
      "doing 20 / 277\n",
      "elapsed time 1411.2004706859589\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.9971\n",
      "batch loss: 0.018010107800364494\n",
      "batch accuracy: 0.9970703125\n",
      "doing 21 / 277\n",
      "elapsed time 1478.9834728240967\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9971\n",
      "batch loss: 0.013814616948366165\n",
      "batch accuracy: 0.9970703125\n",
      "doing 22 / 277\n",
      "elapsed time 1546.6515998840332\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9990\n",
      "batch loss: 0.010220324620604515\n",
      "batch accuracy: 0.9990234375\n",
      "doing 23 / 277\n",
      "elapsed time 1615.5231833457947\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "batch loss: 0.0080751683562994\n",
      "batch accuracy: 1.0\n",
      "doing 24 / 277\n",
      "elapsed time 1682.1491928100586\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9990\n",
      "batch loss: 0.010682512074708939\n",
      "batch accuracy: 0.9990234375\n",
      "doing 25 / 277\n",
      "elapsed time 1748.324743270874\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9951\n",
      "batch loss: 0.013858401216566563\n",
      "batch accuracy: 0.9951171875\n",
      "doing 26 / 277\n",
      "elapsed time 1814.8138673305511\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9990\n",
      "batch loss: 0.016390502452850342\n",
      "batch accuracy: 0.9990234375\n",
      "doing 27 / 277\n",
      "elapsed time 1883.4931581020355\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9990\n",
      "batch loss: 0.009841985069215298\n",
      "batch accuracy: 0.9990234375\n",
      "doing 28 / 277\n",
      "elapsed time 1953.9824974536896\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9980\n",
      "batch loss: 0.010460419580340385\n",
      "batch accuracy: 0.998046875\n",
      "doing 29 / 277\n",
      "elapsed time 2021.25785779953\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9990\n",
      "batch loss: 0.009036263450980186\n",
      "batch accuracy: 0.9990234375\n",
      "doing 30 / 277\n",
      "elapsed time 2090.1490499973297\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9990\n",
      "batch loss: 0.009263270534574986\n",
      "batch accuracy: 0.9990234375\n",
      "doing 31 / 277\n",
      "elapsed time 2156.322101354599\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "batch loss: 0.007696209475398064\n",
      "batch accuracy: 1.0\n",
      "doing 32 / 277\n",
      "elapsed time 2223.2460255622864\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9990\n",
      "batch loss: 0.012079013511538506\n",
      "batch accuracy: 0.9990234375\n",
      "doing 33 / 277\n",
      "elapsed time 2290.002708673477\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9990\n",
      "batch loss: 0.013058382086455822\n",
      "batch accuracy: 0.9990234375\n",
      "doing 34 / 277\n",
      "elapsed time 2357.458343267441\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "batch loss: 0.007915250025689602\n",
      "batch accuracy: 1.0\n",
      "doing 35 / 277\n",
      "elapsed time 2421.5960624217987\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "batch loss: 0.007536585442721844\n",
      "batch accuracy: 1.0\n",
      "doing 36 / 277\n",
      "elapsed time 2489.704116821289\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9980\n",
      "batch loss: 0.013322179205715656\n",
      "batch accuracy: 0.998046875\n",
      "doing 37 / 277\n",
      "elapsed time 2558.14826464653\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9990\n",
      "batch loss: 0.009149853140115738\n",
      "batch accuracy: 0.9990234375\n",
      "doing 38 / 277\n",
      "elapsed time 2625.057499885559\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "batch loss: 0.007447673473507166\n",
      "batch accuracy: 1.0\n",
      "doing 39 / 277\n",
      "elapsed time 2693.7174923419952\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "batch loss: 0.009041407145559788\n",
      "batch accuracy: 1.0\n",
      "doing 40 / 277\n",
      "elapsed time 2759.1524605751038\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "batch loss: 0.008102070540189743\n",
      "batch accuracy: 1.0\n",
      "doing 41 / 277\n",
      "elapsed time 2826.6385056972504\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9990\n",
      "batch loss: 0.011748608201742172\n",
      "batch accuracy: 0.9990234375\n",
      "doing 42 / 277\n",
      "elapsed time 2893.5952818393707\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9990\n",
      "batch loss: 0.00992758758366108\n",
      "batch accuracy: 0.9990234375\n",
      "doing 43 / 277\n",
      "elapsed time 2963.4345831871033\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9990\n",
      "batch loss: 0.009743357077240944\n",
      "batch accuracy: 0.9990234375\n",
      "doing 44 / 277\n",
      "elapsed time 3030.647891521454\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9990\n",
      "batch loss: 0.01201559416949749\n",
      "batch accuracy: 0.9990234375\n",
      "doing 45 / 277\n",
      "elapsed time 3098.6139299869537\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "batch loss: 0.008401580154895782\n",
      "batch accuracy: 1.0\n",
      "doing 46 / 277\n",
      "elapsed time 3166.0425498485565\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9990\n",
      "batch loss: 0.008345071226358414\n",
      "batch accuracy: 0.9990234375\n",
      "doing 47 / 277\n",
      "elapsed time 3235.9205133914948\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9971\n",
      "batch loss: 0.012512288987636566\n",
      "batch accuracy: 0.9970703125\n",
      "doing 48 / 277\n",
      "elapsed time 3305.4643132686615\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "batch loss: 0.0073198736645281315\n",
      "batch accuracy: 1.0\n",
      "doing 49 / 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 3372.6403024196625\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9990\n",
      "batch loss: 0.012675242498517036\n",
      "batch accuracy: 0.9990234375\n",
      "doing 50 / 277\n",
      "elapsed time 3438.790610074997\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9990\n",
      "batch loss: 0.021203454583883286\n",
      "batch accuracy: 0.9990234375\n",
      "doing 51 / 277\n",
      "elapsed time 3503.7488300800323\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "batch loss: 0.0095345638692379\n",
      "batch accuracy: 1.0\n",
      "doing 52 / 277\n",
      "elapsed time 3569.77304148674\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "batch loss: 0.008360380306839943\n",
      "batch accuracy: 1.0\n",
      "doing 53 / 277\n",
      "elapsed time 3638.2876234054565\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9990\n",
      "batch loss: 0.010698171332478523\n",
      "batch accuracy: 0.9990234375\n",
      "doing 54 / 277\n",
      "elapsed time 3705.9322185516357\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9990\n",
      "batch loss: 0.008112732321023941\n",
      "batch accuracy: 0.9990234375\n",
      "doing 55 / 277\n",
      "elapsed time 3772.8346474170685\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9980\n",
      "batch loss: 0.011642467230558395\n",
      "batch accuracy: 0.998046875\n",
      "doing 56 / 277\n",
      "elapsed time 3839.2993228435516\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "batch loss: 0.006721328012645245\n",
      "batch accuracy: 1.0\n",
      "doing 57 / 277\n",
      "elapsed time 3908.9550564289093\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9990\n",
      "batch loss: 0.0091469194740057\n",
      "batch accuracy: 0.9990234375\n",
      "doing 58 / 277\n",
      "elapsed time 3973.311637878418\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9980\n",
      "batch loss: 0.010171458125114441\n",
      "batch accuracy: 0.998046875\n",
      "doing 59 / 277\n",
      "elapsed time 4038.6030468940735\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9990\n",
      "batch loss: 0.010039188899099827\n",
      "batch accuracy: 0.9990234375\n",
      "doing 60 / 277\n",
      "elapsed time 4109.818591833115\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9980\n",
      "batch loss: 0.009654790163040161\n",
      "batch accuracy: 0.998046875\n",
      "doing 61 / 277\n",
      "elapsed time 4176.660617351532\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9980\n",
      "batch loss: 0.010517813265323639\n",
      "batch accuracy: 0.998046875\n",
      "doing 62 / 277\n",
      "elapsed time 4243.952338933945\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9990\n",
      "batch loss: 0.008732602000236511\n",
      "batch accuracy: 0.9990234375\n",
      "doing 63 / 277\n",
      "elapsed time 4311.215342998505\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "batch loss: 0.008992094546556473\n",
      "batch accuracy: 1.0\n",
      "doing 64 / 277\n",
      "elapsed time 4379.30374622345\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9990\n",
      "batch loss: 0.009111904539167881\n",
      "batch accuracy: 0.9990234375\n",
      "doing 65 / 277\n",
      "elapsed time 4446.942048072815\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "batch loss: 0.007996508851647377\n",
      "batch accuracy: 1.0\n",
      "doing 66 / 277\n",
      "elapsed time 4515.324458122253\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "batch loss: 0.007158980704843998\n",
      "batch accuracy: 1.0\n",
      "doing 67 / 277\n",
      "elapsed time 4581.998597621918\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9980\n",
      "batch loss: 0.011954456567764282\n",
      "batch accuracy: 0.998046875\n",
      "doing 68 / 277\n",
      "elapsed time 4652.4632833004\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9990\n",
      "batch loss: 0.006235779263079166\n",
      "batch accuracy: 0.9990234375\n",
      "doing 69 / 277\n",
      "elapsed time 4718.3958876132965\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "batch loss: 0.00865702610462904\n",
      "batch accuracy: 1.0\n",
      "doing 70 / 277\n",
      "elapsed time 4787.620229721069\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "batch loss: 0.008295044302940369\n",
      "batch accuracy: 1.0\n",
      "doing 71 / 277\n",
      "elapsed time 4857.014682292938\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9990\n",
      "batch loss: 0.008166024461388588\n",
      "batch accuracy: 0.9990234375\n",
      "doing 72 / 277\n",
      "elapsed time 4924.021780490875\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9980\n",
      "batch loss: 0.009013554081320763\n",
      "batch accuracy: 0.998046875\n",
      "doing 73 / 277\n",
      "elapsed time 4991.60821557045\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "batch loss: 0.005883660167455673\n",
      "batch accuracy: 1.0\n",
      "doing 74 / 277\n",
      "elapsed time 5061.812941789627\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9990\n",
      "batch loss: 0.009947809390723705\n",
      "batch accuracy: 0.9990234375\n",
      "doing 75 / 277\n",
      "elapsed time 5130.213458538055\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9961\n",
      "batch loss: 0.015658589079976082\n",
      "batch accuracy: 0.99609375\n",
      "doing 76 / 277\n",
      "elapsed time 5198.630921363831\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9990\n",
      "batch loss: 0.009241925552487373\n",
      "batch accuracy: 0.9990234375\n",
      "doing 77 / 277\n",
      "elapsed time 5266.45433306694\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9990\n",
      "batch loss: 0.008986163884401321\n",
      "batch accuracy: 0.9990234375\n",
      "doing 78 / 277\n",
      "elapsed time 5335.337726593018\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9990\n",
      "batch loss: 0.01129869744181633\n",
      "batch accuracy: 0.9990234375\n",
      "doing 79 / 277\n",
      "elapsed time 5401.726572275162\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9990\n",
      "batch loss: 0.006983695551753044\n",
      "batch accuracy: 0.9990234375\n",
      "doing 80 / 277\n",
      "elapsed time 5469.77890920639\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "batch loss: 0.007424540817737579\n",
      "batch accuracy: 1.0\n",
      "doing 81 / 277\n",
      "elapsed time 5538.636384487152\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9990\n",
      "batch loss: 0.010661637410521507\n",
      "batch accuracy: 0.9990234375\n",
      "doing 82 / 277\n",
      "elapsed time 5604.977751731873\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "batch loss: 0.008433258160948753\n",
      "batch accuracy: 1.0\n",
      "doing 83 / 277\n",
      "elapsed time 5673.753995656967\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9990\n",
      "batch loss: 0.008968235924839973\n",
      "batch accuracy: 0.9990234375\n",
      "doing 84 / 277\n",
      "elapsed time 5740.918740987778\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9961\n",
      "batch loss: 0.011231396347284317\n",
      "batch accuracy: 0.99609375\n",
      "doing 85 / 277\n",
      "elapsed time 5809.654855251312\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9990\n",
      "batch loss: 0.00785909779369831\n",
      "batch accuracy: 0.9990234375\n",
      "doing 86 / 277\n",
      "elapsed time 5875.600450515747\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9990\n",
      "batch loss: 0.010123100131750107\n",
      "batch accuracy: 0.9990234375\n",
      "doing 87 / 277\n",
      "elapsed time 5943.82547211647\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9961\n",
      "batch loss: 0.013862158171832561\n",
      "batch accuracy: 0.99609375\n",
      "doing 88 / 277\n",
      "elapsed time 6010.236604452133\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "batch loss: 0.00838173646479845\n",
      "batch accuracy: 1.0\n",
      "doing 89 / 277\n",
      "elapsed time 6078.125152349472\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "batch loss: 0.00664786621928215\n",
      "batch accuracy: 1.0\n",
      "doing 90 / 277\n",
      "elapsed time 6145.276640415192\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9990\n",
      "batch loss: 0.009780612774193287\n",
      "batch accuracy: 0.9990234375\n",
      "doing 91 / 277\n",
      "elapsed time 6214.511087656021\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "batch loss: 0.009475632570683956\n",
      "batch accuracy: 1.0\n",
      "doing 92 / 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 6282.270089864731\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9971\n",
      "batch loss: 0.013118721544742584\n",
      "batch accuracy: 0.9970703125\n",
      "doing 93 / 277\n",
      "elapsed time 6351.872219800949\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9990\n",
      "batch loss: 0.01021004468202591\n",
      "batch accuracy: 0.9990234375\n",
      "doing 94 / 277\n",
      "elapsed time 6423.65255689621\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "batch loss: 0.00859859399497509\n",
      "batch accuracy: 1.0\n",
      "doing 95 / 277\n",
      "elapsed time 6491.949733734131\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9990\n",
      "batch loss: 0.011242725886404514\n",
      "batch accuracy: 0.9990234375\n",
      "doing 96 / 277\n",
      "elapsed time 6559.979022264481\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9990\n",
      "batch loss: 0.008246229961514473\n",
      "batch accuracy: 0.9990234375\n",
      "doing 97 / 277\n",
      "elapsed time 6628.048766851425\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9990\n",
      "batch loss: 0.011395365931093693\n",
      "batch accuracy: 0.9990234375\n",
      "doing 98 / 277\n",
      "elapsed time 6699.294238805771\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9980\n",
      "batch loss: 0.013914121314883232\n",
      "batch accuracy: 0.998046875\n",
      "doing 99 / 277\n",
      "elapsed time 6764.9370856285095\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9980\n",
      "batch loss: 0.010530016385018826\n",
      "batch accuracy: 0.998046875\n",
      "doing 100 / 277\n",
      "elapsed time 6831.126569747925\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9990\n",
      "batch loss: 0.013850389048457146\n",
      "batch accuracy: 0.9990234375\n",
      "doing 101 / 277\n",
      "elapsed time 6900.210631132126\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9971\n",
      "batch loss: 0.010373738594353199\n",
      "batch accuracy: 0.9970703125\n",
      "doing 102 / 277\n",
      "elapsed time 6971.751157283783\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9971\n",
      "batch loss: 0.011856677941977978\n",
      "batch accuracy: 0.9970703125\n",
      "doing 103 / 277\n",
      "elapsed time 7041.082425355911\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9980\n",
      "batch loss: 0.011948750354349613\n",
      "batch accuracy: 0.998046875\n",
      "doing 104 / 277\n",
      "elapsed time 7109.67166185379\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9971\n",
      "batch loss: 0.013095306232571602\n",
      "batch accuracy: 0.9970703125\n",
      "doing 105 / 277\n",
      "elapsed time 7180.99253487587\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9980\n",
      "batch loss: 0.011618172749876976\n",
      "batch accuracy: 0.998046875\n",
      "doing 106 / 277\n",
      "elapsed time 7252.043346166611\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9961\n",
      "batch loss: 0.01286605466157198\n",
      "batch accuracy: 0.99609375\n",
      "doing 107 / 277\n",
      "elapsed time 7319.422384738922\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "batch loss: 0.007001983933150768\n",
      "batch accuracy: 1.0\n",
      "doing 108 / 277\n",
      "elapsed time 7390.189345836639\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9980\n",
      "batch loss: 0.011395393870770931\n",
      "batch accuracy: 0.998046875\n",
      "doing 109 / 277\n",
      "elapsed time 7457.374046802521\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9980\n",
      "batch loss: 0.013767548836767673\n",
      "batch accuracy: 0.998046875\n",
      "doing 110 / 277\n",
      "elapsed time 7527.290990829468\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9990\n",
      "batch loss: 0.009740505367517471\n",
      "batch accuracy: 0.9990234375\n",
      "doing 111 / 277\n",
      "elapsed time 7596.124319314957\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9980\n",
      "batch loss: 0.01237874012440443\n",
      "batch accuracy: 0.998046875\n",
      "doing 112 / 277\n",
      "elapsed time 7666.304155349731\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9990\n",
      "batch loss: 0.008458331227302551\n",
      "batch accuracy: 0.9990234375\n",
      "doing 113 / 277\n",
      "elapsed time 7735.62512421608\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9980\n",
      "batch loss: 0.010852327570319176\n",
      "batch accuracy: 0.998046875\n",
      "doing 114 / 277\n",
      "elapsed time 7805.637197494507\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9980\n",
      "batch loss: 0.011943623423576355\n",
      "batch accuracy: 0.998046875\n",
      "doing 115 / 277\n",
      "elapsed time 7876.544422864914\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9990\n",
      "batch loss: 0.010194007307291031\n",
      "batch accuracy: 0.9990234375\n",
      "doing 116 / 277\n",
      "elapsed time 7947.218033313751\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "batch loss: 0.009410418570041656\n",
      "batch accuracy: 1.0\n",
      "doing 117 / 277\n",
      "elapsed time 8027.944776773453\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9961\n",
      "batch loss: 0.016105061396956444\n",
      "batch accuracy: 0.99609375\n",
      "doing 118 / 277\n",
      "elapsed time 8116.8317766189575\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9990\n",
      "batch loss: 0.010741306468844414\n",
      "batch accuracy: 0.9990234375\n",
      "doing 119 / 277\n",
      "elapsed time 8211.354049444199\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9980\n",
      "batch loss: 0.00917195063084364\n",
      "batch accuracy: 0.998046875\n",
      "doing 120 / 277\n",
      "elapsed time 8307.59892320633\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9990\n",
      "batch loss: 0.009085068479180336\n",
      "batch accuracy: 0.9990234375\n",
      "doing 121 / 277\n",
      "elapsed time 8405.733465194702\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9990\n",
      "batch loss: 0.009225280955433846\n",
      "batch accuracy: 0.9990234375\n",
      "doing 122 / 277\n",
      "elapsed time 8501.1545753479\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9980\n",
      "batch loss: 0.00978812389075756\n",
      "batch accuracy: 0.998046875\n",
      "doing 123 / 277\n",
      "elapsed time 8596.377131938934\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9990\n",
      "batch loss: 0.009001863189041615\n",
      "batch accuracy: 0.9990234375\n",
      "doing 124 / 277\n",
      "elapsed time 8697.521327495575\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "batch loss: 0.008637252263724804\n",
      "batch accuracy: 1.0\n",
      "doing 125 / 277\n",
      "elapsed time 8794.202852725983\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9990\n",
      "batch loss: 0.011031507514417171\n",
      "batch accuracy: 0.9990234375\n",
      "doing 126 / 277\n",
      "elapsed time 8897.300551176071\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9980\n",
      "batch loss: 0.011030727997422218\n",
      "batch accuracy: 0.998046875\n",
      "doing 127 / 277\n",
      "elapsed time 8997.498644590378\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9990\n",
      "batch loss: 0.01260324940085411\n",
      "batch accuracy: 0.9990234375\n",
      "doing 128 / 277\n",
      "elapsed time 9098.224925279617\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9980\n",
      "batch loss: 0.012469882145524025\n",
      "batch accuracy: 0.998046875\n",
      "doing 129 / 277\n",
      "elapsed time 9192.404578447342\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "batch loss: 0.007411390542984009\n",
      "batch accuracy: 1.0\n",
      "doing 130 / 277\n",
      "elapsed time 9297.078593730927\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9990\n",
      "batch loss: 0.009082377888262272\n",
      "batch accuracy: 0.9990234375\n",
      "doing 131 / 277\n",
      "elapsed time 9408.012965202332\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9990\n",
      "batch loss: 0.010665662586688995\n",
      "batch accuracy: 0.9990234375\n",
      "doing 132 / 277\n",
      "elapsed time 9511.713270425797\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9990\n",
      "batch loss: 0.00877546239644289\n",
      "batch accuracy: 0.9990234375\n",
      "doing 133 / 277\n",
      "elapsed time 9615.952743053436\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "batch loss: 0.0070850905030965805\n",
      "batch accuracy: 1.0\n",
      "doing 134 / 277\n",
      "elapsed time 9730.77426314354\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9980\n",
      "batch loss: 0.01049648504704237\n",
      "batch accuracy: 0.998046875\n",
      "doing 135 / 277\n",
      "elapsed time 9836.593883037567\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9990\n",
      "batch loss: 0.011038357391953468\n",
      "batch accuracy: 0.9990234375\n",
      "doing 136 / 277\n",
      "elapsed time 9942.724416017532\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9980\n",
      "batch loss: 0.012668242678046227\n",
      "batch accuracy: 0.998046875\n",
      "doing 137 / 277\n",
      "elapsed time 10047.498865127563\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9990\n",
      "batch loss: 0.009407696314156055\n",
      "batch accuracy: 0.9990234375\n",
      "doing 138 / 277\n",
      "elapsed time 10152.337317705154\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9980\n",
      "batch loss: 0.00923718698322773\n",
      "batch accuracy: 0.998046875\n",
      "doing 139 / 277\n",
      "elapsed time 10265.445940732956\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9990\n",
      "batch loss: 0.008059530518949032\n",
      "batch accuracy: 0.9990234375\n",
      "doing 140 / 277\n",
      "elapsed time 10378.93099284172\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9990\n",
      "batch loss: 0.007650288287550211\n",
      "batch accuracy: 0.9990234375\n",
      "doing 141 / 277\n",
      "elapsed time 10489.750212907791\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9980\n",
      "batch loss: 0.011956742033362389\n",
      "batch accuracy: 0.998046875\n",
      "doing 142 / 277\n",
      "elapsed time 10607.49403476715\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9980\n",
      "batch loss: 0.009494459256529808\n",
      "batch accuracy: 0.998046875\n",
      "doing 143 / 277\n",
      "elapsed time 10722.543180704117\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "batch loss: 0.0067022936418652534\n",
      "batch accuracy: 1.0\n",
      "doing 144 / 277\n",
      "elapsed time 10830.445880174637\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "batch loss: 0.009029872715473175\n",
      "batch accuracy: 1.0\n",
      "doing 145 / 277\n",
      "elapsed time 10937.137624502182\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9980\n",
      "batch loss: 0.010382281616330147\n",
      "batch accuracy: 0.998046875\n",
      "doing 146 / 277\n",
      "elapsed time 11041.390848636627\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "batch loss: 0.007349959574639797\n",
      "batch accuracy: 1.0\n",
      "doing 147 / 277\n",
      "elapsed time 11147.527315855026\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9990\n",
      "batch loss: 0.009131805039942265\n",
      "batch accuracy: 0.9990234375\n",
      "doing 148 / 277\n",
      "elapsed time 11251.537969350815\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9971\n",
      "batch loss: 0.013502208516001701\n",
      "batch accuracy: 0.9970703125\n",
      "doing 149 / 277\n",
      "elapsed time 11354.43454861641\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9990\n",
      "batch loss: 0.007971095852553844\n",
      "batch accuracy: 0.9990234375\n",
      "doing 150 / 277\n",
      "elapsed time 11464.964772701263\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9990\n",
      "batch loss: 0.012714752927422523\n",
      "batch accuracy: 0.9990234375\n",
      "doing 151 / 277\n",
      "elapsed time 11588.040887832642\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "batch loss: 0.0065456572920084\n",
      "batch accuracy: 1.0\n",
      "doing 152 / 277\n",
      "elapsed time 11692.43585729599\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9990\n",
      "batch loss: 0.0071207620203495026\n",
      "batch accuracy: 0.9990234375\n",
      "doing 153 / 277\n",
      "elapsed time 11794.226840496063\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9961\n",
      "batch loss: 0.011720661073923111\n",
      "batch accuracy: 0.99609375\n",
      "doing 154 / 277\n",
      "elapsed time 11902.504362344742\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "batch loss: 0.00923982821404934\n",
      "batch accuracy: 1.0\n",
      "doing 155 / 277\n",
      "elapsed time 12012.001021385193\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9990\n",
      "batch loss: 0.009330552071332932\n",
      "batch accuracy: 0.9990234375\n",
      "doing 156 / 277\n",
      "elapsed time 12116.883985996246\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "batch loss: 0.007432745303958654\n",
      "batch accuracy: 1.0\n",
      "doing 157 / 277\n",
      "elapsed time 12225.637212514877\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9990\n",
      "batch loss: 0.009003984741866589\n",
      "batch accuracy: 0.9990234375\n",
      "doing 158 / 277\n",
      "elapsed time 12330.887210607529\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9990\n",
      "batch loss: 0.012235116213560104\n",
      "batch accuracy: 0.9990234375\n",
      "doing 159 / 277\n",
      "elapsed time 12448.701668262482\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "batch loss: 0.00702033331617713\n",
      "batch accuracy: 1.0\n",
      "doing 160 / 277\n",
      "elapsed time 12562.420420646667\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9961\n",
      "batch loss: 0.013508698903024197\n",
      "batch accuracy: 0.99609375\n",
      "doing 161 / 277\n",
      "elapsed time 12668.6261780262\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "batch loss: 0.008705852553248405\n",
      "batch accuracy: 1.0\n",
      "doing 162 / 277\n",
      "elapsed time 12773.96221780777\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9990\n",
      "batch loss: 0.0074151125736534595\n",
      "batch accuracy: 0.9990234375\n",
      "doing 163 / 277\n",
      "elapsed time 12894.643380641937\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9990\n",
      "batch loss: 0.009350419975817204\n",
      "batch accuracy: 0.9990234375\n",
      "doing 164 / 277\n",
      "elapsed time 13018.120803117752\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9980\n",
      "batch loss: 0.01124783605337143\n",
      "batch accuracy: 0.998046875\n",
      "doing 165 / 277\n",
      "elapsed time 13139.79877281189\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9990\n",
      "batch loss: 0.008464171551167965\n",
      "batch accuracy: 0.9990234375\n",
      "doing 166 / 277\n",
      "elapsed time 13248.203590631485\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "batch loss: 0.006835020147264004\n",
      "batch accuracy: 1.0\n",
      "doing 167 / 277\n",
      "elapsed time 13354.401077747345\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9990\n",
      "batch loss: 0.008891928941011429\n",
      "batch accuracy: 0.9990234375\n",
      "doing 168 / 277\n",
      "elapsed time 13464.052633523941\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9980\n",
      "batch loss: 0.013589008711278439\n",
      "batch accuracy: 0.998046875\n",
      "doing 169 / 277\n",
      "elapsed time 13574.914021730423\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "batch loss: 0.008377349004149437\n",
      "batch accuracy: 1.0\n",
      "doing 170 / 277\n",
      "elapsed time 13684.614721298218\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9990\n",
      "batch loss: 0.00923779048025608\n",
      "batch accuracy: 0.9990234375\n",
      "doing 171 / 277\n",
      "elapsed time 13793.780362606049\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9951\n",
      "batch loss: 0.019067024812102318\n",
      "batch accuracy: 0.9951171875\n",
      "doing 172 / 277\n",
      "elapsed time 13905.168742895126\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9990\n",
      "batch loss: 0.010039351880550385\n",
      "batch accuracy: 0.9990234375\n",
      "doing 173 / 277\n",
      "elapsed time 14032.133492469788\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9980\n",
      "batch loss: 0.024272892624139786\n",
      "batch accuracy: 0.998046875\n",
      "doing 174 / 277\n",
      "elapsed time 14158.183464050293\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9990\n",
      "batch loss: 0.008469769731163979\n",
      "batch accuracy: 0.9990234375\n",
      "doing 175 / 277\n",
      "elapsed time 14288.79386639595\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9990\n",
      "batch loss: 0.010941362008452415\n",
      "batch accuracy: 0.9990234375\n",
      "doing 176 / 277\n",
      "elapsed time 14416.326374530792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0186 - accuracy: 0.9971\n",
      "batch loss: 0.018627610057592392\n",
      "batch accuracy: 0.9970703125\n",
      "doing 177 / 277\n",
      "elapsed time 14553.519644498825\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9990\n",
      "batch loss: 0.012345246970653534\n",
      "batch accuracy: 0.9990234375\n",
      "doing 178 / 277\n",
      "elapsed time 14685.591037273407\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9980\n",
      "batch loss: 0.012259649112820625\n",
      "batch accuracy: 0.998046875\n",
      "doing 179 / 277\n",
      "elapsed time 14817.067280054092\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9951\n",
      "batch loss: 0.016906902194023132\n",
      "batch accuracy: 0.9951171875\n",
      "doing 180 / 277\n",
      "elapsed time 14953.319383382797\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 0.9961\n",
      "batch loss: 0.017186127603054047\n",
      "batch accuracy: 0.99609375\n",
      "doing 181 / 277\n",
      "elapsed time 15089.192165136337\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9980\n",
      "batch loss: 0.014138583093881607\n",
      "batch accuracy: 0.998046875\n",
      "doing 182 / 277\n",
      "elapsed time 15209.569467544556\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.9922\n",
      "batch loss: 0.02469027042388916\n",
      "batch accuracy: 0.9921875\n",
      "doing 183 / 277\n",
      "elapsed time 15324.751094341278\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 0.9932\n",
      "batch loss: 0.020929936319589615\n",
      "batch accuracy: 0.9931640625\n",
      "doing 184 / 277\n",
      "elapsed time 15440.101592302322\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9961\n",
      "batch loss: 0.015955481678247452\n",
      "batch accuracy: 0.99609375\n",
      "doing 185 / 277\n",
      "elapsed time 15564.551151037216\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9961\n",
      "batch loss: 0.01778699830174446\n",
      "batch accuracy: 0.99609375\n",
      "doing 186 / 277\n",
      "elapsed time 15688.470606565475\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9990\n",
      "batch loss: 0.010804693214595318\n",
      "batch accuracy: 0.9990234375\n",
      "doing 187 / 277\n",
      "elapsed time 15823.54874420166\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9961\n",
      "batch loss: 0.01758396625518799\n",
      "batch accuracy: 0.99609375\n",
      "doing 188 / 277\n",
      "elapsed time 15961.95099234581\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9990\n",
      "batch loss: 0.010070034302771091\n",
      "batch accuracy: 0.9990234375\n",
      "doing 189 / 277\n",
      "elapsed time 16095.035196065903\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "batch loss: 0.007450396195054054\n",
      "batch accuracy: 1.0\n",
      "doing 190 / 277\n",
      "elapsed time 16225.563565015793\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9971\n",
      "batch loss: 0.0126692745834589\n",
      "batch accuracy: 0.9970703125\n",
      "doing 191 / 277\n",
      "elapsed time 16365.836149930954\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9990\n",
      "batch loss: 0.011282382532954216\n",
      "batch accuracy: 0.9990234375\n",
      "doing 192 / 277\n",
      "elapsed time 16506.006017684937\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9971\n",
      "batch loss: 0.01907419040799141\n",
      "batch accuracy: 0.9970703125\n",
      "doing 193 / 277\n",
      "elapsed time 16641.320234537125\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9980\n",
      "batch loss: 0.01829797402024269\n",
      "batch accuracy: 0.998046875\n",
      "doing 194 / 277\n",
      "elapsed time 16779.457354068756\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9971\n",
      "batch loss: 0.015970461070537567\n",
      "batch accuracy: 0.9970703125\n",
      "doing 195 / 277\n",
      "elapsed time 16918.652595043182\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0262 - accuracy: 0.9932\n",
      "batch loss: 0.02622065134346485\n",
      "batch accuracy: 0.9931640625\n",
      "doing 196 / 277\n",
      "elapsed time 17055.41269350052\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9961\n",
      "batch loss: 0.01780831441283226\n",
      "batch accuracy: 0.99609375\n",
      "doing 197 / 277\n",
      "elapsed time 17199.697098731995\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9980\n",
      "batch loss: 0.016928113996982574\n",
      "batch accuracy: 0.998046875\n",
      "doing 198 / 277\n",
      "elapsed time 17343.371696710587\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9922\n",
      "batch loss: 0.024633439257740974\n",
      "batch accuracy: 0.9921875\n",
      "doing 199 / 277\n",
      "elapsed time 17490.328018426895\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9932\n",
      "batch loss: 0.022717930376529694\n",
      "batch accuracy: 0.9931640625\n",
      "doing 200 / 277\n",
      "elapsed time 17629.74013853073\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9990\n",
      "batch loss: 0.011294268071651459\n",
      "batch accuracy: 0.9990234375\n",
      "doing 201 / 277\n",
      "elapsed time 17774.750838041306\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9980\n",
      "batch loss: 0.011040562763810158\n",
      "batch accuracy: 0.998046875\n",
      "doing 202 / 277\n",
      "elapsed time 17916.69181227684\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.9941\n",
      "batch loss: 0.021404054015874863\n",
      "batch accuracy: 0.994140625\n",
      "doing 203 / 277\n",
      "elapsed time 18058.30668616295\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 0.9971\n",
      "batch loss: 0.017275087535381317\n",
      "batch accuracy: 0.9970703125\n",
      "doing 204 / 277\n",
      "elapsed time 18206.29612135887\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9961\n",
      "batch loss: 0.01830984093248844\n",
      "batch accuracy: 0.99609375\n",
      "doing 205 / 277\n",
      "elapsed time 18346.78249335289\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9941\n",
      "batch loss: 0.015070904046297073\n",
      "batch accuracy: 0.994140625\n",
      "doing 206 / 277\n",
      "elapsed time 18488.57782101631\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9941\n",
      "batch loss: 0.019505096599459648\n",
      "batch accuracy: 0.994140625\n",
      "doing 207 / 277\n",
      "elapsed time 18630.501765966415\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9961\n",
      "batch loss: 0.02000529319047928\n",
      "batch accuracy: 0.99609375\n",
      "doing 208 / 277\n",
      "elapsed time 18776.96125602722\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9980\n",
      "batch loss: 0.01528006512671709\n",
      "batch accuracy: 0.998046875\n",
      "doing 209 / 277\n",
      "elapsed time 18916.970105409622\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9990\n",
      "batch loss: 0.01222279854118824\n",
      "batch accuracy: 0.9990234375\n",
      "doing 210 / 277\n",
      "elapsed time 19060.904356479645\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9951\n",
      "batch loss: 0.0169993843883276\n",
      "batch accuracy: 0.9951171875\n",
      "doing 211 / 277\n",
      "elapsed time 19206.92657995224\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9971\n",
      "batch loss: 0.0166791919618845\n",
      "batch accuracy: 0.9970703125\n",
      "doing 212 / 277\n",
      "elapsed time 19357.28170967102\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9961\n",
      "batch loss: 0.01687243953347206\n",
      "batch accuracy: 0.99609375\n",
      "doing 213 / 277\n",
      "elapsed time 19505.19459414482\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9990\n",
      "batch loss: 0.011163754388689995\n",
      "batch accuracy: 0.9990234375\n",
      "doing 214 / 277\n",
      "elapsed time 19654.86171579361\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9951\n",
      "batch loss: 0.01606796681880951\n",
      "batch accuracy: 0.9951171875\n",
      "doing 215 / 277\n",
      "elapsed time 19797.22261786461\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9961\n",
      "batch loss: 0.01758931763470173\n",
      "batch accuracy: 0.99609375\n",
      "doing 216 / 277\n",
      "elapsed time 19950.63205885887\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 1.0000\n",
      "batch loss: 0.013377135619521141\n",
      "batch accuracy: 1.0\n",
      "doing 217 / 277\n",
      "elapsed time 20101.88583469391\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "batch loss: 0.008935770951211452\n",
      "batch accuracy: 1.0\n",
      "doing 218 / 277\n",
      "elapsed time 20246.659687519073\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9990\n",
      "batch loss: 0.011876245960593224\n",
      "batch accuracy: 0.9990234375\n",
      "doing 219 / 277\n",
      "elapsed time 20388.762773036957\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9990\n",
      "batch loss: 0.009041368961334229\n",
      "batch accuracy: 0.9990234375\n",
      "doing 220 / 277\n",
      "elapsed time 20540.048807382584\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9990\n",
      "batch loss: 0.01239415630698204\n",
      "batch accuracy: 0.9990234375\n",
      "doing 221 / 277\n",
      "elapsed time 20692.715678691864\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9971\n",
      "batch loss: 0.01341240294277668\n",
      "batch accuracy: 0.9970703125\n",
      "doing 222 / 277\n",
      "elapsed time 20847.626469135284\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "batch loss: 0.011082111857831478\n",
      "batch accuracy: 1.0\n",
      "doing 223 / 277\n",
      "elapsed time 20998.74261379242\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 1.0000\n",
      "batch loss: 0.011153610423207283\n",
      "batch accuracy: 1.0\n",
      "doing 224 / 277\n",
      "elapsed time 21136.04597735405\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 0.9980\n",
      "batch loss: 0.018527060747146606\n",
      "batch accuracy: 0.998046875\n",
      "doing 225 / 277\n",
      "elapsed time 21275.807178020477\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9980\n",
      "batch loss: 0.018318263813853264\n",
      "batch accuracy: 0.998046875\n",
      "doing 226 / 277\n",
      "elapsed time 21416.900060653687\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 0.9951\n",
      "batch loss: 0.015921346843242645\n",
      "batch accuracy: 0.9951171875\n",
      "doing 227 / 277\n",
      "elapsed time 21566.895388126373\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 0.9961\n",
      "batch loss: 0.016529100015759468\n",
      "batch accuracy: 0.99609375\n",
      "doing 228 / 277\n",
      "elapsed time 21708.99962902069\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9961\n",
      "batch loss: 0.019969835877418518\n",
      "batch accuracy: 0.99609375\n",
      "doing 229 / 277\n",
      "elapsed time 21853.818098068237\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9980\n",
      "batch loss: 0.014700004830956459\n",
      "batch accuracy: 0.998046875\n",
      "doing 230 / 277\n",
      "elapsed time 22000.3225607872\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9990\n",
      "batch loss: 0.012605812400579453\n",
      "batch accuracy: 0.9990234375\n",
      "doing 231 / 277\n",
      "elapsed time 22135.245191335678\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "batch loss: 0.009383433498442173\n",
      "batch accuracy: 1.0\n",
      "doing 232 / 277\n",
      "elapsed time 22274.36030125618\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9961\n",
      "batch loss: 0.015215815976262093\n",
      "batch accuracy: 0.99609375\n",
      "doing 233 / 277\n",
      "elapsed time 22416.18077802658\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 0.9971\n",
      "batch loss: 0.015624985098838806\n",
      "batch accuracy: 0.9970703125\n",
      "doing 234 / 277\n",
      "elapsed time 22555.53061747551\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 1.0000\n",
      "batch loss: 0.012004926800727844\n",
      "batch accuracy: 1.0\n",
      "doing 235 / 277\n",
      "elapsed time 22691.599210500717\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "batch loss: 0.008329130709171295\n",
      "batch accuracy: 1.0\n",
      "doing 236 / 277\n",
      "elapsed time 22837.44016766548\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9980\n",
      "batch loss: 0.011365567333996296\n",
      "batch accuracy: 0.998046875\n",
      "doing 237 / 277\n",
      "elapsed time 22989.17617917061\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9971\n",
      "batch loss: 0.013952698558568954\n",
      "batch accuracy: 0.9970703125\n",
      "doing 238 / 277\n",
      "elapsed time 23131.284385442734\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "batch loss: 0.008523404598236084\n",
      "batch accuracy: 1.0\n",
      "doing 239 / 277\n",
      "elapsed time 23283.53807234764\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9990\n",
      "batch loss: 0.00877989549189806\n",
      "batch accuracy: 0.9990234375\n",
      "doing 240 / 277\n",
      "elapsed time 23410.58536338806\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9990\n",
      "batch loss: 0.010582104325294495\n",
      "batch accuracy: 0.9990234375\n",
      "doing 241 / 277\n",
      "elapsed time 23539.391231298447\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9990\n",
      "batch loss: 0.014019757509231567\n",
      "batch accuracy: 0.9990234375\n",
      "doing 242 / 277\n",
      "elapsed time 23673.18805193901\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "batch loss: 0.009666802361607552\n",
      "batch accuracy: 1.0\n",
      "doing 243 / 277\n",
      "elapsed time 23805.394703149796\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9980\n",
      "batch loss: 0.0114006157964468\n",
      "batch accuracy: 0.998046875\n",
      "doing 244 / 277\n",
      "elapsed time 23925.343970298767\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "batch loss: 0.010103246197104454\n",
      "batch accuracy: 1.0\n",
      "doing 245 / 277\n",
      "elapsed time 24049.47548174858\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9980\n",
      "batch loss: 0.009182439185678959\n",
      "batch accuracy: 0.998046875\n",
      "doing 246 / 277\n",
      "elapsed time 24173.2188975811\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9980\n",
      "batch loss: 0.010542755015194416\n",
      "batch accuracy: 0.998046875\n",
      "doing 247 / 277\n",
      "elapsed time 24293.66058421135\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9990\n",
      "batch loss: 0.009665894322097301\n",
      "batch accuracy: 0.9990234375\n",
      "doing 248 / 277\n",
      "elapsed time 24421.701255083084\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "batch loss: 0.006786778103560209\n",
      "batch accuracy: 1.0\n",
      "doing 249 / 277\n",
      "elapsed time 24551.29730629921\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9980\n",
      "batch loss: 0.009709566831588745\n",
      "batch accuracy: 0.998046875\n",
      "doing 250 / 277\n",
      "elapsed time 24685.45750451088\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "batch loss: 0.009339620359241962\n",
      "batch accuracy: 1.0\n",
      "doing 251 / 277\n",
      "elapsed time 24817.914028406143\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9971\n",
      "batch loss: 0.012186801992356777\n",
      "batch accuracy: 0.9970703125\n",
      "doing 252 / 277\n",
      "elapsed time 24946.89399242401\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9990\n",
      "batch loss: 0.010288214311003685\n",
      "batch accuracy: 0.9990234375\n",
      "doing 253 / 277\n",
      "elapsed time 25073.176689863205\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9980\n",
      "batch loss: 0.01271624956279993\n",
      "batch accuracy: 0.998046875\n",
      "doing 254 / 277\n",
      "elapsed time 25205.524687051773\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9980\n",
      "batch loss: 0.012473518028855324\n",
      "batch accuracy: 0.998046875\n",
      "doing 255 / 277\n",
      "elapsed time 25326.16137433052\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "batch loss: 0.009021449834108353\n",
      "batch accuracy: 1.0\n",
      "doing 256 / 277\n",
      "elapsed time 25453.614006996155\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9990\n",
      "batch loss: 0.009326174855232239\n",
      "batch accuracy: 0.9990234375\n",
      "doing 257 / 277\n",
      "elapsed time 25582.48025226593\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9990\n",
      "batch loss: 0.010249458253383636\n",
      "batch accuracy: 0.9990234375\n",
      "doing 258 / 277\n",
      "elapsed time 25704.44674897194\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9990\n",
      "batch loss: 0.0098953228443861\n",
      "batch accuracy: 0.9990234375\n",
      "doing 259 / 277\n",
      "elapsed time 25841.93564081192\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "batch loss: 0.009902643039822578\n",
      "batch accuracy: 1.0\n",
      "doing 260 / 277\n",
      "elapsed time 25982.63651919365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9980\n",
      "batch loss: 0.011279857717454433\n",
      "batch accuracy: 0.998046875\n",
      "doing 261 / 277\n",
      "elapsed time 26115.23384332657\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9980\n",
      "batch loss: 0.014873074367642403\n",
      "batch accuracy: 0.998046875\n",
      "doing 262 / 277\n",
      "elapsed time 26250.519240379333\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9990\n",
      "batch loss: 0.007068058475852013\n",
      "batch accuracy: 0.9990234375\n",
      "doing 263 / 277\n",
      "elapsed time 26388.709293603897\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9990\n",
      "batch loss: 0.0076276278123259544\n",
      "batch accuracy: 0.9990234375\n",
      "doing 264 / 277\n",
      "elapsed time 26513.86302781105\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9971\n",
      "batch loss: 0.01580435037612915\n",
      "batch accuracy: 0.9970703125\n",
      "doing 265 / 277\n",
      "elapsed time 26643.551370620728\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9990\n",
      "batch loss: 0.00807165540754795\n",
      "batch accuracy: 0.9990234375\n",
      "doing 266 / 277\n",
      "elapsed time 26769.420244932175\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9990\n",
      "batch loss: 0.009122704155743122\n",
      "batch accuracy: 0.9990234375\n",
      "doing 267 / 277\n",
      "elapsed time 26896.732409000397\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "batch loss: 0.0077866921201348305\n",
      "batch accuracy: 1.0\n",
      "doing 268 / 277\n",
      "elapsed time 27029.557126760483\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "batch loss: 0.008496873080730438\n",
      "batch accuracy: 1.0\n",
      "doing 269 / 277\n",
      "elapsed time 27161.951526641846\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "batch loss: 0.007586047053337097\n",
      "batch accuracy: 1.0\n",
      "doing 270 / 277\n",
      "elapsed time 27294.11278963089\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9980\n",
      "batch loss: 0.009717394597828388\n",
      "batch accuracy: 0.998046875\n",
      "doing 271 / 277\n",
      "elapsed time 27415.848217010498\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "batch loss: 0.00682226475328207\n",
      "batch accuracy: 1.0\n",
      "doing 272 / 277\n",
      "elapsed time 27536.158421754837\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9990\n",
      "batch loss: 0.010117052122950554\n",
      "batch accuracy: 0.9990234375\n",
      "doing 273 / 277\n",
      "elapsed time 27653.639510154724\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9980\n",
      "batch loss: 0.010581914335489273\n",
      "batch accuracy: 0.998046875\n",
      "doing 274 / 277\n",
      "elapsed time 27773.909391641617\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9961\n",
      "batch loss: 0.011581400409340858\n",
      "batch accuracy: 0.99609375\n",
      "doing 275 / 277\n",
      "elapsed time 27892.205174684525\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9971\n",
      "batch loss: 0.01130357664078474\n",
      "batch accuracy: 0.9970703125\n",
      "doing 276 / 277\n",
      "elapsed time 27951.62345099449\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9982\n",
      "batch loss: 0.008154974319040775\n",
      "batch accuracy: 0.998171865940094\n",
      "Train loss 0.011416246013426716\n",
      "Train accuracy 0.9984386563301086\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4038 - accuracy: 0.9264\n",
      "Validation loss: 0.4038432538509369\n",
      "Validation accuracy: 0.9264444708824158\n",
      "==================================================\n",
      "4 / 5\n",
      "doing 0 / 277\n",
      "elapsed time 109.46957397460938\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9961\n",
      "batch loss: 0.013296877965331078\n",
      "batch accuracy: 0.99609375\n",
      "doing 1 / 277\n",
      "elapsed time 225.1688289642334\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "batch loss: 0.006817275658249855\n",
      "batch accuracy: 1.0\n",
      "doing 2 / 277\n",
      "elapsed time 336.20587158203125\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9980\n",
      "batch loss: 0.008701737970113754\n",
      "batch accuracy: 0.998046875\n",
      "doing 3 / 277\n",
      "elapsed time 451.7683069705963\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "batch loss: 0.008568660356104374\n",
      "batch accuracy: 1.0\n",
      "doing 4 / 277\n",
      "elapsed time 564.1247515678406\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "batch loss: 0.006212000269442797\n",
      "batch accuracy: 1.0\n",
      "doing 5 / 277\n",
      "elapsed time 675.7913348674774\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "batch loss: 0.0059034498408436775\n",
      "batch accuracy: 1.0\n",
      "doing 6 / 277\n",
      "elapsed time 790.4158687591553\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9990\n",
      "batch loss: 0.007502720691263676\n",
      "batch accuracy: 0.9990234375\n",
      "doing 7 / 277\n",
      "elapsed time 903.4042241573334\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "batch loss: 0.007455548737198114\n",
      "batch accuracy: 1.0\n",
      "doing 8 / 277\n",
      "elapsed time 1017.3688449859619\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9990\n",
      "batch loss: 0.008923794142901897\n",
      "batch accuracy: 0.9990234375\n",
      "doing 9 / 277\n",
      "elapsed time 1131.8139107227325\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "batch loss: 0.004920457024127245\n",
      "batch accuracy: 1.0\n",
      "doing 10 / 277\n",
      "elapsed time 1243.7457211017609\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "batch loss: 0.0040830872021615505\n",
      "batch accuracy: 1.0\n",
      "doing 11 / 277\n",
      "elapsed time 1358.6836087703705\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "batch loss: 0.005920238792896271\n",
      "batch accuracy: 1.0\n",
      "doing 12 / 277\n",
      "elapsed time 1471.6582090854645\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "batch loss: 0.006480040960013866\n",
      "batch accuracy: 1.0\n",
      "doing 13 / 277\n",
      "elapsed time 1587.7914843559265\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "batch loss: 0.006351212039589882\n",
      "batch accuracy: 1.0\n",
      "doing 14 / 277\n",
      "elapsed time 1702.0388836860657\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "batch loss: 0.00624052481725812\n",
      "batch accuracy: 1.0\n",
      "doing 15 / 277\n",
      "elapsed time 1818.453501701355\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "batch loss: 0.005726393777877092\n",
      "batch accuracy: 1.0\n",
      "doing 16 / 277\n",
      "elapsed time 1934.4221377372742\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "batch loss: 0.007866896688938141\n",
      "batch accuracy: 1.0\n",
      "doing 17 / 277\n",
      "elapsed time 2047.3067090511322\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9990\n",
      "batch loss: 0.008738108910620213\n",
      "batch accuracy: 0.9990234375\n",
      "doing 18 / 277\n",
      "elapsed time 2160.815407514572\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "batch loss: 0.006504767574369907\n",
      "batch accuracy: 1.0\n",
      "doing 19 / 277\n",
      "elapsed time 2274.551720380783\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "batch loss: 0.005168591625988483\n",
      "batch accuracy: 1.0\n",
      "doing 20 / 277\n",
      "elapsed time 2376.5603108406067\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "batch loss: 0.006723866797983646\n",
      "batch accuracy: 1.0\n",
      "doing 21 / 277\n",
      "elapsed time 2481.573683977127\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "batch loss: 0.004921077750623226\n",
      "batch accuracy: 1.0\n",
      "doing 22 / 277\n",
      "elapsed time 2587.2240595817566\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "batch loss: 0.00679065752774477\n",
      "batch accuracy: 1.0\n",
      "doing 23 / 277\n",
      "elapsed time 2690.786686182022\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9990\n",
      "batch loss: 0.008685972541570663\n",
      "batch accuracy: 0.9990234375\n",
      "doing 24 / 277\n",
      "elapsed time 2795.289920091629\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: 0.007261274382472038\n",
      "batch accuracy: 0.9990234375\n",
      "doing 25 / 277\n",
      "elapsed time 2898.682207584381\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "batch loss: 0.005878414958715439\n",
      "batch accuracy: 1.0\n",
      "doing 26 / 277\n",
      "elapsed time 3002.9452509880066\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "batch loss: 0.006937452591955662\n",
      "batch accuracy: 1.0\n",
      "doing 27 / 277\n",
      "elapsed time 3107.871243238449\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9990\n",
      "batch loss: 0.009199121035635471\n",
      "batch accuracy: 0.9990234375\n",
      "doing 28 / 277\n",
      "elapsed time 3212.1587035655975\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "batch loss: 0.0058657703921198845\n",
      "batch accuracy: 1.0\n",
      "doing 29 / 277\n",
      "elapsed time 3316.0562756061554\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "batch loss: 0.00584440166130662\n",
      "batch accuracy: 1.0\n",
      "doing 30 / 277\n",
      "elapsed time 3418.611720561981\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9990\n",
      "batch loss: 0.007744640111923218\n",
      "batch accuracy: 0.9990234375\n",
      "doing 31 / 277\n",
      "elapsed time 3522.91139626503\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9990\n",
      "batch loss: 0.008333585225045681\n",
      "batch accuracy: 0.9990234375\n",
      "doing 32 / 277\n",
      "elapsed time 3626.411484003067\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "batch loss: 0.005148949567228556\n",
      "batch accuracy: 1.0\n",
      "doing 33 / 277\n",
      "elapsed time 3735.223972558975\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9980\n",
      "batch loss: 0.006347742862999439\n",
      "batch accuracy: 0.998046875\n",
      "doing 34 / 277\n",
      "elapsed time 3847.7208454608917\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "batch loss: 0.005746514070779085\n",
      "batch accuracy: 1.0\n",
      "doing 35 / 277\n",
      "elapsed time 3963.1150131225586\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9990\n",
      "batch loss: 0.007752612233161926\n",
      "batch accuracy: 0.9990234375\n",
      "doing 36 / 277\n",
      "elapsed time 4076.2648117542267\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9990\n",
      "batch loss: 0.006079584360122681\n",
      "batch accuracy: 0.9990234375\n",
      "doing 37 / 277\n",
      "elapsed time 4178.488745689392\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "batch loss: 0.0058015757240355015\n",
      "batch accuracy: 1.0\n",
      "doing 38 / 277\n",
      "elapsed time 4284.58179807663\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "batch loss: 0.004733254201710224\n",
      "batch accuracy: 1.0\n",
      "doing 39 / 277\n",
      "elapsed time 4391.297632694244\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "batch loss: 0.0051682088524103165\n",
      "batch accuracy: 1.0\n",
      "doing 40 / 277\n",
      "elapsed time 4495.517041683197\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9990\n",
      "batch loss: 0.0100984126329422\n",
      "batch accuracy: 0.9990234375\n",
      "doing 41 / 277\n",
      "elapsed time 4601.341094017029\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "batch loss: 0.004139903467148542\n",
      "batch accuracy: 1.0\n",
      "doing 42 / 277\n",
      "elapsed time 4706.977747440338\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "batch loss: 0.007029674481600523\n",
      "batch accuracy: 1.0\n",
      "doing 43 / 277\n",
      "elapsed time 4813.170401573181\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "batch loss: 0.0050506931729614735\n",
      "batch accuracy: 1.0\n",
      "doing 44 / 277\n",
      "elapsed time 4917.057334184647\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9990\n",
      "batch loss: 0.005661889910697937\n",
      "batch accuracy: 0.9990234375\n",
      "doing 45 / 277\n",
      "elapsed time 5021.331516265869\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "batch loss: 0.005437049083411694\n",
      "batch accuracy: 1.0\n",
      "doing 46 / 277\n",
      "elapsed time 5131.303947925568\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "batch loss: 0.004179521929472685\n",
      "batch accuracy: 1.0\n",
      "doing 47 / 277\n",
      "elapsed time 5246.498029708862\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "batch loss: 0.0061860466375947\n",
      "batch accuracy: 1.0\n",
      "doing 48 / 277\n",
      "elapsed time 5358.717769384384\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "batch loss: 0.005924149416387081\n",
      "batch accuracy: 1.0\n",
      "doing 49 / 277\n",
      "elapsed time 5471.675330877304\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "batch loss: 0.005140651948750019\n",
      "batch accuracy: 1.0\n",
      "doing 50 / 277\n",
      "elapsed time 5583.333351135254\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "batch loss: 0.007856082171201706\n",
      "batch accuracy: 1.0\n",
      "doing 51 / 277\n",
      "elapsed time 5696.973212957382\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "batch loss: 0.005520534701645374\n",
      "batch accuracy: 1.0\n",
      "doing 52 / 277\n",
      "elapsed time 5811.793453216553\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 0.9990\n",
      "batch loss: 0.019285814836621284\n",
      "batch accuracy: 0.9990234375\n",
      "doing 53 / 277\n",
      "elapsed time 5923.995829820633\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "batch loss: 0.005654197186231613\n",
      "batch accuracy: 1.0\n",
      "doing 54 / 277\n",
      "elapsed time 6037.0450303554535\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9961\n",
      "batch loss: 0.009832385927438736\n",
      "batch accuracy: 0.99609375\n",
      "doing 55 / 277\n",
      "elapsed time 6148.838670492172\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "batch loss: 0.005902008153498173\n",
      "batch accuracy: 0.9990234375\n",
      "doing 56 / 277\n",
      "elapsed time 6263.085990428925\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9990\n",
      "batch loss: 0.009907834231853485\n",
      "batch accuracy: 0.9990234375\n",
      "doing 57 / 277\n",
      "elapsed time 6377.9729471206665\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "batch loss: 0.004196212161332369\n",
      "batch accuracy: 1.0\n",
      "doing 58 / 277\n",
      "elapsed time 6491.279390096664\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "batch loss: 0.006009031552821398\n",
      "batch accuracy: 1.0\n",
      "doing 59 / 277\n",
      "elapsed time 6601.071663379669\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "batch loss: 0.0059147728607058525\n",
      "batch accuracy: 0.9990234375\n",
      "doing 60 / 277\n",
      "elapsed time 6713.5767912864685\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "batch loss: 0.005596894770860672\n",
      "batch accuracy: 1.0\n",
      "doing 61 / 277\n",
      "elapsed time 6826.212411165237\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9990\n",
      "batch loss: 0.006491339765489101\n",
      "batch accuracy: 0.9990234375\n",
      "doing 62 / 277\n",
      "elapsed time 6937.449346780777\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9990\n",
      "batch loss: 0.0069308290258049965\n",
      "batch accuracy: 0.9990234375\n",
      "doing 63 / 277\n",
      "elapsed time 7049.364312887192\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9990\n",
      "batch loss: 0.009837117046117783\n",
      "batch accuracy: 0.9990234375\n",
      "doing 64 / 277\n",
      "elapsed time 7159.790628194809\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "batch loss: 0.006585166789591312\n",
      "batch accuracy: 1.0\n",
      "doing 65 / 277\n",
      "elapsed time 7265.825711250305\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "batch loss: 0.005045302212238312\n",
      "batch accuracy: 1.0\n",
      "doing 66 / 277\n",
      "elapsed time 7378.858771562576\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "batch loss: 0.006483767181634903\n",
      "batch accuracy: 1.0\n",
      "doing 67 / 277\n",
      "elapsed time 7489.920677423477\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "batch loss: 0.005021777469664812\n",
      "batch accuracy: 1.0\n",
      "doing 68 / 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 7600.11670422554\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "batch loss: 0.005687675438821316\n",
      "batch accuracy: 1.0\n",
      "doing 69 / 277\n",
      "elapsed time 7705.845079898834\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "batch loss: 0.005993325263261795\n",
      "batch accuracy: 1.0\n",
      "doing 70 / 277\n",
      "elapsed time 7806.892302274704\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "batch loss: 0.005559160839766264\n",
      "batch accuracy: 1.0\n",
      "doing 71 / 277\n",
      "elapsed time 7899.797800064087\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "batch loss: 0.006216584704816341\n",
      "batch accuracy: 1.0\n",
      "doing 72 / 277\n",
      "elapsed time 7999.023217916489\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "batch loss: 0.004742961376905441\n",
      "batch accuracy: 1.0\n",
      "doing 73 / 277\n",
      "elapsed time 8097.440820455551\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9990\n",
      "batch loss: 0.00652278121560812\n",
      "batch accuracy: 0.9990234375\n",
      "doing 74 / 277\n",
      "elapsed time 8193.787914276123\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9990\n",
      "batch loss: 0.007452711462974548\n",
      "batch accuracy: 0.9990234375\n",
      "doing 75 / 277\n",
      "elapsed time 8289.885110378265\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9971\n",
      "batch loss: 0.009095262736082077\n",
      "batch accuracy: 0.9970703125\n",
      "doing 76 / 277\n",
      "elapsed time 8384.821252346039\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "batch loss: 0.005852083675563335\n",
      "batch accuracy: 0.9990234375\n",
      "doing 77 / 277\n",
      "elapsed time 8482.254345655441\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "batch loss: 0.00575869670137763\n",
      "batch accuracy: 1.0\n",
      "doing 78 / 277\n",
      "elapsed time 8578.332309246063\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "batch loss: 0.005008796229958534\n",
      "batch accuracy: 1.0\n",
      "doing 79 / 277\n",
      "elapsed time 8671.648344993591\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "batch loss: 0.004915514495223761\n",
      "batch accuracy: 1.0\n",
      "doing 80 / 277\n",
      "elapsed time 8768.32729935646\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "batch loss: 0.004425922874361277\n",
      "batch accuracy: 1.0\n",
      "doing 81 / 277\n",
      "elapsed time 8863.925837516785\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "batch loss: 0.0047820620238780975\n",
      "batch accuracy: 1.0\n",
      "doing 82 / 277\n",
      "elapsed time 8958.182181835175\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "batch loss: 0.006171586457639933\n",
      "batch accuracy: 1.0\n",
      "doing 83 / 277\n",
      "elapsed time 9053.635709047318\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "batch loss: 0.004137758165597916\n",
      "batch accuracy: 1.0\n",
      "doing 84 / 277\n",
      "elapsed time 9147.802545070648\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9990\n",
      "batch loss: 0.00699970917776227\n",
      "batch accuracy: 0.9990234375\n",
      "doing 85 / 277\n",
      "elapsed time 9240.347316265106\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "batch loss: 0.004641538951545954\n",
      "batch accuracy: 1.0\n",
      "doing 86 / 277\n",
      "elapsed time 9334.348207235336\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "batch loss: 0.005727850832045078\n",
      "batch accuracy: 1.0\n",
      "doing 87 / 277\n",
      "elapsed time 9428.839859962463\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "batch loss: 0.004391598980873823\n",
      "batch accuracy: 1.0\n",
      "doing 88 / 277\n",
      "elapsed time 9523.929768323898\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "batch loss: 0.0051216864958405495\n",
      "batch accuracy: 1.0\n",
      "doing 89 / 277\n",
      "elapsed time 9617.86432147026\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "batch loss: 0.005288961809128523\n",
      "batch accuracy: 1.0\n",
      "doing 90 / 277\n",
      "elapsed time 9710.19613981247\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "batch loss: 0.005908530205488205\n",
      "batch accuracy: 0.9990234375\n",
      "doing 91 / 277\n",
      "elapsed time 9802.767855882645\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "batch loss: 0.005225100554525852\n",
      "batch accuracy: 1.0\n",
      "doing 92 / 277\n",
      "elapsed time 9896.15332531929\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "batch loss: 0.004837234504520893\n",
      "batch accuracy: 1.0\n",
      "doing 93 / 277\n",
      "elapsed time 9993.096334695816\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9990\n",
      "batch loss: 0.005737414583563805\n",
      "batch accuracy: 0.9990234375\n",
      "doing 94 / 277\n",
      "elapsed time 10092.55018901825\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9990\n",
      "batch loss: 0.012230397202074528\n",
      "batch accuracy: 0.9990234375\n",
      "doing 95 / 277\n",
      "elapsed time 10196.311062574387\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "batch loss: 0.004300368018448353\n",
      "batch accuracy: 1.0\n",
      "doing 96 / 277\n",
      "elapsed time 10298.153687477112\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "batch loss: 0.005182566121220589\n",
      "batch accuracy: 1.0\n",
      "doing 97 / 277\n",
      "elapsed time 10398.701803684235\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "batch loss: 0.00412435969337821\n",
      "batch accuracy: 1.0\n",
      "doing 98 / 277\n",
      "elapsed time 10500.154554128647\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "batch loss: 0.00574114453047514\n",
      "batch accuracy: 1.0\n",
      "doing 99 / 277\n",
      "elapsed time 10605.425641059875\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9990\n",
      "batch loss: 0.007509142626076937\n",
      "batch accuracy: 0.9990234375\n",
      "doing 100 / 277\n",
      "elapsed time 10709.237112998962\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "batch loss: 0.004731606692075729\n",
      "batch accuracy: 1.0\n",
      "doing 101 / 277\n",
      "elapsed time 10811.250441074371\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "batch loss: 0.004761286545544863\n",
      "batch accuracy: 1.0\n",
      "doing 102 / 277\n",
      "elapsed time 10917.956080436707\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "batch loss: 0.005459614563733339\n",
      "batch accuracy: 1.0\n",
      "doing 103 / 277\n",
      "elapsed time 11029.162560939789\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9990\n",
      "batch loss: 0.007516736164689064\n",
      "batch accuracy: 0.9990234375\n",
      "doing 104 / 277\n",
      "elapsed time 11136.84589266777\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "batch loss: 0.005982605740427971\n",
      "batch accuracy: 1.0\n",
      "doing 105 / 277\n",
      "elapsed time 11244.068723678589\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "batch loss: 0.005914355628192425\n",
      "batch accuracy: 0.9990234375\n",
      "doing 106 / 277\n",
      "elapsed time 11354.87153673172\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "batch loss: 0.0055349450558424\n",
      "batch accuracy: 1.0\n",
      "doing 107 / 277\n",
      "elapsed time 11462.077325105667\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "batch loss: 0.005578463431447744\n",
      "batch accuracy: 1.0\n",
      "doing 108 / 277\n",
      "elapsed time 11581.625886917114\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9990\n",
      "batch loss: 0.007090278901159763\n",
      "batch accuracy: 0.9990234375\n",
      "doing 109 / 277\n",
      "elapsed time 11699.950376987457\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "batch loss: 0.005053888075053692\n",
      "batch accuracy: 1.0\n",
      "doing 110 / 277\n",
      "elapsed time 11823.192984104156\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "batch loss: 0.0051215095445513725\n",
      "batch accuracy: 1.0\n",
      "doing 111 / 277\n",
      "elapsed time 11942.84075665474\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "batch loss: 0.004002904519438744\n",
      "batch accuracy: 1.0\n",
      "doing 112 / 277\n",
      "elapsed time 12060.420011043549\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9990\n",
      "batch loss: 0.008305592462420464\n",
      "batch accuracy: 0.9990234375\n",
      "doing 113 / 277\n",
      "elapsed time 12181.670689821243\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "batch loss: 0.005902422592043877\n",
      "batch accuracy: 0.9990234375\n",
      "doing 114 / 277\n",
      "elapsed time 12301.043316364288\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9990\n",
      "batch loss: 0.006109737791121006\n",
      "batch accuracy: 0.9990234375\n",
      "doing 115 / 277\n",
      "elapsed time 12421.983977079391\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "batch loss: 0.005708999931812286\n",
      "batch accuracy: 1.0\n",
      "doing 116 / 277\n",
      "elapsed time 12543.533953428268\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "batch loss: 0.00571933900937438\n",
      "batch accuracy: 1.0\n",
      "doing 117 / 277\n",
      "elapsed time 12663.583408355713\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "batch loss: 0.005876293405890465\n",
      "batch accuracy: 0.9990234375\n",
      "doing 118 / 277\n",
      "elapsed time 12782.674915790558\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "batch loss: 0.00559099018573761\n",
      "batch accuracy: 1.0\n",
      "doing 119 / 277\n",
      "elapsed time 12900.09718966484\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "batch loss: 0.0035564040299504995\n",
      "batch accuracy: 1.0\n",
      "doing 120 / 277\n",
      "elapsed time 13019.08440232277\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "batch loss: 0.004425628576427698\n",
      "batch accuracy: 1.0\n",
      "doing 121 / 277\n",
      "elapsed time 13137.241569280624\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9980\n",
      "batch loss: 0.006160027347505093\n",
      "batch accuracy: 0.998046875\n",
      "doing 122 / 277\n",
      "elapsed time 13251.507469177246\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "batch loss: 0.0045672086998820305\n",
      "batch accuracy: 1.0\n",
      "doing 123 / 277\n",
      "elapsed time 13367.553205013275\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "batch loss: 0.0050478167831897736\n",
      "batch accuracy: 1.0\n",
      "doing 124 / 277\n",
      "elapsed time 13477.446181297302\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "batch loss: 0.004601421765983105\n",
      "batch accuracy: 1.0\n",
      "doing 125 / 277\n",
      "elapsed time 13591.592923164368\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "batch loss: 0.005435318686068058\n",
      "batch accuracy: 1.0\n",
      "doing 126 / 277\n",
      "elapsed time 13705.050482988358\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9980\n",
      "batch loss: 0.007330489344894886\n",
      "batch accuracy: 0.998046875\n",
      "doing 127 / 277\n",
      "elapsed time 13816.597163200378\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "batch loss: 0.004619451239705086\n",
      "batch accuracy: 1.0\n",
      "doing 128 / 277\n",
      "elapsed time 13927.442543506622\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "batch loss: 0.00464304443448782\n",
      "batch accuracy: 1.0\n",
      "doing 129 / 277\n",
      "elapsed time 14036.023625135422\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "batch loss: 0.004194967448711395\n",
      "batch accuracy: 1.0\n",
      "doing 130 / 277\n",
      "elapsed time 14146.757424592972\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "batch loss: 0.0052263024263083935\n",
      "batch accuracy: 1.0\n",
      "doing 131 / 277\n",
      "elapsed time 14257.24145102501\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "batch loss: 0.004866962321102619\n",
      "batch accuracy: 1.0\n",
      "doing 132 / 277\n",
      "elapsed time 14366.397872924805\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9990\n",
      "batch loss: 0.006487453356385231\n",
      "batch accuracy: 0.9990234375\n",
      "doing 133 / 277\n",
      "elapsed time 14474.914043426514\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "batch loss: 0.0061440495774149895\n",
      "batch accuracy: 1.0\n",
      "doing 134 / 277\n",
      "elapsed time 14583.08010005951\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9990\n",
      "batch loss: 0.007567157968878746\n",
      "batch accuracy: 0.9990234375\n",
      "doing 135 / 277\n",
      "elapsed time 14692.714101791382\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "batch loss: 0.004055678844451904\n",
      "batch accuracy: 1.0\n",
      "doing 136 / 277\n",
      "elapsed time 14799.887950897217\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "batch loss: 0.004786504432559013\n",
      "batch accuracy: 1.0\n",
      "doing 137 / 277\n",
      "elapsed time 14905.821328163147\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9980\n",
      "batch loss: 0.0073579661548137665\n",
      "batch accuracy: 0.998046875\n",
      "doing 138 / 277\n",
      "elapsed time 15011.016573905945\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "batch loss: 0.004573933780193329\n",
      "batch accuracy: 1.0\n",
      "doing 139 / 277\n",
      "elapsed time 15118.842427968979\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9990\n",
      "batch loss: 0.007549886591732502\n",
      "batch accuracy: 0.9990234375\n",
      "doing 140 / 277\n",
      "elapsed time 15224.988822937012\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "batch loss: 0.005007774569094181\n",
      "batch accuracy: 1.0\n",
      "doing 141 / 277\n",
      "elapsed time 15326.53067612648\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9990\n",
      "batch loss: 0.005058981943875551\n",
      "batch accuracy: 0.9990234375\n",
      "doing 142 / 277\n",
      "elapsed time 15428.440852880478\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "batch loss: 0.007440308108925819\n",
      "batch accuracy: 1.0\n",
      "doing 143 / 277\n",
      "elapsed time 15529.709341526031\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "batch loss: 0.005985141731798649\n",
      "batch accuracy: 1.0\n",
      "doing 144 / 277\n",
      "elapsed time 15631.424316167831\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9980\n",
      "batch loss: 0.005693386774510145\n",
      "batch accuracy: 0.998046875\n",
      "doing 145 / 277\n",
      "elapsed time 15736.424224376678\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9971\n",
      "batch loss: 0.007992560043931007\n",
      "batch accuracy: 0.9970703125\n",
      "doing 146 / 277\n",
      "elapsed time 15839.422545194626\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "batch loss: 0.005677560344338417\n",
      "batch accuracy: 1.0\n",
      "doing 147 / 277\n",
      "elapsed time 15941.696460008621\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "batch loss: 0.003466954454779625\n",
      "batch accuracy: 1.0\n",
      "doing 148 / 277\n",
      "elapsed time 16044.011987447739\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "batch loss: 0.005165964365005493\n",
      "batch accuracy: 1.0\n",
      "doing 149 / 277\n",
      "elapsed time 16144.922141313553\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "batch loss: 0.005555435083806515\n",
      "batch accuracy: 1.0\n",
      "doing 150 / 277\n",
      "elapsed time 16246.525590658188\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9990\n",
      "batch loss: 0.007003916427493095\n",
      "batch accuracy: 0.9990234375\n",
      "doing 151 / 277\n",
      "elapsed time 16354.636867523193\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9990\n",
      "batch loss: 0.007486199028789997\n",
      "batch accuracy: 0.9990234375\n",
      "doing 152 / 277\n",
      "elapsed time 16465.305772304535\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "batch loss: 0.005082110874354839\n",
      "batch accuracy: 1.0\n",
      "doing 153 / 277\n",
      "elapsed time 16583.228194236755\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9990\n",
      "batch loss: 0.005169696640223265\n",
      "batch accuracy: 0.9990234375\n",
      "doing 154 / 277\n",
      "elapsed time 16695.634930372238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "batch loss: 0.004889174364507198\n",
      "batch accuracy: 1.0\n",
      "doing 155 / 277\n",
      "elapsed time 16809.32643032074\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "batch loss: 0.0057969773188233376\n",
      "batch accuracy: 1.0\n",
      "doing 156 / 277\n",
      "elapsed time 16924.920494794846\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "batch loss: 0.006291174329817295\n",
      "batch accuracy: 1.0\n",
      "doing 157 / 277\n",
      "elapsed time 17038.245687007904\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9990\n",
      "batch loss: 0.006025982555001974\n",
      "batch accuracy: 0.9990234375\n",
      "doing 158 / 277\n",
      "elapsed time 17150.662581443787\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "batch loss: 0.004958056844770908\n",
      "batch accuracy: 1.0\n",
      "doing 159 / 277\n",
      "elapsed time 17264.29046869278\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "batch loss: 0.0045709977857768536\n",
      "batch accuracy: 1.0\n",
      "doing 160 / 277\n",
      "elapsed time 17375.662928581238\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "batch loss: 0.0055060312151908875\n",
      "batch accuracy: 1.0\n",
      "doing 161 / 277\n",
      "elapsed time 17492.720819473267\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9990\n",
      "batch loss: 0.005610169377177954\n",
      "batch accuracy: 0.9990234375\n",
      "doing 162 / 277\n",
      "elapsed time 17606.777237176895\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "batch loss: 0.007200566586107016\n",
      "batch accuracy: 1.0\n",
      "doing 163 / 277\n",
      "elapsed time 17718.20025420189\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "batch loss: 0.00682152109220624\n",
      "batch accuracy: 1.0\n",
      "doing 164 / 277\n",
      "elapsed time 17829.815836906433\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9990\n",
      "batch loss: 0.006890689954161644\n",
      "batch accuracy: 0.9990234375\n",
      "doing 165 / 277\n",
      "elapsed time 17943.293395757675\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9990\n",
      "batch loss: 0.006782627664506435\n",
      "batch accuracy: 0.9990234375\n",
      "doing 166 / 277\n",
      "elapsed time 18061.69896888733\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "batch loss: 0.005025265272706747\n",
      "batch accuracy: 1.0\n",
      "doing 167 / 277\n",
      "elapsed time 18185.143933534622\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "batch loss: 0.005130537785589695\n",
      "batch accuracy: 1.0\n",
      "doing 168 / 277\n",
      "elapsed time 18313.823999643326\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "batch loss: 0.0054216752760112286\n",
      "batch accuracy: 1.0\n",
      "doing 169 / 277\n",
      "elapsed time 18437.904004335403\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "batch loss: 0.0061492398381233215\n",
      "batch accuracy: 1.0\n",
      "doing 170 / 277\n",
      "elapsed time 18565.839930534363\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9990\n",
      "batch loss: 0.006116189993917942\n",
      "batch accuracy: 0.9990234375\n",
      "doing 171 / 277\n",
      "elapsed time 18695.05185699463\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "batch loss: 0.005940245930105448\n",
      "batch accuracy: 1.0\n",
      "doing 172 / 277\n",
      "elapsed time 18822.873344659805\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9980\n",
      "batch loss: 0.008263432420790195\n",
      "batch accuracy: 0.998046875\n",
      "doing 173 / 277\n",
      "elapsed time 18946.463088989258\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "batch loss: 0.004877889528870583\n",
      "batch accuracy: 1.0\n",
      "doing 174 / 277\n",
      "elapsed time 19066.68392086029\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.0038429289124906063\n",
      "batch accuracy: 1.0\n",
      "doing 175 / 277\n",
      "elapsed time 19190.80249619484\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "batch loss: 0.005576463416218758\n",
      "batch accuracy: 1.0\n",
      "doing 176 / 277\n",
      "elapsed time 19317.477589845657\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9980\n",
      "batch loss: 0.0072417790070176125\n",
      "batch accuracy: 0.998046875\n",
      "doing 177 / 277\n",
      "elapsed time 19439.299688100815\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9990\n",
      "batch loss: 0.007163441739976406\n",
      "batch accuracy: 0.9990234375\n",
      "doing 178 / 277\n",
      "elapsed time 19559.58068037033\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9990\n",
      "batch loss: 0.006594302132725716\n",
      "batch accuracy: 0.9990234375\n",
      "doing 179 / 277\n",
      "elapsed time 19678.765409708023\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9990\n",
      "batch loss: 0.008090924471616745\n",
      "batch accuracy: 0.9990234375\n",
      "doing 180 / 277\n",
      "elapsed time 19798.64911556244\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9980\n",
      "batch loss: 0.01630602404475212\n",
      "batch accuracy: 0.998046875\n",
      "doing 181 / 277\n",
      "elapsed time 19916.37155175209\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9990\n",
      "batch loss: 0.007004198618233204\n",
      "batch accuracy: 0.9990234375\n",
      "doing 182 / 277\n",
      "elapsed time 20034.383311271667\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "batch loss: 0.005521846003830433\n",
      "batch accuracy: 1.0\n",
      "doing 183 / 277\n",
      "elapsed time 20148.683285951614\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "batch loss: 0.006579361390322447\n",
      "batch accuracy: 1.0\n",
      "doing 184 / 277\n",
      "elapsed time 20263.09412240982\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "batch loss: 0.005462804809212685\n",
      "batch accuracy: 1.0\n",
      "doing 185 / 277\n",
      "elapsed time 20378.060401201248\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "batch loss: 0.0078660873696208\n",
      "batch accuracy: 1.0\n",
      "doing 186 / 277\n",
      "elapsed time 20493.711793899536\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "batch loss: 0.006948650348931551\n",
      "batch accuracy: 1.0\n",
      "doing 187 / 277\n",
      "elapsed time 20607.62363100052\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9990\n",
      "batch loss: 0.005379891954362392\n",
      "batch accuracy: 0.9990234375\n",
      "doing 188 / 277\n",
      "elapsed time 20718.706862688065\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9980\n",
      "batch loss: 0.01244079228490591\n",
      "batch accuracy: 0.998046875\n",
      "doing 189 / 277\n",
      "elapsed time 20831.299202680588\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "batch loss: 0.0053786830976605415\n",
      "batch accuracy: 1.0\n",
      "doing 190 / 277\n",
      "elapsed time 20948.75347304344\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9990\n",
      "batch loss: 0.007230475544929504\n",
      "batch accuracy: 0.9990234375\n",
      "doing 191 / 277\n",
      "elapsed time 21059.57992887497\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9951\n",
      "batch loss: 0.013134426437318325\n",
      "batch accuracy: 0.9951171875\n",
      "doing 192 / 277\n",
      "elapsed time 21165.961805582047\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "batch loss: 0.006680123507976532\n",
      "batch accuracy: 1.0\n",
      "doing 193 / 277\n",
      "elapsed time 21268.247488737106\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9990\n",
      "batch loss: 0.007411455735564232\n",
      "batch accuracy: 0.9990234375\n",
      "doing 194 / 277\n",
      "elapsed time 21371.154973983765\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9971\n",
      "batch loss: 0.011987012811005116\n",
      "batch accuracy: 0.9970703125\n",
      "doing 195 / 277\n",
      "elapsed time 21472.36882662773\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "batch loss: 0.006199159659445286\n",
      "batch accuracy: 1.0\n",
      "doing 196 / 277\n",
      "elapsed time 21575.658395528793\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9990\n",
      "batch loss: 0.006944974418729544\n",
      "batch accuracy: 0.9990234375\n",
      "doing 197 / 277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 21678.045726776123\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "batch loss: 0.00596885709092021\n",
      "batch accuracy: 1.0\n",
      "doing 198 / 277\n",
      "elapsed time 21781.914036750793\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9980\n",
      "batch loss: 0.011222923174500465\n",
      "batch accuracy: 0.998046875\n",
      "doing 199 / 277\n",
      "elapsed time 21884.128120660782\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "batch loss: 0.00821974128484726\n",
      "batch accuracy: 1.0\n",
      "doing 200 / 277\n",
      "elapsed time 21986.204437732697\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9980\n",
      "batch loss: 0.010664185509085655\n",
      "batch accuracy: 0.998046875\n",
      "doing 201 / 277\n",
      "elapsed time 22088.068051338196\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9990\n",
      "batch loss: 0.010867342352867126\n",
      "batch accuracy: 0.9990234375\n",
      "doing 202 / 277\n",
      "elapsed time 22191.019915819168\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "batch loss: 0.009250251576304436\n",
      "batch accuracy: 1.0\n",
      "doing 203 / 277\n",
      "elapsed time 22292.287595510483\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "batch loss: 0.006398655008524656\n",
      "batch accuracy: 1.0\n",
      "doing 204 / 277\n",
      "elapsed time 22399.303474664688\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9980\n",
      "batch loss: 0.012852722778916359\n",
      "batch accuracy: 0.998046875\n",
      "doing 205 / 277\n",
      "elapsed time 22507.82014298439\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9990\n",
      "batch loss: 0.012022447772324085\n",
      "batch accuracy: 0.9990234375\n",
      "doing 206 / 277\n",
      "elapsed time 22618.592337846756\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "batch loss: 0.005231352522969246\n",
      "batch accuracy: 1.0\n",
      "doing 207 / 277\n",
      "elapsed time 22727.84273123741\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9990\n",
      "batch loss: 0.014916744083166122\n",
      "batch accuracy: 0.9990234375\n",
      "doing 208 / 277\n",
      "elapsed time 22836.519788503647\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9980\n",
      "batch loss: 0.013359601609408855\n",
      "batch accuracy: 0.998046875\n",
      "doing 209 / 277\n",
      "elapsed time 22943.65118765831\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9980\n",
      "batch loss: 0.00973840057849884\n",
      "batch accuracy: 0.998046875\n",
      "doing 210 / 277\n",
      "elapsed time 23049.069764852524\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9990\n",
      "batch loss: 0.009091626852750778\n",
      "batch accuracy: 0.9990234375\n",
      "doing 211 / 277\n",
      "elapsed time 23157.153212308884\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 0.9932\n",
      "batch loss: 0.022584501653909683\n",
      "batch accuracy: 0.9931640625\n",
      "doing 212 / 277\n",
      "elapsed time 23266.772245168686\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9980\n",
      "batch loss: 0.015121882781386375\n",
      "batch accuracy: 0.998046875\n",
      "doing 213 / 277\n",
      "elapsed time 23374.067009210587\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "batch loss: 0.007620646618306637\n",
      "batch accuracy: 1.0\n",
      "doing 214 / 277\n",
      "elapsed time 23485.003747701645\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9971\n",
      "batch loss: 0.011700797826051712\n",
      "batch accuracy: 0.9970703125\n",
      "doing 215 / 277\n",
      "elapsed time 23597.600499153137\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9980\n",
      "batch loss: 0.013909105211496353\n",
      "batch accuracy: 0.998046875\n",
      "doing 216 / 277\n",
      "elapsed time 23705.21862435341\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9971\n",
      "batch loss: 0.011580631136894226\n",
      "batch accuracy: 0.9970703125\n",
      "doing 217 / 277\n",
      "elapsed time 23814.51437306404\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "batch loss: 0.007776598446071148\n",
      "batch accuracy: 1.0\n",
      "doing 218 / 277\n",
      "elapsed time 23923.32993745804\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9971\n",
      "batch loss: 0.014166420325636864\n",
      "batch accuracy: 0.9970703125\n",
      "doing 219 / 277\n",
      "elapsed time 24040.015104293823\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9990\n",
      "batch loss: 0.009869787842035294\n",
      "batch accuracy: 0.9990234375\n",
      "doing 220 / 277\n",
      "elapsed time 24159.743093967438\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "batch loss: 0.008210085332393646\n",
      "batch accuracy: 1.0\n",
      "doing 221 / 277\n",
      "elapsed time 24278.743131160736\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9990\n",
      "batch loss: 0.008769371546804905\n",
      "batch accuracy: 0.9990234375\n",
      "doing 222 / 277\n",
      "elapsed time 24394.860181570053\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9980\n",
      "batch loss: 0.012793689966201782\n",
      "batch accuracy: 0.998046875\n",
      "doing 223 / 277\n",
      "elapsed time 24512.37723660469\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "batch loss: 0.00959992315620184\n",
      "batch accuracy: 1.0\n",
      "doing 224 / 277\n",
      "elapsed time 24631.09854388237\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9990\n",
      "batch loss: 0.0073419599793851376\n",
      "batch accuracy: 0.9990234375\n",
      "doing 225 / 277\n",
      "elapsed time 24753.319526910782\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9971\n",
      "batch loss: 0.011318372562527657\n",
      "batch accuracy: 0.9970703125\n",
      "doing 226 / 277\n",
      "elapsed time 24869.745042324066\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9971\n",
      "batch loss: 0.014111722819507122\n",
      "batch accuracy: 0.9970703125\n",
      "doing 227 / 277\n",
      "elapsed time 24989.167877435684\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "batch loss: 0.008612625300884247\n",
      "batch accuracy: 1.0\n",
      "doing 228 / 277\n",
      "elapsed time 25104.683601140976\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "batch loss: 0.007606396451592445\n",
      "batch accuracy: 1.0\n",
      "doing 229 / 277\n",
      "elapsed time 25223.28283047676\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9971\n",
      "batch loss: 0.010993385687470436\n",
      "batch accuracy: 0.9970703125\n",
      "doing 230 / 277\n",
      "elapsed time 25340.636731863022\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9971\n",
      "batch loss: 0.011398548260331154\n",
      "batch accuracy: 0.9970703125\n",
      "doing 231 / 277\n",
      "elapsed time 25453.183106660843\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9990\n",
      "batch loss: 0.006477765738964081\n",
      "batch accuracy: 0.9990234375\n",
      "doing 232 / 277\n",
      "elapsed time 25572.12622308731\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "batch loss: 0.008277775719761848\n",
      "batch accuracy: 1.0\n",
      "doing 233 / 277\n",
      "elapsed time 25683.80530166626\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9990\n",
      "batch loss: 0.009617319330573082\n",
      "batch accuracy: 0.9990234375\n",
      "doing 234 / 277\n",
      "elapsed time 25796.787900209427\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "batch loss: 0.008625322952866554\n",
      "batch accuracy: 1.0\n",
      "doing 235 / 277\n",
      "elapsed time 25908.76948952675\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9990\n",
      "batch loss: 0.00811313558369875\n",
      "batch accuracy: 0.9990234375\n",
      "doing 236 / 277\n",
      "elapsed time 26015.94878387451\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9980\n",
      "batch loss: 0.008465347811579704\n",
      "batch accuracy: 0.998046875\n",
      "doing 237 / 277\n",
      "elapsed time 26125.738505601883\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "batch loss: 0.007518049795180559\n",
      "batch accuracy: 1.0\n",
      "doing 238 / 277\n",
      "elapsed time 26236.17336177826\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "batch loss: 0.007585116196423769\n",
      "batch accuracy: 1.0\n",
      "doing 239 / 277\n",
      "elapsed time 26345.65553855896\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "batch loss: 0.008122973144054413\n",
      "batch accuracy: 1.0\n",
      "doing 240 / 277\n",
      "elapsed time 26454.314475774765\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9990\n",
      "batch loss: 0.007858550176024437\n",
      "batch accuracy: 0.9990234375\n",
      "doing 241 / 277\n",
      "elapsed time 26561.575459718704\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9980\n",
      "batch loss: 0.008483110927045345\n",
      "batch accuracy: 0.998046875\n",
      "doing 242 / 277\n",
      "elapsed time 26667.56990647316\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "batch loss: 0.00462085846811533\n",
      "batch accuracy: 1.0\n",
      "doing 243 / 277\n",
      "elapsed time 26776.24133515358\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9990\n",
      "batch loss: 0.007573103532195091\n",
      "batch accuracy: 0.9990234375\n",
      "doing 244 / 277\n",
      "elapsed time 26885.36311340332\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9990\n",
      "batch loss: 0.010347241535782814\n",
      "batch accuracy: 0.9990234375\n",
      "doing 245 / 277\n",
      "elapsed time 26992.03846669197\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "batch loss: 0.004973321221768856\n",
      "batch accuracy: 1.0\n",
      "doing 246 / 277\n",
      "elapsed time 27097.319462537766\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "batch loss: 0.0075570703484117985\n",
      "batch accuracy: 1.0\n",
      "doing 247 / 277\n",
      "elapsed time 27203.13305234909\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9990\n",
      "batch loss: 0.007566120475530624\n",
      "batch accuracy: 0.9990234375\n",
      "doing 248 / 277\n",
      "elapsed time 27306.588552236557\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "batch loss: 0.006021067500114441\n",
      "batch accuracy: 1.0\n",
      "doing 249 / 277\n",
      "elapsed time 27407.596670866013\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9971\n",
      "batch loss: 0.010389192029833794\n",
      "batch accuracy: 0.9970703125\n",
      "doing 250 / 277\n",
      "elapsed time 27506.207730054855\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9980\n",
      "batch loss: 0.007993858307600021\n",
      "batch accuracy: 0.998046875\n",
      "doing 251 / 277\n",
      "elapsed time 27604.661465883255\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "batch loss: 0.006445908918976784\n",
      "batch accuracy: 1.0\n",
      "doing 252 / 277\n",
      "elapsed time 27706.16929078102\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9980\n",
      "batch loss: 0.006971342489123344\n",
      "batch accuracy: 0.998046875\n",
      "doing 253 / 277\n",
      "elapsed time 27807.02492570877\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "batch loss: 0.00732021126896143\n",
      "batch accuracy: 1.0\n",
      "doing 254 / 277\n",
      "elapsed time 27911.97088456154\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9990\n",
      "batch loss: 0.007830062881112099\n",
      "batch accuracy: 0.9990234375\n",
      "doing 255 / 277\n",
      "elapsed time 28021.906976938248\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "batch loss: 0.005850817076861858\n",
      "batch accuracy: 1.0\n",
      "doing 256 / 277\n",
      "elapsed time 28131.768758773804\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9990\n",
      "batch loss: 0.0077149029821157455\n",
      "batch accuracy: 0.9990234375\n",
      "doing 257 / 277\n",
      "elapsed time 28241.465087890625\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "batch loss: 0.004916009958833456\n",
      "batch accuracy: 1.0\n",
      "doing 258 / 277\n",
      "elapsed time 28349.814297914505\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "batch loss: 0.0057419827207922935\n",
      "batch accuracy: 1.0\n",
      "doing 259 / 277\n",
      "elapsed time 28456.841447114944\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "batch loss: 0.00568368099629879\n",
      "batch accuracy: 1.0\n",
      "doing 260 / 277\n",
      "elapsed time 28568.88368010521\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9990\n",
      "batch loss: 0.008044512011110783\n",
      "batch accuracy: 0.9990234375\n",
      "doing 261 / 277\n",
      "elapsed time 28682.47401189804\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9990\n",
      "batch loss: 0.007075008936226368\n",
      "batch accuracy: 0.9990234375\n",
      "doing 262 / 277\n",
      "elapsed time 28797.384765625\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "batch loss: 0.0052472688257694244\n",
      "batch accuracy: 1.0\n",
      "doing 263 / 277\n",
      "elapsed time 28911.038110733032\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9990\n",
      "batch loss: 0.007536944933235645\n",
      "batch accuracy: 0.9990234375\n",
      "doing 264 / 277\n",
      "elapsed time 29021.395354509354\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9990\n",
      "batch loss: 0.0073576257564127445\n",
      "batch accuracy: 0.9990234375\n",
      "doing 265 / 277\n",
      "elapsed time 29135.10972213745\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "batch loss: 0.007339839357882738\n",
      "batch accuracy: 1.0\n",
      "doing 266 / 277\n",
      "elapsed time 29248.998420000076\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "batch loss: 0.005258900113403797\n",
      "batch accuracy: 1.0\n",
      "doing 267 / 277\n",
      "elapsed time 29360.18573474884\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9990\n",
      "batch loss: 0.010044470429420471\n",
      "batch accuracy: 0.9990234375\n",
      "doing 268 / 277\n",
      "elapsed time 29478.922970294952\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9990\n",
      "batch loss: 0.00701129948720336\n",
      "batch accuracy: 0.9990234375\n",
      "doing 269 / 277\n",
      "elapsed time 29604.320356845856\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "batch loss: 0.005857784766703844\n",
      "batch accuracy: 1.0\n",
      "doing 270 / 277\n",
      "elapsed time 29729.989196062088\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "batch loss: 0.005433602258563042\n",
      "batch accuracy: 1.0\n",
      "doing 271 / 277\n",
      "elapsed time 29859.024552106857\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9990\n",
      "batch loss: 0.0075067696161568165\n",
      "batch accuracy: 0.9990234375\n",
      "doing 272 / 277\n",
      "elapsed time 29986.141706228256\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "batch loss: 0.007152865640819073\n",
      "batch accuracy: 1.0\n",
      "doing 273 / 277\n",
      "elapsed time 30110.09623169899\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9990\n",
      "batch loss: 0.008168907836079597\n",
      "batch accuracy: 0.9990234375\n",
      "doing 274 / 277\n",
      "elapsed time 30230.115426540375\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "batch loss: 0.005582026205956936\n",
      "batch accuracy: 1.0\n",
      "doing 275 / 277\n",
      "elapsed time 30352.738000154495\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "batch loss: 0.005593897774815559\n",
      "batch accuracy: 1.0\n",
      "doing 276 / 277\n",
      "elapsed time 30417.685973644257\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "batch loss: 0.005357139743864536\n",
      "batch accuracy: 1.0\n",
      "Train loss 0.007017608255396735\n",
      "Train accuracy 0.999383038131769\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4185 - accuracy: 0.9238\n",
      "Validation loss: 0.4184567332267761\n",
      "Validation accuracy: 0.9237777590751648\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "epoch_train_loss = []\n",
    "epoch_train_acc = []\n",
    "epoch_validation_loss = []\n",
    "epoch_validation_acc = []\n",
    "for ep in range(epoch):\n",
    "    print(\"=\" * 50)\n",
    "    print(ep, \"/\", epoch)\n",
    "    step_loss = []\n",
    "    step_acc = []\n",
    "    \n",
    "    # batch_size=1000でHDDからバッチを取得する\n",
    "    for X_batch, Y_batch in get_batch(batch_size):\n",
    "        model.train_on_batch(X_batch, Y_batch)\n",
    "        score = model.evaluate(X_batch, Y_batch)\n",
    "        print(\"batch loss:\", score[0])\n",
    "        print(\"batch accuracy:\", score[1])\n",
    "        step_loss.append(score[0])\n",
    "        step_acc.append(score[1])\n",
    "    print(\"Train loss\", np.mean(step_loss))\n",
    "    print(\"Train accuracy\", np.mean(step_acc))\n",
    "    score = model.evaluate(x_validation, y_validation)\n",
    "    print(\"Validation loss:\", score[0])\n",
    "    print(\"Validation accuracy:\", score[1])\n",
    "    epoch_train_loss.append(np.mean(step_loss))\n",
    "    epoch_train_acc.append(np.mean(step_acc))\n",
    "    epoch_validation_loss.append(score[0])\n",
    "    epoch_validation_acc.append(score[1])\n",
    "    \n",
    "    shuffle_indices = random.sample(list(range(len(x_train))), len(x_train))\n",
    "    x_train = [x_train[i] for i in shuffle_indices]\n",
    "    y_train = y_train[shuffle_indices]\n",
    "    \n",
    "    model.save(cnn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|            Variable Name|    Memory|\n",
      " ------------------------------------ \n",
      "|       ImageDataGenerator|      1064|\n",
      "|                       In|       352|\n",
      "|                    Input|       144|\n",
      "|                    KFold|      1064|\n",
      "|          KerasClassifier|      1064|\n",
      "|            NOTEBOOK_NAME|        93|\n",
      "|                      Out|       248|\n",
      "|                     Pool|        72|\n",
      "|                   TRAINS|   2380496|\n",
      "|              VALIDATIONS|     38224|\n",
      "|                  X_batch|       144|\n",
      "|                  Y_batch|       112|\n",
      "|                      arr|     36072|\n",
      "|               batch_size|        28|\n",
      "|               cnf_matrix|       760|\n",
      "|                 cnn_path|       112|\n",
      "|         confusion_matrix|       144|\n",
      "|                     copy|        88|\n",
      "|             create_model|       144|\n",
      "|          cross_val_score|       144|\n",
      "|                      csv|        88|\n",
      "|                      cv2|        88|\n",
      "|                data_size|        28|\n",
      "|                 datapath|        59|\n",
      "|                   device|        80|\n",
      "|                  dirname|        57|\n",
      "|              encord_size|        28|\n",
      "|                       ep|        28|\n",
      "|                    epoch|        28|\n",
      "|          epoch_train_acc|       200|\n",
      "|         epoch_train_loss|       200|\n",
      "|     epoch_validation_acc|       200|\n",
      "|    epoch_validation_loss|       200|\n",
      "|                     exit|        64|\n",
      "|                        f|       224|\n",
      "|              faulty_case|       144|\n",
      "|                      fig|        64|\n",
      "|                     fig1|        64|\n",
      "|                     fig2|        64|\n",
      "|                 filename|        58|\n",
      "|                filenames|       104|\n",
      "|                get_batch|       144|\n",
      "|              get_ipython|        72|\n",
      "|                     glob|        88|\n",
      "|                 gridspec|        88|\n",
      "|                       gs|        64|\n",
      "|                    image|        88|\n",
      "|                itertools|        88|\n",
      "|                   joblib|        88|\n",
      "|                     join|       144|\n",
      "|                    keras|        88|\n",
      "|                   layers|        88|\n",
      "|              line_notify|       144|\n",
      "|          line_notify_img|       144|\n",
      "|               line_token|        92|\n",
      "|               load_array|       144|\n",
      "|             logical_gpus|       104|\n",
      "|                 max_size|        28|\n",
      "|                    model|        64|\n",
      "|                   models|        88|\n",
      "|                    new_y|       112|\n",
      "|                       np|        88|\n",
      "|                       os|        88|\n",
      "|                        p|        64|\n",
      "|                     path|        62|\n",
      "|                       pd|        88|\n",
      "|         physical_devices|       104|\n",
      "|                   pickle|        88|\n",
      "|    plot_confusion_matrix|       144|\n",
      "|                      plt|        88|\n",
      "|                     quit|        64|\n",
      "|                   random|        88|\n",
      "|                 requests|        88|\n",
      "|                        s|        93|\n",
      "|                    score|       104|\n",
      "|          shuffle_indices|   2265440|\n",
      "|                 step_acc|      2544|\n",
      "|                step_loss|      2544|\n",
      "|                 strategy|        64|\n",
      "|                      sys|        88|\n",
      "|                testscore|        24|\n",
      "|                       tf|        88|\n",
      "|                   tfback|        88|\n",
      "|                     time|        88|\n",
      "|           to_categorical|       144|\n",
      "|         train_test_split|       144|\n",
      "|               trainscore|        32|\n",
      "|                valiscore|        24|\n",
      "|                 var_name|        57|\n",
      "|                 warnings|        88|\n",
      "|                   x_test|  13500144|\n",
      "|                  x_train|   2380496|\n",
      "|             x_validation|       144|\n",
      "|                        y|     36112|\n",
      "|                y_predict|      3696|\n",
      "|                   y_test|       112|\n",
      "|               y_test_max|      3696|\n",
      "|           y_test_predict|      3696|\n",
      "|                  y_train|  10194268|\n",
      "|             y_validation|       112|\n",
      "|         y_validation_max|     36096|\n",
      "|     y_validation_predict|     36096|\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n",
    "print(\" ------------------------------------ \")\n",
    "for var_name in dir():\n",
    "    if not var_name.startswith(\"_\"):\n",
    "        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストデータで評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = joblib.load('./data/multi_' + str(max_size) + '/test/xtest.pickle')\n",
    "y_test = joblib.load('./data/multi_' + str(max_size) + '/test/ytest.pickle')\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 6ms/step - loss: 2.0807 - accuracy: 0.8356\n",
      "Test loss: 2.080690860748291\n",
      "Test accuracy: 0.8355555534362793\n",
      "Train accuracy: 0.999383038131769\n",
      "Validation accuracy: 0.9237777590751648\n",
      "Test accuracy: 0.8355555534362793\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "# score = model.evaluate(x_validation, y_validation)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "testscore = score[1]\n",
    "trainscore = epoch_train_acc[-1]\n",
    "valiscore = epoch_validation_acc[-1]\n",
    "print(\"Train accuracy:\", trainscore)\n",
    "print(\"Validation accuracy:\", valiscore)\n",
    "print(\"Test accuracy:\", testscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8355555555555556"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = np.argmax(model.predict(x_test), axis=1)\n",
    "y_test_max = np.argmax(y_test, axis=1)\n",
    "np.sum(y_test_max == y_predict, axis=0, dtype='float') / x_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- モデルは以下．\n",
    "    - 入力層\n",
    "    - 畳み込み層3つ\n",
    "    - Flatten層（1次元に）\n",
    "    - 全結合層3つ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100, 100, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 100, 100, 8)       224       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 16)      1168      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 100, 100, 32)      4640      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 320000)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                20480064  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 297       \n",
      "=================================================================\n",
      "Total params: 20,488,473\n",
      "Trainable params: 20,488,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- accuracyグラフ，lossグラフは以下．\n",
    "- 5epoch程度で落ち着いている．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracy plot\n",
    "fig1 = plt.figure()\n",
    "plt.plot(epoch_train_acc)\n",
    "plt.plot(epoch_validation_acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "fig1.savefig(\"multisize_accuracy.png\")\n",
    "\n",
    "# loss plot\n",
    "fig2 = plt.figure()\n",
    "plt.plot(epoch_train_loss)\n",
    "plt.plot(epoch_validation_loss)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "fig2.savefig(\"multisize_loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    fmt = '.4f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.xticks([0, 1, 2, 3, 4, 5, 6, 7 ,8], [\"Center\", \"Donut\", \"Edge-Loc\", \"Edge-Ring\", \"Loc\", \"Near-full\", \"Random\", \"Scratch\", \"None\"])\n",
    "    plt.yticks([0, 1, 2, 3, 4, 5, 6, 7 ,8], [\"Center\", \"Donut\", \"Edge-Loc\", \"Edge-Ring\", \"Loc\", \"Near-full\", \"Random\", \"Scratch\", \"None\"])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- validation confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x1080 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "y_validation_predict = np.argmax(model.predict(x_validation), axis=1)\n",
    "y_validation_max = np.argmax(y_validation, axis=1)\n",
    "cnf_matrix = confusion_matrix(y_validation_max, y_validation_predict)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "from matplotlib import gridspec\n",
    "fig = plt.figure(figsize=(8, 15)) \n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 1]) \n",
    "\n",
    "## Plot non-normalized confusion matrix\n",
    "plt.subplot(gs[0])\n",
    "plot_confusion_matrix(cnf_matrix, title='Confusion matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.subplot(gs[1])\n",
    "plot_confusion_matrix(cnf_matrix, normalize=True, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"multisize_valiconfmat.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x1080 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "y_test_predict = np.argmax(model.predict(x_test), axis=1)\n",
    "y_test_max = np.argmax(y_test, axis=1)\n",
    "cnf_matrix = confusion_matrix(y_test_max, y_test_predict)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "from matplotlib import gridspec\n",
    "fig = plt.figure(figsize=(8, 15)) \n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 1]) \n",
    "\n",
    "## Plot non-normalized confusion matrix\n",
    "plt.subplot(gs[0])\n",
    "plot_confusion_matrix(cnf_matrix, title='Confusion matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.subplot(gs[1])\n",
    "plot_confusion_matrix(cnf_matrix, normalize=True, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"multisize_testconfmat.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='notify-api.line.me', port=443): Max retries exceeded with url: /api/notify (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f81487912d0>: Failed to establish a new connection: [Errno 110] Connection timed out'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             )\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             )\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             )\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7f81487912d0>: Failed to establish a new connection: [Errno 110] Connection timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    755\u001b[0m             retries = retries.increment(\n\u001b[0;32m--> 756\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m             )\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='notify-api.line.me', port=443): Max retries exceeded with url: /api/notify (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f81487912d0>: Failed to establish a new connection: [Errno 110] Connection timed out'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-e7b2220b3d63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, proxies=proxies)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mline_notify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"学習が終了しました \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;31m# line_notify(\"Shawon: \" + str(shawon) + \", rotation_num: \" + str(rotation_num) + \", inversion: \" + str(inversion) + \", trials: \" + str(trials))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mline_notify_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"正解率\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multisize_accuracy.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-e7b2220b3d63>\u001b[0m in \u001b[0;36mline_notify\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;34m'https'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'https://proxy.uec.ac.jp:8080'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     }\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, proxies=proxies)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# LINEに画像を送る関数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \"\"\"\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='notify-api.line.me', port=443): Max retries exceeded with url: /api/notify (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f81487912d0>: Failed to establish a new connection: [Errno 110] Connection timed out'))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# LINEの設定\n",
    "path = './lineapi.txt'\n",
    "with open(path) as f:\n",
    "    s = f.read()\n",
    "    line_token = s.rstrip('\\n')\n",
    "\n",
    "# LINEに通知する関数\n",
    "def line_notify(text):\n",
    "    url = \"https://notify-api.line.me/api/notify\"\n",
    "    data = {\"message\": text}\n",
    "    headers = {\"Authorization\": \"Bearer \" + line_token}\n",
    "    proxies = {\n",
    "        'http': 'http://proxy.uec.ac.jp:8080',\n",
    "        'https': 'https://proxy.uec.ac.jp:8080',\n",
    "    }\n",
    "    requests.post(url, headers=headers)#, proxies=proxies)\n",
    "\n",
    "# LINEに画像を送る関数\n",
    "def line_notify_img(text, imgpath):\n",
    "    url = \"https://notify-api.line.me/api/notify\"\n",
    "    data = {\"message\": text, \"notificationDisabled\": True}\n",
    "    files = {\"imageFile\": open(imgpath, \"rb\")}\n",
    "    headers = {\"Authorization\": \"Bearer \" + line_token}\n",
    "    proxies = {\n",
    "        'http': 'http://proxy.uec.ac.jp:8080',\n",
    "        'https': 'https://proxy.uec.ac.jp:8080',\n",
    "    }\n",
    "    requests.post(url, data=data, files=files, headers=headers)#, proxies=proxies)\n",
    "    \n",
    "line_notify(\"学習が終了しました \")\n",
    "# line_notify(\"Shawon: \" + str(shawon) + \", rotation_num: \" + str(rotation_num) + \", inversion: \" + str(inversion) + \", trials: \" + str(trials))\n",
    "line_notify_img(\"正解率\", \"multisize_accuracy.png\")\n",
    "line_notify_img(\"Loss\", \"multisize_loss.png\")\n",
    "line_notify_img(\"validation混同行列\", \"multisize_valiconfmat.png\")\n",
    "line_notify_img(\"test混同行列\", \"multisize_testconfmat.png\")\n",
    "line_notify(\"train:\" + str(trainscore) + \"\\nvali:\" + str(valiscore) + \"\\ntest:\" + str(testscore))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wafermap",
   "language": "python",
   "name": "wafermap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
