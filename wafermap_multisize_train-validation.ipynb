{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提案手法の実験（ラベルが適切か出力）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## マルチサイズ\n",
    "- データオーギュメンテーション（鏡映，回転を追加）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import，入力データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/LSWMD.pkl\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU') memory growth: True\n",
      "PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU') memory growth: True\n",
      "PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU') memory growth: True\n",
      "PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU') memory growth: True\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU'), LogicalDevice(name='/device:GPU:1', device_type='GPU'), LogicalDevice(name='/device:GPU:2', device_type='GPU'), LogicalDevice(name='/device:GPU:3', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LSWMD.pkl']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import copy\n",
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "if len(physical_devices) > 0:\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "        print('{} memory growth: {}'.format(device, tf.config.experimental.get_memory_growth(device)))\n",
    "else:\n",
    "    print(\"Not enough GPU hardware devices available\")\n",
    "logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "print(logical_gpus)\n",
    "import keras\n",
    "from tensorflow.keras import layers, Input, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier \n",
    "import keras.backend.tensorflow_backend as tfback\n",
    "# from tf.keras.utils import multi_gpu_model\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datapath = join('data', 'wafer')\n",
    "print(os.listdir(\"../input\"))\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define\n",
    "max_size = 100\n",
    "encord_size = int(max_size / 2)\n",
    "\n",
    "NOTEBOOK_NAME = 'wafermap_multisize_train_validation'\n",
    "cnn_path = './model/cnn_' + str(max_size) + '_' + NOTEBOOK_NAME + '.h5'\n",
    "\n",
    "epoch = 30\n",
    "batch_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faulty case list : ['Center', 'Donut', 'Edge-Loc', 'Edge-Ring', 'Loc', 'Near-full', 'Random', 'Scratch', 'none']\n"
     ]
    }
   ],
   "source": [
    "faulty_case = ['Center', 'Donut', 'Edge-Loc', 'Edge-Ring', 'Loc', 'Near-full', 'Random', 'Scratch', 'none']\n",
    "print('Faulty case list : {}'.format(faulty_case))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習を行う\n",
    "- 不良ラベルを0-8の9次元のベクトルとして表現する．\n",
    "- one-hotエンコーディングを行っている．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの読み出し"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire the .npy name\n",
    "data_size = len(glob.glob('./data/multi_' + str(max_size) + '/train/' + '*.npy'))\n",
    "TRAINS = ['./data/multi_' + str(max_size) + '/train/' + str(i) + '.npy' for i in range(data_size)]\n",
    "# one-hot-encoding\n",
    "y = joblib.load('./data/multi_' + str(max_size) + '/train/y.pickle')\n",
    "new_y = to_categorical(y)\n",
    "# split test\n",
    "\n",
    "# shuffle_indices = random.sample(list(range(len(TRAINS))), 10000)\n",
    "# TRAINS = [TRAINS[i] for i in shuffle_indices]\n",
    "# new_y = new_y[shuffle_indices]\n",
    "\n",
    "x_train = TRAINS\n",
    "y_train = new_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- validaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire the .npy name\n",
    "data_size = len(glob.glob('./data/multi_' + str(max_size) + '/validation/' + '*.npy'))\n",
    "VALIDATIONS = ['./data/multi_' + str(max_size) + '/validation/' + str(i) + '.npy' for i in range(data_size)]\n",
    "# one-hot-encoding\n",
    "y = joblib.load('./data/multi_' + str(max_size) + '/validation/y.pickle')\n",
    "new_y = to_categorical(y)\n",
    "# split test\n",
    "\n",
    "# shuffle_indices = random.sample(list(range(len(TRAINS))), 10000)\n",
    "# TRAINS = [TRAINS[i] for i in shuffle_indices]\n",
    "# new_y = new_y[shuffle_indices]\n",
    "\n",
    "x_validation = VALIDATIONS\n",
    "y_validation = new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchを取得する関数\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "def load_array(file):\n",
    "    return np.load(file)\n",
    "\n",
    "def get_batch(batch_size): \n",
    "    global x_train, y_train\n",
    "    SIZE = len(x_train)\n",
    "    # n_batchs\n",
    "    n_batchs = SIZE//batch_size + 1\n",
    "    # for でyield\n",
    "    i = 0\n",
    "    start = time.time()\n",
    "    while (i < n_batchs):\n",
    "        print(\"doing\", i, \"/\", n_batchs)\n",
    "        Y_batch = y_train[(i * batch_size):((i + 1) * batch_size)]\n",
    "        \n",
    "        #あるbatchのfilenameの配列を持っておく\n",
    "        X_batch_name = x_train[(i * batch_size):((i + 1) * batch_size)]\n",
    "\n",
    "        # filenameにしたがってバッチのtensorを構築\n",
    "        with Pool() as p:\n",
    "            arr = p.map(load_array, X_batch_name)\n",
    "            \n",
    "        X_batch = np.array(arr).reshape(len(X_batch_name), max_size, max_size, 3)\n",
    "#         X_batch = np.array([np.load(file)\n",
    "#                             for file in X_batch_name]).reshape(len(X_batch_name), max_size, max_size, 3)\n",
    "        i += 1\n",
    "        print('elapsed time', time.time()-start)\n",
    "        yield X_batch, Y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 学習データとテストデータに分割する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train x : 296993, y : (296993, 9)\n",
      "Validation x: 4500, y : (4500, 9)\n"
     ]
    }
   ],
   "source": [
    "print('Train x : {}, y : {}'.format(len(x_train), y_train.shape))\n",
    "print('Validation x: {}, y : {}'.format(len(x_validation), y_validation.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading X_validation...\n"
     ]
    }
   ],
   "source": [
    "print(\"loading X_validation...\")\n",
    "with Pool() as p:\n",
    "    arr = p.map(load_array, x_validation)\n",
    "\n",
    "x_validation = np.array(arr).reshape(len(x_validation), max_size, max_size, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 学習データ246635枚，テストデータ121477枚．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- モデルの定義を行う．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    with tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\", \"/gpu:2\", \"/gpu:3\"], \n",
    "                                        cross_device_ops = tf.distribute.HierarchicalCopyAllReduce()).scope():\n",
    "        input_shape = (max_size, max_size, 3)\n",
    "        input_tensor = Input(input_shape)\n",
    "\n",
    "        conv_1 = layers.Conv2D(8, (3,3), activation='relu', padding='same')(input_tensor)\n",
    "        conv_2 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(conv_1)\n",
    "        conv_3 = layers.Conv2D(32, (3,3), activation='relu', padding='same')(conv_2)\n",
    "\n",
    "        flat = layers.Flatten()(conv_3)\n",
    "\n",
    "        dense_1 = layers.Dense(64, activation='relu')(flat)\n",
    "        dense_2 = layers.Dense(32, activation='relu')(dense_1)\n",
    "        output_tensor = layers.Dense(9, activation='softmax')(dense_2)\n",
    "\n",
    "        model = models.Model(input_tensor, output_tensor)\n",
    "        model.compile(optimizer='Adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3-Fold Cross validationで分割して学習する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = KerasClassifier(build_fn=create_model, epochs=30, batch_size=1024, verbose=1) \n",
    "# # 3-Fold Crossvalidation\n",
    "# kfold = KFold(n_splits=3, shuffle=True, random_state=2019) \n",
    "# # results = cross_val_score(model, x_train, y_train, cv=kfold)\n",
    "# # # Check 3-fold model's mean accuracy\n",
    "# # print('Simple CNN Cross validation score : {:.4f}'.format(np.mean(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cross validiationによる精度は99.55%であった．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cross validationなしで学習する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:XLA_GPU:0')\n",
      "Number of devices: 3\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\", \"device:XLA_GPU:0\"], cross_device_ops = tf.distribute.HierarchicalCopyAllReduce())\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=5\n",
    "batch_size=1024\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "0 / 5\n",
      "doing 0 / 291\n",
      "elapsed time 125.40386772155762\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9971\n",
      "batch loss: 0.016785230487585068\n",
      "batch accuracy: 0.9970703125\n",
      "doing 1 / 291\n",
      "elapsed time 244.12810635566711\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0201 - accuracy: 0.9980\n",
      "batch loss: 0.020062480121850967\n",
      "batch accuracy: 0.998046875\n",
      "doing 2 / 291\n",
      "elapsed time 369.28113865852356\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0206 - accuracy: 0.9980\n",
      "batch loss: 0.020620662719011307\n",
      "batch accuracy: 0.998046875\n",
      "doing 3 / 291\n",
      "elapsed time 486.5176889896393\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0257 - accuracy: 0.9961\n",
      "batch loss: 0.025748014450073242\n",
      "batch accuracy: 0.99609375\n",
      "doing 4 / 291\n",
      "elapsed time 611.5808672904968\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9941\n",
      "batch loss: 0.022912021726369858\n",
      "batch accuracy: 0.994140625\n",
      "doing 5 / 291\n",
      "elapsed time 732.7142405509949\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 0.9990\n",
      "batch loss: 0.015557894483208656\n",
      "batch accuracy: 0.9990234375\n",
      "doing 6 / 291\n",
      "elapsed time 849.791225194931\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9971\n",
      "batch loss: 0.015216558240354061\n",
      "batch accuracy: 0.9970703125\n",
      "doing 7 / 291\n",
      "elapsed time 969.2515642642975\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9980\n",
      "batch loss: 0.014480682089924812\n",
      "batch accuracy: 0.998046875\n",
      "doing 8 / 291\n",
      "elapsed time 1085.811817407608\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9961\n",
      "batch loss: 0.01980246976017952\n",
      "batch accuracy: 0.99609375\n",
      "doing 9 / 291\n",
      "elapsed time 1208.6644661426544\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9961\n",
      "batch loss: 0.019058717414736748\n",
      "batch accuracy: 0.99609375\n",
      "doing 10 / 291\n",
      "elapsed time 1329.7013275623322\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0137 - accuracy: 0.9971\n",
      "batch loss: 0.013663860969245434\n",
      "batch accuracy: 0.9970703125\n",
      "doing 11 / 291\n",
      "elapsed time 1442.945569038391\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9980\n",
      "batch loss: 0.012552464380860329\n",
      "batch accuracy: 0.998046875\n",
      "doing 12 / 291\n",
      "elapsed time 1566.6169855594635\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 0.9932\n",
      "batch loss: 0.02335679903626442\n",
      "batch accuracy: 0.9931640625\n",
      "doing 13 / 291\n",
      "elapsed time 1689.0087659358978\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9941\n",
      "batch loss: 0.021214406937360764\n",
      "batch accuracy: 0.994140625\n",
      "doing 14 / 291\n",
      "elapsed time 1807.4060671329498\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9990\n",
      "batch loss: 0.011162851005792618\n",
      "batch accuracy: 0.9990234375\n",
      "doing 15 / 291\n",
      "elapsed time 1921.5423290729523\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 0.9961\n",
      "batch loss: 0.01653764583170414\n",
      "batch accuracy: 0.99609375\n",
      "doing 16 / 291\n",
      "elapsed time 2040.0275902748108\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9980\n",
      "batch loss: 0.013364977203309536\n",
      "batch accuracy: 0.998046875\n",
      "doing 17 / 291\n",
      "elapsed time 2156.3831560611725\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9980\n",
      "batch loss: 0.012453008443117142\n",
      "batch accuracy: 0.998046875\n",
      "doing 18 / 291\n",
      "elapsed time 2287.1435708999634\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0138 - accuracy: 0.9980\n",
      "batch loss: 0.01383061334490776\n",
      "batch accuracy: 0.998046875\n",
      "doing 19 / 291\n",
      "elapsed time 2415.4969086647034\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9961\n",
      "batch loss: 0.018197428435087204\n",
      "batch accuracy: 0.99609375\n",
      "doing 20 / 291\n",
      "elapsed time 2538.0403711795807\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9961\n",
      "batch loss: 0.012911370024085045\n",
      "batch accuracy: 0.99609375\n",
      "doing 21 / 291\n",
      "elapsed time 2671.465494632721\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9980\n",
      "batch loss: 0.012362770736217499\n",
      "batch accuracy: 0.998046875\n",
      "doing 22 / 291\n",
      "elapsed time 2799.9504203796387\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0137 - accuracy: 0.9971\n",
      "batch loss: 0.013650587759912014\n",
      "batch accuracy: 0.9970703125\n",
      "doing 23 / 291\n",
      "elapsed time 2922.7282195091248\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9951\n",
      "batch loss: 0.014869241043925285\n",
      "batch accuracy: 0.9951171875\n",
      "doing 24 / 291\n",
      "elapsed time 3049.9150516986847\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9980\n",
      "batch loss: 0.01452065072953701\n",
      "batch accuracy: 0.998046875\n",
      "doing 25 / 291\n",
      "elapsed time 3175.9472131729126\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.9961\n",
      "batch loss: 0.016552984714508057\n",
      "batch accuracy: 0.99609375\n",
      "doing 26 / 291\n",
      "elapsed time 3296.1735343933105\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9961\n",
      "batch loss: 0.012847952544689178\n",
      "batch accuracy: 0.99609375\n",
      "doing 27 / 291\n",
      "elapsed time 3417.6002807617188\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 0.9961\n",
      "batch loss: 0.02262243628501892\n",
      "batch accuracy: 0.99609375\n",
      "doing 28 / 291\n",
      "elapsed time 3539.9683125019073\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9990\n",
      "batch loss: 0.012223592028021812\n",
      "batch accuracy: 0.9990234375\n",
      "doing 29 / 291\n",
      "elapsed time 3672.5473926067352\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0193 - accuracy: 0.9961\n",
      "batch loss: 0.01927272044122219\n",
      "batch accuracy: 0.99609375\n",
      "doing 30 / 291\n",
      "elapsed time 3793.2589449882507\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9990\n",
      "batch loss: 0.010363291017711163\n",
      "batch accuracy: 0.9990234375\n",
      "doing 31 / 291\n",
      "elapsed time 3912.023060321808\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9971\n",
      "batch loss: 0.01311363186687231\n",
      "batch accuracy: 0.9970703125\n",
      "doing 32 / 291\n",
      "elapsed time 4036.5259716510773\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.9951\n",
      "batch loss: 0.016594108194112778\n",
      "batch accuracy: 0.9951171875\n",
      "doing 33 / 291\n",
      "elapsed time 4159.597029209137\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9951\n",
      "batch loss: 0.019574157893657684\n",
      "batch accuracy: 0.9951171875\n",
      "doing 34 / 291\n",
      "elapsed time 4280.226296901703\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0136 - accuracy: 0.9971\n",
      "batch loss: 0.013584797270596027\n",
      "batch accuracy: 0.9970703125\n",
      "doing 35 / 291\n",
      "elapsed time 4407.13823390007\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9971\n",
      "batch loss: 0.01485656388103962\n",
      "batch accuracy: 0.9970703125\n",
      "doing 36 / 291\n",
      "elapsed time 4531.23263168335\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0165 - accuracy: 0.9980\n",
      "batch loss: 0.016497377306222916\n",
      "batch accuracy: 0.998046875\n",
      "doing 37 / 291\n",
      "elapsed time 4659.280162572861\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9990\n",
      "batch loss: 0.011346599087119102\n",
      "batch accuracy: 0.9990234375\n",
      "doing 38 / 291\n",
      "elapsed time 4784.065618276596\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9971\n",
      "batch loss: 0.013286489993333817\n",
      "batch accuracy: 0.9970703125\n",
      "doing 39 / 291\n",
      "elapsed time 4916.1873326301575\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0179 - accuracy: 0.9961\n",
      "batch loss: 0.017913348972797394\n",
      "batch accuracy: 0.99609375\n",
      "doing 40 / 291\n",
      "elapsed time 5045.511063337326\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0136 - accuracy: 0.9961\n",
      "batch loss: 0.013617674820125103\n",
      "batch accuracy: 0.99609375\n",
      "doing 41 / 291\n",
      "elapsed time 5175.158210039139\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9971\n",
      "batch loss: 0.012514560483396053\n",
      "batch accuracy: 0.9970703125\n",
      "doing 42 / 291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 5309.626695394516\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.9971\n",
      "batch loss: 0.013364054262638092\n",
      "batch accuracy: 0.9970703125\n",
      "doing 43 / 291\n",
      "elapsed time 5451.723969221115\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "batch loss: 0.010175518691539764\n",
      "batch accuracy: 1.0\n",
      "doing 44 / 291\n",
      "elapsed time 5575.43655705452\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 0.9961\n",
      "batch loss: 0.015851449221372604\n",
      "batch accuracy: 0.99609375\n",
      "doing 45 / 291\n",
      "elapsed time 5702.554989337921\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9980\n",
      "batch loss: 0.01273126620799303\n",
      "batch accuracy: 0.998046875\n",
      "doing 46 / 291\n",
      "elapsed time 5839.397887706757\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9951\n",
      "batch loss: 0.019806930795311928\n",
      "batch accuracy: 0.9951171875\n",
      "doing 47 / 291\n",
      "elapsed time 5973.836897611618\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9990\n",
      "batch loss: 0.011233394034206867\n",
      "batch accuracy: 0.9990234375\n",
      "doing 48 / 291\n",
      "elapsed time 6106.795977830887\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9990\n",
      "batch loss: 0.010889669880270958\n",
      "batch accuracy: 0.9990234375\n",
      "doing 49 / 291\n",
      "elapsed time 6244.225409269333\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9932\n",
      "batch loss: 0.016783127561211586\n",
      "batch accuracy: 0.9931640625\n",
      "doing 50 / 291\n",
      "elapsed time 6371.303693771362\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 1.0000\n",
      "batch loss: 0.012017874047160149\n",
      "batch accuracy: 1.0\n",
      "doing 51 / 291\n",
      "elapsed time 6503.2370698452\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9980\n",
      "batch loss: 0.010815773159265518\n",
      "batch accuracy: 0.998046875\n",
      "doing 52 / 291\n",
      "elapsed time 6632.171790361404\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9971\n",
      "batch loss: 0.010714511387050152\n",
      "batch accuracy: 0.9970703125\n",
      "doing 53 / 291\n",
      "elapsed time 6761.231249094009\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "batch loss: 0.00940871424973011\n",
      "batch accuracy: 1.0\n",
      "doing 54 / 291\n",
      "elapsed time 6883.482520341873\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.9971\n",
      "batch loss: 0.024704890325665474\n",
      "batch accuracy: 0.9970703125\n",
      "doing 55 / 291\n",
      "elapsed time 7006.520981550217\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9990\n",
      "batch loss: 0.013392733410000801\n",
      "batch accuracy: 0.9990234375\n",
      "doing 56 / 291\n",
      "elapsed time 7135.479912519455\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9990\n",
      "batch loss: 0.011823929846286774\n",
      "batch accuracy: 0.9990234375\n",
      "doing 57 / 291\n",
      "elapsed time 7240.488041639328\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9980\n",
      "batch loss: 0.011302073486149311\n",
      "batch accuracy: 0.998046875\n",
      "doing 58 / 291\n",
      "elapsed time 7321.31320977211\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9961\n",
      "batch loss: 0.013951078988611698\n",
      "batch accuracy: 0.99609375\n",
      "doing 59 / 291\n",
      "elapsed time 7400.98205780983\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9980\n",
      "batch loss: 0.016643427312374115\n",
      "batch accuracy: 0.998046875\n",
      "doing 60 / 291\n",
      "elapsed time 7483.707420349121\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9951\n",
      "batch loss: 0.02532094530761242\n",
      "batch accuracy: 0.9951171875\n",
      "doing 61 / 291\n",
      "elapsed time 7570.513448238373\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0153 - accuracy: 0.9971\n",
      "batch loss: 0.015254788100719452\n",
      "batch accuracy: 0.9970703125\n",
      "doing 62 / 291\n",
      "elapsed time 7650.536014080048\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9971\n",
      "batch loss: 0.016404926776885986\n",
      "batch accuracy: 0.9970703125\n",
      "doing 63 / 291\n",
      "elapsed time 7735.693084478378\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9971\n",
      "batch loss: 0.01675298623740673\n",
      "batch accuracy: 0.9970703125\n",
      "doing 64 / 291\n",
      "elapsed time 7818.055877685547\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9961\n",
      "batch loss: 0.013990107923746109\n",
      "batch accuracy: 0.99609375\n",
      "doing 65 / 291\n",
      "elapsed time 7900.969157457352\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0154 - accuracy: 0.9980\n",
      "batch loss: 0.015351295471191406\n",
      "batch accuracy: 0.998046875\n",
      "doing 66 / 291\n",
      "elapsed time 7982.273264169693\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9971\n",
      "batch loss: 0.013160999864339828\n",
      "batch accuracy: 0.9970703125\n",
      "doing 67 / 291\n",
      "elapsed time 8062.436997175217\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9980\n",
      "batch loss: 0.011442062444984913\n",
      "batch accuracy: 0.998046875\n",
      "doing 68 / 291\n",
      "elapsed time 8149.425641298294\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 0.9971\n",
      "batch loss: 0.015894867479801178\n",
      "batch accuracy: 0.9970703125\n",
      "doing 69 / 291\n",
      "elapsed time 8234.129464149475\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 0.9980\n",
      "batch loss: 0.018450412899255753\n",
      "batch accuracy: 0.998046875\n",
      "doing 70 / 291\n",
      "elapsed time 8320.035091400146\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0186 - accuracy: 0.9980\n",
      "batch loss: 0.018586277961730957\n",
      "batch accuracy: 0.998046875\n",
      "doing 71 / 291\n",
      "elapsed time 8404.42694067955\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9980\n",
      "batch loss: 0.009696584194898605\n",
      "batch accuracy: 0.998046875\n",
      "doing 72 / 291\n",
      "elapsed time 8488.339463949203\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9980\n",
      "batch loss: 0.01373712345957756\n",
      "batch accuracy: 0.998046875\n",
      "doing 73 / 291\n",
      "elapsed time 8572.525090932846\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9971\n",
      "batch loss: 0.014575600624084473\n",
      "batch accuracy: 0.9970703125\n",
      "doing 74 / 291\n",
      "elapsed time 8656.965416431427\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9951\n",
      "batch loss: 0.01755794882774353\n",
      "batch accuracy: 0.9951171875\n",
      "doing 75 / 291\n",
      "elapsed time 8741.998064041138\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "batch loss: 0.009464741684496403\n",
      "batch accuracy: 1.0\n",
      "doing 76 / 291\n",
      "elapsed time 8825.36606001854\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "batch loss: 0.00579161336645484\n",
      "batch accuracy: 1.0\n",
      "doing 77 / 291\n",
      "elapsed time 8913.847284793854\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9980\n",
      "batch loss: 0.011496754363179207\n",
      "batch accuracy: 0.998046875\n",
      "doing 78 / 291\n",
      "elapsed time 8995.092478752136\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 0.9961\n",
      "batch loss: 0.017215397208929062\n",
      "batch accuracy: 0.99609375\n",
      "doing 79 / 291\n",
      "elapsed time 9078.52966928482\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9980\n",
      "batch loss: 0.013101084157824516\n",
      "batch accuracy: 0.998046875\n",
      "doing 80 / 291\n",
      "elapsed time 9163.581582784653\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9980\n",
      "batch loss: 0.011297747492790222\n",
      "batch accuracy: 0.998046875\n",
      "doing 81 / 291\n",
      "elapsed time 9249.786433458328\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9990\n",
      "batch loss: 0.012217573821544647\n",
      "batch accuracy: 0.9990234375\n",
      "doing 82 / 291\n",
      "elapsed time 9330.872961521149\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9961\n",
      "batch loss: 0.012711646035313606\n",
      "batch accuracy: 0.99609375\n",
      "doing 83 / 291\n",
      "elapsed time 9413.38372540474\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0129 - accuracy: 0.9990\n",
      "batch loss: 0.01291694212704897\n",
      "batch accuracy: 0.9990234375\n",
      "doing 84 / 291\n",
      "elapsed time 9497.682105064392\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9971\n",
      "batch loss: 0.014786657877266407\n",
      "batch accuracy: 0.9970703125\n",
      "doing 85 / 291\n",
      "elapsed time 9582.958233356476\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 0.9980\n",
      "batch loss: 0.012314604595303535\n",
      "batch accuracy: 0.998046875\n",
      "doing 86 / 291\n",
      "elapsed time 9666.80262684822\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 0.9990\n",
      "batch loss: 0.012074860744178295\n",
      "batch accuracy: 0.9990234375\n",
      "doing 87 / 291\n",
      "elapsed time 9752.847869157791\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9971\n",
      "batch loss: 0.013507996685802937\n",
      "batch accuracy: 0.9970703125\n",
      "doing 88 / 291\n",
      "elapsed time 9836.446427106857\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9990\n",
      "batch loss: 0.01121297013014555\n",
      "batch accuracy: 0.9990234375\n",
      "doing 89 / 291\n",
      "elapsed time 9923.260331392288\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9980\n",
      "batch loss: 0.012418670579791069\n",
      "batch accuracy: 0.998046875\n",
      "doing 90 / 291\n",
      "elapsed time 10008.165644645691\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "batch loss: 0.008059089072048664\n",
      "batch accuracy: 1.0\n",
      "doing 91 / 291\n",
      "elapsed time 10089.957017660141\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 0.9971\n",
      "batch loss: 0.017173798754811287\n",
      "batch accuracy: 0.9970703125\n",
      "doing 92 / 291\n",
      "elapsed time 10177.41041469574\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9980\n",
      "batch loss: 0.012682626955211163\n",
      "batch accuracy: 0.998046875\n",
      "doing 93 / 291\n",
      "elapsed time 10263.089348554611\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0225 - accuracy: 0.9951\n",
      "batch loss: 0.02250535599887371\n",
      "batch accuracy: 0.9951171875\n",
      "doing 94 / 291\n",
      "elapsed time 10344.961698770523\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9971\n",
      "batch loss: 0.012609640136361122\n",
      "batch accuracy: 0.9970703125\n",
      "doing 95 / 291\n",
      "elapsed time 10432.174420833588\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9990\n",
      "batch loss: 0.006693949922919273\n",
      "batch accuracy: 0.9990234375\n",
      "doing 96 / 291\n",
      "elapsed time 10518.147962331772\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9990\n",
      "batch loss: 0.012589813210070133\n",
      "batch accuracy: 0.9990234375\n",
      "doing 97 / 291\n",
      "elapsed time 10601.336630105972\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9990\n",
      "batch loss: 0.011027125641703606\n",
      "batch accuracy: 0.9990234375\n",
      "doing 98 / 291\n",
      "elapsed time 10688.010221242905\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "batch loss: 0.009923884645104408\n",
      "batch accuracy: 1.0\n",
      "doing 99 / 291\n",
      "elapsed time 10773.82526397705\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9971\n",
      "batch loss: 0.011731700040400028\n",
      "batch accuracy: 0.9970703125\n",
      "doing 100 / 291\n",
      "elapsed time 10858.496644735336\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9990\n",
      "batch loss: 0.014393694698810577\n",
      "batch accuracy: 0.9990234375\n",
      "doing 101 / 291\n",
      "elapsed time 10945.238320350647\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9990\n",
      "batch loss: 0.010556565597653389\n",
      "batch accuracy: 0.9990234375\n",
      "doing 102 / 291\n",
      "elapsed time 11030.171250343323\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9990\n",
      "batch loss: 0.00991206243634224\n",
      "batch accuracy: 0.9990234375\n",
      "doing 103 / 291\n",
      "elapsed time 11113.824153900146\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0150 - accuracy: 0.9951\n",
      "batch loss: 0.015041191130876541\n",
      "batch accuracy: 0.9951171875\n",
      "doing 104 / 291\n",
      "elapsed time 11201.369534254074\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9990\n",
      "batch loss: 0.007414786145091057\n",
      "batch accuracy: 0.9990234375\n",
      "doing 105 / 291\n",
      "elapsed time 11285.350642681122\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0371 - accuracy: 0.9932\n",
      "batch loss: 0.037056200206279755\n",
      "batch accuracy: 0.9931640625\n",
      "doing 106 / 291\n",
      "elapsed time 11369.260931015015\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9971\n",
      "batch loss: 0.011532057076692581\n",
      "batch accuracy: 0.9970703125\n",
      "doing 107 / 291\n",
      "elapsed time 11457.990000963211\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9951\n",
      "batch loss: 0.015133637934923172\n",
      "batch accuracy: 0.9951171875\n",
      "doing 108 / 291\n",
      "elapsed time 11545.195458650589\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9980\n",
      "batch loss: 0.011961470358073711\n",
      "batch accuracy: 0.998046875\n",
      "doing 109 / 291\n",
      "elapsed time 11629.210086107254\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9980\n",
      "batch loss: 0.010176132433116436\n",
      "batch accuracy: 0.998046875\n",
      "doing 110 / 291\n",
      "elapsed time 11717.58444595337\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0089 - accuracy: 0.9990\n",
      "batch loss: 0.008880583569407463\n",
      "batch accuracy: 0.9990234375\n",
      "doing 111 / 291\n",
      "elapsed time 11804.583417415619\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9990\n",
      "batch loss: 0.00897269882261753\n",
      "batch accuracy: 0.9990234375\n",
      "doing 112 / 291\n",
      "elapsed time 11890.843923807144\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9971\n",
      "batch loss: 0.010450480505824089\n",
      "batch accuracy: 0.9970703125\n",
      "doing 113 / 291\n",
      "elapsed time 11975.744040727615\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0165 - accuracy: 0.9971\n",
      "batch loss: 0.016451621428132057\n",
      "batch accuracy: 0.9970703125\n",
      "doing 114 / 291\n",
      "elapsed time 12064.187247991562\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9990\n",
      "batch loss: 0.010235067456960678\n",
      "batch accuracy: 0.9990234375\n",
      "doing 115 / 291\n",
      "elapsed time 12149.385289907455\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9990\n",
      "batch loss: 0.00812398362904787\n",
      "batch accuracy: 0.9990234375\n",
      "doing 116 / 291\n",
      "elapsed time 12236.986377954483\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9990\n",
      "batch loss: 0.008154819719493389\n",
      "batch accuracy: 0.9990234375\n",
      "doing 117 / 291\n",
      "elapsed time 12321.063625097275\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9971\n",
      "batch loss: 0.012835074216127396\n",
      "batch accuracy: 0.9970703125\n",
      "doing 118 / 291\n",
      "elapsed time 12410.694129943848\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9980\n",
      "batch loss: 0.014562037773430347\n",
      "batch accuracy: 0.998046875\n",
      "doing 119 / 291\n",
      "elapsed time 12494.882505655289\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 0.9971\n",
      "batch loss: 0.012966648675501347\n",
      "batch accuracy: 0.9970703125\n",
      "doing 120 / 291\n",
      "elapsed time 12580.516775369644\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9961\n",
      "batch loss: 0.016102762892842293\n",
      "batch accuracy: 0.99609375\n",
      "doing 121 / 291\n",
      "elapsed time 12669.460653305054\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0150 - accuracy: 0.9971\n",
      "batch loss: 0.014986196532845497\n",
      "batch accuracy: 0.9970703125\n",
      "doing 122 / 291\n",
      "elapsed time 12757.188057422638\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9971\n",
      "batch loss: 0.01668808050453663\n",
      "batch accuracy: 0.9970703125\n",
      "doing 123 / 291\n",
      "elapsed time 12840.382182359695\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9980\n",
      "batch loss: 0.015052715316414833\n",
      "batch accuracy: 0.998046875\n",
      "doing 124 / 291\n",
      "elapsed time 12927.25484085083\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9961\n",
      "batch loss: 0.013701986521482468\n",
      "batch accuracy: 0.99609375\n",
      "doing 125 / 291\n",
      "elapsed time 13010.545453310013\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9990\n",
      "batch loss: 0.008661189116537571\n",
      "batch accuracy: 0.9990234375\n",
      "doing 126 / 291\n",
      "elapsed time 13093.770763874054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9980\n",
      "batch loss: 0.011883866041898727\n",
      "batch accuracy: 0.998046875\n",
      "doing 127 / 291\n",
      "elapsed time 13179.70748090744\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0196 - accuracy: 0.9980\n",
      "batch loss: 0.019583219662308693\n",
      "batch accuracy: 0.998046875\n",
      "doing 128 / 291\n",
      "elapsed time 13262.714722633362\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.9980\n",
      "batch loss: 0.008546644821763039\n",
      "batch accuracy: 0.998046875\n",
      "doing 129 / 291\n",
      "elapsed time 13347.876908540726\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "batch loss: 0.008719254285097122\n",
      "batch accuracy: 1.0\n",
      "doing 130 / 291\n",
      "elapsed time 13434.819469928741\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "batch loss: 0.007962859235703945\n",
      "batch accuracy: 1.0\n",
      "doing 131 / 291\n",
      "elapsed time 13520.319859981537\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9961\n",
      "batch loss: 0.014620780944824219\n",
      "batch accuracy: 0.99609375\n",
      "doing 132 / 291\n",
      "elapsed time 13602.879828453064\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0129 - accuracy: 0.9971\n",
      "batch loss: 0.012922246940433979\n",
      "batch accuracy: 0.9970703125\n",
      "doing 133 / 291\n",
      "elapsed time 13687.870080947876\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9941\n",
      "batch loss: 0.020961333066225052\n",
      "batch accuracy: 0.994140625\n",
      "doing 134 / 291\n",
      "elapsed time 13772.576961755753\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9990\n",
      "batch loss: 0.008348501287400723\n",
      "batch accuracy: 0.9990234375\n",
      "doing 135 / 291\n",
      "elapsed time 13855.757399559021\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9990\n",
      "batch loss: 0.011486843228340149\n",
      "batch accuracy: 0.9990234375\n",
      "doing 136 / 291\n",
      "elapsed time 13945.355738639832\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "batch loss: 0.008296115323901176\n",
      "batch accuracy: 1.0\n",
      "doing 137 / 291\n",
      "elapsed time 14031.684623718262\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "batch loss: 0.008794921450316906\n",
      "batch accuracy: 1.0\n",
      "doing 138 / 291\n",
      "elapsed time 14113.202315092087\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9961\n",
      "batch loss: 0.013678614981472492\n",
      "batch accuracy: 0.99609375\n",
      "doing 139 / 291\n",
      "elapsed time 14200.411572694778\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "batch loss: 0.010376197285950184\n",
      "batch accuracy: 1.0\n",
      "doing 140 / 291\n",
      "elapsed time 14290.401893854141\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9971\n",
      "batch loss: 0.012894276529550552\n",
      "batch accuracy: 0.9970703125\n",
      "doing 141 / 291\n",
      "elapsed time 14376.749842882156\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9980\n",
      "batch loss: 0.011907790787518024\n",
      "batch accuracy: 0.998046875\n",
      "doing 142 / 291\n",
      "elapsed time 14464.040843009949\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9980\n",
      "batch loss: 0.009129440411925316\n",
      "batch accuracy: 0.998046875\n",
      "doing 143 / 291\n",
      "elapsed time 14549.353371620178\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "batch loss: 0.007970618084073067\n",
      "batch accuracy: 1.0\n",
      "doing 144 / 291\n",
      "elapsed time 14638.061261415482\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 0.9951\n",
      "batch loss: 0.014648014679551125\n",
      "batch accuracy: 0.9951171875\n",
      "doing 145 / 291\n",
      "elapsed time 14725.27806019783\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "batch loss: 0.008412746712565422\n",
      "batch accuracy: 1.0\n",
      "doing 146 / 291\n",
      "elapsed time 14812.90964269638\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9990\n",
      "batch loss: 0.009540742263197899\n",
      "batch accuracy: 0.9990234375\n",
      "doing 147 / 291\n",
      "elapsed time 14897.548408269882\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9980\n",
      "batch loss: 0.008858133107423782\n",
      "batch accuracy: 0.998046875\n",
      "doing 148 / 291\n",
      "elapsed time 14985.414587497711\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9971\n",
      "batch loss: 0.01783997192978859\n",
      "batch accuracy: 0.9970703125\n",
      "doing 149 / 291\n",
      "elapsed time 15076.28732085228\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9980\n",
      "batch loss: 0.01910850778222084\n",
      "batch accuracy: 0.998046875\n",
      "doing 150 / 291\n",
      "elapsed time 15163.57234120369\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9961\n",
      "batch loss: 0.011376606300473213\n",
      "batch accuracy: 0.99609375\n",
      "doing 151 / 291\n",
      "elapsed time 15251.304026126862\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9980\n",
      "batch loss: 0.008976545184850693\n",
      "batch accuracy: 0.998046875\n",
      "doing 152 / 291\n",
      "elapsed time 15340.454904079437\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "batch loss: 0.005505809560418129\n",
      "batch accuracy: 1.0\n",
      "doing 153 / 291\n",
      "elapsed time 15426.116273641586\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9971\n",
      "batch loss: 0.01625838503241539\n",
      "batch accuracy: 0.9970703125\n",
      "doing 154 / 291\n",
      "elapsed time 15512.724925279617\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.9951\n",
      "batch loss: 0.016082406044006348\n",
      "batch accuracy: 0.9951171875\n",
      "doing 155 / 291\n",
      "elapsed time 15598.535812854767\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "batch loss: 0.008570266887545586\n",
      "batch accuracy: 1.0\n",
      "doing 156 / 291\n",
      "elapsed time 15684.469760894775\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9990\n",
      "batch loss: 0.01084446907043457\n",
      "batch accuracy: 0.9990234375\n",
      "doing 157 / 291\n",
      "elapsed time 15772.984280109406\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.9980\n",
      "batch loss: 0.018726233392953873\n",
      "batch accuracy: 0.998046875\n",
      "doing 158 / 291\n",
      "elapsed time 15858.382652759552\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9971\n",
      "batch loss: 0.0115988003090024\n",
      "batch accuracy: 0.9970703125\n",
      "doing 159 / 291\n",
      "elapsed time 15949.061506986618\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9990\n",
      "batch loss: 0.01411436591297388\n",
      "batch accuracy: 0.9990234375\n",
      "doing 160 / 291\n",
      "elapsed time 16036.64096403122\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9980\n",
      "batch loss: 0.00979185476899147\n",
      "batch accuracy: 0.998046875\n",
      "doing 161 / 291\n",
      "elapsed time 16120.020482301712\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 0.9961\n",
      "batch loss: 0.015604283660650253\n",
      "batch accuracy: 0.99609375\n",
      "doing 162 / 291\n",
      "elapsed time 16203.00365614891\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9990\n",
      "batch loss: 0.009254115633666515\n",
      "batch accuracy: 0.9990234375\n",
      "doing 163 / 291\n",
      "elapsed time 16287.33992099762\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9971\n",
      "batch loss: 0.012193489819765091\n",
      "batch accuracy: 0.9970703125\n",
      "doing 164 / 291\n",
      "elapsed time 16370.395390033722\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.9980\n",
      "batch loss: 0.0084847342222929\n",
      "batch accuracy: 0.998046875\n",
      "doing 165 / 291\n",
      "elapsed time 16452.732357501984\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9980\n",
      "batch loss: 0.008016642183065414\n",
      "batch accuracy: 0.998046875\n",
      "doing 166 / 291\n",
      "elapsed time 16538.396178007126\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 0.9971\n",
      "batch loss: 0.012312933802604675\n",
      "batch accuracy: 0.9970703125\n",
      "doing 167 / 291\n",
      "elapsed time 16627.226375102997\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9980\n",
      "batch loss: 0.008802996948361397\n",
      "batch accuracy: 0.998046875\n",
      "doing 168 / 291\n",
      "elapsed time 16720.1110599041\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "batch loss: 0.008854769170284271\n",
      "batch accuracy: 1.0\n",
      "doing 169 / 291\n",
      "elapsed time 16808.92971420288\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9980\n",
      "batch loss: 0.010889478027820587\n",
      "batch accuracy: 0.998046875\n",
      "doing 170 / 291\n",
      "elapsed time 16899.19707274437\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.9971\n",
      "batch loss: 0.013909980654716492\n",
      "batch accuracy: 0.9970703125\n",
      "doing 171 / 291\n",
      "elapsed time 16992.431708097458\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9971\n",
      "batch loss: 0.011682613752782345\n",
      "batch accuracy: 0.9970703125\n",
      "doing 172 / 291\n",
      "elapsed time 17085.498185634613\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9990\n",
      "batch loss: 0.010883267968893051\n",
      "batch accuracy: 0.9990234375\n",
      "doing 173 / 291\n",
      "elapsed time 17179.36278653145\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "batch loss: 0.010881692171096802\n",
      "batch accuracy: 1.0\n",
      "doing 174 / 291\n",
      "elapsed time 17270.257942914963\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9990\n",
      "batch loss: 0.009807873517274857\n",
      "batch accuracy: 0.9990234375\n",
      "doing 175 / 291\n",
      "elapsed time 17362.24835729599\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9971\n",
      "batch loss: 0.012219354510307312\n",
      "batch accuracy: 0.9970703125\n",
      "doing 176 / 291\n",
      "elapsed time 17453.69672012329\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 0.9941\n",
      "batch loss: 0.020634060725569725\n",
      "batch accuracy: 0.994140625\n",
      "doing 177 / 291\n",
      "elapsed time 17545.862872600555\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9980\n",
      "batch loss: 0.011856799013912678\n",
      "batch accuracy: 0.998046875\n",
      "doing 178 / 291\n",
      "elapsed time 17633.24710559845\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0093 - accuracy: 0.9990\n",
      "batch loss: 0.009336191229522228\n",
      "batch accuracy: 0.9990234375\n",
      "doing 179 / 291\n",
      "elapsed time 17723.269370794296\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9980\n",
      "batch loss: 0.009151463396847248\n",
      "batch accuracy: 0.998046875\n",
      "doing 180 / 291\n",
      "elapsed time 17813.2997944355\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9980\n",
      "batch loss: 0.0081352973356843\n",
      "batch accuracy: 0.998046875\n",
      "doing 181 / 291\n",
      "elapsed time 17902.92214202881\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9990\n",
      "batch loss: 0.008096639066934586\n",
      "batch accuracy: 0.9990234375\n",
      "doing 182 / 291\n",
      "elapsed time 17992.820637464523\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9971\n",
      "batch loss: 0.014339564368128777\n",
      "batch accuracy: 0.9970703125\n",
      "doing 183 / 291\n",
      "elapsed time 18086.160878181458\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9961\n",
      "batch loss: 0.014761624857783318\n",
      "batch accuracy: 0.99609375\n",
      "doing 184 / 291\n",
      "elapsed time 18176.703659296036\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "batch loss: 0.006445554085075855\n",
      "batch accuracy: 1.0\n",
      "doing 185 / 291\n",
      "elapsed time 18270.07636117935\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9980\n",
      "batch loss: 0.009948892518877983\n",
      "batch accuracy: 0.998046875\n",
      "doing 186 / 291\n",
      "elapsed time 18361.4339530468\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9990\n",
      "batch loss: 0.007749155163764954\n",
      "batch accuracy: 0.9990234375\n",
      "doing 187 / 291\n",
      "elapsed time 18451.388758659363\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9951\n",
      "batch loss: 0.021175125613808632\n",
      "batch accuracy: 0.9951171875\n",
      "doing 188 / 291\n",
      "elapsed time 18542.526151418686\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9990\n",
      "batch loss: 0.0085934242233634\n",
      "batch accuracy: 0.9990234375\n",
      "doing 189 / 291\n",
      "elapsed time 18635.457461118698\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9980\n",
      "batch loss: 0.011230620555579662\n",
      "batch accuracy: 0.998046875\n",
      "doing 190 / 291\n",
      "elapsed time 18725.96657347679\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9980\n",
      "batch loss: 0.01316453143954277\n",
      "batch accuracy: 0.998046875\n",
      "doing 191 / 291\n",
      "elapsed time 18816.065007209778\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9990\n",
      "batch loss: 0.010103048756718636\n",
      "batch accuracy: 0.9990234375\n",
      "doing 192 / 291\n",
      "elapsed time 18905.996878147125\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9990\n",
      "batch loss: 0.00838485173881054\n",
      "batch accuracy: 0.9990234375\n",
      "doing 193 / 291\n",
      "elapsed time 18997.37518620491\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9980\n",
      "batch loss: 0.011149263940751553\n",
      "batch accuracy: 0.998046875\n",
      "doing 194 / 291\n",
      "elapsed time 19090.139320850372\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0109 - accuracy: 0.9971\n",
      "batch loss: 0.01090310886502266\n",
      "batch accuracy: 0.9970703125\n",
      "doing 195 / 291\n",
      "elapsed time 19182.513071775436\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9990\n",
      "batch loss: 0.013101286254823208\n",
      "batch accuracy: 0.9990234375\n",
      "doing 196 / 291\n",
      "elapsed time 19272.998564720154\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9961\n",
      "batch loss: 0.013080781325697899\n",
      "batch accuracy: 0.99609375\n",
      "doing 197 / 291\n",
      "elapsed time 19361.960721731186\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9990\n",
      "batch loss: 0.010751735419034958\n",
      "batch accuracy: 0.9990234375\n",
      "doing 198 / 291\n",
      "elapsed time 19451.588077783585\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9980\n",
      "batch loss: 0.011166457086801529\n",
      "batch accuracy: 0.998046875\n",
      "doing 199 / 291\n",
      "elapsed time 19545.01367855072\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 0.9951\n",
      "batch loss: 0.01723172701895237\n",
      "batch accuracy: 0.9951171875\n",
      "doing 200 / 291\n",
      "elapsed time 19638.782559394836\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9961\n",
      "batch loss: 0.0124996118247509\n",
      "batch accuracy: 0.99609375\n",
      "doing 201 / 291\n",
      "elapsed time 19728.416571378708\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9990\n",
      "batch loss: 0.009890664368867874\n",
      "batch accuracy: 0.9990234375\n",
      "doing 202 / 291\n",
      "elapsed time 19814.975847244263\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9961\n",
      "batch loss: 0.013754022307693958\n",
      "batch accuracy: 0.99609375\n",
      "doing 203 / 291\n",
      "elapsed time 19905.374381303787\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9971\n",
      "batch loss: 0.01196360308676958\n",
      "batch accuracy: 0.9970703125\n",
      "doing 204 / 291\n",
      "elapsed time 20000.41046524048\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0170 - accuracy: 0.9941\n",
      "batch loss: 0.01702173240482807\n",
      "batch accuracy: 0.994140625\n",
      "doing 205 / 291\n",
      "elapsed time 20095.013238430023\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "batch loss: 0.0071836793795228004\n",
      "batch accuracy: 1.0\n",
      "doing 206 / 291\n",
      "elapsed time 20185.322500944138\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9980\n",
      "batch loss: 0.011130782775580883\n",
      "batch accuracy: 0.998046875\n",
      "doing 207 / 291\n",
      "elapsed time 20275.886499643326\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9990\n",
      "batch loss: 0.008455798029899597\n",
      "batch accuracy: 0.9990234375\n",
      "doing 208 / 291\n",
      "elapsed time 20367.601738214493\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "batch loss: 0.007542246021330357\n",
      "batch accuracy: 1.0\n",
      "doing 209 / 291\n",
      "elapsed time 20460.03547358513\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9980\n",
      "batch loss: 0.018246211111545563\n",
      "batch accuracy: 0.998046875\n",
      "doing 210 / 291\n",
      "elapsed time 20551.20774459839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0109 - accuracy: 0.9990\n",
      "batch loss: 0.010905619710683823\n",
      "batch accuracy: 0.9990234375\n",
      "doing 211 / 291\n",
      "elapsed time 20640.32648873329\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0152 - accuracy: 0.9961\n",
      "batch loss: 0.0151570625603199\n",
      "batch accuracy: 0.99609375\n",
      "doing 212 / 291\n",
      "elapsed time 20727.585088014603\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9980\n",
      "batch loss: 0.014572776854038239\n",
      "batch accuracy: 0.998046875\n",
      "doing 213 / 291\n",
      "elapsed time 20818.18301844597\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9980\n",
      "batch loss: 0.012539735063910484\n",
      "batch accuracy: 0.998046875\n",
      "doing 214 / 291\n",
      "elapsed time 20904.79783654213\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9971\n",
      "batch loss: 0.014098829589784145\n",
      "batch accuracy: 0.9970703125\n",
      "doing 215 / 291\n",
      "elapsed time 20991.661830425262\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9971\n",
      "batch loss: 0.014092890545725822\n",
      "batch accuracy: 0.9970703125\n",
      "doing 216 / 291\n",
      "elapsed time 21082.6532869339\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9990\n",
      "batch loss: 0.008382164873182774\n",
      "batch accuracy: 0.9990234375\n",
      "doing 217 / 291\n",
      "elapsed time 21175.911267757416\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9971\n",
      "batch loss: 0.010635335929691792\n",
      "batch accuracy: 0.9970703125\n",
      "doing 218 / 291\n",
      "elapsed time 21263.942969560623\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9961\n",
      "batch loss: 0.011475511826574802\n",
      "batch accuracy: 0.99609375\n",
      "doing 219 / 291\n",
      "elapsed time 21358.55750656128\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9961\n",
      "batch loss: 0.012161165475845337\n",
      "batch accuracy: 0.99609375\n",
      "doing 220 / 291\n",
      "elapsed time 21444.323027849197\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9980\n",
      "batch loss: 0.00994512066245079\n",
      "batch accuracy: 0.998046875\n",
      "doing 221 / 291\n",
      "elapsed time 21536.082062244415\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9971\n",
      "batch loss: 0.011438563466072083\n",
      "batch accuracy: 0.9970703125\n",
      "doing 222 / 291\n",
      "elapsed time 21627.999455451965\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9961\n",
      "batch loss: 0.010229045525193214\n",
      "batch accuracy: 0.99609375\n",
      "doing 223 / 291\n",
      "elapsed time 21715.688626289368\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9980\n",
      "batch loss: 0.008314374834299088\n",
      "batch accuracy: 0.998046875\n",
      "doing 224 / 291\n",
      "elapsed time 21807.42718577385\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9990\n",
      "batch loss: 0.009121921844780445\n",
      "batch accuracy: 0.9990234375\n",
      "doing 225 / 291\n",
      "elapsed time 21901.50855088234\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "batch loss: 0.0063836160115897655\n",
      "batch accuracy: 1.0\n",
      "doing 226 / 291\n",
      "elapsed time 21993.51423573494\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9990\n",
      "batch loss: 0.007993255741894245\n",
      "batch accuracy: 0.9990234375\n",
      "doing 227 / 291\n",
      "elapsed time 22083.14191508293\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "batch loss: 0.006977882236242294\n",
      "batch accuracy: 1.0\n",
      "doing 228 / 291\n",
      "elapsed time 22174.760783672333\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0148 - accuracy: 0.9961\n",
      "batch loss: 0.014796178787946701\n",
      "batch accuracy: 0.99609375\n",
      "doing 229 / 291\n",
      "elapsed time 22268.59501338005\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9971\n",
      "batch loss: 0.019123313948512077\n",
      "batch accuracy: 0.9970703125\n",
      "doing 230 / 291\n",
      "elapsed time 22362.57119202614\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9980\n",
      "batch loss: 0.009281499311327934\n",
      "batch accuracy: 0.998046875\n",
      "doing 231 / 291\n",
      "elapsed time 22453.248614788055\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9971\n",
      "batch loss: 0.01223064586520195\n",
      "batch accuracy: 0.9970703125\n",
      "doing 232 / 291\n",
      "elapsed time 22544.64816880226\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9971\n",
      "batch loss: 0.020989641547203064\n",
      "batch accuracy: 0.9970703125\n",
      "doing 233 / 291\n",
      "elapsed time 22640.09218096733\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9961\n",
      "batch loss: 0.01144570391625166\n",
      "batch accuracy: 0.99609375\n",
      "doing 234 / 291\n",
      "elapsed time 22732.973794460297\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9971\n",
      "batch loss: 0.01036128867417574\n",
      "batch accuracy: 0.9970703125\n",
      "doing 235 / 291\n",
      "elapsed time 22827.105938911438\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9990\n",
      "batch loss: 0.012261511757969856\n",
      "batch accuracy: 0.9990234375\n",
      "doing 236 / 291\n",
      "elapsed time 22919.408405065536\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9980\n",
      "batch loss: 0.010378830134868622\n",
      "batch accuracy: 0.998046875\n",
      "doing 237 / 291\n",
      "elapsed time 23013.13894557953\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9990\n",
      "batch loss: 0.012308696284890175\n",
      "batch accuracy: 0.9990234375\n",
      "doing 238 / 291\n",
      "elapsed time 23102.907833337784\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 0.9971\n",
      "batch loss: 0.022190142422914505\n",
      "batch accuracy: 0.9970703125\n",
      "doing 239 / 291\n",
      "elapsed time 23194.783754587173\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9951\n",
      "batch loss: 0.019075576215982437\n",
      "batch accuracy: 0.9951171875\n",
      "doing 240 / 291\n",
      "elapsed time 23287.26458477974\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 0.9980\n",
      "batch loss: 0.0090976906940341\n",
      "batch accuracy: 0.998046875\n",
      "doing 241 / 291\n",
      "elapsed time 23378.25469136238\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "batch loss: 0.007085807621479034\n",
      "batch accuracy: 1.0\n",
      "doing 242 / 291\n",
      "elapsed time 23473.31266951561\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9980\n",
      "batch loss: 0.011404203251004219\n",
      "batch accuracy: 0.998046875\n",
      "doing 243 / 291\n",
      "elapsed time 23562.771835565567\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9961\n",
      "batch loss: 0.015167783945798874\n",
      "batch accuracy: 0.99609375\n",
      "doing 244 / 291\n",
      "elapsed time 23656.863898277283\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9971\n",
      "batch loss: 0.018211789429187775\n",
      "batch accuracy: 0.9970703125\n",
      "doing 245 / 291\n",
      "elapsed time 23745.61037826538\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9971\n",
      "batch loss: 0.010189387015998363\n",
      "batch accuracy: 0.9970703125\n",
      "doing 246 / 291\n",
      "elapsed time 23838.44057226181\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9990\n",
      "batch loss: 0.007634239736944437\n",
      "batch accuracy: 0.9990234375\n",
      "doing 247 / 291\n",
      "elapsed time 23929.90914297104\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9990\n",
      "batch loss: 0.008133837953209877\n",
      "batch accuracy: 0.9990234375\n",
      "doing 248 / 291\n",
      "elapsed time 24019.053688764572\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9971\n",
      "batch loss: 0.012716569006443024\n",
      "batch accuracy: 0.9970703125\n",
      "doing 249 / 291\n",
      "elapsed time 24109.228331565857\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 0.9941\n",
      "batch loss: 0.02206128090620041\n",
      "batch accuracy: 0.994140625\n",
      "doing 250 / 291\n",
      "elapsed time 24203.987993001938\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9990\n",
      "batch loss: 0.008521484211087227\n",
      "batch accuracy: 0.9990234375\n",
      "doing 251 / 291\n",
      "elapsed time 24296.724089622498\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9990\n",
      "batch loss: 0.008761185221374035\n",
      "batch accuracy: 0.9990234375\n",
      "doing 252 / 291\n",
      "elapsed time 24389.844351291656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.9961\n",
      "batch loss: 0.01821225881576538\n",
      "batch accuracy: 0.99609375\n",
      "doing 253 / 291\n",
      "elapsed time 24485.4326338768\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9961\n",
      "batch loss: 0.015168262645602226\n",
      "batch accuracy: 0.99609375\n",
      "doing 254 / 291\n",
      "elapsed time 24577.83527779579\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9980\n",
      "batch loss: 0.010589074343442917\n",
      "batch accuracy: 0.998046875\n",
      "doing 255 / 291\n",
      "elapsed time 24669.73304915428\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.9932\n",
      "batch loss: 0.01750069111585617\n",
      "batch accuracy: 0.9931640625\n",
      "doing 256 / 291\n",
      "elapsed time 24759.027610063553\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9980\n",
      "batch loss: 0.00920011755079031\n",
      "batch accuracy: 0.998046875\n",
      "doing 257 / 291\n",
      "elapsed time 24852.35159420967\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9980\n",
      "batch loss: 0.010504106990993023\n",
      "batch accuracy: 0.998046875\n",
      "doing 258 / 291\n",
      "elapsed time 24946.045949697495\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9990\n",
      "batch loss: 0.007316102739423513\n",
      "batch accuracy: 0.9990234375\n",
      "doing 259 / 291\n",
      "elapsed time 25037.369663476944\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9990\n",
      "batch loss: 0.008381431922316551\n",
      "batch accuracy: 0.9990234375\n",
      "doing 260 / 291\n",
      "elapsed time 25132.458594083786\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9961\n",
      "batch loss: 0.015458093024790287\n",
      "batch accuracy: 0.99609375\n",
      "doing 261 / 291\n",
      "elapsed time 25221.151752233505\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "batch loss: 0.008234361186623573\n",
      "batch accuracy: 1.0\n",
      "doing 262 / 291\n",
      "elapsed time 25313.199308872223\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9980\n",
      "batch loss: 0.010609293356537819\n",
      "batch accuracy: 0.998046875\n",
      "doing 263 / 291\n",
      "elapsed time 25402.847013950348\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9961\n",
      "batch loss: 0.013073996640741825\n",
      "batch accuracy: 0.99609375\n",
      "doing 264 / 291\n",
      "elapsed time 25494.534168958664\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9980\n",
      "batch loss: 0.012518385425209999\n",
      "batch accuracy: 0.998046875\n",
      "doing 265 / 291\n",
      "elapsed time 25585.55494403839\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9990\n",
      "batch loss: 0.007747347000986338\n",
      "batch accuracy: 0.9990234375\n",
      "doing 266 / 291\n",
      "elapsed time 25679.750108242035\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 0.9941\n",
      "batch loss: 0.017126109451055527\n",
      "batch accuracy: 0.994140625\n",
      "doing 267 / 291\n",
      "elapsed time 25775.56697320938\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "batch loss: 0.010996661148965359\n",
      "batch accuracy: 1.0\n",
      "doing 268 / 291\n",
      "elapsed time 25874.579975128174\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0130 - accuracy: 0.9961\n",
      "batch loss: 0.012950338423252106\n",
      "batch accuracy: 0.99609375\n",
      "doing 269 / 291\n",
      "elapsed time 25966.863193511963\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0197 - accuracy: 0.9951\n",
      "batch loss: 0.01966366544365883\n",
      "batch accuracy: 0.9951171875\n",
      "doing 270 / 291\n",
      "elapsed time 26060.011034965515\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9971\n",
      "batch loss: 0.010118317790329456\n",
      "batch accuracy: 0.9970703125\n",
      "doing 271 / 291\n",
      "elapsed time 26152.533046483994\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9941\n",
      "batch loss: 0.01665838249027729\n",
      "batch accuracy: 0.994140625\n",
      "doing 272 / 291\n",
      "elapsed time 26243.67770266533\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9971\n",
      "batch loss: 0.018854521214962006\n",
      "batch accuracy: 0.9970703125\n",
      "doing 273 / 291\n",
      "elapsed time 26337.48057627678\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "batch loss: 0.0062155090272426605\n",
      "batch accuracy: 1.0\n",
      "doing 274 / 291\n",
      "elapsed time 26429.420616149902\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "batch loss: 0.005567600019276142\n",
      "batch accuracy: 1.0\n",
      "doing 275 / 291\n",
      "elapsed time 26521.0068295002\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9990\n",
      "batch loss: 0.006733119487762451\n",
      "batch accuracy: 0.9990234375\n",
      "doing 276 / 291\n",
      "elapsed time 26614.75200009346\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9990\n",
      "batch loss: 0.006330485921353102\n",
      "batch accuracy: 0.9990234375\n",
      "doing 277 / 291\n",
      "elapsed time 26707.37281394005\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9980\n",
      "batch loss: 0.01022508554160595\n",
      "batch accuracy: 0.998046875\n",
      "doing 278 / 291\n",
      "elapsed time 26799.159949064255\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.9980\n",
      "batch loss: 0.010424011386930943\n",
      "batch accuracy: 0.998046875\n",
      "doing 279 / 291\n",
      "elapsed time 26894.49222636223\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 0.9971\n",
      "batch loss: 0.010023778304457664\n",
      "batch accuracy: 0.9970703125\n",
      "doing 280 / 291\n",
      "elapsed time 26980.84711623192\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "batch loss: 0.00706854835152626\n",
      "batch accuracy: 1.0\n",
      "doing 281 / 291\n",
      "elapsed time 27078.233914375305\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9971\n",
      "batch loss: 0.013263468630611897\n",
      "batch accuracy: 0.9970703125\n",
      "doing 282 / 291\n",
      "elapsed time 27170.871048927307\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9990\n",
      "batch loss: 0.008080210536718369\n",
      "batch accuracy: 0.9990234375\n",
      "doing 283 / 291\n",
      "elapsed time 27265.278374433517\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9990\n",
      "batch loss: 0.008142628706991673\n",
      "batch accuracy: 0.9990234375\n",
      "doing 284 / 291\n",
      "elapsed time 27355.927647590637\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9971\n",
      "batch loss: 0.0095797348767519\n",
      "batch accuracy: 0.9970703125\n",
      "doing 285 / 291\n",
      "elapsed time 27445.714123010635\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "batch loss: 0.008431203663349152\n",
      "batch accuracy: 1.0\n",
      "doing 286 / 291\n",
      "elapsed time 27541.838259220123\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9980\n",
      "batch loss: 0.014699002727866173\n",
      "batch accuracy: 0.998046875\n",
      "doing 287 / 291\n",
      "elapsed time 27634.065222501755\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9961\n",
      "batch loss: 0.015825867652893066\n",
      "batch accuracy: 0.99609375\n",
      "doing 288 / 291\n",
      "elapsed time 27725.518990039825\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9990\n",
      "batch loss: 0.011753044091165066\n",
      "batch accuracy: 0.9990234375\n",
      "doing 289 / 291\n",
      "elapsed time 27818.25273489952\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9990\n",
      "batch loss: 0.008185995742678642\n",
      "batch accuracy: 0.9990234375\n",
      "doing 290 / 291\n",
      "elapsed time 27822.916196346283\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "batch loss: 0.002095538889989257\n",
      "batch accuracy: 1.0\n",
      "Train loss 0.012792741258139001\n",
      "Train accuracy 0.9976710158934707\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4544 - accuracy: 0.9224\n",
      "Validation loss: 0.4544168710708618\n",
      "Validation accuracy: 0.9224444627761841\n",
      "==================================================\n",
      "1 / 5\n",
      "doing 0 / 291\n",
      "elapsed time 64.13805508613586\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "batch loss: 0.0063099912367761135\n",
      "batch accuracy: 1.0\n",
      "doing 1 / 291\n",
      "elapsed time 127.95162653923035\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9980\n",
      "batch loss: 0.00818830356001854\n",
      "batch accuracy: 0.998046875\n",
      "doing 2 / 291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 194.68538975715637\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9990\n",
      "batch loss: 0.006292153149843216\n",
      "batch accuracy: 0.9990234375\n",
      "doing 3 / 291\n",
      "elapsed time 258.63696098327637\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "batch loss: 0.006446056067943573\n",
      "batch accuracy: 1.0\n",
      "doing 4 / 291\n",
      "elapsed time 327.39063334465027\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "batch loss: 0.007027476094663143\n",
      "batch accuracy: 1.0\n",
      "doing 5 / 291\n",
      "elapsed time 394.9944121837616\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "batch loss: 0.00549865560606122\n",
      "batch accuracy: 1.0\n",
      "doing 6 / 291\n",
      "elapsed time 463.02724719047546\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "batch loss: 0.005493678152561188\n",
      "batch accuracy: 1.0\n",
      "doing 7 / 291\n",
      "elapsed time 532.3282375335693\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 0.9980\n",
      "batch loss: 0.009139345958828926\n",
      "batch accuracy: 0.998046875\n",
      "doing 8 / 291\n",
      "elapsed time 598.8146634101868\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "batch loss: 0.006086114794015884\n",
      "batch accuracy: 1.0\n",
      "doing 9 / 291\n",
      "elapsed time 663.425256729126\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "batch loss: 0.006493588909506798\n",
      "batch accuracy: 1.0\n",
      "doing 10 / 291\n",
      "elapsed time 728.8620297908783\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "batch loss: 0.00651998445391655\n",
      "batch accuracy: 1.0\n",
      "doing 11 / 291\n",
      "elapsed time 796.3750538825989\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "batch loss: 0.004951547831296921\n",
      "batch accuracy: 1.0\n",
      "doing 12 / 291\n",
      "elapsed time 861.4733791351318\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9990\n",
      "batch loss: 0.007429611403495073\n",
      "batch accuracy: 0.9990234375\n",
      "doing 13 / 291\n",
      "elapsed time 929.9459836483002\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "batch loss: 0.007332243956625462\n",
      "batch accuracy: 1.0\n",
      "doing 14 / 291\n",
      "elapsed time 992.8579931259155\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9990\n",
      "batch loss: 0.006699051707983017\n",
      "batch accuracy: 0.9990234375\n",
      "doing 15 / 291\n",
      "elapsed time 1060.6039662361145\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 0.9990\n",
      "batch loss: 0.0061883023008704185\n",
      "batch accuracy: 0.9990234375\n",
      "doing 16 / 291\n",
      "elapsed time 1128.561429977417\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9990\n",
      "batch loss: 0.00650748098269105\n",
      "batch accuracy: 0.9990234375\n",
      "doing 17 / 291\n",
      "elapsed time 1199.0226347446442\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 0.9990\n",
      "batch loss: 0.006979493424296379\n",
      "batch accuracy: 0.9990234375\n",
      "doing 18 / 291\n",
      "elapsed time 1264.606366634369\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "batch loss: 0.005090789869427681\n",
      "batch accuracy: 1.0\n",
      "doing 19 / 291\n",
      "elapsed time 1327.4405624866486\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9990\n",
      "batch loss: 0.007324513979256153\n",
      "batch accuracy: 0.9990234375\n",
      "doing 20 / 291\n",
      "elapsed time 1394.8979260921478\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9990\n",
      "batch loss: 0.004491707310080528\n",
      "batch accuracy: 0.9990234375\n",
      "doing 21 / 291\n",
      "elapsed time 1463.5108177661896\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9980\n",
      "batch loss: 0.008465300314128399\n",
      "batch accuracy: 0.998046875\n",
      "doing 22 / 291\n",
      "elapsed time 1529.1518547534943\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "batch loss: 0.0041435351595282555\n",
      "batch accuracy: 1.0\n",
      "doing 23 / 291\n",
      "elapsed time 1595.1758916378021\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9990\n",
      "batch loss: 0.0080767422914505\n",
      "batch accuracy: 0.9990234375\n",
      "doing 24 / 291\n",
      "elapsed time 1658.9647488594055\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9980\n",
      "batch loss: 0.013606695458292961\n",
      "batch accuracy: 0.998046875\n",
      "doing 25 / 291\n",
      "elapsed time 1725.0466661453247\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9990\n",
      "batch loss: 0.006318041123449802\n",
      "batch accuracy: 0.9990234375\n",
      "doing 26 / 291\n",
      "elapsed time 1787.9831581115723\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "batch loss: 0.004443730227649212\n",
      "batch accuracy: 1.0\n",
      "doing 27 / 291\n",
      "elapsed time 1855.2756736278534\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9990\n",
      "batch loss: 0.004664496518671513\n",
      "batch accuracy: 0.9990234375\n",
      "doing 28 / 291\n",
      "elapsed time 1916.5183551311493\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9980\n",
      "batch loss: 0.0072888461872935295\n",
      "batch accuracy: 0.998046875\n",
      "doing 29 / 291\n",
      "elapsed time 1983.3594267368317\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "batch loss: 0.004750968888401985\n",
      "batch accuracy: 1.0\n",
      "doing 30 / 291\n",
      "elapsed time 2051.352269887924\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "batch loss: 0.004796531982719898\n",
      "batch accuracy: 1.0\n",
      "doing 31 / 291\n",
      "elapsed time 2123.3939237594604\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9971\n",
      "batch loss: 0.009397009387612343\n",
      "batch accuracy: 0.9970703125\n",
      "doing 32 / 291\n",
      "elapsed time 2194.9950597286224\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9980\n",
      "batch loss: 0.009894631803035736\n",
      "batch accuracy: 0.998046875\n",
      "doing 33 / 291\n",
      "elapsed time 2260.181544780731\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.9990\n",
      "batch loss: 0.005799997132271528\n",
      "batch accuracy: 0.9990234375\n",
      "doing 34 / 291\n",
      "elapsed time 2323.6229870319366\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.9990\n",
      "batch loss: 0.004677006509155035\n",
      "batch accuracy: 0.9990234375\n",
      "doing 35 / 291\n",
      "elapsed time 2388.0303251743317\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9980\n",
      "batch loss: 0.011517323553562164\n",
      "batch accuracy: 0.998046875\n",
      "doing 36 / 291\n",
      "elapsed time 2456.560900449753\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9990\n",
      "batch loss: 0.005429770797491074\n",
      "batch accuracy: 0.9990234375\n",
      "doing 37 / 291\n",
      "elapsed time 2524.45707654953\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "batch loss: 0.004639590624719858\n",
      "batch accuracy: 1.0\n",
      "doing 38 / 291\n",
      "elapsed time 2602.2477102279663\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "batch loss: 0.004776839166879654\n",
      "batch accuracy: 1.0\n",
      "doing 39 / 291\n",
      "elapsed time 2687.613948583603\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9990\n",
      "batch loss: 0.005841518752276897\n",
      "batch accuracy: 0.9990234375\n",
      "doing 40 / 291\n",
      "elapsed time 2771.067633152008\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9990\n",
      "batch loss: 0.007649241015315056\n",
      "batch accuracy: 0.9990234375\n",
      "doing 41 / 291\n",
      "elapsed time 2861.147274494171\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9990\n",
      "batch loss: 0.007071956060826778\n",
      "batch accuracy: 0.9990234375\n",
      "doing 42 / 291\n",
      "elapsed time 2948.8129839897156\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9990\n",
      "batch loss: 0.006828870624303818\n",
      "batch accuracy: 0.9990234375\n",
      "doing 43 / 291\n",
      "elapsed time 3032.761472940445\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9990\n",
      "batch loss: 0.007211464922875166\n",
      "batch accuracy: 0.9990234375\n",
      "doing 44 / 291\n",
      "elapsed time 3120.532385826111\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9990\n",
      "batch loss: 0.008435040712356567\n",
      "batch accuracy: 0.9990234375\n",
      "doing 45 / 291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 3210.7139644622803\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9971\n",
      "batch loss: 0.007328297942876816\n",
      "batch accuracy: 0.9970703125\n",
      "doing 46 / 291\n",
      "elapsed time 3298.7983679771423\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9990\n",
      "batch loss: 0.009444333612918854\n",
      "batch accuracy: 0.9990234375\n",
      "doing 47 / 291\n",
      "elapsed time 3383.979659318924\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9990\n",
      "batch loss: 0.005225994624197483\n",
      "batch accuracy: 0.9990234375\n",
      "doing 48 / 291\n",
      "elapsed time 3471.9621617794037\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9990\n",
      "batch loss: 0.006164433900266886\n",
      "batch accuracy: 0.9990234375\n",
      "doing 49 / 291\n",
      "elapsed time 3560.7963304519653\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9990\n",
      "batch loss: 0.006683727726340294\n",
      "batch accuracy: 0.9990234375\n",
      "doing 50 / 291\n",
      "elapsed time 3646.754467487335\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 0.9980\n",
      "batch loss: 0.005997348576784134\n",
      "batch accuracy: 0.998046875\n",
      "doing 51 / 291\n",
      "elapsed time 3734.8837299346924\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.9990\n",
      "batch loss: 0.004968700464814901\n",
      "batch accuracy: 0.9990234375\n",
      "doing 52 / 291\n",
      "elapsed time 3822.384626150131\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9990\n",
      "batch loss: 0.014105971902608871\n",
      "batch accuracy: 0.9990234375\n",
      "doing 53 / 291\n",
      "elapsed time 3905.593073606491\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9980\n",
      "batch loss: 0.007799216546118259\n",
      "batch accuracy: 0.998046875\n",
      "doing 54 / 291\n",
      "elapsed time 3990.5342688560486\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9980\n",
      "batch loss: 0.008418816141784191\n",
      "batch accuracy: 0.998046875\n",
      "doing 55 / 291\n",
      "elapsed time 4076.643628358841\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "batch loss: 0.006392659619450569\n",
      "batch accuracy: 1.0\n",
      "doing 56 / 291\n",
      "elapsed time 4154.781962156296\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "batch loss: 0.005531487986445427\n",
      "batch accuracy: 1.0\n",
      "doing 57 / 291\n",
      "elapsed time 4247.300656795502\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 0.9980\n",
      "batch loss: 0.007165077142417431\n",
      "batch accuracy: 0.998046875\n",
      "doing 58 / 291\n",
      "elapsed time 4343.97886633873\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 0.9990\n",
      "batch loss: 0.006925418972969055\n",
      "batch accuracy: 0.9990234375\n",
      "doing 59 / 291\n",
      "elapsed time 4436.010712623596\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9990\n",
      "batch loss: 0.00924664456397295\n",
      "batch accuracy: 0.9990234375\n",
      "doing 60 / 291\n",
      "elapsed time 4525.699254989624\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "batch loss: 0.006015919614583254\n",
      "batch accuracy: 1.0\n",
      "doing 61 / 291\n",
      "elapsed time 4623.514892101288\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.9990\n",
      "batch loss: 0.007500024046748877\n",
      "batch accuracy: 0.9990234375\n",
      "doing 62 / 291\n",
      "elapsed time 4717.1313853263855\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "batch loss: 0.005591933615505695\n",
      "batch accuracy: 1.0\n",
      "doing 63 / 291\n",
      "elapsed time 4814.976226568222\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "batch loss: 0.00429945532232523\n",
      "batch accuracy: 1.0\n",
      "doing 64 / 291\n",
      "elapsed time 4909.001753568649\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9990\n",
      "batch loss: 0.0068593984469771385\n",
      "batch accuracy: 0.9990234375\n",
      "doing 65 / 291\n",
      "elapsed time 4999.7180190086365\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 0.9990\n",
      "batch loss: 0.007718428038060665\n",
      "batch accuracy: 0.9990234375\n",
      "doing 66 / 291\n",
      "elapsed time 5097.290303945541\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9980\n",
      "batch loss: 0.00824219174683094\n",
      "batch accuracy: 0.998046875\n",
      "doing 67 / 291\n",
      "elapsed time 5198.921739578247\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9990\n",
      "batch loss: 0.005513183772563934\n",
      "batch accuracy: 0.9990234375\n",
      "doing 68 / 291\n",
      "elapsed time 5293.184002876282\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "batch loss: 0.0036021070554852486\n",
      "batch accuracy: 1.0\n",
      "doing 69 / 291\n",
      "elapsed time 5389.888242721558\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9971\n",
      "batch loss: 0.0145082026720047\n",
      "batch accuracy: 0.9970703125\n",
      "doing 70 / 291\n",
      "elapsed time 5488.930225610733\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9980\n",
      "batch loss: 0.00838384684175253\n",
      "batch accuracy: 0.998046875\n",
      "doing 71 / 291\n",
      "elapsed time 5585.064986467361\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9990\n",
      "batch loss: 0.007041459903120995\n",
      "batch accuracy: 0.9990234375\n",
      "doing 72 / 291\n",
      "elapsed time 5685.826506137848\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "batch loss: 0.006043347530066967\n",
      "batch accuracy: 1.0\n",
      "doing 73 / 291\n",
      "elapsed time 5781.835369110107\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "batch loss: 0.006487993989139795\n",
      "batch accuracy: 1.0\n",
      "doing 74 / 291\n",
      "elapsed time 5879.089354991913\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9971\n",
      "batch loss: 0.008235135115683079\n",
      "batch accuracy: 0.9970703125\n",
      "doing 75 / 291\n",
      "elapsed time 5978.20979142189\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9990\n",
      "batch loss: 0.00853239931166172\n",
      "batch accuracy: 0.9990234375\n",
      "doing 76 / 291\n",
      "elapsed time 6076.251205205917\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "batch loss: 0.006154689937829971\n",
      "batch accuracy: 1.0\n",
      "doing 77 / 291\n",
      "elapsed time 6178.24252986908\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "batch loss: 0.004753823857754469\n",
      "batch accuracy: 1.0\n",
      "doing 78 / 291\n",
      "elapsed time 6280.809982776642\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9980\n",
      "batch loss: 0.009804747998714447\n",
      "batch accuracy: 0.998046875\n",
      "doing 79 / 291\n",
      "elapsed time 6380.278456449509\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 0.9990\n",
      "batch loss: 0.004586515948176384\n",
      "batch accuracy: 0.9990234375\n",
      "doing 80 / 291\n",
      "elapsed time 6475.727902412415\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9990\n",
      "batch loss: 0.004980265162885189\n",
      "batch accuracy: 0.9990234375\n",
      "doing 81 / 291\n",
      "elapsed time 6574.215314149857\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9980\n",
      "batch loss: 0.008162442594766617\n",
      "batch accuracy: 0.998046875\n",
      "doing 82 / 291\n",
      "elapsed time 6677.425990343094\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "batch loss: 0.0060084424912929535\n",
      "batch accuracy: 1.0\n",
      "doing 83 / 291\n",
      "elapsed time 6782.407938718796\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "batch loss: 0.004553166218101978\n",
      "batch accuracy: 1.0\n",
      "doing 84 / 291\n",
      "elapsed time 6882.672167539597\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9990\n",
      "batch loss: 0.004989024251699448\n",
      "batch accuracy: 0.9990234375\n",
      "doing 85 / 291\n",
      "elapsed time 6976.884163379669\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9980\n",
      "batch loss: 0.009398862719535828\n",
      "batch accuracy: 0.998046875\n",
      "doing 86 / 291\n",
      "elapsed time 7081.556227445602\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9980\n",
      "batch loss: 0.00881241075694561\n",
      "batch accuracy: 0.998046875\n",
      "doing 87 / 291\n",
      "elapsed time 7188.993668079376\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 0.9980\n",
      "batch loss: 0.007701120339334011\n",
      "batch accuracy: 0.998046875\n",
      "doing 88 / 291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 7283.957921504974\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 0.9990\n",
      "batch loss: 0.006010449957102537\n",
      "batch accuracy: 0.9990234375\n",
      "doing 89 / 291\n",
      "elapsed time 7387.957194805145\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 0.9990\n",
      "batch loss: 0.0044528101570904255\n",
      "batch accuracy: 0.9990234375\n",
      "doing 90 / 291\n",
      "elapsed time 7485.16442322731\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9980\n",
      "batch loss: 0.011013706214725971\n",
      "batch accuracy: 0.998046875\n",
      "doing 91 / 291\n",
      "elapsed time 7588.863197803497\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9990\n",
      "batch loss: 0.006283254828304052\n",
      "batch accuracy: 0.9990234375\n",
      "doing 92 / 291\n",
      "elapsed time 7691.5716671943665\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9990\n",
      "batch loss: 0.009538100101053715\n",
      "batch accuracy: 0.9990234375\n",
      "doing 93 / 291\n",
      "elapsed time 7787.853270292282\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9990\n",
      "batch loss: 0.005268748849630356\n",
      "batch accuracy: 0.9990234375\n",
      "doing 94 / 291\n",
      "elapsed time 7890.206085205078\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9990\n",
      "batch loss: 0.005506082903593779\n",
      "batch accuracy: 0.9990234375\n",
      "doing 95 / 291\n",
      "elapsed time 7996.180508613586\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "batch loss: 0.005005526356399059\n",
      "batch accuracy: 1.0\n",
      "doing 96 / 291\n",
      "elapsed time 8098.944699048996\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9990\n",
      "batch loss: 0.0070883650332689285\n",
      "batch accuracy: 0.9990234375\n",
      "doing 97 / 291\n",
      "elapsed time 8200.524561405182\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "batch loss: 0.005186785943806171\n",
      "batch accuracy: 1.0\n",
      "doing 98 / 291\n",
      "elapsed time 8281.757537841797\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "batch loss: 0.005882915109395981\n",
      "batch accuracy: 0.9990234375\n",
      "doing 99 / 291\n",
      "elapsed time 8356.825973510742\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "batch loss: 0.005877100396901369\n",
      "batch accuracy: 0.9990234375\n",
      "doing 100 / 291\n",
      "elapsed time 8429.983323574066\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "batch loss: 0.004971684422343969\n",
      "batch accuracy: 1.0\n",
      "doing 101 / 291\n",
      "elapsed time 8503.469877958298\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "batch loss: 0.006682971958070993\n",
      "batch accuracy: 1.0\n",
      "doing 102 / 291\n",
      "elapsed time 8579.400043010712\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 0.9990\n",
      "batch loss: 0.005684409290552139\n",
      "batch accuracy: 0.9990234375\n",
      "doing 103 / 291\n",
      "elapsed time 8652.412442207336\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 0.9980\n",
      "batch loss: 0.007641993463039398\n",
      "batch accuracy: 0.998046875\n",
      "doing 104 / 291\n",
      "elapsed time 8723.940419197083\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "batch loss: 0.005864114034920931\n",
      "batch accuracy: 0.9990234375\n",
      "doing 105 / 291\n",
      "elapsed time 8794.734257221222\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "batch loss: 0.006145022809505463\n",
      "batch accuracy: 0.998046875\n",
      "doing 106 / 291\n",
      "elapsed time 8867.453645467758\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9971\n",
      "batch loss: 0.010325747542083263\n",
      "batch accuracy: 0.9970703125\n",
      "doing 107 / 291\n",
      "elapsed time 8940.615817785263\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "batch loss: 0.006730344146490097\n",
      "batch accuracy: 1.0\n",
      "doing 108 / 291\n",
      "elapsed time 9012.463453054428\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9980\n",
      "batch loss: 0.010372450575232506\n",
      "batch accuracy: 0.998046875\n",
      "doing 109 / 291\n",
      "elapsed time 9087.205868005753\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "batch loss: 0.004364466294646263\n",
      "batch accuracy: 1.0\n",
      "doing 110 / 291\n",
      "elapsed time 9159.150347471237\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9990\n",
      "batch loss: 0.006259920075535774\n",
      "batch accuracy: 0.9990234375\n",
      "doing 111 / 291\n",
      "elapsed time 9233.296563386917\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9990\n",
      "batch loss: 0.0053109414875507355\n",
      "batch accuracy: 0.9990234375\n",
      "doing 112 / 291\n",
      "elapsed time 9306.484110355377\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "batch loss: 0.005219781305640936\n",
      "batch accuracy: 1.0\n",
      "doing 113 / 291\n",
      "elapsed time 9377.959721803665\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "batch loss: 0.006892940495163202\n",
      "batch accuracy: 1.0\n",
      "doing 114 / 291\n",
      "elapsed time 9449.785129070282\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.9990\n",
      "batch loss: 0.007406191434711218\n",
      "batch accuracy: 0.9990234375\n",
      "doing 115 / 291\n",
      "elapsed time 9525.32087278366\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9990\n",
      "batch loss: 0.004197617061436176\n",
      "batch accuracy: 0.9990234375\n",
      "doing 116 / 291\n",
      "elapsed time 9599.763772249222\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "batch loss: 0.005982410162687302\n",
      "batch accuracy: 1.0\n",
      "doing 117 / 291\n",
      "elapsed time 9677.03255200386\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9971\n",
      "batch loss: 0.011721942573785782\n",
      "batch accuracy: 0.9970703125\n",
      "doing 118 / 291\n",
      "elapsed time 9753.988815546036\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9980\n",
      "batch loss: 0.006983304396271706\n",
      "batch accuracy: 0.998046875\n",
      "doing 119 / 291\n",
      "elapsed time 9829.43383026123\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9990\n",
      "batch loss: 0.005398389883339405\n",
      "batch accuracy: 0.9990234375\n",
      "doing 120 / 291\n",
      "elapsed time 9903.343187093735\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "batch loss: 0.006130803842097521\n",
      "batch accuracy: 0.998046875\n",
      "doing 121 / 291\n",
      "elapsed time 9982.803325891495\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9971\n",
      "batch loss: 0.01065905299037695\n",
      "batch accuracy: 0.9970703125\n",
      "doing 122 / 291\n",
      "elapsed time 10060.552836179733\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 0.9980\n",
      "batch loss: 0.006781310308724642\n",
      "batch accuracy: 0.998046875\n",
      "doing 123 / 291\n",
      "elapsed time 10136.24685883522\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9990\n",
      "batch loss: 0.01486365869641304\n",
      "batch accuracy: 0.9990234375\n",
      "doing 124 / 291\n",
      "elapsed time 10211.531033754349\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9971\n",
      "batch loss: 0.008406421169638634\n",
      "batch accuracy: 0.9970703125\n",
      "doing 125 / 291\n",
      "elapsed time 10285.464963436127\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9990\n",
      "batch loss: 0.007506112102419138\n",
      "batch accuracy: 0.9990234375\n",
      "doing 126 / 291\n",
      "elapsed time 10360.185559511185\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9971\n",
      "batch loss: 0.010317990556359291\n",
      "batch accuracy: 0.9970703125\n",
      "doing 127 / 291\n",
      "elapsed time 10437.208795547485\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9961\n",
      "batch loss: 0.019845297560095787\n",
      "batch accuracy: 0.99609375\n",
      "doing 128 / 291\n",
      "elapsed time 10514.413367986679\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0133 - accuracy: 0.9980\n",
      "batch loss: 0.013328922912478447\n",
      "batch accuracy: 0.998046875\n",
      "doing 129 / 291\n",
      "elapsed time 10592.766141176224\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 0.9980\n",
      "batch loss: 0.019803009927272797\n",
      "batch accuracy: 0.998046875\n",
      "doing 130 / 291\n",
      "elapsed time 10669.844357013702\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "batch loss: 0.007198648527264595\n",
      "batch accuracy: 1.0\n",
      "doing 131 / 291\n",
      "elapsed time 10746.45418548584\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0124 - accuracy: 0.9980\n",
      "batch loss: 0.01235424354672432\n",
      "batch accuracy: 0.998046875\n",
      "doing 132 / 291\n",
      "elapsed time 10825.7507417202\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0201 - accuracy: 0.9980\n",
      "batch loss: 0.020107578486204147\n",
      "batch accuracy: 0.998046875\n",
      "doing 133 / 291\n",
      "elapsed time 10902.514955997467\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9980\n",
      "batch loss: 0.011390716768801212\n",
      "batch accuracy: 0.998046875\n",
      "doing 134 / 291\n",
      "elapsed time 10978.667158842087\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0153 - accuracy: 0.9971\n",
      "batch loss: 0.015257487073540688\n",
      "batch accuracy: 0.9970703125\n",
      "doing 135 / 291\n",
      "elapsed time 11056.635699748993\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "batch loss: 0.01080829743295908\n",
      "batch accuracy: 1.0\n",
      "doing 136 / 291\n",
      "elapsed time 11131.123301744461\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9990\n",
      "batch loss: 0.010319942608475685\n",
      "batch accuracy: 0.9990234375\n",
      "doing 137 / 291\n",
      "elapsed time 11208.052110671997\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "batch loss: 0.0042975726537406445\n",
      "batch accuracy: 1.0\n",
      "doing 138 / 291\n",
      "elapsed time 11286.768405914307\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9990\n",
      "batch loss: 0.0071172695606946945\n",
      "batch accuracy: 0.9990234375\n",
      "doing 139 / 291\n",
      "elapsed time 11363.799845218658\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9980\n",
      "batch loss: 0.010893336497247219\n",
      "batch accuracy: 0.998046875\n",
      "doing 140 / 291\n",
      "elapsed time 11442.478487730026\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9990\n",
      "batch loss: 0.010597174987196922\n",
      "batch accuracy: 0.9990234375\n",
      "doing 141 / 291\n",
      "elapsed time 11519.090414524078\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 0.9990\n",
      "batch loss: 0.007104901131242514\n",
      "batch accuracy: 0.9990234375\n",
      "doing 142 / 291\n",
      "elapsed time 11596.459374427795\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9980\n",
      "batch loss: 0.009640033356845379\n",
      "batch accuracy: 0.998046875\n",
      "doing 143 / 291\n",
      "elapsed time 11673.707080364227\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9980\n",
      "batch loss: 0.006827876903116703\n",
      "batch accuracy: 0.998046875\n",
      "doing 144 / 291\n",
      "elapsed time 11752.535445451736\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9980\n",
      "batch loss: 0.011818458326160908\n",
      "batch accuracy: 0.998046875\n",
      "doing 145 / 291\n",
      "elapsed time 11830.626022338867\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9990\n",
      "batch loss: 0.00838560052216053\n",
      "batch accuracy: 0.9990234375\n",
      "doing 146 / 291\n",
      "elapsed time 11906.730401039124\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9990\n",
      "batch loss: 0.008664553984999657\n",
      "batch accuracy: 0.9990234375\n",
      "doing 147 / 291\n",
      "elapsed time 11985.710688591003\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9971\n",
      "batch loss: 0.012586764991283417\n",
      "batch accuracy: 0.9970703125\n",
      "doing 148 / 291\n",
      "elapsed time 12063.46438217163\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9980\n",
      "batch loss: 0.011583404615521431\n",
      "batch accuracy: 0.998046875\n",
      "doing 149 / 291\n",
      "elapsed time 12140.583586931229\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9990\n",
      "batch loss: 0.008547433651983738\n",
      "batch accuracy: 0.9990234375\n",
      "doing 150 / 291\n",
      "elapsed time 12219.588511228561\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9980\n",
      "batch loss: 0.010143324732780457\n",
      "batch accuracy: 0.998046875\n",
      "doing 151 / 291\n",
      "elapsed time 12296.58525967598\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9990\n",
      "batch loss: 0.00661160983145237\n",
      "batch accuracy: 0.9990234375\n",
      "doing 152 / 291\n",
      "elapsed time 12375.715238332748\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "batch loss: 0.005384563468396664\n",
      "batch accuracy: 1.0\n",
      "doing 153 / 291\n",
      "elapsed time 12450.986137866974\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9990\n",
      "batch loss: 0.011244643479585648\n",
      "batch accuracy: 0.9990234375\n",
      "doing 154 / 291\n",
      "elapsed time 12529.668035507202\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9990\n",
      "batch loss: 0.00796235166490078\n",
      "batch accuracy: 0.9990234375\n",
      "doing 155 / 291\n",
      "elapsed time 12609.660447359085\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "batch loss: 0.005719376262277365\n",
      "batch accuracy: 1.0\n",
      "doing 156 / 291\n",
      "elapsed time 12688.907366514206\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "batch loss: 0.0074196141213178635\n",
      "batch accuracy: 1.0\n",
      "doing 157 / 291\n",
      "elapsed time 12766.459427833557\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9971\n",
      "batch loss: 0.011516779661178589\n",
      "batch accuracy: 0.9970703125\n",
      "doing 158 / 291\n",
      "elapsed time 12846.242892026901\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9980\n",
      "batch loss: 0.012807433493435383\n",
      "batch accuracy: 0.998046875\n",
      "doing 159 / 291\n",
      "elapsed time 12925.416404485703\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9980\n",
      "batch loss: 0.01102563738822937\n",
      "batch accuracy: 0.998046875\n",
      "doing 160 / 291\n",
      "elapsed time 13004.073960542679\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "batch loss: 0.005795181263238192\n",
      "batch accuracy: 1.0\n",
      "doing 161 / 291\n",
      "elapsed time 13083.35931110382\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9990\n",
      "batch loss: 0.011923694983124733\n",
      "batch accuracy: 0.9990234375\n",
      "doing 162 / 291\n",
      "elapsed time 13157.888798475266\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9980\n",
      "batch loss: 0.013483896851539612\n",
      "batch accuracy: 0.998046875\n",
      "doing 163 / 291\n",
      "elapsed time 13235.764575242996\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9980\n",
      "batch loss: 0.005379076581448317\n",
      "batch accuracy: 0.998046875\n",
      "doing 164 / 291\n",
      "elapsed time 13313.748970270157\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9990\n",
      "batch loss: 0.008698326535522938\n",
      "batch accuracy: 0.9990234375\n",
      "doing 165 / 291\n",
      "elapsed time 13392.714501619339\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9971\n",
      "batch loss: 0.018435634672641754\n",
      "batch accuracy: 0.9970703125\n",
      "doing 166 / 291\n",
      "elapsed time 13470.326681375504\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9990\n",
      "batch loss: 0.007154136896133423\n",
      "batch accuracy: 0.9990234375\n",
      "doing 167 / 291\n",
      "elapsed time 13546.464356422424\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9990\n",
      "batch loss: 0.01165762823075056\n",
      "batch accuracy: 0.9990234375\n",
      "doing 168 / 291\n",
      "elapsed time 13624.028783798218\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 0.9990\n",
      "batch loss: 0.005406868178397417\n",
      "batch accuracy: 0.9990234375\n",
      "doing 169 / 291\n",
      "elapsed time 13701.548894643784\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 0.9980\n",
      "batch loss: 0.009144622832536697\n",
      "batch accuracy: 0.998046875\n",
      "doing 170 / 291\n",
      "elapsed time 13779.129213809967\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "batch loss: 0.007256803102791309\n",
      "batch accuracy: 1.0\n",
      "doing 171 / 291\n",
      "elapsed time 13855.259006738663\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "batch loss: 0.0071221403777599335\n",
      "batch accuracy: 1.0\n",
      "doing 172 / 291\n",
      "elapsed time 13932.253650188446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9961\n",
      "batch loss: 0.011787009425461292\n",
      "batch accuracy: 0.99609375\n",
      "doing 173 / 291\n",
      "elapsed time 14011.805733680725\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9961\n",
      "batch loss: 0.010096633806824684\n",
      "batch accuracy: 0.99609375\n",
      "doing 174 / 291\n",
      "elapsed time 14089.722388029099\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 0.9980\n",
      "batch loss: 0.011485014110803604\n",
      "batch accuracy: 0.998046875\n",
      "doing 175 / 291\n",
      "elapsed time 14165.926087379456\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9990\n",
      "batch loss: 0.0071967365220189095\n",
      "batch accuracy: 0.9990234375\n",
      "doing 176 / 291\n",
      "elapsed time 14241.109461307526\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9990\n",
      "batch loss: 0.007776079699397087\n",
      "batch accuracy: 0.9990234375\n",
      "doing 177 / 291\n",
      "elapsed time 14315.636355161667\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9990\n",
      "batch loss: 0.0068684592843055725\n",
      "batch accuracy: 0.9990234375\n",
      "doing 178 / 291\n",
      "elapsed time 14395.249766588211\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9990\n",
      "batch loss: 0.008307305164635181\n",
      "batch accuracy: 0.9990234375\n",
      "doing 179 / 291\n",
      "elapsed time 14470.86922287941\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9980\n",
      "batch loss: 0.008323119021952152\n",
      "batch accuracy: 0.998046875\n",
      "doing 180 / 291\n",
      "elapsed time 14548.833703517914\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "batch loss: 0.006299154832959175\n",
      "batch accuracy: 1.0\n",
      "doing 181 / 291\n",
      "elapsed time 14625.902041196823\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "batch loss: 0.011667497456073761\n",
      "batch accuracy: 1.0\n",
      "doing 182 / 291\n",
      "elapsed time 14702.937819004059\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9961\n",
      "batch loss: 0.013614850118756294\n",
      "batch accuracy: 0.99609375\n",
      "doing 183 / 291\n",
      "elapsed time 14778.715013504028\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 0.9990\n",
      "batch loss: 0.006061617750674486\n",
      "batch accuracy: 0.9990234375\n",
      "doing 184 / 291\n",
      "elapsed time 14855.341331243515\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9980\n",
      "batch loss: 0.00799185037612915\n",
      "batch accuracy: 0.998046875\n",
      "doing 185 / 291\n",
      "elapsed time 14935.503581762314\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9990\n",
      "batch loss: 0.008349128998816013\n",
      "batch accuracy: 0.9990234375\n",
      "doing 186 / 291\n",
      "elapsed time 15015.079124450684\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9990\n",
      "batch loss: 0.006646217778325081\n",
      "batch accuracy: 0.9990234375\n",
      "doing 187 / 291\n",
      "elapsed time 15093.994814395905\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "batch loss: 0.005897803232073784\n",
      "batch accuracy: 0.9990234375\n",
      "doing 188 / 291\n",
      "elapsed time 15170.199003219604\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9990\n",
      "batch loss: 0.008430884219706059\n",
      "batch accuracy: 0.9990234375\n",
      "doing 189 / 291\n",
      "elapsed time 15248.634983778\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "batch loss: 0.006273023784160614\n",
      "batch accuracy: 1.0\n",
      "doing 190 / 291\n",
      "elapsed time 15326.060767650604\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9980\n",
      "batch loss: 0.01107448898255825\n",
      "batch accuracy: 0.998046875\n",
      "doing 191 / 291\n",
      "elapsed time 15401.878118753433\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9990\n",
      "batch loss: 0.009200782515108585\n",
      "batch accuracy: 0.9990234375\n",
      "doing 192 / 291\n",
      "elapsed time 15479.013337373734\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9980\n",
      "batch loss: 0.009187636896967888\n",
      "batch accuracy: 0.998046875\n",
      "doing 193 / 291\n",
      "elapsed time 15558.901071548462\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9980\n",
      "batch loss: 0.014643068425357342\n",
      "batch accuracy: 0.998046875\n",
      "doing 194 / 291\n",
      "elapsed time 15635.616981744766\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9980\n",
      "batch loss: 0.012453056871891022\n",
      "batch accuracy: 0.998046875\n",
      "doing 195 / 291\n",
      "elapsed time 15712.735264539719\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "batch loss: 0.00555828120559454\n",
      "batch accuracy: 1.0\n",
      "doing 196 / 291\n",
      "elapsed time 15789.534194231033\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9980\n",
      "batch loss: 0.013933099806308746\n",
      "batch accuracy: 0.998046875\n",
      "doing 197 / 291\n",
      "elapsed time 15868.358587503433\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9971\n",
      "batch loss: 0.01139005832374096\n",
      "batch accuracy: 0.9970703125\n",
      "doing 198 / 291\n",
      "elapsed time 15943.578557014465\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9990\n",
      "batch loss: 0.00559715460985899\n",
      "batch accuracy: 0.9990234375\n",
      "doing 199 / 291\n",
      "elapsed time 16020.308216810226\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9990\n",
      "batch loss: 0.006849709898233414\n",
      "batch accuracy: 0.9990234375\n",
      "doing 200 / 291\n",
      "elapsed time 16094.6175365448\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9980\n",
      "batch loss: 0.010966610163450241\n",
      "batch accuracy: 0.998046875\n",
      "doing 201 / 291\n",
      "elapsed time 16172.612708806992\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9990\n",
      "batch loss: 0.006858335342258215\n",
      "batch accuracy: 0.9990234375\n",
      "doing 202 / 291\n",
      "elapsed time 16250.287707328796\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9990\n",
      "batch loss: 0.006850773934274912\n",
      "batch accuracy: 0.9990234375\n",
      "doing 203 / 291\n",
      "elapsed time 16326.454515457153\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9990\n",
      "batch loss: 0.008801810443401337\n",
      "batch accuracy: 0.9990234375\n",
      "doing 204 / 291\n",
      "elapsed time 16405.926861524582\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9980\n",
      "batch loss: 0.009603356942534447\n",
      "batch accuracy: 0.998046875\n",
      "doing 205 / 291\n",
      "elapsed time 16481.589934825897\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9980\n",
      "batch loss: 0.013451917096972466\n",
      "batch accuracy: 0.998046875\n",
      "doing 206 / 291\n",
      "elapsed time 16562.195419073105\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0129 - accuracy: 0.9980\n",
      "batch loss: 0.012882208451628685\n",
      "batch accuracy: 0.998046875\n",
      "doing 207 / 291\n",
      "elapsed time 16641.18810391426\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "batch loss: 0.007011164911091328\n",
      "batch accuracy: 1.0\n",
      "doing 208 / 291\n",
      "elapsed time 16714.278014421463\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9990\n",
      "batch loss: 0.007782012224197388\n",
      "batch accuracy: 0.9990234375\n",
      "doing 209 / 291\n",
      "elapsed time 16789.78551721573\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "batch loss: 0.008395633660256863\n",
      "batch accuracy: 1.0\n",
      "doing 210 / 291\n",
      "elapsed time 16867.96276497841\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "batch loss: 0.006301749963313341\n",
      "batch accuracy: 1.0\n",
      "doing 211 / 291\n",
      "elapsed time 16945.720417261124\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9971\n",
      "batch loss: 0.010675938799977303\n",
      "batch accuracy: 0.9970703125\n",
      "doing 212 / 291\n",
      "elapsed time 17021.578439474106\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9980\n",
      "batch loss: 0.00999195035547018\n",
      "batch accuracy: 0.998046875\n",
      "doing 213 / 291\n",
      "elapsed time 17101.17046880722\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9990\n",
      "batch loss: 0.007420654408633709\n",
      "batch accuracy: 0.9990234375\n",
      "doing 214 / 291\n",
      "elapsed time 17178.976722717285\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "batch loss: 0.00540627958253026\n",
      "batch accuracy: 1.0\n",
      "doing 215 / 291\n",
      "elapsed time 17255.81358551979\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9980\n",
      "batch loss: 0.009069114923477173\n",
      "batch accuracy: 0.998046875\n",
      "doing 216 / 291\n",
      "elapsed time 17333.299224853516\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9990\n",
      "batch loss: 0.010824067518115044\n",
      "batch accuracy: 0.9990234375\n",
      "doing 217 / 291\n",
      "elapsed time 17412.087062835693\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9961\n",
      "batch loss: 0.014830118045210838\n",
      "batch accuracy: 0.99609375\n",
      "doing 218 / 291\n",
      "elapsed time 17488.516156435013\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9990\n",
      "batch loss: 0.008498127572238445\n",
      "batch accuracy: 0.9990234375\n",
      "doing 219 / 291\n",
      "elapsed time 17569.431293964386\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9980\n",
      "batch loss: 0.010316887870430946\n",
      "batch accuracy: 0.998046875\n",
      "doing 220 / 291\n",
      "elapsed time 17648.547025203705\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0224 - accuracy: 0.9951\n",
      "batch loss: 0.022429240867495537\n",
      "batch accuracy: 0.9951171875\n",
      "doing 221 / 291\n",
      "elapsed time 17726.08394265175\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0314 - accuracy: 0.9951\n",
      "batch loss: 0.03144174814224243\n",
      "batch accuracy: 0.9951171875\n",
      "doing 222 / 291\n",
      "elapsed time 17802.43101477623\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9971\n",
      "batch loss: 0.012945563532412052\n",
      "batch accuracy: 0.9970703125\n",
      "doing 223 / 291\n",
      "elapsed time 17879.061148881912\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0215 - accuracy: 0.9941\n",
      "batch loss: 0.021548466756939888\n",
      "batch accuracy: 0.994140625\n",
      "doing 224 / 291\n",
      "elapsed time 17957.620536327362\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9971\n",
      "batch loss: 0.014082411304116249\n",
      "batch accuracy: 0.9970703125\n",
      "doing 225 / 291\n",
      "elapsed time 18037.856645822525\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9971\n",
      "batch loss: 0.016698436811566353\n",
      "batch accuracy: 0.9970703125\n",
      "doing 226 / 291\n",
      "elapsed time 18115.87381529808\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9990\n",
      "batch loss: 0.00989990308880806\n",
      "batch accuracy: 0.9990234375\n",
      "doing 227 / 291\n",
      "elapsed time 18194.16773223877\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0140 - accuracy: 0.9951\n",
      "batch loss: 0.014048977755010128\n",
      "batch accuracy: 0.9951171875\n",
      "doing 228 / 291\n",
      "elapsed time 18274.039630889893\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9980\n",
      "batch loss: 0.012415342964231968\n",
      "batch accuracy: 0.998046875\n",
      "doing 229 / 291\n",
      "elapsed time 18351.383027791977\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 0.9961\n",
      "batch loss: 0.01724638231098652\n",
      "batch accuracy: 0.99609375\n",
      "doing 230 / 291\n",
      "elapsed time 18429.26657629013\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "batch loss: 0.008800428360700607\n",
      "batch accuracy: 1.0\n",
      "doing 231 / 291\n",
      "elapsed time 18508.361127614975\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9980\n",
      "batch loss: 0.012113833799958229\n",
      "batch accuracy: 0.998046875\n",
      "doing 232 / 291\n",
      "elapsed time 18585.555121421814\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9990\n",
      "batch loss: 0.007659612689167261\n",
      "batch accuracy: 0.9990234375\n",
      "doing 233 / 291\n",
      "elapsed time 18663.85498547554\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9980\n",
      "batch loss: 0.010191814973950386\n",
      "batch accuracy: 0.998046875\n",
      "doing 234 / 291\n",
      "elapsed time 18739.349860668182\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "batch loss: 0.005918890703469515\n",
      "batch accuracy: 0.9990234375\n",
      "doing 235 / 291\n",
      "elapsed time 18819.223224639893\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9961\n",
      "batch loss: 0.011610380373895168\n",
      "batch accuracy: 0.99609375\n",
      "doing 236 / 291\n",
      "elapsed time 18899.0121383667\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "batch loss: 0.006585314869880676\n",
      "batch accuracy: 1.0\n",
      "doing 237 / 291\n",
      "elapsed time 18978.14997768402\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 0.9980\n",
      "batch loss: 0.014256459660828114\n",
      "batch accuracy: 0.998046875\n",
      "doing 238 / 291\n",
      "elapsed time 19056.979170560837\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9971\n",
      "batch loss: 0.0074755530804395676\n",
      "batch accuracy: 0.9970703125\n",
      "doing 239 / 291\n",
      "elapsed time 19136.120146274567\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "batch loss: 0.006740898825228214\n",
      "batch accuracy: 1.0\n",
      "doing 240 / 291\n",
      "elapsed time 19213.079875946045\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9971\n",
      "batch loss: 0.00911184586584568\n",
      "batch accuracy: 0.9970703125\n",
      "doing 241 / 291\n",
      "elapsed time 19293.266969680786\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.9990\n",
      "batch loss: 0.0051502650603652\n",
      "batch accuracy: 0.9990234375\n",
      "doing 242 / 291\n",
      "elapsed time 19371.369820833206\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "batch loss: 0.008596113882958889\n",
      "batch accuracy: 1.0\n",
      "doing 243 / 291\n",
      "elapsed time 19449.984250068665\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 0.9990\n",
      "batch loss: 0.007835142314434052\n",
      "batch accuracy: 0.9990234375\n",
      "doing 244 / 291\n",
      "elapsed time 19526.096036672592\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "batch loss: 0.005478811915963888\n",
      "batch accuracy: 1.0\n",
      "doing 245 / 291\n",
      "elapsed time 19603.65101480484\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9990\n",
      "batch loss: 0.009211387485265732\n",
      "batch accuracy: 0.9990234375\n",
      "doing 246 / 291\n",
      "elapsed time 19681.35619854927\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9980\n",
      "batch loss: 0.01074800081551075\n",
      "batch accuracy: 0.998046875\n",
      "doing 247 / 291\n",
      "elapsed time 19759.885080337524\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "batch loss: 0.005707278847694397\n",
      "batch accuracy: 1.0\n",
      "doing 248 / 291\n",
      "elapsed time 19836.33280825615\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9990\n",
      "batch loss: 0.00778286624699831\n",
      "batch accuracy: 0.9990234375\n",
      "doing 249 / 291\n",
      "elapsed time 19916.9290702343\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9990\n",
      "batch loss: 0.00721580209210515\n",
      "batch accuracy: 0.9990234375\n",
      "doing 250 / 291\n",
      "elapsed time 19994.94381928444\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "batch loss: 0.004316000267863274\n",
      "batch accuracy: 1.0\n",
      "doing 251 / 291\n",
      "elapsed time 20071.926636219025\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9980\n",
      "batch loss: 0.008348614908754826\n",
      "batch accuracy: 0.998046875\n",
      "doing 252 / 291\n",
      "elapsed time 20152.57479763031\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9990\n",
      "batch loss: 0.006662760395556688\n",
      "batch accuracy: 0.9990234375\n",
      "doing 253 / 291\n",
      "elapsed time 20230.256245613098\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9990\n",
      "batch loss: 0.008546476252377033\n",
      "batch accuracy: 0.9990234375\n",
      "doing 254 / 291\n",
      "elapsed time 20309.660652399063\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "batch loss: 0.007138659246265888\n",
      "batch accuracy: 1.0\n",
      "doing 255 / 291\n",
      "elapsed time 20385.26922392845\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9971\n",
      "batch loss: 0.01447577215731144\n",
      "batch accuracy: 0.9970703125\n",
      "doing 256 / 291\n",
      "elapsed time 20463.49688911438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "batch loss: 0.005498986225575209\n",
      "batch accuracy: 1.0\n",
      "doing 257 / 291\n",
      "elapsed time 20539.13473200798\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9990\n",
      "batch loss: 0.00670494744554162\n",
      "batch accuracy: 0.9990234375\n",
      "doing 258 / 291\n",
      "elapsed time 20615.743827581406\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9990\n",
      "batch loss: 0.0078078582882881165\n",
      "batch accuracy: 0.9990234375\n",
      "doing 259 / 291\n",
      "elapsed time 20694.999618291855\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9990\n",
      "batch loss: 0.006428120192140341\n",
      "batch accuracy: 0.9990234375\n",
      "doing 260 / 291\n",
      "elapsed time 20772.98767209053\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9961\n",
      "batch loss: 0.015240006148815155\n",
      "batch accuracy: 0.99609375\n",
      "doing 261 / 291\n",
      "elapsed time 20852.22092103958\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "batch loss: 0.00551672512665391\n",
      "batch accuracy: 1.0\n",
      "doing 262 / 291\n",
      "elapsed time 20929.703572511673\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9980\n",
      "batch loss: 0.007756339386105537\n",
      "batch accuracy: 0.998046875\n",
      "doing 263 / 291\n",
      "elapsed time 21009.082181453705\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "batch loss: 0.005298947915434837\n",
      "batch accuracy: 1.0\n",
      "doing 264 / 291\n",
      "elapsed time 21085.591923236847\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 0.9990\n",
      "batch loss: 0.006013860926032066\n",
      "batch accuracy: 0.9990234375\n",
      "doing 265 / 291\n",
      "elapsed time 21163.198045492172\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9980\n",
      "batch loss: 0.008159744553267956\n",
      "batch accuracy: 0.998046875\n",
      "doing 266 / 291\n",
      "elapsed time 21239.28490805626\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0154 - accuracy: 0.9971\n",
      "batch loss: 0.015435032546520233\n",
      "batch accuracy: 0.9970703125\n",
      "doing 267 / 291\n",
      "elapsed time 21317.554937839508\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9980\n",
      "batch loss: 0.00861280132085085\n",
      "batch accuracy: 0.998046875\n",
      "doing 268 / 291\n",
      "elapsed time 21394.93891143799\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0137 - accuracy: 0.9941\n",
      "batch loss: 0.01366426795721054\n",
      "batch accuracy: 0.994140625\n",
      "doing 269 / 291\n",
      "elapsed time 21473.22940468788\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 0.9990\n",
      "batch loss: 0.007005852647125721\n",
      "batch accuracy: 0.9990234375\n",
      "doing 270 / 291\n",
      "elapsed time 21550.34267640114\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9971\n",
      "batch loss: 0.011168906465172768\n",
      "batch accuracy: 0.9970703125\n",
      "doing 271 / 291\n",
      "elapsed time 21626.252480745316\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 0.9990\n",
      "batch loss: 0.0070861331187188625\n",
      "batch accuracy: 0.9990234375\n",
      "doing 272 / 291\n",
      "elapsed time 21705.244154691696\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9980\n",
      "batch loss: 0.009714582934975624\n",
      "batch accuracy: 0.998046875\n",
      "doing 273 / 291\n",
      "elapsed time 21783.194417476654\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "batch loss: 0.007289583794772625\n",
      "batch accuracy: 1.0\n",
      "doing 274 / 291\n",
      "elapsed time 21860.102222442627\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "batch loss: 0.004134295508265495\n",
      "batch accuracy: 1.0\n",
      "doing 275 / 291\n",
      "elapsed time 21937.78139233589\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "batch loss: 0.0044036624021828175\n",
      "batch accuracy: 1.0\n",
      "doing 276 / 291\n",
      "elapsed time 22018.20389199257\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9990\n",
      "batch loss: 0.004280204884707928\n",
      "batch accuracy: 0.9990234375\n",
      "doing 277 / 291\n",
      "elapsed time 22095.83826303482\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9971\n",
      "batch loss: 0.011950626038014889\n",
      "batch accuracy: 0.9970703125\n",
      "doing 278 / 291\n",
      "elapsed time 22174.905989408493\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9990\n",
      "batch loss: 0.007925203070044518\n",
      "batch accuracy: 0.9990234375\n",
      "doing 279 / 291\n",
      "elapsed time 22252.804744243622\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9990\n",
      "batch loss: 0.005981181748211384\n",
      "batch accuracy: 0.9990234375\n",
      "doing 280 / 291\n",
      "elapsed time 22331.4097571373\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9980\n",
      "batch loss: 0.012648647651076317\n",
      "batch accuracy: 0.998046875\n",
      "doing 281 / 291\n",
      "elapsed time 22413.430444955826\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9971\n",
      "batch loss: 0.012092245742678642\n",
      "batch accuracy: 0.9970703125\n",
      "doing 282 / 291\n",
      "elapsed time 22488.804127454758\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9990\n",
      "batch loss: 0.005739213433116674\n",
      "batch accuracy: 0.9990234375\n",
      "doing 283 / 291\n",
      "elapsed time 22570.369729042053\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9990\n",
      "batch loss: 0.008079295046627522\n",
      "batch accuracy: 0.9990234375\n",
      "doing 284 / 291\n",
      "elapsed time 22650.488260507584\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9990\n",
      "batch loss: 0.006366452667862177\n",
      "batch accuracy: 0.9990234375\n",
      "doing 285 / 291\n",
      "elapsed time 22728.394643068314\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9971\n",
      "batch loss: 0.012845362536609173\n",
      "batch accuracy: 0.9970703125\n",
      "doing 286 / 291\n",
      "elapsed time 22805.12302660942\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "batch loss: 0.00466024549677968\n",
      "batch accuracy: 1.0\n",
      "doing 287 / 291\n",
      "elapsed time 22886.386986017227\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.9980\n",
      "batch loss: 0.007287103682756424\n",
      "batch accuracy: 0.998046875\n",
      "doing 288 / 291\n",
      "elapsed time 22965.09058904648\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "batch loss: 0.0051617999561131\n",
      "batch accuracy: 1.0\n",
      "doing 289 / 291\n",
      "elapsed time 23045.03133392334\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "batch loss: 0.004249866120517254\n",
      "batch accuracy: 1.0\n",
      "doing 290 / 291\n",
      "elapsed time 23048.888065576553\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.0787e-04 - accuracy: 1.0000\n",
      "batch loss: 0.0007078719791024923\n",
      "batch accuracy: 1.0\n",
      "Train loss 0.008405675214660895\n",
      "Train accuracy 0.9987113402061856\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5047 - accuracy: 0.9169\n",
      "Validation loss: 0.5046674013137817\n",
      "Validation accuracy: 0.9168888926506042\n",
      "==================================================\n",
      "2 / 5\n",
      "doing 0 / 291\n",
      "elapsed time 37.21263122558594\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9990\n",
      "batch loss: 0.004637719132006168\n",
      "batch accuracy: 0.9990234375\n",
      "doing 1 / 291\n",
      "elapsed time 74.82905745506287\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9980\n",
      "batch loss: 0.005722701083868742\n",
      "batch accuracy: 0.998046875\n",
      "doing 2 / 291\n",
      "elapsed time 111.84612536430359\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "batch loss: 0.004845587536692619\n",
      "batch accuracy: 1.0\n",
      "doing 3 / 291\n",
      "elapsed time 147.5871443748474\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "batch loss: 0.004132520407438278\n",
      "batch accuracy: 1.0\n",
      "doing 4 / 291\n",
      "elapsed time 187.58452582359314\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9980\n",
      "batch loss: 0.00636187894269824\n",
      "batch accuracy: 0.998046875\n",
      "doing 5 / 291\n",
      "elapsed time 225.52810525894165\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "batch loss: 0.00399817805737257\n",
      "batch accuracy: 1.0\n",
      "doing 6 / 291\n",
      "elapsed time 266.11994099617004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "batch loss: 0.0048623341135680676\n",
      "batch accuracy: 1.0\n",
      "doing 7 / 291\n",
      "elapsed time 306.6662402153015\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "batch loss: 0.004002416040748358\n",
      "batch accuracy: 1.0\n",
      "doing 8 / 291\n",
      "elapsed time 346.1102077960968\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9990\n",
      "batch loss: 0.0050322143360972404\n",
      "batch accuracy: 0.9990234375\n",
      "doing 9 / 291\n",
      "elapsed time 383.5871889591217\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.0038487326819449663\n",
      "batch accuracy: 1.0\n",
      "doing 10 / 291\n",
      "elapsed time 421.48721837997437\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "batch loss: 0.005395432468503714\n",
      "batch accuracy: 1.0\n",
      "doing 11 / 291\n",
      "elapsed time 459.87158489227295\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "batch loss: 0.004446927458047867\n",
      "batch accuracy: 1.0\n",
      "doing 12 / 291\n",
      "elapsed time 498.59188079833984\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "batch loss: 0.005451082251966\n",
      "batch accuracy: 1.0\n",
      "doing 13 / 291\n",
      "elapsed time 535.2646117210388\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9990\n",
      "batch loss: 0.006760984659194946\n",
      "batch accuracy: 0.9990234375\n",
      "doing 14 / 291\n",
      "elapsed time 573.481734752655\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9980\n",
      "batch loss: 0.008825104683637619\n",
      "batch accuracy: 0.998046875\n",
      "doing 15 / 291\n",
      "elapsed time 610.796715259552\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9990\n",
      "batch loss: 0.004409667570143938\n",
      "batch accuracy: 0.9990234375\n",
      "doing 16 / 291\n",
      "elapsed time 651.7917549610138\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "batch loss: 0.00449959933757782\n",
      "batch accuracy: 1.0\n",
      "doing 17 / 291\n",
      "elapsed time 692.057222366333\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "batch loss: 0.006147704087197781\n",
      "batch accuracy: 0.998046875\n",
      "doing 18 / 291\n",
      "elapsed time 731.5272591114044\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "batch loss: 0.0024414837826043367\n",
      "batch accuracy: 1.0\n",
      "doing 19 / 291\n",
      "elapsed time 767.8172147274017\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9980\n",
      "batch loss: 0.00545924250036478\n",
      "batch accuracy: 0.998046875\n",
      "doing 20 / 291\n",
      "elapsed time 806.004477262497\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "batch loss: 0.004009099677205086\n",
      "batch accuracy: 1.0\n",
      "doing 21 / 291\n",
      "elapsed time 845.944596529007\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "batch loss: 0.004198273178189993\n",
      "batch accuracy: 1.0\n",
      "doing 22 / 291\n",
      "elapsed time 888.1889002323151\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9990\n",
      "batch loss: 0.005004333797842264\n",
      "batch accuracy: 0.9990234375\n",
      "doing 23 / 291\n",
      "elapsed time 926.3249750137329\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9980\n",
      "batch loss: 0.00578626524657011\n",
      "batch accuracy: 0.998046875\n",
      "doing 24 / 291\n",
      "elapsed time 965.0822854042053\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.0038269893266260624\n",
      "batch accuracy: 1.0\n",
      "doing 25 / 291\n",
      "elapsed time 1005.2617373466492\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9990\n",
      "batch loss: 0.006413666531443596\n",
      "batch accuracy: 0.9990234375\n",
      "doing 26 / 291\n",
      "elapsed time 1044.302358865738\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "batch loss: 0.0032404595986008644\n",
      "batch accuracy: 1.0\n",
      "doing 27 / 291\n",
      "elapsed time 1083.4715435504913\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "batch loss: 0.0025427485816180706\n",
      "batch accuracy: 1.0\n",
      "doing 28 / 291\n",
      "elapsed time 1121.7218837738037\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9990\n",
      "batch loss: 0.005726877599954605\n",
      "batch accuracy: 0.9990234375\n",
      "doing 29 / 291\n",
      "elapsed time 1156.6522448062897\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "batch loss: 0.005036757327616215\n",
      "batch accuracy: 1.0\n",
      "doing 30 / 291\n",
      "elapsed time 1195.6235275268555\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "batch loss: 0.005250921472907066\n",
      "batch accuracy: 1.0\n",
      "doing 31 / 291\n",
      "elapsed time 1232.3791558742523\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9990\n",
      "batch loss: 0.01290377601981163\n",
      "batch accuracy: 0.9990234375\n",
      "doing 32 / 291\n",
      "elapsed time 1271.3065357208252\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "batch loss: 0.0037180131766945124\n",
      "batch accuracy: 1.0\n",
      "doing 33 / 291\n",
      "elapsed time 1306.9244592189789\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.003804083913564682\n",
      "batch accuracy: 1.0\n",
      "doing 34 / 291\n",
      "elapsed time 1347.7399263381958\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "batch loss: 0.004192438442260027\n",
      "batch accuracy: 1.0\n",
      "doing 35 / 291\n",
      "elapsed time 1386.6162254810333\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0119 - accuracy: 0.9990\n",
      "batch loss: 0.011910464614629745\n",
      "batch accuracy: 0.9990234375\n",
      "doing 36 / 291\n",
      "elapsed time 1425.9349646568298\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "batch loss: 0.003114735707640648\n",
      "batch accuracy: 1.0\n",
      "doing 37 / 291\n",
      "elapsed time 1463.8460352420807\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9990\n",
      "batch loss: 0.004538183566182852\n",
      "batch accuracy: 0.9990234375\n",
      "doing 38 / 291\n",
      "elapsed time 1502.8228318691254\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.003335141809657216\n",
      "batch accuracy: 1.0\n",
      "doing 39 / 291\n",
      "elapsed time 1540.0591077804565\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "batch loss: 0.003715872298926115\n",
      "batch accuracy: 1.0\n",
      "doing 40 / 291\n",
      "elapsed time 1576.3924794197083\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.9990\n",
      "batch loss: 0.005201895255595446\n",
      "batch accuracy: 0.9990234375\n",
      "doing 41 / 291\n",
      "elapsed time 1615.8639843463898\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "batch loss: 0.003198659513145685\n",
      "batch accuracy: 1.0\n",
      "doing 42 / 291\n",
      "elapsed time 1655.9218363761902\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "batch loss: 0.004159693606197834\n",
      "batch accuracy: 1.0\n",
      "doing 43 / 291\n",
      "elapsed time 1692.7172701358795\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.0028152051381766796\n",
      "batch accuracy: 1.0\n",
      "doing 44 / 291\n",
      "elapsed time 1729.1225051879883\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9990\n",
      "batch loss: 0.004099091049283743\n",
      "batch accuracy: 0.9990234375\n",
      "doing 45 / 291\n",
      "elapsed time 1767.9487257003784\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "batch loss: 0.004033636301755905\n",
      "batch accuracy: 1.0\n",
      "doing 46 / 291\n",
      "elapsed time 1804.9848725795746\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9990\n",
      "batch loss: 0.004166979808360338\n",
      "batch accuracy: 0.9990234375\n",
      "doing 47 / 291\n",
      "elapsed time 1846.6467063426971\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9990\n",
      "batch loss: 0.006035659462213516\n",
      "batch accuracy: 0.9990234375\n",
      "doing 48 / 291\n",
      "elapsed time 1896.4118819236755\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9990\n",
      "batch loss: 0.004216070286929607\n",
      "batch accuracy: 0.9990234375\n",
      "doing 49 / 291\n",
      "elapsed time 1946.6498725414276\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "batch loss: 0.0031125745736062527\n",
      "batch accuracy: 1.0\n",
      "doing 50 / 291\n",
      "elapsed time 1995.6956584453583\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.0027695519383996725\n",
      "batch accuracy: 1.0\n",
      "doing 51 / 291\n",
      "elapsed time 2045.0332579612732\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.0033003920689225197\n",
      "batch accuracy: 1.0\n",
      "doing 52 / 291\n",
      "elapsed time 2093.227895259857\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9990\n",
      "batch loss: 0.004709639120846987\n",
      "batch accuracy: 0.9990234375\n",
      "doing 53 / 291\n",
      "elapsed time 2141.4802532196045\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9990\n",
      "batch loss: 0.004307327326387167\n",
      "batch accuracy: 0.9990234375\n",
      "doing 54 / 291\n",
      "elapsed time 2190.3028247356415\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9990\n",
      "batch loss: 0.004303652793169022\n",
      "batch accuracy: 0.9990234375\n",
      "doing 55 / 291\n",
      "elapsed time 2239.322350502014\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "batch loss: 0.0026028272695839405\n",
      "batch accuracy: 1.0\n",
      "doing 56 / 291\n",
      "elapsed time 2292.5443296432495\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9990\n",
      "batch loss: 0.0045968517661094666\n",
      "batch accuracy: 0.9990234375\n",
      "doing 57 / 291\n",
      "elapsed time 2343.563636779785\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "batch loss: 0.0028569153510034084\n",
      "batch accuracy: 1.0\n",
      "doing 58 / 291\n",
      "elapsed time 2389.8394091129303\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9980\n",
      "batch loss: 0.010006011463701725\n",
      "batch accuracy: 0.998046875\n",
      "doing 59 / 291\n",
      "elapsed time 2439.1856739521027\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.0028247919399291277\n",
      "batch accuracy: 1.0\n",
      "doing 60 / 291\n",
      "elapsed time 2489.647706270218\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "batch loss: 0.004072141833603382\n",
      "batch accuracy: 1.0\n",
      "doing 61 / 291\n",
      "elapsed time 2539.0618708133698\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9990\n",
      "batch loss: 0.0037205966655164957\n",
      "batch accuracy: 0.9990234375\n",
      "doing 62 / 291\n",
      "elapsed time 2590.2904241085052\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "batch loss: 0.004967388231307268\n",
      "batch accuracy: 1.0\n",
      "doing 63 / 291\n",
      "elapsed time 2641.6402912139893\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "batch loss: 0.003089698264375329\n",
      "batch accuracy: 1.0\n",
      "doing 64 / 291\n",
      "elapsed time 2691.414211988449\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 0.9980\n",
      "batch loss: 0.005671630147844553\n",
      "batch accuracy: 0.998046875\n",
      "doing 65 / 291\n",
      "elapsed time 2741.2472290992737\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9990\n",
      "batch loss: 0.006319613195955753\n",
      "batch accuracy: 0.9990234375\n",
      "doing 66 / 291\n",
      "elapsed time 2790.92582321167\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9990\n",
      "batch loss: 0.006006408017128706\n",
      "batch accuracy: 0.9990234375\n",
      "doing 67 / 291\n",
      "elapsed time 2839.9916846752167\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9990\n",
      "batch loss: 0.005329062230885029\n",
      "batch accuracy: 0.9990234375\n",
      "doing 68 / 291\n",
      "elapsed time 2889.7061529159546\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "batch loss: 0.004209556151181459\n",
      "batch accuracy: 1.0\n",
      "doing 69 / 291\n",
      "elapsed time 2937.274095773697\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9980\n",
      "batch loss: 0.00962962955236435\n",
      "batch accuracy: 0.998046875\n",
      "doing 70 / 291\n",
      "elapsed time 2988.1850724220276\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "batch loss: 0.0031760132405906916\n",
      "batch accuracy: 1.0\n",
      "doing 71 / 291\n",
      "elapsed time 3034.9458391666412\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9990\n",
      "batch loss: 0.004273517057299614\n",
      "batch accuracy: 0.9990234375\n",
      "doing 72 / 291\n",
      "elapsed time 3086.043856859207\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "batch loss: 0.005750431213527918\n",
      "batch accuracy: 1.0\n",
      "doing 73 / 291\n",
      "elapsed time 3135.596981048584\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "batch loss: 0.0035594720393419266\n",
      "batch accuracy: 1.0\n",
      "doing 74 / 291\n",
      "elapsed time 3186.0496604442596\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9990\n",
      "batch loss: 0.007479834835976362\n",
      "batch accuracy: 0.9990234375\n",
      "doing 75 / 291\n",
      "elapsed time 3231.868913412094\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "batch loss: 0.0038764607161283493\n",
      "batch accuracy: 1.0\n",
      "doing 76 / 291\n",
      "elapsed time 3279.2927420139313\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.0028188179712742567\n",
      "batch accuracy: 1.0\n",
      "doing 77 / 291\n",
      "elapsed time 3332.9737219810486\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.9990\n",
      "batch loss: 0.004971958696842194\n",
      "batch accuracy: 0.9990234375\n",
      "doing 78 / 291\n",
      "elapsed time 3395.6711916923523\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "batch loss: 0.003697974607348442\n",
      "batch accuracy: 1.0\n",
      "doing 79 / 291\n",
      "elapsed time 3457.5189950466156\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0057 - accuracy: 0.9980\n",
      "batch loss: 0.005722425878047943\n",
      "batch accuracy: 0.998046875\n",
      "doing 80 / 291\n",
      "elapsed time 3519.387312889099\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "batch loss: 0.003595197107642889\n",
      "batch accuracy: 1.0\n",
      "doing 81 / 291\n",
      "elapsed time 3577.651114463806\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.0027537981513887644\n",
      "batch accuracy: 1.0\n",
      "doing 82 / 291\n",
      "elapsed time 3637.524416923523\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "batch loss: 0.0042836046777665615\n",
      "batch accuracy: 1.0\n",
      "doing 83 / 291\n",
      "elapsed time 3699.13983297348\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9990\n",
      "batch loss: 0.00462501822039485\n",
      "batch accuracy: 0.9990234375\n",
      "doing 84 / 291\n",
      "elapsed time 3760.4455597400665\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "batch loss: 0.0030493938829749823\n",
      "batch accuracy: 1.0\n",
      "doing 85 / 291\n",
      "elapsed time 3822.1800866127014\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9990\n",
      "batch loss: 0.00663771852850914\n",
      "batch accuracy: 0.9990234375\n",
      "doing 86 / 291\n",
      "elapsed time 3885.2167201042175\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9990\n",
      "batch loss: 0.005535086616873741\n",
      "batch accuracy: 0.9990234375\n",
      "doing 87 / 291\n",
      "elapsed time 3947.9745967388153\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "batch loss: 0.004489041864871979\n",
      "batch accuracy: 1.0\n",
      "doing 88 / 291\n",
      "elapsed time 4005.9388983249664\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9990\n",
      "batch loss: 0.00506094703450799\n",
      "batch accuracy: 0.9990234375\n",
      "doing 89 / 291\n",
      "elapsed time 4066.2669262886047\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9990\n",
      "batch loss: 0.0050942562520504\n",
      "batch accuracy: 0.9990234375\n",
      "doing 90 / 291\n",
      "elapsed time 4124.186895132065\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "batch loss: 0.005496311001479626\n",
      "batch accuracy: 1.0\n",
      "doing 91 / 291\n",
      "elapsed time 4183.118280649185\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9990\n",
      "batch loss: 0.007044341880828142\n",
      "batch accuracy: 0.9990234375\n",
      "doing 92 / 291\n",
      "elapsed time 4242.924235343933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "batch loss: 0.004448132589459419\n",
      "batch accuracy: 1.0\n",
      "doing 93 / 291\n",
      "elapsed time 4305.325657606125\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "batch loss: 0.00389481196179986\n",
      "batch accuracy: 1.0\n",
      "doing 94 / 291\n",
      "elapsed time 4368.692806720734\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.003819661680608988\n",
      "batch accuracy: 1.0\n",
      "doing 95 / 291\n",
      "elapsed time 4431.576910495758\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "batch loss: 0.004405425861477852\n",
      "batch accuracy: 1.0\n",
      "doing 96 / 291\n",
      "elapsed time 4495.618722200394\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 0.9990\n",
      "batch loss: 0.0056505361571908\n",
      "batch accuracy: 0.9990234375\n",
      "doing 97 / 291\n",
      "elapsed time 4555.2376754283905\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "batch loss: 0.003854543436318636\n",
      "batch accuracy: 1.0\n",
      "doing 98 / 291\n",
      "elapsed time 4616.527353525162\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "batch loss: 0.0033977075945585966\n",
      "batch accuracy: 1.0\n",
      "doing 99 / 291\n",
      "elapsed time 4676.757326126099\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "batch loss: 0.00408839900046587\n",
      "batch accuracy: 1.0\n",
      "doing 100 / 291\n",
      "elapsed time 4748.323400735855\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "batch loss: 0.0038528458680957556\n",
      "batch accuracy: 1.0\n",
      "doing 101 / 291\n",
      "elapsed time 4819.164543390274\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9980\n",
      "batch loss: 0.005706381984055042\n",
      "batch accuracy: 0.998046875\n",
      "doing 102 / 291\n",
      "elapsed time 4886.776062011719\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9990\n",
      "batch loss: 0.005599719472229481\n",
      "batch accuracy: 0.9990234375\n",
      "doing 103 / 291\n",
      "elapsed time 4953.657689571381\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "batch loss: 0.003993723541498184\n",
      "batch accuracy: 1.0\n",
      "doing 104 / 291\n",
      "elapsed time 5021.108075380325\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.9990\n",
      "batch loss: 0.004778480622917414\n",
      "batch accuracy: 0.9990234375\n",
      "doing 105 / 291\n",
      "elapsed time 5087.824779510498\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9990\n",
      "batch loss: 0.004960309714078903\n",
      "batch accuracy: 0.9990234375\n",
      "doing 106 / 291\n",
      "elapsed time 5157.02978849411\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9990\n",
      "batch loss: 0.004327621776610613\n",
      "batch accuracy: 0.9990234375\n",
      "doing 107 / 291\n",
      "elapsed time 5225.006559371948\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9990\n",
      "batch loss: 0.010077986866235733\n",
      "batch accuracy: 0.9990234375\n",
      "doing 108 / 291\n",
      "elapsed time 5293.69474363327\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "batch loss: 0.004607051610946655\n",
      "batch accuracy: 1.0\n",
      "doing 109 / 291\n",
      "elapsed time 5361.861469745636\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9980\n",
      "batch loss: 0.007907269522547722\n",
      "batch accuracy: 0.998046875\n",
      "doing 110 / 291\n",
      "elapsed time 5434.232637882233\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9990\n",
      "batch loss: 0.005005927290767431\n",
      "batch accuracy: 0.9990234375\n",
      "doing 111 / 291\n",
      "elapsed time 5507.823796272278\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "batch loss: 0.005580357741564512\n",
      "batch accuracy: 1.0\n",
      "doing 112 / 291\n",
      "elapsed time 5584.3775181770325\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9990\n",
      "batch loss: 0.011388826183974743\n",
      "batch accuracy: 0.9990234375\n",
      "doing 113 / 291\n",
      "elapsed time 5656.8373782634735\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "batch loss: 0.0035141862463206053\n",
      "batch accuracy: 1.0\n",
      "doing 114 / 291\n",
      "elapsed time 5731.120598554611\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "batch loss: 0.004459175281226635\n",
      "batch accuracy: 1.0\n",
      "doing 115 / 291\n",
      "elapsed time 5805.178808689117\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "batch loss: 0.005223958287388086\n",
      "batch accuracy: 1.0\n",
      "doing 116 / 291\n",
      "elapsed time 5878.656289100647\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.0037552332505583763\n",
      "batch accuracy: 1.0\n",
      "doing 117 / 291\n",
      "elapsed time 5953.318217277527\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9990\n",
      "batch loss: 0.003944238647818565\n",
      "batch accuracy: 0.9990234375\n",
      "doing 118 / 291\n",
      "elapsed time 6027.219873905182\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9990\n",
      "batch loss: 0.006750849075615406\n",
      "batch accuracy: 0.9990234375\n",
      "doing 119 / 291\n",
      "elapsed time 6102.40648317337\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "batch loss: 0.004316232167184353\n",
      "batch accuracy: 1.0\n",
      "doing 120 / 291\n",
      "elapsed time 6175.52344918251\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "batch loss: 0.004213873762637377\n",
      "batch accuracy: 1.0\n",
      "doing 121 / 291\n",
      "elapsed time 6252.622750759125\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.0037826886400580406\n",
      "batch accuracy: 1.0\n",
      "doing 122 / 291\n",
      "elapsed time 6326.082832098007\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.003347282763570547\n",
      "batch accuracy: 1.0\n",
      "doing 123 / 291\n",
      "elapsed time 6401.017491579056\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9990\n",
      "batch loss: 0.00674415985122323\n",
      "batch accuracy: 0.9990234375\n",
      "doing 124 / 291\n",
      "elapsed time 6478.685604572296\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9980\n",
      "batch loss: 0.011248825117945671\n",
      "batch accuracy: 0.998046875\n",
      "doing 125 / 291\n",
      "elapsed time 6554.9711673259735\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "batch loss: 0.0034301101695746183\n",
      "batch accuracy: 1.0\n",
      "doing 126 / 291\n",
      "elapsed time 6630.3822157382965\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9980\n",
      "batch loss: 0.007221891079097986\n",
      "batch accuracy: 0.998046875\n",
      "doing 127 / 291\n",
      "elapsed time 6706.116204738617\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9971\n",
      "batch loss: 0.011234339326620102\n",
      "batch accuracy: 0.9970703125\n",
      "doing 128 / 291\n",
      "elapsed time 6780.6024050712585\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9980\n",
      "batch loss: 0.006402925588190556\n",
      "batch accuracy: 0.998046875\n",
      "doing 129 / 291\n",
      "elapsed time 6857.507191896439\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9990\n",
      "batch loss: 0.0038886265829205513\n",
      "batch accuracy: 0.9990234375\n",
      "doing 130 / 291\n",
      "elapsed time 6934.581952095032\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9990\n",
      "batch loss: 0.00554511696100235\n",
      "batch accuracy: 0.9990234375\n",
      "doing 131 / 291\n",
      "elapsed time 7010.749040842056\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.0027982834726572037\n",
      "batch accuracy: 1.0\n",
      "doing 132 / 291\n",
      "elapsed time 7088.476390838623\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "batch loss: 0.003021934302523732\n",
      "batch accuracy: 1.0\n",
      "doing 133 / 291\n",
      "elapsed time 7168.219840288162\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "batch loss: 0.0036099511198699474\n",
      "batch accuracy: 1.0\n",
      "doing 134 / 291\n",
      "elapsed time 7247.256913900375\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.0038114525377750397\n",
      "batch accuracy: 1.0\n",
      "doing 135 / 291\n",
      "elapsed time 7325.876400232315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.0037795938551425934\n",
      "batch accuracy: 1.0\n",
      "doing 136 / 291\n",
      "elapsed time 7404.491505622864\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "batch loss: 0.0023532570339739323\n",
      "batch accuracy: 1.0\n",
      "doing 137 / 291\n",
      "elapsed time 7482.67923784256\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "batch loss: 0.0032391564454883337\n",
      "batch accuracy: 1.0\n",
      "doing 138 / 291\n",
      "elapsed time 7557.379023075104\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9980\n",
      "batch loss: 0.009369993582367897\n",
      "batch accuracy: 0.998046875\n",
      "doing 139 / 291\n",
      "elapsed time 7636.487626791\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.002812066115438938\n",
      "batch accuracy: 1.0\n",
      "doing 140 / 291\n",
      "elapsed time 7715.820611000061\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "batch loss: 0.0037321383133530617\n",
      "batch accuracy: 1.0\n",
      "doing 141 / 291\n",
      "elapsed time 7796.484333753586\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9990\n",
      "batch loss: 0.004251969512552023\n",
      "batch accuracy: 0.9990234375\n",
      "doing 142 / 291\n",
      "elapsed time 7873.656457185745\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.9990\n",
      "batch loss: 0.005207113455981016\n",
      "batch accuracy: 0.9990234375\n",
      "doing 143 / 291\n",
      "elapsed time 7950.273700714111\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9990\n",
      "batch loss: 0.0038190349005162716\n",
      "batch accuracy: 0.9990234375\n",
      "doing 144 / 291\n",
      "elapsed time 8028.399382829666\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "batch loss: 0.0031051705591380596\n",
      "batch accuracy: 1.0\n",
      "doing 145 / 291\n",
      "elapsed time 8105.975337266922\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.003267287276685238\n",
      "batch accuracy: 1.0\n",
      "doing 146 / 291\n",
      "elapsed time 8185.195399284363\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.9990\n",
      "batch loss: 0.004965119995176792\n",
      "batch accuracy: 0.9990234375\n",
      "doing 147 / 291\n",
      "elapsed time 8261.179505586624\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "batch loss: 0.004878875333815813\n",
      "batch accuracy: 1.0\n",
      "doing 148 / 291\n",
      "elapsed time 8339.231858253479\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "batch loss: 0.0033993246033787727\n",
      "batch accuracy: 1.0\n",
      "doing 149 / 291\n",
      "elapsed time 8415.9125289917\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9980\n",
      "batch loss: 0.009177379310131073\n",
      "batch accuracy: 0.998046875\n",
      "doing 150 / 291\n",
      "elapsed time 8494.368053674698\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "batch loss: 0.003980217967182398\n",
      "batch accuracy: 1.0\n",
      "doing 151 / 291\n",
      "elapsed time 8571.711996078491\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "batch loss: 0.004522431176155806\n",
      "batch accuracy: 1.0\n",
      "doing 152 / 291\n",
      "elapsed time 8650.014445781708\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.9990\n",
      "batch loss: 0.004443249199539423\n",
      "batch accuracy: 0.9990234375\n",
      "doing 153 / 291\n",
      "elapsed time 8731.295849561691\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 0.9980\n",
      "batch loss: 0.005266399588435888\n",
      "batch accuracy: 0.998046875\n",
      "doing 154 / 291\n",
      "elapsed time 8810.223764181137\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9990\n",
      "batch loss: 0.006002066656947136\n",
      "batch accuracy: 0.9990234375\n",
      "doing 155 / 291\n",
      "elapsed time 8886.871433973312\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9980\n",
      "batch loss: 0.010822253301739693\n",
      "batch accuracy: 0.998046875\n",
      "doing 156 / 291\n",
      "elapsed time 8964.550721645355\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "batch loss: 0.002854920458048582\n",
      "batch accuracy: 1.0\n",
      "doing 157 / 291\n",
      "elapsed time 9039.677957773209\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "batch loss: 0.004356836434453726\n",
      "batch accuracy: 1.0\n",
      "doing 158 / 291\n",
      "elapsed time 9118.561584711075\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.0033375881612300873\n",
      "batch accuracy: 1.0\n",
      "doing 159 / 291\n",
      "elapsed time 9193.02374958992\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "batch loss: 0.003637093584984541\n",
      "batch accuracy: 1.0\n",
      "doing 160 / 291\n",
      "elapsed time 9270.649462461472\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9990\n",
      "batch loss: 0.005141649395227432\n",
      "batch accuracy: 0.9990234375\n",
      "doing 161 / 291\n",
      "elapsed time 9347.833333492279\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 0.9980\n",
      "batch loss: 0.007155147846788168\n",
      "batch accuracy: 0.998046875\n",
      "doing 162 / 291\n",
      "elapsed time 9425.4476583004\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "batch loss: 0.0063881659880280495\n",
      "batch accuracy: 1.0\n",
      "doing 163 / 291\n",
      "elapsed time 9504.337829113007\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9990\n",
      "batch loss: 0.004642414394766092\n",
      "batch accuracy: 0.9990234375\n",
      "doing 164 / 291\n",
      "elapsed time 9583.335537672043\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "batch loss: 0.005892719607800245\n",
      "batch accuracy: 1.0\n",
      "doing 165 / 291\n",
      "elapsed time 9660.40007686615\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9990\n",
      "batch loss: 0.004650433547794819\n",
      "batch accuracy: 0.9990234375\n",
      "doing 166 / 291\n",
      "elapsed time 9738.382040023804\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9990\n",
      "batch loss: 0.00890431273728609\n",
      "batch accuracy: 0.9990234375\n",
      "doing 167 / 291\n",
      "elapsed time 9815.01120877266\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9990\n",
      "batch loss: 0.005222569685429335\n",
      "batch accuracy: 0.9990234375\n",
      "doing 168 / 291\n",
      "elapsed time 9894.713894844055\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "batch loss: 0.004846475087106228\n",
      "batch accuracy: 1.0\n",
      "doing 169 / 291\n",
      "elapsed time 9973.989922761917\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9990\n",
      "batch loss: 0.0048753852024674416\n",
      "batch accuracy: 0.9990234375\n",
      "doing 170 / 291\n",
      "elapsed time 10051.500725746155\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9990\n",
      "batch loss: 0.004473096691071987\n",
      "batch accuracy: 0.9990234375\n",
      "doing 171 / 291\n",
      "elapsed time 10130.374873161316\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "batch loss: 0.0036211819387972355\n",
      "batch accuracy: 1.0\n",
      "doing 172 / 291\n",
      "elapsed time 10207.283313035965\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.9990\n",
      "batch loss: 0.005218895152211189\n",
      "batch accuracy: 0.9990234375\n",
      "doing 173 / 291\n",
      "elapsed time 10286.175238132477\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9990\n",
      "batch loss: 0.004813440144062042\n",
      "batch accuracy: 0.9990234375\n",
      "doing 174 / 291\n",
      "elapsed time 10365.374501228333\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "batch loss: 0.004735540132969618\n",
      "batch accuracy: 1.0\n",
      "doing 175 / 291\n",
      "elapsed time 10444.935237884521\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 0.9990\n",
      "batch loss: 0.006380078382790089\n",
      "batch accuracy: 0.9990234375\n",
      "doing 176 / 291\n",
      "elapsed time 10523.92287325859\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "batch loss: 0.004215390421450138\n",
      "batch accuracy: 1.0\n",
      "doing 177 / 291\n",
      "elapsed time 10601.955187797546\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "batch loss: 0.003561930265277624\n",
      "batch accuracy: 1.0\n",
      "doing 178 / 291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 10682.174149036407\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9990\n",
      "batch loss: 0.0033643413335084915\n",
      "batch accuracy: 0.9990234375\n",
      "doing 179 / 291\n",
      "elapsed time 10763.90272808075\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.003276103176176548\n",
      "batch accuracy: 1.0\n",
      "doing 180 / 291\n",
      "elapsed time 10844.011433839798\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "batch loss: 0.003872110042721033\n",
      "batch accuracy: 1.0\n",
      "doing 181 / 291\n",
      "elapsed time 10923.743601322174\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 0.9990\n",
      "batch loss: 0.004486908204853535\n",
      "batch accuracy: 0.9990234375\n",
      "doing 182 / 291\n",
      "elapsed time 11005.693364620209\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9980\n",
      "batch loss: 0.007992907427251339\n",
      "batch accuracy: 0.998046875\n",
      "doing 183 / 291\n",
      "elapsed time 11088.932710647583\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.003316350281238556\n",
      "batch accuracy: 1.0\n",
      "doing 184 / 291\n",
      "elapsed time 11169.170439720154\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9990\n",
      "batch loss: 0.004846495576202869\n",
      "batch accuracy: 0.9990234375\n",
      "doing 185 / 291\n",
      "elapsed time 11249.241828203201\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.003791862167418003\n",
      "batch accuracy: 1.0\n",
      "doing 186 / 291\n",
      "elapsed time 11327.126985788345\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "batch loss: 0.00368682062253356\n",
      "batch accuracy: 1.0\n",
      "doing 187 / 291\n",
      "elapsed time 11408.159772396088\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "batch loss: 0.004412400536239147\n",
      "batch accuracy: 1.0\n",
      "doing 188 / 291\n",
      "elapsed time 11484.20960021019\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.0038294082041829824\n",
      "batch accuracy: 1.0\n",
      "doing 189 / 291\n",
      "elapsed time 11559.306323289871\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "batch loss: 0.0032465262338519096\n",
      "batch accuracy: 1.0\n",
      "doing 190 / 291\n",
      "elapsed time 11636.728004217148\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "batch loss: 0.005576147697865963\n",
      "batch accuracy: 1.0\n",
      "doing 191 / 291\n",
      "elapsed time 11712.698866128922\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 0.9990\n",
      "batch loss: 0.005616366863250732\n",
      "batch accuracy: 0.9990234375\n",
      "doing 192 / 291\n",
      "elapsed time 11793.730145215988\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "batch loss: 0.003616777714341879\n",
      "batch accuracy: 1.0\n",
      "doing 193 / 291\n",
      "elapsed time 11873.065832614899\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "batch loss: 0.005403672344982624\n",
      "batch accuracy: 1.0\n",
      "doing 194 / 291\n",
      "elapsed time 11953.394787788391\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "batch loss: 0.004495422821491957\n",
      "batch accuracy: 1.0\n",
      "doing 195 / 291\n",
      "elapsed time 12032.853530406952\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9990\n",
      "batch loss: 0.004076342564076185\n",
      "batch accuracy: 0.9990234375\n",
      "doing 196 / 291\n",
      "elapsed time 12113.432246923447\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9990\n",
      "batch loss: 0.006880083121359348\n",
      "batch accuracy: 0.9990234375\n",
      "doing 197 / 291\n",
      "elapsed time 12193.020383834839\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9990\n",
      "batch loss: 0.004719678312540054\n",
      "batch accuracy: 0.9990234375\n",
      "doing 198 / 291\n",
      "elapsed time 12273.289908647537\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9990\n",
      "batch loss: 0.004424314014613628\n",
      "batch accuracy: 0.9990234375\n",
      "doing 199 / 291\n",
      "elapsed time 12352.323674917221\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0023041076492518187\n",
      "batch accuracy: 1.0\n",
      "doing 200 / 291\n",
      "elapsed time 12433.519972801208\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9990\n",
      "batch loss: 0.003689289093017578\n",
      "batch accuracy: 0.9990234375\n",
      "doing 201 / 291\n",
      "elapsed time 12511.440402030945\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9980\n",
      "batch loss: 0.016144055873155594\n",
      "batch accuracy: 0.998046875\n",
      "doing 202 / 291\n",
      "elapsed time 12590.439414024353\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9990\n",
      "batch loss: 0.009704390540719032\n",
      "batch accuracy: 0.9990234375\n",
      "doing 203 / 291\n",
      "elapsed time 12669.595968008041\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "batch loss: 0.003212141804397106\n",
      "batch accuracy: 1.0\n",
      "doing 204 / 291\n",
      "elapsed time 12748.44067311287\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "batch loss: 0.003607638878747821\n",
      "batch accuracy: 1.0\n",
      "doing 205 / 291\n",
      "elapsed time 12824.246166944504\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0119 - accuracy: 0.9990\n",
      "batch loss: 0.011898471042513847\n",
      "batch accuracy: 0.9990234375\n",
      "doing 206 / 291\n",
      "elapsed time 12904.725943803787\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9990\n",
      "batch loss: 0.00942915491759777\n",
      "batch accuracy: 0.9990234375\n",
      "doing 207 / 291\n",
      "elapsed time 12986.874136209488\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9980\n",
      "batch loss: 0.007501061074435711\n",
      "batch accuracy: 0.998046875\n",
      "doing 208 / 291\n",
      "elapsed time 13064.830609083176\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "batch loss: 0.004850839730352163\n",
      "batch accuracy: 1.0\n",
      "doing 209 / 291\n",
      "elapsed time 13144.10035777092\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "batch loss: 0.003863692283630371\n",
      "batch accuracy: 1.0\n",
      "doing 210 / 291\n",
      "elapsed time 13222.929018735886\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9990\n",
      "batch loss: 0.010581143200397491\n",
      "batch accuracy: 0.9990234375\n",
      "doing 211 / 291\n",
      "elapsed time 13302.702686071396\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "batch loss: 0.005937526002526283\n",
      "batch accuracy: 0.9990234375\n",
      "doing 212 / 291\n",
      "elapsed time 13377.245224952698\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9990\n",
      "batch loss: 0.0055091953836381435\n",
      "batch accuracy: 0.9990234375\n",
      "doing 213 / 291\n",
      "elapsed time 13456.667407512665\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9990\n",
      "batch loss: 0.006959571503102779\n",
      "batch accuracy: 0.9990234375\n",
      "doing 214 / 291\n",
      "elapsed time 13538.398854970932\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 0.9990\n",
      "batch loss: 0.00499246921390295\n",
      "batch accuracy: 0.9990234375\n",
      "doing 215 / 291\n",
      "elapsed time 13613.151438474655\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "batch loss: 0.004651292692869902\n",
      "batch accuracy: 1.0\n",
      "doing 216 / 291\n",
      "elapsed time 13693.130270004272\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "batch loss: 0.004200418014079332\n",
      "batch accuracy: 1.0\n",
      "doing 217 / 291\n",
      "elapsed time 13772.544344902039\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "batch loss: 0.0048496839590370655\n",
      "batch accuracy: 1.0\n",
      "doing 218 / 291\n",
      "elapsed time 13850.92878651619\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "batch loss: 0.0054343268275260925\n",
      "batch accuracy: 1.0\n",
      "doing 219 / 291\n",
      "elapsed time 13931.376841068268\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9990\n",
      "batch loss: 0.004771296866238117\n",
      "batch accuracy: 0.9990234375\n",
      "doing 220 / 291\n",
      "elapsed time 14012.656440258026\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.003779338439926505\n",
      "batch accuracy: 1.0\n",
      "doing 221 / 291\n",
      "elapsed time 14092.06568646431\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "batch loss: 0.004093925468623638\n",
      "batch accuracy: 1.0\n",
      "doing 222 / 291\n",
      "elapsed time 14172.888830184937\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9990\n",
      "batch loss: 0.003425426548346877\n",
      "batch accuracy: 0.9990234375\n",
      "doing 223 / 291\n",
      "elapsed time 14254.971620082855\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "batch loss: 0.003537612734362483\n",
      "batch accuracy: 1.0\n",
      "doing 224 / 291\n",
      "elapsed time 14336.061740875244\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 0.9990\n",
      "batch loss: 0.006417007651180029\n",
      "batch accuracy: 0.9990234375\n",
      "doing 225 / 291\n",
      "elapsed time 14416.252218008041\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "batch loss: 0.004496424458920956\n",
      "batch accuracy: 1.0\n",
      "doing 226 / 291\n",
      "elapsed time 14496.202160835266\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.002834359183907509\n",
      "batch accuracy: 1.0\n",
      "doing 227 / 291\n",
      "elapsed time 14578.04691195488\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "batch loss: 0.0024808424059301615\n",
      "batch accuracy: 1.0\n",
      "doing 228 / 291\n",
      "elapsed time 14658.052595853806\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.003305385820567608\n",
      "batch accuracy: 1.0\n",
      "doing 229 / 291\n",
      "elapsed time 14736.226202726364\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "batch loss: 0.0020555073861032724\n",
      "batch accuracy: 1.0\n",
      "doing 230 / 291\n",
      "elapsed time 14820.985642910004\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.0028324013110250235\n",
      "batch accuracy: 1.0\n",
      "doing 231 / 291\n",
      "elapsed time 14902.809503555298\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9980\n",
      "batch loss: 0.008926043286919594\n",
      "batch accuracy: 0.998046875\n",
      "doing 232 / 291\n",
      "elapsed time 14978.658979654312\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9990\n",
      "batch loss: 0.003523439634591341\n",
      "batch accuracy: 0.9990234375\n",
      "doing 233 / 291\n",
      "elapsed time 15056.844447851181\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9990\n",
      "batch loss: 0.00907395500689745\n",
      "batch accuracy: 0.9990234375\n",
      "doing 234 / 291\n",
      "elapsed time 15136.092275857925\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.003778537968173623\n",
      "batch accuracy: 1.0\n",
      "doing 235 / 291\n",
      "elapsed time 15218.804668188095\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9990\n",
      "batch loss: 0.005047533195465803\n",
      "batch accuracy: 0.9990234375\n",
      "doing 236 / 291\n",
      "elapsed time 15296.44329547882\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "batch loss: 0.00427706865593791\n",
      "batch accuracy: 1.0\n",
      "doing 237 / 291\n",
      "elapsed time 15377.920624256134\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "batch loss: 0.005637778900563717\n",
      "batch accuracy: 1.0\n",
      "doing 238 / 291\n",
      "elapsed time 15458.8352227211\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.003821895457804203\n",
      "batch accuracy: 1.0\n",
      "doing 239 / 291\n",
      "elapsed time 15537.721449375153\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "batch loss: 0.005655829794704914\n",
      "batch accuracy: 1.0\n",
      "doing 240 / 291\n",
      "elapsed time 15617.934087753296\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.0032648479100316763\n",
      "batch accuracy: 1.0\n",
      "doing 241 / 291\n",
      "elapsed time 15701.007084608078\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9990\n",
      "batch loss: 0.004805289208889008\n",
      "batch accuracy: 0.9990234375\n",
      "doing 242 / 291\n",
      "elapsed time 15779.681214094162\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "batch loss: 0.0044077178463339806\n",
      "batch accuracy: 1.0\n",
      "doing 243 / 291\n",
      "elapsed time 15859.141999959946\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0023411333095282316\n",
      "batch accuracy: 1.0\n",
      "doing 244 / 291\n",
      "elapsed time 15940.303592920303\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.9990\n",
      "batch loss: 0.003921027295291424\n",
      "batch accuracy: 0.9990234375\n",
      "doing 245 / 291\n",
      "elapsed time 16021.783566236496\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "batch loss: 0.004243507981300354\n",
      "batch accuracy: 1.0\n",
      "doing 246 / 291\n",
      "elapsed time 16101.41803431511\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "batch loss: 0.004421981517225504\n",
      "batch accuracy: 1.0\n",
      "doing 247 / 291\n",
      "elapsed time 16181.11474108696\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9990\n",
      "batch loss: 0.004525516182184219\n",
      "batch accuracy: 0.9990234375\n",
      "doing 248 / 291\n",
      "elapsed time 16262.1398062706\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.003809649031609297\n",
      "batch accuracy: 1.0\n",
      "doing 249 / 291\n",
      "elapsed time 16338.066802501678\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "batch loss: 0.0029967455193400383\n",
      "batch accuracy: 1.0\n",
      "doing 250 / 291\n",
      "elapsed time 16419.328523159027\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "batch loss: 0.004315698519349098\n",
      "batch accuracy: 1.0\n",
      "doing 251 / 291\n",
      "elapsed time 16496.96643972397\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9990\n",
      "batch loss: 0.004219065420329571\n",
      "batch accuracy: 0.9990234375\n",
      "doing 252 / 291\n",
      "elapsed time 16577.443385839462\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9980\n",
      "batch loss: 0.005853333510458469\n",
      "batch accuracy: 0.998046875\n",
      "doing 253 / 291\n",
      "elapsed time 16656.839448928833\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9990\n",
      "batch loss: 0.004132501780986786\n",
      "batch accuracy: 0.9990234375\n",
      "doing 254 / 291\n",
      "elapsed time 16736.37753391266\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "batch loss: 0.0021152698900550604\n",
      "batch accuracy: 1.0\n",
      "doing 255 / 291\n",
      "elapsed time 16817.16464829445\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.003767053596675396\n",
      "batch accuracy: 1.0\n",
      "doing 256 / 291\n",
      "elapsed time 16898.023277521133\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "batch loss: 0.005673401989042759\n",
      "batch accuracy: 1.0\n",
      "doing 257 / 291\n",
      "elapsed time 16978.079158067703\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "batch loss: 0.005335482768714428\n",
      "batch accuracy: 1.0\n",
      "doing 258 / 291\n",
      "elapsed time 17057.852496385574\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9980\n",
      "batch loss: 0.007038578391075134\n",
      "batch accuracy: 0.998046875\n",
      "doing 259 / 291\n",
      "elapsed time 17139.493618249893\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.003758186474442482\n",
      "batch accuracy: 1.0\n",
      "doing 260 / 291\n",
      "elapsed time 17218.769062757492\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9990\n",
      "batch loss: 0.004406848456710577\n",
      "batch accuracy: 0.9990234375\n",
      "doing 261 / 291\n",
      "elapsed time 17300.577208280563\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9990\n",
      "batch loss: 0.0040241023525595665\n",
      "batch accuracy: 0.9990234375\n",
      "doing 262 / 291\n",
      "elapsed time 17378.35047006607\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "batch loss: 0.003733322024345398\n",
      "batch accuracy: 1.0\n",
      "doing 263 / 291\n",
      "elapsed time 17460.639798402786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "batch loss: 0.0032200838904827833\n",
      "batch accuracy: 1.0\n",
      "doing 264 / 291\n",
      "elapsed time 17540.1219997406\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 0.9980\n",
      "batch loss: 0.005888328421860933\n",
      "batch accuracy: 0.998046875\n",
      "doing 265 / 291\n",
      "elapsed time 17619.350049972534\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "batch loss: 0.004008989781141281\n",
      "batch accuracy: 1.0\n",
      "doing 266 / 291\n",
      "elapsed time 17699.904747247696\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9971\n",
      "batch loss: 0.011948695406317711\n",
      "batch accuracy: 0.9970703125\n",
      "doing 267 / 291\n",
      "elapsed time 17782.03853034973\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "batch loss: 0.003358990652486682\n",
      "batch accuracy: 1.0\n",
      "doing 268 / 291\n",
      "elapsed time 17863.53765964508\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "batch loss: 0.003670869627967477\n",
      "batch accuracy: 1.0\n",
      "doing 269 / 291\n",
      "elapsed time 17944.83192896843\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9990\n",
      "batch loss: 0.0031295358203351498\n",
      "batch accuracy: 0.9990234375\n",
      "doing 270 / 291\n",
      "elapsed time 18026.630625724792\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "batch loss: 0.002637858036905527\n",
      "batch accuracy: 1.0\n",
      "doing 271 / 291\n",
      "elapsed time 18106.35791993141\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9990\n",
      "batch loss: 0.004845402203500271\n",
      "batch accuracy: 0.9990234375\n",
      "doing 272 / 291\n",
      "elapsed time 18187.035112142563\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9990\n",
      "batch loss: 0.004867364652454853\n",
      "batch accuracy: 0.9990234375\n",
      "doing 273 / 291\n",
      "elapsed time 18269.14108157158\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9990\n",
      "batch loss: 0.004184563644230366\n",
      "batch accuracy: 0.9990234375\n",
      "doing 274 / 291\n",
      "elapsed time 18350.574026823044\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9980\n",
      "batch loss: 0.005514837335795164\n",
      "batch accuracy: 0.998046875\n",
      "doing 275 / 291\n",
      "elapsed time 18428.391339302063\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "batch loss: 0.0031268876045942307\n",
      "batch accuracy: 1.0\n",
      "doing 276 / 291\n",
      "elapsed time 18506.803419828415\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "batch loss: 0.0030553839169442654\n",
      "batch accuracy: 1.0\n",
      "doing 277 / 291\n",
      "elapsed time 18585.005697011948\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9990\n",
      "batch loss: 0.00572461262345314\n",
      "batch accuracy: 0.9990234375\n",
      "doing 278 / 291\n",
      "elapsed time 18662.92160987854\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 0.9990\n",
      "batch loss: 0.00649486668407917\n",
      "batch accuracy: 0.9990234375\n",
      "doing 279 / 291\n",
      "elapsed time 18743.617064476013\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "batch loss: 0.003396340413019061\n",
      "batch accuracy: 1.0\n",
      "doing 280 / 291\n",
      "elapsed time 18822.751788377762\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "batch loss: 0.004616704769432545\n",
      "batch accuracy: 1.0\n",
      "doing 281 / 291\n",
      "elapsed time 18902.419893741608\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0023203601595014334\n",
      "batch accuracy: 1.0\n",
      "doing 282 / 291\n",
      "elapsed time 18980.009206533432\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9990\n",
      "batch loss: 0.009436998516321182\n",
      "batch accuracy: 0.9990234375\n",
      "doing 283 / 291\n",
      "elapsed time 19060.070487499237\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "batch loss: 0.002863586414605379\n",
      "batch accuracy: 1.0\n",
      "doing 284 / 291\n",
      "elapsed time 19139.98319721222\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "batch loss: 0.004069988150149584\n",
      "batch accuracy: 1.0\n",
      "doing 285 / 291\n",
      "elapsed time 19220.00456047058\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9990\n",
      "batch loss: 0.004090338014066219\n",
      "batch accuracy: 0.9990234375\n",
      "doing 286 / 291\n",
      "elapsed time 19299.000725507736\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.9990\n",
      "batch loss: 0.005020341370254755\n",
      "batch accuracy: 0.9990234375\n",
      "doing 287 / 291\n",
      "elapsed time 19378.524779319763\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9990\n",
      "batch loss: 0.007187620736658573\n",
      "batch accuracy: 0.9990234375\n",
      "doing 288 / 291\n",
      "elapsed time 19458.129856348038\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "batch loss: 0.004136068746447563\n",
      "batch accuracy: 1.0\n",
      "doing 289 / 291\n",
      "elapsed time 19536.556015968323\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "batch loss: 0.0026877864729613066\n",
      "batch accuracy: 1.0\n",
      "doing 290 / 291\n",
      "elapsed time 19540.916954040527\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.9655e-04 - accuracy: 1.0000\n",
      "batch loss: 0.0003965500509366393\n",
      "batch accuracy: 1.0\n",
      "Train loss 0.004875735866619575\n",
      "Train accuracy 0.9994529907646048\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5371 - accuracy: 0.9164\n",
      "Validation loss: 0.5370606184005737\n",
      "Validation accuracy: 0.9164444208145142\n",
      "==================================================\n",
      "3 / 5\n",
      "doing 0 / 291\n",
      "elapsed time 52.75060033798218\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9980\n",
      "batch loss: 0.00532939936965704\n",
      "batch accuracy: 0.998046875\n",
      "doing 1 / 291\n",
      "elapsed time 104.52032017707825\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "batch loss: 0.001909676007926464\n",
      "batch accuracy: 1.0\n",
      "doing 2 / 291\n",
      "elapsed time 155.85138821601868\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "batch loss: 0.00293851550668478\n",
      "batch accuracy: 1.0\n",
      "doing 3 / 291\n",
      "elapsed time 208.64439392089844\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9990\n",
      "batch loss: 0.003342181909829378\n",
      "batch accuracy: 0.9990234375\n",
      "doing 4 / 291\n",
      "elapsed time 260.97522807121277\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.0032535966020077467\n",
      "batch accuracy: 1.0\n",
      "doing 5 / 291\n",
      "elapsed time 316.005038022995\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "batch loss: 0.003356463508680463\n",
      "batch accuracy: 1.0\n",
      "doing 6 / 291\n",
      "elapsed time 370.52622413635254\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9990\n",
      "batch loss: 0.004746902268379927\n",
      "batch accuracy: 0.9990234375\n",
      "doing 7 / 291\n",
      "elapsed time 424.2187297344208\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9990\n",
      "batch loss: 0.005048440769314766\n",
      "batch accuracy: 0.9990234375\n",
      "doing 8 / 291\n",
      "elapsed time 476.57826495170593\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "batch loss: 0.0029730643145740032\n",
      "batch accuracy: 1.0\n",
      "doing 9 / 291\n",
      "elapsed time 531.8331568241119\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "batch loss: 0.0026541058905422688\n",
      "batch accuracy: 1.0\n",
      "doing 10 / 291\n",
      "elapsed time 585.1796925067902\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "batch loss: 0.001960551831871271\n",
      "batch accuracy: 1.0\n",
      "doing 11 / 291\n",
      "elapsed time 637.2187955379486\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.002808203222230077\n",
      "batch accuracy: 1.0\n",
      "doing 12 / 291\n",
      "elapsed time 687.3479747772217\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.003316012676805258\n",
      "batch accuracy: 1.0\n",
      "doing 13 / 291\n",
      "elapsed time 739.0360178947449\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "batch loss: 0.002070664893835783\n",
      "batch accuracy: 1.0\n",
      "doing 14 / 291\n",
      "elapsed time 790.3121662139893\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "batch loss: 0.0019100347999483347\n",
      "batch accuracy: 1.0\n",
      "doing 15 / 291\n",
      "elapsed time 842.0875675678253\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "batch loss: 0.0034308754839003086\n",
      "batch accuracy: 1.0\n",
      "doing 16 / 291\n",
      "elapsed time 893.2226476669312\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9990\n",
      "batch loss: 0.0045893192291259766\n",
      "batch accuracy: 0.9990234375\n",
      "doing 17 / 291\n",
      "elapsed time 950.5367436408997\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.003266803687438369\n",
      "batch accuracy: 1.0\n",
      "doing 18 / 291\n",
      "elapsed time 1003.465175151825\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9990\n",
      "batch loss: 0.0034897320438176394\n",
      "batch accuracy: 0.9990234375\n",
      "doing 19 / 291\n",
      "elapsed time 1059.0628011226654\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "batch loss: 0.0037451600655913353\n",
      "batch accuracy: 1.0\n",
      "doing 20 / 291\n",
      "elapsed time 1111.0429139137268\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "batch loss: 0.0027103356551378965\n",
      "batch accuracy: 1.0\n",
      "doing 21 / 291\n",
      "elapsed time 1163.5212171077728\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "batch loss: 0.0024345656856894493\n",
      "batch accuracy: 1.0\n",
      "doing 22 / 291\n",
      "elapsed time 1217.2230355739594\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "batch loss: 0.0029443728271871805\n",
      "batch accuracy: 1.0\n",
      "doing 23 / 291\n",
      "elapsed time 1274.6879165172577\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "batch loss: 0.002861905377358198\n",
      "batch accuracy: 1.0\n",
      "doing 24 / 291\n",
      "elapsed time 1325.4801700115204\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "batch loss: 0.002500808797776699\n",
      "batch accuracy: 1.0\n",
      "doing 25 / 291\n",
      "elapsed time 1382.147783756256\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9990\n",
      "batch loss: 0.005332790315151215\n",
      "batch accuracy: 0.9990234375\n",
      "doing 26 / 291\n",
      "elapsed time 1437.6423444747925\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.003307957202196121\n",
      "batch accuracy: 1.0\n",
      "doing 27 / 291\n",
      "elapsed time 1491.7910549640656\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "batch loss: 0.004521805793046951\n",
      "batch accuracy: 1.0\n",
      "doing 28 / 291\n",
      "elapsed time 1547.0572986602783\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "batch loss: 0.002872113138437271\n",
      "batch accuracy: 1.0\n",
      "doing 29 / 291\n",
      "elapsed time 1601.338216304779\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0022987714037299156\n",
      "batch accuracy: 1.0\n",
      "doing 30 / 291\n",
      "elapsed time 1656.7767541408539\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "batch loss: 0.003036909271031618\n",
      "batch accuracy: 1.0\n",
      "doing 31 / 291\n",
      "elapsed time 1708.4231100082397\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "batch loss: 0.003681552829220891\n",
      "batch accuracy: 1.0\n",
      "doing 32 / 291\n",
      "elapsed time 1765.0120739936829\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "batch loss: 0.002383043523877859\n",
      "batch accuracy: 1.0\n",
      "doing 33 / 291\n",
      "elapsed time 1820.1541194915771\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "batch loss: 0.0021312416065484285\n",
      "batch accuracy: 1.0\n",
      "doing 34 / 291\n",
      "elapsed time 1871.7420403957367\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.002275096485391259\n",
      "batch accuracy: 1.0\n",
      "doing 35 / 291\n",
      "elapsed time 1927.0642561912537\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9990\n",
      "batch loss: 0.003826950676739216\n",
      "batch accuracy: 0.9990234375\n",
      "doing 36 / 291\n",
      "elapsed time 1976.8522853851318\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "batch loss: 0.0023893998004496098\n",
      "batch accuracy: 1.0\n",
      "doing 37 / 291\n",
      "elapsed time 2037.236277103424\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "batch loss: 0.0020896545611321926\n",
      "batch accuracy: 1.0\n",
      "doing 38 / 291\n",
      "elapsed time 2107.629183769226\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "batch loss: 0.003003557212650776\n",
      "batch accuracy: 1.0\n",
      "doing 39 / 291\n",
      "elapsed time 2184.428517818451\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "batch loss: 0.0030912640504539013\n",
      "batch accuracy: 1.0\n",
      "doing 40 / 291\n",
      "elapsed time 2259.181984901428\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "batch loss: 0.0030650857370346785\n",
      "batch accuracy: 1.0\n",
      "doing 41 / 291\n",
      "elapsed time 2332.287817955017\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9990\n",
      "batch loss: 0.004313589073717594\n",
      "batch accuracy: 0.9990234375\n",
      "doing 42 / 291\n",
      "elapsed time 2405.0521504879\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "batch loss: 0.0020898673683404922\n",
      "batch accuracy: 1.0\n",
      "doing 43 / 291\n",
      "elapsed time 2478.319722175598\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "batch loss: 0.0017886718269437551\n",
      "batch accuracy: 1.0\n",
      "doing 44 / 291\n",
      "elapsed time 2556.597616672516\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "batch loss: 0.002471152227371931\n",
      "batch accuracy: 1.0\n",
      "doing 45 / 291\n",
      "elapsed time 2631.9934256076813\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9990\n",
      "batch loss: 0.00441173417493701\n",
      "batch accuracy: 0.9990234375\n",
      "doing 46 / 291\n",
      "elapsed time 2706.204010248184\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "batch loss: 0.002534712664783001\n",
      "batch accuracy: 1.0\n",
      "doing 47 / 291\n",
      "elapsed time 2784.157195329666\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "batch loss: 0.0028891353867948055\n",
      "batch accuracy: 1.0\n",
      "doing 48 / 291\n",
      "elapsed time 2861.086597442627\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "batch loss: 0.0014420808292925358\n",
      "batch accuracy: 1.0\n",
      "doing 49 / 291\n",
      "elapsed time 2942.692586660385\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "batch loss: 0.0037013546098023653\n",
      "batch accuracy: 1.0\n",
      "doing 50 / 291\n",
      "elapsed time 3022.448346376419\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "batch loss: 0.0025424747727811337\n",
      "batch accuracy: 1.0\n",
      "doing 51 / 291\n",
      "elapsed time 3099.3164002895355\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "batch loss: 0.0016771251102909446\n",
      "batch accuracy: 1.0\n",
      "doing 52 / 291\n",
      "elapsed time 3179.426464319229\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "batch loss: 0.0018798854434862733\n",
      "batch accuracy: 1.0\n",
      "doing 53 / 291\n",
      "elapsed time 3257.9008252620697\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "batch loss: 0.002058587968349457\n",
      "batch accuracy: 1.0\n",
      "doing 54 / 291\n",
      "elapsed time 3337.727151632309\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "batch loss: 0.002095239469781518\n",
      "batch accuracy: 1.0\n",
      "doing 55 / 291\n",
      "elapsed time 3427.889764070511\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "batch loss: 0.002657894976437092\n",
      "batch accuracy: 1.0\n",
      "doing 56 / 291\n",
      "elapsed time 3513.083391904831\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0022599680814892054\n",
      "batch accuracy: 1.0\n",
      "doing 57 / 291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 3592.769460916519\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "batch loss: 0.0018957946449518204\n",
      "batch accuracy: 1.0\n",
      "doing 58 / 291\n",
      "elapsed time 3686.2029542922974\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "batch loss: 0.0012366143055260181\n",
      "batch accuracy: 1.0\n",
      "doing 59 / 291\n",
      "elapsed time 3776.5696127414703\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "batch loss: 0.0019256845116615295\n",
      "batch accuracy: 1.0\n",
      "doing 60 / 291\n",
      "elapsed time 3860.520961999893\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "batch loss: 0.001736803911626339\n",
      "batch accuracy: 1.0\n",
      "doing 61 / 291\n",
      "elapsed time 3947.0973007678986\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "batch loss: 0.0024672728031873703\n",
      "batch accuracy: 1.0\n",
      "doing 62 / 291\n",
      "elapsed time 4033.515110015869\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "batch loss: 0.0014594083186239004\n",
      "batch accuracy: 1.0\n",
      "doing 63 / 291\n",
      "elapsed time 4121.579902887344\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "batch loss: 0.0019670026376843452\n",
      "batch accuracy: 1.0\n",
      "doing 64 / 291\n",
      "elapsed time 4208.284764051437\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "batch loss: 0.0016561099328100681\n",
      "batch accuracy: 1.0\n",
      "doing 65 / 291\n",
      "elapsed time 4300.668776273727\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0022676726803183556\n",
      "batch accuracy: 1.0\n",
      "doing 66 / 291\n",
      "elapsed time 4395.87922000885\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "batch loss: 0.002578089479357004\n",
      "batch accuracy: 1.0\n",
      "doing 67 / 291\n",
      "elapsed time 4488.716583967209\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "batch loss: 0.0017493723426014185\n",
      "batch accuracy: 1.0\n",
      "doing 68 / 291\n",
      "elapsed time 4587.801114559174\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "batch loss: 0.0020071931648999453\n",
      "batch accuracy: 1.0\n",
      "doing 69 / 291\n",
      "elapsed time 4692.887001991272\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "batch loss: 0.0017225622432306409\n",
      "batch accuracy: 1.0\n",
      "doing 70 / 291\n",
      "elapsed time 4786.483438491821\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "batch loss: 0.001080846879631281\n",
      "batch accuracy: 1.0\n",
      "doing 71 / 291\n",
      "elapsed time 4875.341773986816\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0022585131227970123\n",
      "batch accuracy: 1.0\n",
      "doing 72 / 291\n",
      "elapsed time 4965.628857851028\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "batch loss: 0.0016691023483872414\n",
      "batch accuracy: 1.0\n",
      "doing 73 / 291\n",
      "elapsed time 5056.539973020554\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "batch loss: 0.0015342652332037687\n",
      "batch accuracy: 1.0\n",
      "doing 74 / 291\n",
      "elapsed time 5148.432492494583\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "batch loss: 0.002405267208814621\n",
      "batch accuracy: 1.0\n",
      "doing 75 / 291\n",
      "elapsed time 5240.423512220383\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0023092993069440126\n",
      "batch accuracy: 1.0\n",
      "doing 76 / 291\n",
      "elapsed time 5341.032723665237\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9990\n",
      "batch loss: 0.0041815610602498055\n",
      "batch accuracy: 0.9990234375\n",
      "doing 77 / 291\n",
      "elapsed time 5443.429740905762\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9990\n",
      "batch loss: 0.005725313443690538\n",
      "batch accuracy: 0.9990234375\n",
      "doing 78 / 291\n",
      "elapsed time 5570.10503077507\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0023329700343310833\n",
      "batch accuracy: 1.0\n",
      "doing 79 / 291\n",
      "elapsed time 5685.290339231491\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0023164507001638412\n",
      "batch accuracy: 1.0\n",
      "doing 80 / 291\n",
      "elapsed time 5792.142033100128\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "batch loss: 0.0017042281106114388\n",
      "batch accuracy: 1.0\n",
      "doing 81 / 291\n",
      "elapsed time 5900.764908075333\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9990\n",
      "batch loss: 0.004934300668537617\n",
      "batch accuracy: 0.9990234375\n",
      "doing 82 / 291\n",
      "elapsed time 6017.11107468605\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "batch loss: 0.0019974694587290287\n",
      "batch accuracy: 1.0\n",
      "doing 83 / 291\n",
      "elapsed time 6126.9979910850525\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "batch loss: 0.002221549628302455\n",
      "batch accuracy: 1.0\n",
      "doing 84 / 291\n",
      "elapsed time 6237.667115211487\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "batch loss: 0.0017718772869557142\n",
      "batch accuracy: 1.0\n",
      "doing 85 / 291\n",
      "elapsed time 6347.582620382309\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "batch loss: 0.0031123729422688484\n",
      "batch accuracy: 1.0\n",
      "doing 86 / 291\n",
      "elapsed time 6466.2351150512695\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "batch loss: 0.0031684166751801968\n",
      "batch accuracy: 1.0\n",
      "doing 87 / 291\n",
      "elapsed time 6585.432433843613\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.0027543699834495783\n",
      "batch accuracy: 1.0\n",
      "doing 88 / 291\n",
      "elapsed time 6695.74630188942\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "batch loss: 0.0012878200504928827\n",
      "batch accuracy: 1.0\n",
      "doing 89 / 291\n",
      "elapsed time 6808.700073480606\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "batch loss: 0.002538977889344096\n",
      "batch accuracy: 1.0\n",
      "doing 90 / 291\n",
      "elapsed time 6936.600690841675\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "batch loss: 0.001960495952516794\n",
      "batch accuracy: 1.0\n",
      "doing 91 / 291\n",
      "elapsed time 7066.520015239716\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "batch loss: 0.002704625017940998\n",
      "batch accuracy: 1.0\n",
      "doing 92 / 291\n",
      "elapsed time 7188.357597112656\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "batch loss: 0.004214792978018522\n",
      "batch accuracy: 1.0\n",
      "doing 93 / 291\n",
      "elapsed time 7301.753302574158\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "batch loss: 0.005903162062168121\n",
      "batch accuracy: 1.0\n",
      "doing 94 / 291\n",
      "elapsed time 7413.245054483414\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9990\n",
      "batch loss: 0.003257125848904252\n",
      "batch accuracy: 0.9990234375\n",
      "doing 95 / 291\n",
      "elapsed time 7524.31675195694\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "batch loss: 0.0027154607232660055\n",
      "batch accuracy: 1.0\n",
      "doing 96 / 291\n",
      "elapsed time 7636.080962181091\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9971\n",
      "batch loss: 0.011829834431409836\n",
      "batch accuracy: 0.9970703125\n",
      "doing 97 / 291\n",
      "elapsed time 7749.694705963135\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9980\n",
      "batch loss: 0.006399994716048241\n",
      "batch accuracy: 0.998046875\n",
      "doing 98 / 291\n",
      "elapsed time 7867.959235191345\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.0032977531664073467\n",
      "batch accuracy: 1.0\n",
      "doing 99 / 291\n",
      "elapsed time 7993.703102827072\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9961\n",
      "batch loss: 0.0102694658562541\n",
      "batch accuracy: 0.99609375\n",
      "doing 100 / 291\n",
      "elapsed time 8125.959396123886\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.003301813267171383\n",
      "batch accuracy: 1.0\n",
      "doing 101 / 291\n",
      "elapsed time 8260.6100897789\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "batch loss: 0.0030113705433905125\n",
      "batch accuracy: 1.0\n",
      "doing 102 / 291\n",
      "elapsed time 8396.005225658417\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9990\n",
      "batch loss: 0.0036854716017842293\n",
      "batch accuracy: 0.9990234375\n",
      "doing 103 / 291\n",
      "elapsed time 8526.868114233017\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "batch loss: 0.004140926990658045\n",
      "batch accuracy: 1.0\n",
      "doing 104 / 291\n",
      "elapsed time 8664.77931022644\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9980\n",
      "batch loss: 0.007782435975968838\n",
      "batch accuracy: 0.998046875\n",
      "doing 105 / 291\n",
      "elapsed time 8803.54851102829\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9990\n",
      "batch loss: 0.0076966118067502975\n",
      "batch accuracy: 0.9990234375\n",
      "doing 106 / 291\n",
      "elapsed time 8944.719063043594\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "batch loss: 0.002432961016893387\n",
      "batch accuracy: 1.0\n",
      "doing 107 / 291\n",
      "elapsed time 9075.753102779388\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 0.9990\n",
      "batch loss: 0.004669709596782923\n",
      "batch accuracy: 0.9990234375\n",
      "doing 108 / 291\n",
      "elapsed time 9205.970220804214\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 0.9990\n",
      "batch loss: 0.005719349253922701\n",
      "batch accuracy: 0.9990234375\n",
      "doing 109 / 291\n",
      "elapsed time 9325.703245162964\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9990\n",
      "batch loss: 0.006999065633863211\n",
      "batch accuracy: 0.9990234375\n",
      "doing 110 / 291\n",
      "elapsed time 9447.917488574982\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9990\n",
      "batch loss: 0.0028994292952120304\n",
      "batch accuracy: 0.9990234375\n",
      "doing 111 / 291\n",
      "elapsed time 9577.78852391243\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "batch loss: 0.0029912760946899652\n",
      "batch accuracy: 1.0\n",
      "doing 112 / 291\n",
      "elapsed time 9708.672813892365\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9990\n",
      "batch loss: 0.0060263159684836864\n",
      "batch accuracy: 0.9990234375\n",
      "doing 113 / 291\n",
      "elapsed time 9846.910567045212\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.9990\n",
      "batch loss: 0.00496323686093092\n",
      "batch accuracy: 0.9990234375\n",
      "doing 114 / 291\n",
      "elapsed time 9988.740500688553\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "batch loss: 0.003516481025144458\n",
      "batch accuracy: 1.0\n",
      "doing 115 / 291\n",
      "elapsed time 10129.98213839531\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9980\n",
      "batch loss: 0.0063135623931884766\n",
      "batch accuracy: 0.998046875\n",
      "doing 116 / 291\n",
      "elapsed time 10275.523652791977\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "batch loss: 0.005905747413635254\n",
      "batch accuracy: 0.9990234375\n",
      "doing 117 / 291\n",
      "elapsed time 10419.205266237259\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "batch loss: 0.0020610149949789047\n",
      "batch accuracy: 1.0\n",
      "doing 118 / 291\n",
      "elapsed time 10557.62076330185\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9990\n",
      "batch loss: 0.008761519566178322\n",
      "batch accuracy: 0.9990234375\n",
      "doing 119 / 291\n",
      "elapsed time 10696.707325696945\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "batch loss: 0.003966054413467646\n",
      "batch accuracy: 1.0\n",
      "doing 120 / 291\n",
      "elapsed time 10839.753239393234\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.9990\n",
      "batch loss: 0.004813903942704201\n",
      "batch accuracy: 0.9990234375\n",
      "doing 121 / 291\n",
      "elapsed time 10982.42985033989\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.003785199485719204\n",
      "batch accuracy: 1.0\n",
      "doing 122 / 291\n",
      "elapsed time 11123.983814954758\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "batch loss: 0.0026201780419796705\n",
      "batch accuracy: 1.0\n",
      "doing 123 / 291\n",
      "elapsed time 11266.450234889984\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9990\n",
      "batch loss: 0.0038606671150773764\n",
      "batch accuracy: 0.9990234375\n",
      "doing 124 / 291\n",
      "elapsed time 11411.372817277908\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9990\n",
      "batch loss: 0.003824046812951565\n",
      "batch accuracy: 0.9990234375\n",
      "doing 125 / 291\n",
      "elapsed time 11554.80425453186\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9980\n",
      "batch loss: 0.007205519825220108\n",
      "batch accuracy: 0.998046875\n",
      "doing 126 / 291\n",
      "elapsed time 11700.48831319809\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9980\n",
      "batch loss: 0.007122041657567024\n",
      "batch accuracy: 0.998046875\n",
      "doing 127 / 291\n",
      "elapsed time 11841.232556581497\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "batch loss: 0.004753535147756338\n",
      "batch accuracy: 1.0\n",
      "doing 128 / 291\n",
      "elapsed time 11988.71420264244\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9980\n",
      "batch loss: 0.008661530911922455\n",
      "batch accuracy: 0.998046875\n",
      "doing 129 / 291\n",
      "elapsed time 12134.02767086029\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9980\n",
      "batch loss: 0.008295830339193344\n",
      "batch accuracy: 0.998046875\n",
      "doing 130 / 291\n",
      "elapsed time 12280.84059214592\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 0.9990\n",
      "batch loss: 0.0064912764355540276\n",
      "batch accuracy: 0.9990234375\n",
      "doing 131 / 291\n",
      "elapsed time 12426.89752149582\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "batch loss: 0.004663235507905483\n",
      "batch accuracy: 1.0\n",
      "doing 132 / 291\n",
      "elapsed time 12572.70416545868\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9951\n",
      "batch loss: 0.014935977756977081\n",
      "batch accuracy: 0.9951171875\n",
      "doing 133 / 291\n",
      "elapsed time 12721.400506019592\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9863\n",
      "batch loss: 0.04593169689178467\n",
      "batch accuracy: 0.986328125\n",
      "doing 134 / 291\n",
      "elapsed time 12871.66464471817\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 0.9883\n",
      "batch loss: 0.028043964877724648\n",
      "batch accuracy: 0.98828125\n",
      "doing 135 / 291\n",
      "elapsed time 13015.044367074966\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1116 - accuracy: 0.9844\n",
      "batch loss: 0.11155633628368378\n",
      "batch accuracy: 0.984375\n",
      "doing 136 / 291\n",
      "elapsed time 13168.605088472366\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0299 - accuracy: 0.9951\n",
      "batch loss: 0.02986951172351837\n",
      "batch accuracy: 0.9951171875\n",
      "doing 137 / 291\n",
      "elapsed time 13317.294432640076\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0365 - accuracy: 0.9951\n",
      "batch loss: 0.0365038737654686\n",
      "batch accuracy: 0.9951171875\n",
      "doing 138 / 291\n",
      "elapsed time 13461.857079744339\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9844\n",
      "batch loss: 0.060585662722587585\n",
      "batch accuracy: 0.984375\n",
      "doing 139 / 291\n",
      "elapsed time 13615.032635688782\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0262 - accuracy: 0.9932\n",
      "batch loss: 0.02620142325758934\n",
      "batch accuracy: 0.9931640625\n",
      "doing 140 / 291\n",
      "elapsed time 13763.7354991436\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0319 - accuracy: 0.9893\n",
      "batch loss: 0.03190033882856369\n",
      "batch accuracy: 0.9892578125\n",
      "doing 141 / 291\n",
      "elapsed time 13911.213545560837\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9854\n",
      "batch loss: 0.040134258568286896\n",
      "batch accuracy: 0.9853515625\n",
      "doing 142 / 291\n",
      "elapsed time 14059.236588954926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0524 - accuracy: 0.9883\n",
      "batch loss: 0.05236516892910004\n",
      "batch accuracy: 0.98828125\n",
      "doing 143 / 291\n",
      "elapsed time 14212.771812438965\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.9863\n",
      "batch loss: 0.0348653607070446\n",
      "batch accuracy: 0.986328125\n",
      "doing 144 / 291\n",
      "elapsed time 14362.865790843964\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 0.9941\n",
      "batch loss: 0.03165915235877037\n",
      "batch accuracy: 0.994140625\n",
      "doing 145 / 291\n",
      "elapsed time 14518.364914894104\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0216 - accuracy: 0.9951\n",
      "batch loss: 0.02158736065030098\n",
      "batch accuracy: 0.9951171875\n",
      "doing 146 / 291\n",
      "elapsed time 14667.956662416458\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9932\n",
      "batch loss: 0.0264064222574234\n",
      "batch accuracy: 0.9931640625\n",
      "doing 147 / 291\n",
      "elapsed time 14832.094696760178\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 0.9902\n",
      "batch loss: 0.020232947543263435\n",
      "batch accuracy: 0.990234375\n",
      "doing 148 / 291\n",
      "elapsed time 14983.59585571289\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.9922\n",
      "batch loss: 0.02667650580406189\n",
      "batch accuracy: 0.9921875\n",
      "doing 149 / 291\n",
      "elapsed time 15129.865097522736\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9951\n",
      "batch loss: 0.01389750000089407\n",
      "batch accuracy: 0.9951171875\n",
      "doing 150 / 291\n",
      "elapsed time 15279.121536016464\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9941\n",
      "batch loss: 0.01361845899373293\n",
      "batch accuracy: 0.994140625\n",
      "doing 151 / 291\n",
      "elapsed time 15420.714244127274\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9922\n",
      "batch loss: 0.02032935619354248\n",
      "batch accuracy: 0.9921875\n",
      "doing 152 / 291\n",
      "elapsed time 15556.998997449875\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9971\n",
      "batch loss: 0.014718146063387394\n",
      "batch accuracy: 0.9970703125\n",
      "doing 153 / 291\n",
      "elapsed time 15694.174976348877\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 0.9951\n",
      "batch loss: 0.024373115971684456\n",
      "batch accuracy: 0.9951171875\n",
      "doing 154 / 291\n",
      "elapsed time 15841.377900600433\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 0.9951\n",
      "batch loss: 0.01617198996245861\n",
      "batch accuracy: 0.9951171875\n",
      "doing 155 / 291\n",
      "elapsed time 15986.617852210999\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9971\n",
      "batch loss: 0.013368443585932255\n",
      "batch accuracy: 0.9970703125\n",
      "doing 156 / 291\n",
      "elapsed time 16132.569640636444\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9980\n",
      "batch loss: 0.00908052921295166\n",
      "batch accuracy: 0.998046875\n",
      "doing 157 / 291\n",
      "elapsed time 16274.592757940292\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9990\n",
      "batch loss: 0.01183239370584488\n",
      "batch accuracy: 0.9990234375\n",
      "doing 158 / 291\n",
      "elapsed time 16420.615576028824\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9980\n",
      "batch loss: 0.011636939831078053\n",
      "batch accuracy: 0.998046875\n",
      "doing 159 / 291\n",
      "elapsed time 16566.47640323639\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9971\n",
      "batch loss: 0.011815912090241909\n",
      "batch accuracy: 0.9970703125\n",
      "doing 160 / 291\n",
      "elapsed time 16706.345428943634\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9980\n",
      "batch loss: 0.010215457528829575\n",
      "batch accuracy: 0.998046875\n",
      "doing 161 / 291\n",
      "elapsed time 16853.45144701004\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "batch loss: 0.007622621487826109\n",
      "batch accuracy: 1.0\n",
      "doing 162 / 291\n",
      "elapsed time 17001.93792128563\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9961\n",
      "batch loss: 0.012924004346132278\n",
      "batch accuracy: 0.99609375\n",
      "doing 163 / 291\n",
      "elapsed time 17150.7596411705\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 0.9971\n",
      "batch loss: 0.010316368192434311\n",
      "batch accuracy: 0.9970703125\n",
      "doing 164 / 291\n",
      "elapsed time 17294.832436323166\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9971\n",
      "batch loss: 0.008672136813402176\n",
      "batch accuracy: 0.9970703125\n",
      "doing 165 / 291\n",
      "elapsed time 17428.854178905487\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 0.9990\n",
      "batch loss: 0.007550145499408245\n",
      "batch accuracy: 0.9990234375\n",
      "doing 166 / 291\n",
      "elapsed time 17560.538058519363\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9980\n",
      "batch loss: 0.008840389549732208\n",
      "batch accuracy: 0.998046875\n",
      "doing 167 / 291\n",
      "elapsed time 17692.685777187347\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "batch loss: 0.007727122865617275\n",
      "batch accuracy: 1.0\n",
      "doing 168 / 291\n",
      "elapsed time 17825.04246044159\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9990\n",
      "batch loss: 0.008335706777870655\n",
      "batch accuracy: 0.9990234375\n",
      "doing 169 / 291\n",
      "elapsed time 17947.436553001404\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9980\n",
      "batch loss: 0.01026787981390953\n",
      "batch accuracy: 0.998046875\n",
      "doing 170 / 291\n",
      "elapsed time 18066.241318702698\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "batch loss: 0.007516269106417894\n",
      "batch accuracy: 1.0\n",
      "doing 171 / 291\n",
      "elapsed time 18190.921805143356\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9980\n",
      "batch loss: 0.012676716782152653\n",
      "batch accuracy: 0.998046875\n",
      "doing 172 / 291\n",
      "elapsed time 18312.83594274521\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "batch loss: 0.00606925506144762\n",
      "batch accuracy: 1.0\n",
      "doing 173 / 291\n",
      "elapsed time 18447.8330578804\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "batch loss: 0.0076788924634456635\n",
      "batch accuracy: 1.0\n",
      "doing 174 / 291\n",
      "elapsed time 18579.62606859207\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 0.9990\n",
      "batch loss: 0.006436220370233059\n",
      "batch accuracy: 0.9990234375\n",
      "doing 175 / 291\n",
      "elapsed time 18712.023250579834\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9990\n",
      "batch loss: 0.008166207000613213\n",
      "batch accuracy: 0.9990234375\n",
      "doing 176 / 291\n",
      "elapsed time 18849.16800379753\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "batch loss: 0.008603989146649837\n",
      "batch accuracy: 1.0\n",
      "doing 177 / 291\n",
      "elapsed time 18985.901599168777\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "batch loss: 0.005940758623182774\n",
      "batch accuracy: 1.0\n",
      "doing 178 / 291\n",
      "elapsed time 19111.625799894333\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9990\n",
      "batch loss: 0.01123211719095707\n",
      "batch accuracy: 0.9990234375\n",
      "doing 179 / 291\n",
      "elapsed time 19241.107759714127\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "batch loss: 0.006449165754020214\n",
      "batch accuracy: 1.0\n",
      "doing 180 / 291\n",
      "elapsed time 19366.464656352997\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9990\n",
      "batch loss: 0.008478963747620583\n",
      "batch accuracy: 0.9990234375\n",
      "doing 181 / 291\n",
      "elapsed time 19490.61399078369\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "batch loss: 0.006412934511899948\n",
      "batch accuracy: 1.0\n",
      "doing 182 / 291\n",
      "elapsed time 19617.083153486252\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "batch loss: 0.0061822207644581795\n",
      "batch accuracy: 1.0\n",
      "doing 183 / 291\n",
      "elapsed time 19750.98813867569\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "batch loss: 0.006288338452577591\n",
      "batch accuracy: 1.0\n",
      "doing 184 / 291\n",
      "elapsed time 19891.913546323776\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "batch loss: 0.004747419618070126\n",
      "batch accuracy: 1.0\n",
      "doing 185 / 291\n",
      "elapsed time 20031.695975780487\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9990\n",
      "batch loss: 0.009937560185790062\n",
      "batch accuracy: 0.9990234375\n",
      "doing 186 / 291\n",
      "elapsed time 20167.562423706055\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "batch loss: 0.006521454080939293\n",
      "batch accuracy: 1.0\n",
      "doing 187 / 291\n",
      "elapsed time 20304.514822006226\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "batch loss: 0.006538436748087406\n",
      "batch accuracy: 1.0\n",
      "doing 188 / 291\n",
      "elapsed time 20439.176393032074\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "batch loss: 0.004272873979061842\n",
      "batch accuracy: 1.0\n",
      "doing 189 / 291\n",
      "elapsed time 20567.584079504013\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "batch loss: 0.006742390803992748\n",
      "batch accuracy: 1.0\n",
      "doing 190 / 291\n",
      "elapsed time 20705.02753853798\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "batch loss: 0.0052131665870547295\n",
      "batch accuracy: 1.0\n",
      "doing 191 / 291\n",
      "elapsed time 20827.88979101181\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.003801574930548668\n",
      "batch accuracy: 1.0\n",
      "doing 192 / 291\n",
      "elapsed time 20955.6422996521\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9980\n",
      "batch loss: 0.00562850758433342\n",
      "batch accuracy: 0.998046875\n",
      "doing 193 / 291\n",
      "elapsed time 21095.326300621033\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "batch loss: 0.0042724693194031715\n",
      "batch accuracy: 1.0\n",
      "doing 194 / 291\n",
      "elapsed time 21234.92972421646\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0081 - accuracy: 0.9980\n",
      "batch loss: 0.008058669976890087\n",
      "batch accuracy: 0.998046875\n",
      "doing 195 / 291\n",
      "elapsed time 21363.7283782959\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "batch loss: 0.0042999861761927605\n",
      "batch accuracy: 1.0\n",
      "doing 196 / 291\n",
      "elapsed time 21485.10807442665\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9990\n",
      "batch loss: 0.0066564264707267284\n",
      "batch accuracy: 0.9990234375\n",
      "doing 197 / 291\n",
      "elapsed time 21606.104257822037\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "batch loss: 0.004795403685420752\n",
      "batch accuracy: 1.0\n",
      "doing 198 / 291\n",
      "elapsed time 21726.329100608826\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "batch loss: 0.006284884177148342\n",
      "batch accuracy: 1.0\n",
      "doing 199 / 291\n",
      "elapsed time 21845.859087467194\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "batch loss: 0.005180258769541979\n",
      "batch accuracy: 1.0\n",
      "doing 200 / 291\n",
      "elapsed time 21964.642800331116\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 0.9971\n",
      "batch loss: 0.007942847907543182\n",
      "batch accuracy: 0.9970703125\n",
      "doing 201 / 291\n",
      "elapsed time 22074.759647130966\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "batch loss: 0.006088677793741226\n",
      "batch accuracy: 0.998046875\n",
      "doing 202 / 291\n",
      "elapsed time 22183.255862236023\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9980\n",
      "batch loss: 0.005756580736488104\n",
      "batch accuracy: 0.998046875\n",
      "doing 203 / 291\n",
      "elapsed time 22293.87685751915\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "batch loss: 0.0039542983286082745\n",
      "batch accuracy: 1.0\n",
      "doing 204 / 291\n",
      "elapsed time 22408.038287639618\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.9980\n",
      "batch loss: 0.007377991918474436\n",
      "batch accuracy: 0.998046875\n",
      "doing 205 / 291\n",
      "elapsed time 22522.260051488876\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "batch loss: 0.004644474480301142\n",
      "batch accuracy: 1.0\n",
      "doing 206 / 291\n",
      "elapsed time 22634.804903268814\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "batch loss: 0.0030864954460412264\n",
      "batch accuracy: 1.0\n",
      "doing 207 / 291\n",
      "elapsed time 22748.475878477097\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "batch loss: 0.0031033363193273544\n",
      "batch accuracy: 1.0\n",
      "doing 208 / 291\n",
      "elapsed time 22860.131804466248\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9980\n",
      "batch loss: 0.008569376543164253\n",
      "batch accuracy: 0.998046875\n",
      "doing 209 / 291\n",
      "elapsed time 22973.610469818115\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "batch loss: 0.003723656525835395\n",
      "batch accuracy: 1.0\n",
      "doing 210 / 291\n",
      "elapsed time 23086.13384628296\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "batch loss: 0.003884377656504512\n",
      "batch accuracy: 1.0\n",
      "doing 211 / 291\n",
      "elapsed time 23200.829423666\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.0033481470309197903\n",
      "batch accuracy: 1.0\n",
      "doing 212 / 291\n",
      "elapsed time 23314.126627206802\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9980\n",
      "batch loss: 0.005551359616219997\n",
      "batch accuracy: 0.998046875\n",
      "doing 213 / 291\n",
      "elapsed time 23424.598177433014\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 0.9990\n",
      "batch loss: 0.005533539690077305\n",
      "batch accuracy: 0.9990234375\n",
      "doing 214 / 291\n",
      "elapsed time 23536.361463546753\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "batch loss: 0.004128080792725086\n",
      "batch accuracy: 1.0\n",
      "doing 215 / 291\n",
      "elapsed time 23647.923523902893\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "batch loss: 0.0035471853334456682\n",
      "batch accuracy: 1.0\n",
      "doing 216 / 291\n",
      "elapsed time 23765.10023546219\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.002772750100120902\n",
      "batch accuracy: 1.0\n",
      "doing 217 / 291\n",
      "elapsed time 23880.271386384964\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "batch loss: 0.0031691943295300007\n",
      "batch accuracy: 1.0\n",
      "doing 218 / 291\n",
      "elapsed time 23997.500571489334\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 0.9990\n",
      "batch loss: 0.004586508497595787\n",
      "batch accuracy: 0.9990234375\n",
      "doing 219 / 291\n",
      "elapsed time 24110.26531481743\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9990\n",
      "batch loss: 0.004382764454931021\n",
      "batch accuracy: 0.9990234375\n",
      "doing 220 / 291\n",
      "elapsed time 24222.082668066025\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "batch loss: 0.0038601551204919815\n",
      "batch accuracy: 1.0\n",
      "doing 221 / 291\n",
      "elapsed time 24326.4709277153\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "batch loss: 0.005945920012891293\n",
      "batch accuracy: 0.9990234375\n",
      "doing 222 / 291\n",
      "elapsed time 24431.23770594597\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 0.9990\n",
      "batch loss: 0.00491604208946228\n",
      "batch accuracy: 0.9990234375\n",
      "doing 223 / 291\n",
      "elapsed time 24532.794995307922\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9990\n",
      "batch loss: 0.003596981754526496\n",
      "batch accuracy: 0.9990234375\n",
      "doing 224 / 291\n",
      "elapsed time 24635.564992427826\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 0.9990\n",
      "batch loss: 0.006622230634093285\n",
      "batch accuracy: 0.9990234375\n",
      "doing 225 / 291\n",
      "elapsed time 24739.503786802292\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9990\n",
      "batch loss: 0.008202250115573406\n",
      "batch accuracy: 0.9990234375\n",
      "doing 226 / 291\n",
      "elapsed time 24841.9992146492\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "batch loss: 0.0031747177708894014\n",
      "batch accuracy: 1.0\n",
      "doing 227 / 291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 24948.143361091614\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "batch loss: 0.004582335241138935\n",
      "batch accuracy: 1.0\n",
      "doing 228 / 291\n",
      "elapsed time 25050.177313804626\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9990\n",
      "batch loss: 0.004382693208754063\n",
      "batch accuracy: 0.9990234375\n",
      "doing 229 / 291\n",
      "elapsed time 25152.56917500496\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9990\n",
      "batch loss: 0.0038605770096182823\n",
      "batch accuracy: 0.9990234375\n",
      "doing 230 / 291\n",
      "elapsed time 25260.09503674507\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "batch loss: 0.004398428834974766\n",
      "batch accuracy: 1.0\n",
      "doing 231 / 291\n",
      "elapsed time 25363.796778440475\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 0.9990\n",
      "batch loss: 0.004904585890471935\n",
      "batch accuracy: 0.9990234375\n",
      "doing 232 / 291\n",
      "elapsed time 25467.976559638977\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "batch loss: 0.0035091701429337263\n",
      "batch accuracy: 1.0\n",
      "doing 233 / 291\n",
      "elapsed time 25571.370099067688\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "batch loss: 0.0035668713971972466\n",
      "batch accuracy: 1.0\n",
      "doing 234 / 291\n",
      "elapsed time 25675.54040122032\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "batch loss: 0.002550041303038597\n",
      "batch accuracy: 1.0\n",
      "doing 235 / 291\n",
      "elapsed time 25791.997106552124\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9990\n",
      "batch loss: 0.003478908445686102\n",
      "batch accuracy: 0.9990234375\n",
      "doing 236 / 291\n",
      "elapsed time 25905.655135154724\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9980\n",
      "batch loss: 0.007580950390547514\n",
      "batch accuracy: 0.998046875\n",
      "doing 237 / 291\n",
      "elapsed time 26017.55060648918\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "batch loss: 0.001982906134799123\n",
      "batch accuracy: 1.0\n",
      "doing 238 / 291\n",
      "elapsed time 26117.896614313126\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9990\n",
      "batch loss: 0.004375357646495104\n",
      "batch accuracy: 0.9990234375\n",
      "doing 239 / 291\n",
      "elapsed time 26219.860109090805\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.0032589503098279238\n",
      "batch accuracy: 1.0\n",
      "doing 240 / 291\n",
      "elapsed time 26325.25564599037\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "batch loss: 0.0029052174650132656\n",
      "batch accuracy: 1.0\n",
      "doing 241 / 291\n",
      "elapsed time 26429.547912836075\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9990\n",
      "batch loss: 0.003922389820218086\n",
      "batch accuracy: 0.9990234375\n",
      "doing 242 / 291\n",
      "elapsed time 26533.85777068138\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9990\n",
      "batch loss: 0.003428766969591379\n",
      "batch accuracy: 0.9990234375\n",
      "doing 243 / 291\n",
      "elapsed time 26638.057263612747\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "batch loss: 0.0026708757504820824\n",
      "batch accuracy: 1.0\n",
      "doing 244 / 291\n",
      "elapsed time 26740.498747348785\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "batch loss: 0.0029587880708277225\n",
      "batch accuracy: 1.0\n",
      "doing 245 / 291\n",
      "elapsed time 26844.559687137604\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9990\n",
      "batch loss: 0.003344261087477207\n",
      "batch accuracy: 0.9990234375\n",
      "doing 246 / 291\n",
      "elapsed time 26947.15839123726\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9990\n",
      "batch loss: 0.006445799022912979\n",
      "batch accuracy: 0.9990234375\n",
      "doing 247 / 291\n",
      "elapsed time 27054.508680343628\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "batch loss: 0.004110432229936123\n",
      "batch accuracy: 1.0\n",
      "doing 248 / 291\n",
      "elapsed time 27169.06102180481\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9990\n",
      "batch loss: 0.004437216557562351\n",
      "batch accuracy: 0.9990234375\n",
      "doing 249 / 291\n",
      "elapsed time 27283.06666636467\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 0.9990\n",
      "batch loss: 0.005301566794514656\n",
      "batch accuracy: 0.9990234375\n",
      "doing 250 / 291\n",
      "elapsed time 27397.071747541428\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "batch loss: 0.003499313024803996\n",
      "batch accuracy: 1.0\n",
      "doing 251 / 291\n",
      "elapsed time 27512.072796821594\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "batch loss: 0.0036181416362524033\n",
      "batch accuracy: 1.0\n",
      "doing 252 / 291\n",
      "elapsed time 27625.046415567398\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "batch loss: 0.003610598621889949\n",
      "batch accuracy: 1.0\n",
      "doing 253 / 291\n",
      "elapsed time 27738.25323367119\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "batch loss: 0.0034967337269335985\n",
      "batch accuracy: 1.0\n",
      "doing 254 / 291\n",
      "elapsed time 27851.398983240128\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.0033254106529057026\n",
      "batch accuracy: 1.0\n",
      "doing 255 / 291\n",
      "elapsed time 27966.540142297745\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9990\n",
      "batch loss: 0.004514620173722506\n",
      "batch accuracy: 0.9990234375\n",
      "doing 256 / 291\n",
      "elapsed time 28082.696139335632\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "batch loss: 0.004025918431580067\n",
      "batch accuracy: 1.0\n",
      "doing 257 / 291\n",
      "elapsed time 28194.91321849823\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "batch loss: 0.0036618164740502834\n",
      "batch accuracy: 1.0\n",
      "doing 258 / 291\n",
      "elapsed time 28304.622578382492\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "batch loss: 0.004768888466060162\n",
      "batch accuracy: 1.0\n",
      "doing 259 / 291\n",
      "elapsed time 28417.24570298195\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9980\n",
      "batch loss: 0.011973059736192226\n",
      "batch accuracy: 0.998046875\n",
      "doing 260 / 291\n",
      "elapsed time 28531.033987045288\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "batch loss: 0.004014287143945694\n",
      "batch accuracy: 1.0\n",
      "doing 261 / 291\n",
      "elapsed time 28647.319296598434\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "batch loss: 0.002675216179341078\n",
      "batch accuracy: 1.0\n",
      "doing 262 / 291\n",
      "elapsed time 28758.869031906128\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9990\n",
      "batch loss: 0.0038729882799088955\n",
      "batch accuracy: 0.9990234375\n",
      "doing 263 / 291\n",
      "elapsed time 28871.739325523376\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "batch loss: 0.004133375361561775\n",
      "batch accuracy: 1.0\n",
      "doing 264 / 291\n",
      "elapsed time 28982.318252563477\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "batch loss: 0.004395746160298586\n",
      "batch accuracy: 1.0\n",
      "doing 265 / 291\n",
      "elapsed time 29094.05820131302\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "batch loss: 0.002637707395479083\n",
      "batch accuracy: 1.0\n",
      "doing 266 / 291\n",
      "elapsed time 29206.201954126358\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "batch loss: 0.004195230547338724\n",
      "batch accuracy: 1.0\n",
      "doing 267 / 291\n",
      "elapsed time 29315.66223859787\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "batch loss: 0.003517839591950178\n",
      "batch accuracy: 1.0\n",
      "doing 268 / 291\n",
      "elapsed time 29427.8121945858\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9990\n",
      "batch loss: 0.010522148571908474\n",
      "batch accuracy: 0.9990234375\n",
      "doing 269 / 291\n",
      "elapsed time 29539.81636762619\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9990\n",
      "batch loss: 0.004233705345541239\n",
      "batch accuracy: 0.9990234375\n",
      "doing 270 / 291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 29647.643122434616\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.002803601324558258\n",
      "batch accuracy: 1.0\n",
      "doing 271 / 291\n",
      "elapsed time 29746.666246175766\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "batch loss: 0.00253051845356822\n",
      "batch accuracy: 1.0\n",
      "doing 272 / 291\n",
      "elapsed time 29843.821642160416\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "batch loss: 0.0017524712020531297\n",
      "batch accuracy: 1.0\n",
      "doing 273 / 291\n",
      "elapsed time 29940.936698436737\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "batch loss: 0.002204136224463582\n",
      "batch accuracy: 1.0\n",
      "doing 274 / 291\n",
      "elapsed time 30040.08496284485\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "batch loss: 0.0029492967296391726\n",
      "batch accuracy: 1.0\n",
      "doing 275 / 291\n",
      "elapsed time 30138.089821338654\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "batch loss: 0.0030970266088843346\n",
      "batch accuracy: 1.0\n",
      "doing 276 / 291\n",
      "elapsed time 30233.61240172386\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "batch loss: 0.003107129829004407\n",
      "batch accuracy: 1.0\n",
      "doing 277 / 291\n",
      "elapsed time 30328.517087459564\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "batch loss: 0.0025717264506965876\n",
      "batch accuracy: 1.0\n",
      "doing 278 / 291\n",
      "elapsed time 30423.76952314377\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "batch loss: 0.002631124807521701\n",
      "batch accuracy: 1.0\n",
      "doing 279 / 291\n",
      "elapsed time 30518.677799224854\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 0.9990\n",
      "batch loss: 0.003346541430801153\n",
      "batch accuracy: 0.9990234375\n",
      "doing 280 / 291\n",
      "elapsed time 30612.583348035812\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "batch loss: 0.002523699076846242\n",
      "batch accuracy: 1.0\n",
      "doing 281 / 291\n",
      "elapsed time 30706.433351278305\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "batch loss: 0.00313344644382596\n",
      "batch accuracy: 1.0\n",
      "doing 282 / 291\n",
      "elapsed time 30803.31420826912\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "batch loss: 0.00221403781324625\n",
      "batch accuracy: 1.0\n",
      "doing 283 / 291\n",
      "elapsed time 30896.9264626503\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0022563268430531025\n",
      "batch accuracy: 1.0\n",
      "doing 284 / 291\n",
      "elapsed time 30993.127973794937\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "batch loss: 0.001972784288227558\n",
      "batch accuracy: 1.0\n",
      "doing 285 / 291\n",
      "elapsed time 31089.308479070663\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "batch loss: 0.0025725546292960644\n",
      "batch accuracy: 1.0\n",
      "doing 286 / 291\n",
      "elapsed time 31182.770753622055\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "batch loss: 0.002070485847070813\n",
      "batch accuracy: 1.0\n",
      "doing 287 / 291\n",
      "elapsed time 31276.591509103775\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.002286946401000023\n",
      "batch accuracy: 1.0\n",
      "doing 288 / 291\n",
      "elapsed time 31369.773630857468\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.002284376649186015\n",
      "batch accuracy: 1.0\n",
      "doing 289 / 291\n",
      "elapsed time 31461.986446619034\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 0.9990\n",
      "batch loss: 0.003304895246401429\n",
      "batch accuracy: 0.9990234375\n",
      "doing 290 / 291\n",
      "elapsed time 31467.04322052002\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "batch loss: 0.0018587169470265508\n",
      "batch accuracy: 1.0\n",
      "Train loss 0.0066069645212668785\n",
      "Train accuracy 0.9988824903350515\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5649 - accuracy: 0.9196\n",
      "Validation loss: 0.5649308562278748\n",
      "Validation accuracy: 0.9195555448532104\n",
      "==================================================\n",
      "4 / 5\n",
      "doing 0 / 291\n",
      "elapsed time 93.40936756134033\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0023315211292356253\n",
      "batch accuracy: 1.0\n",
      "doing 1 / 291\n",
      "elapsed time 188.07604694366455\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "batch loss: 0.003206942928954959\n",
      "batch accuracy: 1.0\n",
      "doing 2 / 291\n",
      "elapsed time 281.11268067359924\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "batch loss: 0.0021548238582909107\n",
      "batch accuracy: 1.0\n",
      "doing 3 / 291\n",
      "elapsed time 374.55781865119934\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "batch loss: 0.0015770439058542252\n",
      "batch accuracy: 1.0\n",
      "doing 4 / 291\n",
      "elapsed time 471.0636291503906\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.002279058564454317\n",
      "batch accuracy: 1.0\n",
      "doing 5 / 291\n",
      "elapsed time 569.4158899784088\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "batch loss: 0.001407470554113388\n",
      "batch accuracy: 1.0\n",
      "doing 6 / 291\n",
      "elapsed time 674.9256961345673\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "batch loss: 0.001671633217483759\n",
      "batch accuracy: 1.0\n",
      "doing 7 / 291\n",
      "elapsed time 778.0871193408966\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "batch loss: 0.00223542214371264\n",
      "batch accuracy: 1.0\n",
      "doing 8 / 291\n",
      "elapsed time 880.3844101428986\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "batch loss: 0.0018485886976122856\n",
      "batch accuracy: 1.0\n",
      "doing 9 / 291\n",
      "elapsed time 981.9713506698608\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.0028255425859242678\n",
      "batch accuracy: 1.0\n",
      "doing 10 / 291\n",
      "elapsed time 1083.53945851326\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0023461999371647835\n",
      "batch accuracy: 1.0\n",
      "doing 11 / 291\n",
      "elapsed time 1187.255295753479\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.0027938643470406532\n",
      "batch accuracy: 1.0\n",
      "doing 12 / 291\n",
      "elapsed time 1285.7472469806671\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "batch loss: 0.0019613932818174362\n",
      "batch accuracy: 1.0\n",
      "doing 13 / 291\n",
      "elapsed time 1388.598981142044\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "batch loss: 0.0019501012284308672\n",
      "batch accuracy: 1.0\n",
      "doing 14 / 291\n",
      "elapsed time 1493.258585691452\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0023047705180943012\n",
      "batch accuracy: 1.0\n",
      "doing 15 / 291\n",
      "elapsed time 1603.6104626655579\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "batch loss: 0.0021751096937805414\n",
      "batch accuracy: 1.0\n",
      "doing 16 / 291\n",
      "elapsed time 1710.8822176456451\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "batch loss: 0.0024898808915168047\n",
      "batch accuracy: 1.0\n",
      "doing 17 / 291\n",
      "elapsed time 1819.7779026031494\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "batch loss: 0.0020025335252285004\n",
      "batch accuracy: 1.0\n",
      "doing 18 / 291\n",
      "elapsed time 1928.1654391288757\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "batch loss: 0.0015219127526506782\n",
      "batch accuracy: 1.0\n",
      "doing 19 / 291\n",
      "elapsed time 2042.0599973201752\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "batch loss: 0.0031714513897895813\n",
      "batch accuracy: 1.0\n",
      "doing 20 / 291\n",
      "elapsed time 2165.9454765319824\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9990\n",
      "batch loss: 0.0036121990997344255\n",
      "batch accuracy: 0.9990234375\n",
      "doing 21 / 291\n",
      "elapsed time 2286.908893108368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.0037676719948649406\n",
      "batch accuracy: 1.0\n",
      "doing 22 / 291\n",
      "elapsed time 2403.573315382004\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9990\n",
      "batch loss: 0.005182255990803242\n",
      "batch accuracy: 0.9990234375\n",
      "doing 23 / 291\n",
      "elapsed time 2521.723771095276\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "batch loss: 0.001634787768125534\n",
      "batch accuracy: 1.0\n",
      "doing 24 / 291\n",
      "elapsed time 2640.054066181183\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "batch loss: 0.0025489251129329205\n",
      "batch accuracy: 1.0\n",
      "doing 25 / 291\n",
      "elapsed time 2757.3690321445465\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "batch loss: 0.0026694622356444597\n",
      "batch accuracy: 1.0\n",
      "doing 26 / 291\n",
      "elapsed time 2873.0004749298096\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9990\n",
      "batch loss: 0.0035574613139033318\n",
      "batch accuracy: 0.9990234375\n",
      "doing 27 / 291\n",
      "elapsed time 2990.431268930435\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.002820489462465048\n",
      "batch accuracy: 1.0\n",
      "doing 28 / 291\n",
      "elapsed time 3107.5475606918335\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "batch loss: 0.0021827444434165955\n",
      "batch accuracy: 1.0\n",
      "doing 29 / 291\n",
      "elapsed time 3225.6498103141785\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9990\n",
      "batch loss: 0.0040040030144155025\n",
      "batch accuracy: 0.9990234375\n",
      "doing 30 / 291\n",
      "elapsed time 3342.3383524417877\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "batch loss: 0.003013378707692027\n",
      "batch accuracy: 1.0\n",
      "doing 31 / 291\n",
      "elapsed time 3460.5062804222107\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "batch loss: 0.0035476668272167444\n",
      "batch accuracy: 1.0\n",
      "doing 32 / 291\n",
      "elapsed time 3576.5178186893463\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9990\n",
      "batch loss: 0.005314355716109276\n",
      "batch accuracy: 0.9990234375\n",
      "doing 33 / 291\n",
      "elapsed time 3690.8662552833557\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "batch loss: 0.0024889761116355658\n",
      "batch accuracy: 1.0\n",
      "doing 34 / 291\n",
      "elapsed time 3807.598363637924\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "batch loss: 0.002605206100270152\n",
      "batch accuracy: 1.0\n",
      "doing 35 / 291\n",
      "elapsed time 3922.8612887859344\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "batch loss: 0.0020677782595157623\n",
      "batch accuracy: 1.0\n",
      "doing 36 / 291\n",
      "elapsed time 4034.960602283478\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "batch loss: 0.0028548911213874817\n",
      "batch accuracy: 1.0\n",
      "doing 37 / 291\n",
      "elapsed time 4146.373667240143\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 0.9990\n",
      "batch loss: 0.0032391310669481754\n",
      "batch accuracy: 0.9990234375\n",
      "doing 38 / 291\n",
      "elapsed time 4260.909533500671\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "batch loss: 0.0026709819212555885\n",
      "batch accuracy: 1.0\n",
      "doing 39 / 291\n",
      "elapsed time 4374.904322862625\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0023299590684473515\n",
      "batch accuracy: 1.0\n",
      "doing 40 / 291\n",
      "elapsed time 4481.1377389431\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "batch loss: 0.0019217083463445306\n",
      "batch accuracy: 1.0\n",
      "doing 41 / 291\n",
      "elapsed time 4591.120945215225\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "batch loss: 0.0025489190593361855\n",
      "batch accuracy: 1.0\n",
      "doing 42 / 291\n",
      "elapsed time 4703.776074171066\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9990\n",
      "batch loss: 0.004651982337236404\n",
      "batch accuracy: 0.9990234375\n",
      "doing 43 / 291\n",
      "elapsed time 4811.976046323776\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.9961\n",
      "batch loss: 0.010539108887314796\n",
      "batch accuracy: 0.99609375\n",
      "doing 44 / 291\n",
      "elapsed time 4921.419152021408\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9971\n",
      "batch loss: 0.00932530127465725\n",
      "batch accuracy: 0.9970703125\n",
      "doing 45 / 291\n",
      "elapsed time 5030.080690860748\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.0038421712815761566\n",
      "batch accuracy: 1.0\n",
      "doing 46 / 291\n",
      "elapsed time 5139.491532325745\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9980\n",
      "batch loss: 0.005461300257593393\n",
      "batch accuracy: 0.998046875\n",
      "doing 47 / 291\n",
      "elapsed time 5249.408131599426\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0275 - accuracy: 0.9951\n",
      "batch loss: 0.027548518031835556\n",
      "batch accuracy: 0.9951171875\n",
      "doing 48 / 291\n",
      "elapsed time 5355.192575216293\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0337 - accuracy: 0.9932\n",
      "batch loss: 0.033673692494630814\n",
      "batch accuracy: 0.9931640625\n",
      "doing 49 / 291\n",
      "elapsed time 5461.472188711166\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9961\n",
      "batch loss: 0.009802242740988731\n",
      "batch accuracy: 0.99609375\n",
      "doing 50 / 291\n",
      "elapsed time 5569.698214292526\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3815 - accuracy: 0.9590\n",
      "batch loss: 0.3814753293991089\n",
      "batch accuracy: 0.958984375\n",
      "doing 51 / 291\n",
      "elapsed time 5674.985785007477\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0187 - accuracy: 0.9941\n",
      "batch loss: 0.01869300752878189\n",
      "batch accuracy: 0.994140625\n",
      "doing 52 / 291\n",
      "elapsed time 5777.902354478836\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1937 - accuracy: 0.9434\n",
      "batch loss: 0.19371798634529114\n",
      "batch accuracy: 0.943359375\n",
      "doing 53 / 291\n",
      "elapsed time 5879.436099529266\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9990\n",
      "batch loss: 0.009724026545882225\n",
      "batch accuracy: 0.9990234375\n",
      "doing 54 / 291\n",
      "elapsed time 5982.607933998108\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3585 - accuracy: 0.9160\n",
      "batch loss: 0.3584679365158081\n",
      "batch accuracy: 0.916015625\n",
      "doing 55 / 291\n",
      "elapsed time 6086.154852628708\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0879 - accuracy: 0.9697\n",
      "batch loss: 0.08789131045341492\n",
      "batch accuracy: 0.9697265625\n",
      "doing 56 / 291\n",
      "elapsed time 6187.388979434967\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1004 - accuracy: 0.9688\n",
      "batch loss: 0.10041312128305435\n",
      "batch accuracy: 0.96875\n",
      "doing 57 / 291\n",
      "elapsed time 6288.282752275467\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0894 - accuracy: 0.9717\n",
      "batch loss: 0.0893736407160759\n",
      "batch accuracy: 0.9716796875\n",
      "doing 58 / 291\n",
      "elapsed time 6390.226674795151\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9893\n",
      "batch loss: 0.036301493644714355\n",
      "batch accuracy: 0.9892578125\n",
      "doing 59 / 291\n",
      "elapsed time 6492.103899717331\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1238 - accuracy: 0.9609\n",
      "batch loss: 0.12384465336799622\n",
      "batch accuracy: 0.9609375\n",
      "doing 60 / 291\n",
      "elapsed time 6593.2631158828735\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0819 - accuracy: 0.9697\n",
      "batch loss: 0.08194070309400558\n",
      "batch accuracy: 0.9697265625\n",
      "doing 61 / 291\n",
      "elapsed time 6693.7159123420715\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9932\n",
      "batch loss: 0.020006518810987473\n",
      "batch accuracy: 0.9931640625\n",
      "doing 62 / 291\n",
      "elapsed time 6797.460353374481\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.9775\n",
      "batch loss: 0.06730982661247253\n",
      "batch accuracy: 0.9775390625\n",
      "doing 63 / 291\n",
      "elapsed time 6908.675429105759\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1044 - accuracy: 0.9746\n",
      "batch loss: 0.10435955226421356\n",
      "batch accuracy: 0.974609375\n",
      "doing 64 / 291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 7024.757811307907\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9785\n",
      "batch loss: 0.05754875764250755\n",
      "batch accuracy: 0.978515625\n",
      "doing 65 / 291\n",
      "elapsed time 7137.345966100693\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9814\n",
      "batch loss: 0.05022026225924492\n",
      "batch accuracy: 0.9814453125\n",
      "doing 66 / 291\n",
      "elapsed time 7251.835193395615\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0287 - accuracy: 0.9912\n",
      "batch loss: 0.028748195618391037\n",
      "batch accuracy: 0.9912109375\n",
      "doing 67 / 291\n",
      "elapsed time 7365.090368032455\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0690 - accuracy: 0.9736\n",
      "batch loss: 0.06900633126497269\n",
      "batch accuracy: 0.9736328125\n",
      "doing 68 / 291\n",
      "elapsed time 7475.597012042999\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9844\n",
      "batch loss: 0.05067574977874756\n",
      "batch accuracy: 0.984375\n",
      "doing 69 / 291\n",
      "elapsed time 7590.187710762024\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 0.9961\n",
      "batch loss: 0.02676178514957428\n",
      "batch accuracy: 0.99609375\n",
      "doing 70 / 291\n",
      "elapsed time 7702.7811188697815\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0189 - accuracy: 0.9971\n",
      "batch loss: 0.018863167613744736\n",
      "batch accuracy: 0.9970703125\n",
      "doing 71 / 291\n",
      "elapsed time 7815.547027826309\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0312 - accuracy: 0.9902\n",
      "batch loss: 0.031164029613137245\n",
      "batch accuracy: 0.990234375\n",
      "doing 72 / 291\n",
      "elapsed time 7929.751208305359\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0337 - accuracy: 0.9893\n",
      "batch loss: 0.03370604291558266\n",
      "batch accuracy: 0.9892578125\n",
      "doing 73 / 291\n",
      "elapsed time 8041.686336755753\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9854\n",
      "batch loss: 0.05008302256464958\n",
      "batch accuracy: 0.9853515625\n",
      "doing 74 / 291\n",
      "elapsed time 8154.826050281525\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 0.9912\n",
      "batch loss: 0.034100450575351715\n",
      "batch accuracy: 0.9912109375\n",
      "doing 75 / 291\n",
      "elapsed time 8268.52625656128\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0358 - accuracy: 0.9893\n",
      "batch loss: 0.03577888756990433\n",
      "batch accuracy: 0.9892578125\n",
      "doing 76 / 291\n",
      "elapsed time 8382.769156694412\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9971\n",
      "batch loss: 0.02930058166384697\n",
      "batch accuracy: 0.9970703125\n",
      "doing 77 / 291\n",
      "elapsed time 8493.243689537048\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0217 - accuracy: 0.9971\n",
      "batch loss: 0.021664679050445557\n",
      "batch accuracy: 0.9970703125\n",
      "doing 78 / 291\n",
      "elapsed time 8610.72623515129\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9990\n",
      "batch loss: 0.014619281515479088\n",
      "batch accuracy: 0.9990234375\n",
      "doing 79 / 291\n",
      "elapsed time 8737.08080625534\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0222 - accuracy: 0.9941\n",
      "batch loss: 0.0222354456782341\n",
      "batch accuracy: 0.994140625\n",
      "doing 80 / 291\n",
      "elapsed time 8863.951110124588\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9932\n",
      "batch loss: 0.022004807367920876\n",
      "batch accuracy: 0.9931640625\n",
      "doing 81 / 291\n",
      "elapsed time 8995.28582072258\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0256 - accuracy: 0.9932\n",
      "batch loss: 0.02558288164436817\n",
      "batch accuracy: 0.9931640625\n",
      "doing 82 / 291\n",
      "elapsed time 9123.865360975266\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9961\n",
      "batch loss: 0.026947900652885437\n",
      "batch accuracy: 0.99609375\n",
      "doing 83 / 291\n",
      "elapsed time 9250.946797132492\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "batch loss: 0.016536079347133636\n",
      "batch accuracy: 1.0\n",
      "doing 84 / 291\n",
      "elapsed time 9376.535463571548\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0235 - accuracy: 0.9932\n",
      "batch loss: 0.023523759096860886\n",
      "batch accuracy: 0.9931640625\n",
      "doing 85 / 291\n",
      "elapsed time 9501.203066110611\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0237 - accuracy: 0.9932\n",
      "batch loss: 0.02366425283253193\n",
      "batch accuracy: 0.9931640625\n",
      "doing 86 / 291\n",
      "elapsed time 9627.61054944992\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9980\n",
      "batch loss: 0.014141952618956566\n",
      "batch accuracy: 0.998046875\n",
      "doing 87 / 291\n",
      "elapsed time 9750.911415100098\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9971\n",
      "batch loss: 0.014348415657877922\n",
      "batch accuracy: 0.9970703125\n",
      "doing 88 / 291\n",
      "elapsed time 9876.378247022629\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9971\n",
      "batch loss: 0.01569254696369171\n",
      "batch accuracy: 0.9970703125\n",
      "doing 89 / 291\n",
      "elapsed time 9996.448382139206\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9980\n",
      "batch loss: 0.01139218732714653\n",
      "batch accuracy: 0.998046875\n",
      "doing 90 / 291\n",
      "elapsed time 10117.456775665283\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0140 - accuracy: 0.9971\n",
      "batch loss: 0.013959523290395737\n",
      "batch accuracy: 0.9970703125\n",
      "doing 91 / 291\n",
      "elapsed time 10238.087720155716\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 0.9980\n",
      "batch loss: 0.016202591359615326\n",
      "batch accuracy: 0.998046875\n",
      "doing 92 / 291\n",
      "elapsed time 10354.706005334854\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9990\n",
      "batch loss: 0.010923848487436771\n",
      "batch accuracy: 0.9990234375\n",
      "doing 93 / 291\n",
      "elapsed time 10475.023540496826\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9971\n",
      "batch loss: 0.011101268231868744\n",
      "batch accuracy: 0.9970703125\n",
      "doing 94 / 291\n",
      "elapsed time 10589.774622678757\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9971\n",
      "batch loss: 0.012377824634313583\n",
      "batch accuracy: 0.9970703125\n",
      "doing 95 / 291\n",
      "elapsed time 10701.919927597046\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9961\n",
      "batch loss: 0.010800812393426895\n",
      "batch accuracy: 0.99609375\n",
      "doing 96 / 291\n",
      "elapsed time 10813.521876811981\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "batch loss: 0.008488371968269348\n",
      "batch accuracy: 1.0\n",
      "doing 97 / 291\n",
      "elapsed time 10926.837127923965\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9951\n",
      "batch loss: 0.0157794076949358\n",
      "batch accuracy: 0.9951171875\n",
      "doing 98 / 291\n",
      "elapsed time 11039.185972690582\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9990\n",
      "batch loss: 0.008680885657668114\n",
      "batch accuracy: 0.9990234375\n",
      "doing 99 / 291\n",
      "elapsed time 11152.188601970673\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9990\n",
      "batch loss: 0.008250093087553978\n",
      "batch accuracy: 0.9990234375\n",
      "doing 100 / 291\n",
      "elapsed time 11264.322973489761\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "batch loss: 0.007865550927817822\n",
      "batch accuracy: 1.0\n",
      "doing 101 / 291\n",
      "elapsed time 11376.40741944313\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9990\n",
      "batch loss: 0.006174743175506592\n",
      "batch accuracy: 0.9990234375\n",
      "doing 102 / 291\n",
      "elapsed time 11490.554285764694\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "batch loss: 0.007476265542209148\n",
      "batch accuracy: 1.0\n",
      "doing 103 / 291\n",
      "elapsed time 11601.213345527649\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "batch loss: 0.005996941588819027\n",
      "batch accuracy: 1.0\n",
      "doing 104 / 291\n",
      "elapsed time 11703.622117996216\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "batch loss: 0.007345250807702541\n",
      "batch accuracy: 1.0\n",
      "doing 105 / 291\n",
      "elapsed time 11804.562887191772\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9990\n",
      "batch loss: 0.010348135605454445\n",
      "batch accuracy: 0.9990234375\n",
      "doing 106 / 291\n",
      "elapsed time 11908.048912525177\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9980\n",
      "batch loss: 0.010508079081773758\n",
      "batch accuracy: 0.998046875\n",
      "doing 107 / 291\n",
      "elapsed time 12011.25219655037\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "batch loss: 0.005826923064887524\n",
      "batch accuracy: 1.0\n",
      "doing 108 / 291\n",
      "elapsed time 12116.881022453308\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "batch loss: 0.005106805823743343\n",
      "batch accuracy: 1.0\n",
      "doing 109 / 291\n",
      "elapsed time 12221.090373039246\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "batch loss: 0.007973074913024902\n",
      "batch accuracy: 1.0\n",
      "doing 110 / 291\n",
      "elapsed time 12325.810954093933\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9990\n",
      "batch loss: 0.006113965064287186\n",
      "batch accuracy: 0.9990234375\n",
      "doing 111 / 291\n",
      "elapsed time 12428.326358795166\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9990\n",
      "batch loss: 0.0062058768235147\n",
      "batch accuracy: 0.9990234375\n",
      "doing 112 / 291\n",
      "elapsed time 12529.898918628693\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "batch loss: 0.0038788276724517345\n",
      "batch accuracy: 1.0\n",
      "doing 113 / 291\n",
      "elapsed time 12630.397230863571\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "batch loss: 0.0050344280898571014\n",
      "batch accuracy: 1.0\n",
      "doing 114 / 291\n",
      "elapsed time 12732.107187747955\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "batch loss: 0.006383509375154972\n",
      "batch accuracy: 1.0\n",
      "doing 115 / 291\n",
      "elapsed time 12832.793223381042\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "batch loss: 0.0067075821571052074\n",
      "batch accuracy: 1.0\n",
      "doing 116 / 291\n",
      "elapsed time 12938.444155454636\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "batch loss: 0.006070544011890888\n",
      "batch accuracy: 1.0\n",
      "doing 117 / 291\n",
      "elapsed time 13044.472720861435\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9990\n",
      "batch loss: 0.005811980925500393\n",
      "batch accuracy: 0.9990234375\n",
      "doing 118 / 291\n",
      "elapsed time 13154.171612262726\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9990\n",
      "batch loss: 0.0048751225695014\n",
      "batch accuracy: 0.9990234375\n",
      "doing 119 / 291\n",
      "elapsed time 13263.969503164291\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "batch loss: 0.004359941463917494\n",
      "batch accuracy: 1.0\n",
      "doing 120 / 291\n",
      "elapsed time 13370.729848861694\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "batch loss: 0.004652387462556362\n",
      "batch accuracy: 1.0\n",
      "doing 121 / 291\n",
      "elapsed time 13477.381131887436\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9980\n",
      "batch loss: 0.008368782699108124\n",
      "batch accuracy: 0.998046875\n",
      "doing 122 / 291\n",
      "elapsed time 13584.774208307266\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 0.9990\n",
      "batch loss: 0.004136477597057819\n",
      "batch accuracy: 0.9990234375\n",
      "doing 123 / 291\n",
      "elapsed time 13690.629366636276\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "batch loss: 0.0059320395812392235\n",
      "batch accuracy: 1.0\n",
      "doing 124 / 291\n",
      "elapsed time 13797.297204494476\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 0.9980\n",
      "batch loss: 0.006376058328896761\n",
      "batch accuracy: 0.998046875\n",
      "doing 125 / 291\n",
      "elapsed time 13904.186544179916\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 0.9980\n",
      "batch loss: 0.006522702984511852\n",
      "batch accuracy: 0.998046875\n",
      "doing 126 / 291\n",
      "elapsed time 14012.049776792526\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9990\n",
      "batch loss: 0.0057778125628829\n",
      "batch accuracy: 0.9990234375\n",
      "doing 127 / 291\n",
      "elapsed time 14117.679680347443\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "batch loss: 0.004208236932754517\n",
      "batch accuracy: 1.0\n",
      "doing 128 / 291\n",
      "elapsed time 14222.458136796951\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 0.9990\n",
      "batch loss: 0.006878959015011787\n",
      "batch accuracy: 0.9990234375\n",
      "doing 129 / 291\n",
      "elapsed time 14329.44910645485\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "batch loss: 0.006164739839732647\n",
      "batch accuracy: 1.0\n",
      "doing 130 / 291\n",
      "elapsed time 14437.776618242264\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9990\n",
      "batch loss: 0.0046678390353918076\n",
      "batch accuracy: 0.9990234375\n",
      "doing 131 / 291\n",
      "elapsed time 14556.65526843071\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "batch loss: 0.004676652140915394\n",
      "batch accuracy: 1.0\n",
      "doing 132 / 291\n",
      "elapsed time 14674.647919654846\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "batch loss: 0.004087177105247974\n",
      "batch accuracy: 1.0\n",
      "doing 133 / 291\n",
      "elapsed time 14795.396427631378\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "batch loss: 0.004390466958284378\n",
      "batch accuracy: 1.0\n",
      "doing 134 / 291\n",
      "elapsed time 14914.04701256752\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "batch loss: 0.006873476784676313\n",
      "batch accuracy: 1.0\n",
      "doing 135 / 291\n",
      "elapsed time 15031.722538232803\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "batch loss: 0.00415398646146059\n",
      "batch accuracy: 1.0\n",
      "doing 136 / 291\n",
      "elapsed time 15149.372018575668\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "batch loss: 0.0034367067273706198\n",
      "batch accuracy: 1.0\n",
      "doing 137 / 291\n",
      "elapsed time 15270.824826955795\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "batch loss: 0.0028643023688346148\n",
      "batch accuracy: 1.0\n",
      "doing 138 / 291\n",
      "elapsed time 15392.36049413681\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "batch loss: 0.004037164617329836\n",
      "batch accuracy: 1.0\n",
      "doing 139 / 291\n",
      "elapsed time 15512.719408273697\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "batch loss: 0.00352021143771708\n",
      "batch accuracy: 1.0\n",
      "doing 140 / 291\n",
      "elapsed time 15628.256777524948\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.9990\n",
      "batch loss: 0.006924704648554325\n",
      "batch accuracy: 0.9990234375\n",
      "doing 141 / 291\n",
      "elapsed time 15745.936292171478\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "batch loss: 0.006109800189733505\n",
      "batch accuracy: 0.998046875\n",
      "doing 142 / 291\n",
      "elapsed time 15862.62405872345\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.9990\n",
      "batch loss: 0.004216800443828106\n",
      "batch accuracy: 0.9990234375\n",
      "doing 143 / 291\n",
      "elapsed time 15980.194741010666\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "batch loss: 0.00398688018321991\n",
      "batch accuracy: 1.0\n",
      "doing 144 / 291\n",
      "elapsed time 16092.46471786499\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9990\n",
      "batch loss: 0.0056647444143891335\n",
      "batch accuracy: 0.9990234375\n",
      "doing 145 / 291\n",
      "elapsed time 16205.970125675201\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9990\n",
      "batch loss: 0.007997733540832996\n",
      "batch accuracy: 0.9990234375\n",
      "doing 146 / 291\n",
      "elapsed time 16318.272172689438\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "batch loss: 0.0030311583541333675\n",
      "batch accuracy: 1.0\n",
      "doing 147 / 291\n",
      "elapsed time 16425.952733278275\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "batch loss: 0.003479529172182083\n",
      "batch accuracy: 1.0\n",
      "doing 148 / 291\n",
      "elapsed time 16534.12767791748\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0022812485694885254\n",
      "batch accuracy: 1.0\n",
      "doing 149 / 291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 16643.027719020844\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9990\n",
      "batch loss: 0.004324925597757101\n",
      "batch accuracy: 0.9990234375\n",
      "doing 150 / 291\n",
      "elapsed time 16754.638875246048\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.0038441079668700695\n",
      "batch accuracy: 1.0\n",
      "doing 151 / 291\n",
      "elapsed time 16862.125993013382\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9980\n",
      "batch loss: 0.008536030538380146\n",
      "batch accuracy: 0.998046875\n",
      "doing 152 / 291\n",
      "elapsed time 16969.844123601913\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9990\n",
      "batch loss: 0.0033306858967989683\n",
      "batch accuracy: 0.9990234375\n",
      "doing 153 / 291\n",
      "elapsed time 17080.773540258408\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9990\n",
      "batch loss: 0.003793169744312763\n",
      "batch accuracy: 0.9990234375\n",
      "doing 154 / 291\n",
      "elapsed time 17187.446492671967\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9990\n",
      "batch loss: 0.005779320374131203\n",
      "batch accuracy: 0.9990234375\n",
      "doing 155 / 291\n",
      "elapsed time 17297.05215716362\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "batch loss: 0.004685952328145504\n",
      "batch accuracy: 1.0\n",
      "doing 156 / 291\n",
      "elapsed time 17402.063361167908\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "batch loss: 0.004158381372690201\n",
      "batch accuracy: 1.0\n",
      "doing 157 / 291\n",
      "elapsed time 17508.75197482109\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.0038296845741569996\n",
      "batch accuracy: 1.0\n",
      "doing 158 / 291\n",
      "elapsed time 17615.981871843338\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "batch loss: 0.0039910441264510155\n",
      "batch accuracy: 1.0\n",
      "doing 159 / 291\n",
      "elapsed time 17722.592609643936\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9990\n",
      "batch loss: 0.004360755439847708\n",
      "batch accuracy: 0.9990234375\n",
      "doing 160 / 291\n",
      "elapsed time 17826.73060798645\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "batch loss: 0.00324232573620975\n",
      "batch accuracy: 1.0\n",
      "doing 161 / 291\n",
      "elapsed time 17930.3805642128\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9990\n",
      "batch loss: 0.006555196363478899\n",
      "batch accuracy: 0.9990234375\n",
      "doing 162 / 291\n",
      "elapsed time 18030.535360097885\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "batch loss: 0.0031316420063376427\n",
      "batch accuracy: 1.0\n",
      "doing 163 / 291\n",
      "elapsed time 18127.98890185356\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.002829059027135372\n",
      "batch accuracy: 1.0\n",
      "doing 164 / 291\n",
      "elapsed time 18229.381367444992\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "batch loss: 0.0024741049855947495\n",
      "batch accuracy: 1.0\n",
      "doing 165 / 291\n",
      "elapsed time 18329.84795165062\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "batch loss: 0.001815156196244061\n",
      "batch accuracy: 1.0\n",
      "doing 166 / 291\n",
      "elapsed time 18435.163701295853\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "batch loss: 0.0038132553454488516\n",
      "batch accuracy: 1.0\n",
      "doing 167 / 291\n",
      "elapsed time 18542.587868452072\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "batch loss: 0.0038695333059877157\n",
      "batch accuracy: 1.0\n",
      "doing 168 / 291\n",
      "elapsed time 18651.20925283432\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9990\n",
      "batch loss: 0.007996010594069958\n",
      "batch accuracy: 0.9990234375\n",
      "doing 169 / 291\n",
      "elapsed time 18760.353506565094\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "batch loss: 0.003937501925975084\n",
      "batch accuracy: 1.0\n",
      "doing 170 / 291\n",
      "elapsed time 18870.298179864883\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "batch loss: 0.0047938209027051926\n",
      "batch accuracy: 1.0\n",
      "doing 171 / 291\n",
      "elapsed time 18980.158513069153\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "batch loss: 0.0016775865806266665\n",
      "batch accuracy: 1.0\n",
      "doing 172 / 291\n",
      "elapsed time 19092.026305437088\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "batch loss: 0.0034559587948024273\n",
      "batch accuracy: 1.0\n",
      "doing 173 / 291\n",
      "elapsed time 19210.594596147537\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "batch loss: 0.003531733760610223\n",
      "batch accuracy: 1.0\n",
      "doing 174 / 291\n",
      "elapsed time 19325.164789676666\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "batch loss: 0.004396646749228239\n",
      "batch accuracy: 1.0\n",
      "doing 175 / 291\n",
      "elapsed time 19437.875168323517\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9990\n",
      "batch loss: 0.010284274816513062\n",
      "batch accuracy: 0.9990234375\n",
      "doing 176 / 291\n",
      "elapsed time 19551.261776208878\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "batch loss: 0.0030878735706210136\n",
      "batch accuracy: 1.0\n",
      "doing 177 / 291\n",
      "elapsed time 19661.331036806107\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "batch loss: 0.0027182193007320166\n",
      "batch accuracy: 1.0\n",
      "doing 178 / 291\n",
      "elapsed time 19773.59223628044\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "batch loss: 0.0020072301849722862\n",
      "batch accuracy: 1.0\n",
      "doing 179 / 291\n",
      "elapsed time 19883.50288248062\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "batch loss: 0.0042045931331813335\n",
      "batch accuracy: 1.0\n",
      "doing 180 / 291\n",
      "elapsed time 20004.76968574524\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "batch loss: 0.0026281289756298065\n",
      "batch accuracy: 1.0\n",
      "doing 181 / 291\n",
      "elapsed time 20130.56692814827\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "batch loss: 0.003399355337023735\n",
      "batch accuracy: 1.0\n",
      "doing 182 / 291\n",
      "elapsed time 20255.09207224846\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "batch loss: 0.0038873760495334864\n",
      "batch accuracy: 1.0\n",
      "doing 183 / 291\n",
      "elapsed time 20378.27857208252\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9990\n",
      "batch loss: 0.005511250346899033\n",
      "batch accuracy: 0.9990234375\n",
      "doing 184 / 291\n",
      "elapsed time 20502.436902999878\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "batch loss: 0.0018989669624716043\n",
      "batch accuracy: 1.0\n",
      "doing 185 / 291\n",
      "elapsed time 20628.52958035469\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.0027747503481805325\n",
      "batch accuracy: 1.0\n",
      "doing 186 / 291\n",
      "elapsed time 20752.125244379044\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "batch loss: 0.0020079356618225574\n",
      "batch accuracy: 1.0\n",
      "doing 187 / 291\n",
      "elapsed time 20873.116626501083\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "batch loss: 0.0026166411116719246\n",
      "batch accuracy: 1.0\n",
      "doing 188 / 291\n",
      "elapsed time 20994.70988178253\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9990\n",
      "batch loss: 0.003460734151303768\n",
      "batch accuracy: 0.9990234375\n",
      "doing 189 / 291\n",
      "elapsed time 21114.998354911804\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "batch loss: 0.003034674795344472\n",
      "batch accuracy: 1.0\n",
      "doing 190 / 291\n",
      "elapsed time 21236.28033399582\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.003275863593444228\n",
      "batch accuracy: 1.0\n",
      "doing 191 / 291\n",
      "elapsed time 21353.534327983856\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "batch loss: 0.003426091279834509\n",
      "batch accuracy: 1.0\n",
      "doing 192 / 291\n",
      "elapsed time 21469.853315353394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "batch loss: 0.003587996819987893\n",
      "batch accuracy: 1.0\n",
      "doing 193 / 291\n",
      "elapsed time 21583.284848213196\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "batch loss: 0.0025848294608294964\n",
      "batch accuracy: 1.0\n",
      "doing 194 / 291\n",
      "elapsed time 21699.664943933487\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9990\n",
      "batch loss: 0.004583612084388733\n",
      "batch accuracy: 0.9990234375\n",
      "doing 195 / 291\n",
      "elapsed time 21814.073044776917\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.002776001114398241\n",
      "batch accuracy: 1.0\n",
      "doing 196 / 291\n",
      "elapsed time 21925.42171382904\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "batch loss: 0.0026357080787420273\n",
      "batch accuracy: 1.0\n",
      "doing 197 / 291\n",
      "elapsed time 22038.09751534462\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "batch loss: 0.0046426584012806416\n",
      "batch accuracy: 1.0\n",
      "doing 198 / 291\n",
      "elapsed time 22148.374539852142\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0023271916434168816\n",
      "batch accuracy: 1.0\n",
      "doing 199 / 291\n",
      "elapsed time 22260.038291215897\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0022760210558772087\n",
      "batch accuracy: 1.0\n",
      "doing 200 / 291\n",
      "elapsed time 22373.586470365524\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9990\n",
      "batch loss: 0.003819420002400875\n",
      "batch accuracy: 0.9990234375\n",
      "doing 201 / 291\n",
      "elapsed time 22483.879636526108\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "batch loss: 0.002214409876614809\n",
      "batch accuracy: 1.0\n",
      "doing 202 / 291\n",
      "elapsed time 22592.787771463394\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0023057556245476007\n",
      "batch accuracy: 1.0\n",
      "doing 203 / 291\n",
      "elapsed time 22704.279612779617\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "batch loss: 0.002374910516664386\n",
      "batch accuracy: 1.0\n",
      "doing 204 / 291\n",
      "elapsed time 22813.20623087883\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.002336428966373205\n",
      "batch accuracy: 1.0\n",
      "doing 205 / 291\n",
      "elapsed time 22920.632915735245\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "batch loss: 0.0028916047886013985\n",
      "batch accuracy: 1.0\n",
      "doing 206 / 291\n",
      "elapsed time 23028.24963760376\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "batch loss: 0.002155809663236141\n",
      "batch accuracy: 1.0\n",
      "doing 207 / 291\n",
      "elapsed time 23137.553407907486\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "batch loss: 0.0035792298149317503\n",
      "batch accuracy: 1.0\n",
      "doing 208 / 291\n",
      "elapsed time 23242.473064422607\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.9990\n",
      "batch loss: 0.0038753622211515903\n",
      "batch accuracy: 0.9990234375\n",
      "doing 209 / 291\n",
      "elapsed time 23345.739270687103\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9990\n",
      "batch loss: 0.004696022719144821\n",
      "batch accuracy: 0.9990234375\n",
      "doing 210 / 291\n",
      "elapsed time 23449.992501974106\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9990\n",
      "batch loss: 0.003275463590398431\n",
      "batch accuracy: 0.9990234375\n",
      "doing 211 / 291\n",
      "elapsed time 23553.071308851242\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "batch loss: 0.0027337782084941864\n",
      "batch accuracy: 1.0\n",
      "doing 212 / 291\n",
      "elapsed time 23654.150500059128\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9990\n",
      "batch loss: 0.01066550612449646\n",
      "batch accuracy: 0.9990234375\n",
      "doing 213 / 291\n",
      "elapsed time 23758.71175122261\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "batch loss: 0.004460799507796764\n",
      "batch accuracy: 1.0\n",
      "doing 214 / 291\n",
      "elapsed time 23862.18904542923\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "batch loss: 0.0017919441452249885\n",
      "batch accuracy: 1.0\n",
      "doing 215 / 291\n",
      "elapsed time 23973.143191099167\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "batch loss: 0.0021440249402076006\n",
      "batch accuracy: 1.0\n",
      "doing 216 / 291\n",
      "elapsed time 24087.518845319748\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.003311604494228959\n",
      "batch accuracy: 1.0\n",
      "doing 217 / 291\n",
      "elapsed time 24200.14262986183\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "batch loss: 0.0034446832723915577\n",
      "batch accuracy: 1.0\n",
      "doing 218 / 291\n",
      "elapsed time 24307.99621129036\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9980\n",
      "batch loss: 0.004341005347669125\n",
      "batch accuracy: 0.998046875\n",
      "doing 219 / 291\n",
      "elapsed time 24423.60907268524\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "batch loss: 0.003349281381815672\n",
      "batch accuracy: 1.0\n",
      "doing 220 / 291\n",
      "elapsed time 24536.02747631073\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9990\n",
      "batch loss: 0.006248973309993744\n",
      "batch accuracy: 0.9990234375\n",
      "doing 221 / 291\n",
      "elapsed time 24649.6084420681\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "batch loss: 0.002891065552830696\n",
      "batch accuracy: 1.0\n",
      "doing 222 / 291\n",
      "elapsed time 24762.329576730728\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "batch loss: 0.0014363129157572985\n",
      "batch accuracy: 1.0\n",
      "doing 223 / 291\n",
      "elapsed time 24871.73776125908\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "batch loss: 0.0015523945912718773\n",
      "batch accuracy: 1.0\n",
      "doing 224 / 291\n",
      "elapsed time 24982.499435663223\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "batch loss: 0.001863423502072692\n",
      "batch accuracy: 1.0\n",
      "doing 225 / 291\n",
      "elapsed time 25094.090827465057\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "batch loss: 0.0028562010265886784\n",
      "batch accuracy: 1.0\n",
      "doing 226 / 291\n",
      "elapsed time 25206.877975702286\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "batch loss: 0.0021582916378974915\n",
      "batch accuracy: 1.0\n",
      "doing 227 / 291\n",
      "elapsed time 25310.2695145607\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "batch loss: 0.002875224919989705\n",
      "batch accuracy: 1.0\n",
      "doing 228 / 291\n",
      "elapsed time 25412.637501239777\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "batch loss: 0.003731807693839073\n",
      "batch accuracy: 1.0\n",
      "doing 229 / 291\n",
      "elapsed time 25524.023136615753\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "batch loss: 0.0021019186824560165\n",
      "batch accuracy: 1.0\n",
      "doing 230 / 291\n",
      "elapsed time 25638.677399396896\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "batch loss: 0.0019510345300659537\n",
      "batch accuracy: 1.0\n",
      "doing 231 / 291\n",
      "elapsed time 25752.016397237778\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "batch loss: 0.0027112672105431557\n",
      "batch accuracy: 1.0\n",
      "doing 232 / 291\n",
      "elapsed time 25862.20221066475\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "batch loss: 0.0020981146953999996\n",
      "batch accuracy: 1.0\n",
      "doing 233 / 291\n",
      "elapsed time 25974.170135974884\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "batch loss: 0.0019892537966370583\n",
      "batch accuracy: 1.0\n",
      "doing 234 / 291\n",
      "elapsed time 26090.47017598152\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "batch loss: 0.0018985663773491979\n",
      "batch accuracy: 1.0\n",
      "doing 235 / 291\n",
      "elapsed time 26204.52417731285\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "batch loss: 0.0023518609814345837\n",
      "batch accuracy: 1.0\n",
      "doing 236 / 291\n",
      "elapsed time 26318.361359119415\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 0.9990\n",
      "batch loss: 0.003605914767831564\n",
      "batch accuracy: 0.9990234375\n",
      "doing 237 / 291\n",
      "elapsed time 26431.763348817825\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "batch loss: 0.0030307089909911156\n",
      "batch accuracy: 1.0\n",
      "doing 238 / 291\n",
      "elapsed time 26542.800416707993\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "batch loss: 0.0014722582418471575\n",
      "batch accuracy: 1.0\n",
      "doing 239 / 291\n",
      "elapsed time 26653.19347858429\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.002322356216609478\n",
      "batch accuracy: 1.0\n",
      "doing 240 / 291\n",
      "elapsed time 26764.887237548828\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "batch loss: 0.0024358415976166725\n",
      "batch accuracy: 1.0\n",
      "doing 241 / 291\n",
      "elapsed time 26876.677672624588\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "batch loss: 0.002417202340438962\n",
      "batch accuracy: 1.0\n",
      "doing 242 / 291\n",
      "elapsed time 26992.080104112625\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "batch loss: 0.0023686890490353107\n",
      "batch accuracy: 1.0\n",
      "doing 243 / 291\n",
      "elapsed time 27104.97148180008\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0023330207914114\n",
      "batch accuracy: 1.0\n",
      "doing 244 / 291\n",
      "elapsed time 27213.084075689316\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.0027800374664366245\n",
      "batch accuracy: 1.0\n",
      "doing 245 / 291\n",
      "elapsed time 27326.917913913727\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9980\n",
      "batch loss: 0.004314680118113756\n",
      "batch accuracy: 0.998046875\n",
      "doing 246 / 291\n",
      "elapsed time 27434.727383375168\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "batch loss: 0.0025768750347197056\n",
      "batch accuracy: 1.0\n",
      "doing 247 / 291\n",
      "elapsed time 27540.90406560898\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "batch loss: 0.0021983422338962555\n",
      "batch accuracy: 1.0\n",
      "doing 248 / 291\n",
      "elapsed time 27647.975428819656\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.9990\n",
      "batch loss: 0.005184532143175602\n",
      "batch accuracy: 0.9990234375\n",
      "doing 249 / 291\n",
      "elapsed time 27757.543405056\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.00225503440015018\n",
      "batch accuracy: 1.0\n",
      "doing 250 / 291\n",
      "elapsed time 27868.995721817017\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "batch loss: 0.0019523759838193655\n",
      "batch accuracy: 1.0\n",
      "doing 251 / 291\n",
      "elapsed time 27981.921191215515\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9990\n",
      "batch loss: 0.004712107591331005\n",
      "batch accuracy: 0.9990234375\n",
      "doing 252 / 291\n",
      "elapsed time 28091.231285333633\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "batch loss: 0.0029447339475154877\n",
      "batch accuracy: 1.0\n",
      "doing 253 / 291\n",
      "elapsed time 28201.320486545563\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9990\n",
      "batch loss: 0.00398301100358367\n",
      "batch accuracy: 0.9990234375\n",
      "doing 254 / 291\n",
      "elapsed time 28310.875356674194\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 0.9990\n",
      "batch loss: 0.0029859542846679688\n",
      "batch accuracy: 0.9990234375\n",
      "doing 255 / 291\n",
      "elapsed time 28415.863089084625\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0023028994910418987\n",
      "batch accuracy: 1.0\n",
      "doing 256 / 291\n",
      "elapsed time 28519.095363378525\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "batch loss: 0.002432456472888589\n",
      "batch accuracy: 1.0\n",
      "doing 257 / 291\n",
      "elapsed time 28616.91302728653\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "batch loss: 0.002153934445232153\n",
      "batch accuracy: 1.0\n",
      "doing 258 / 291\n",
      "elapsed time 28714.333634138107\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "batch loss: 0.00186234584543854\n",
      "batch accuracy: 1.0\n",
      "doing 259 / 291\n",
      "elapsed time 28813.73605442047\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "batch loss: 0.003015897236764431\n",
      "batch accuracy: 1.0\n",
      "doing 260 / 291\n",
      "elapsed time 28918.580914497375\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.9990\n",
      "batch loss: 0.004180420655757189\n",
      "batch accuracy: 0.9990234375\n",
      "doing 261 / 291\n",
      "elapsed time 29022.446251630783\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "batch loss: 0.0024019405245780945\n",
      "batch accuracy: 1.0\n",
      "doing 262 / 291\n",
      "elapsed time 29129.37912607193\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9971\n",
      "batch loss: 0.005723633803427219\n",
      "batch accuracy: 0.9970703125\n",
      "doing 263 / 291\n",
      "elapsed time 29236.96511387825\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "batch loss: 0.002812756225466728\n",
      "batch accuracy: 1.0\n",
      "doing 264 / 291\n",
      "elapsed time 29343.35462665558\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9990\n",
      "batch loss: 0.008462924510240555\n",
      "batch accuracy: 0.9990234375\n",
      "doing 265 / 291\n",
      "elapsed time 29450.925983667374\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "batch loss: 0.002965722233057022\n",
      "batch accuracy: 1.0\n",
      "doing 266 / 291\n",
      "elapsed time 29556.367429971695\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9990\n",
      "batch loss: 0.0034817454870790243\n",
      "batch accuracy: 0.9990234375\n",
      "doing 267 / 291\n",
      "elapsed time 29665.21431350708\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.0023026594426482916\n",
      "batch accuracy: 1.0\n",
      "doing 268 / 291\n",
      "elapsed time 29773.523232221603\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "batch loss: 0.0018137048464268446\n",
      "batch accuracy: 1.0\n",
      "doing 269 / 291\n",
      "elapsed time 29883.022586107254\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "batch loss: 0.0016243633581325412\n",
      "batch accuracy: 1.0\n",
      "doing 270 / 291\n",
      "elapsed time 29991.370545625687\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "batch loss: 0.0018325306009501219\n",
      "batch accuracy: 1.0\n",
      "doing 271 / 291\n",
      "elapsed time 30099.03726696968\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "batch loss: 0.0019774490501731634\n",
      "batch accuracy: 1.0\n",
      "doing 272 / 291\n",
      "elapsed time 30204.52992463112\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "batch loss: 0.0018866730388253927\n",
      "batch accuracy: 1.0\n",
      "doing 273 / 291\n",
      "elapsed time 30315.004194498062\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9990\n",
      "batch loss: 0.0029881359077990055\n",
      "batch accuracy: 0.9990234375\n",
      "doing 274 / 291\n",
      "elapsed time 30420.326503515244\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "batch loss: 0.0017757781315594912\n",
      "batch accuracy: 1.0\n",
      "doing 275 / 291\n",
      "elapsed time 30541.4784655571\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "batch loss: 0.0013813665136694908\n",
      "batch accuracy: 1.0\n",
      "doing 276 / 291\n",
      "elapsed time 30656.4489941597\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "batch loss: 0.0024981661699712276\n",
      "batch accuracy: 1.0\n",
      "doing 277 / 291\n",
      "elapsed time 30771.8653383255\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "batch loss: 0.0017746679950505495\n",
      "batch accuracy: 1.0\n",
      "doing 278 / 291\n",
      "elapsed time 30887.624868392944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "batch loss: 0.0028642723336815834\n",
      "batch accuracy: 1.0\n",
      "doing 279 / 291\n",
      "elapsed time 30999.976235628128\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "batch loss: 0.0013691239291802049\n",
      "batch accuracy: 1.0\n",
      "doing 280 / 291\n",
      "elapsed time 31109.719552993774\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "batch loss: 0.002336320001631975\n",
      "batch accuracy: 1.0\n",
      "doing 281 / 291\n",
      "elapsed time 31219.962062120438\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9990\n",
      "batch loss: 0.0031455587595701218\n",
      "batch accuracy: 0.9990234375\n",
      "doing 282 / 291\n",
      "elapsed time 31327.999744176865\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "batch loss: 0.0021973634138703346\n",
      "batch accuracy: 1.0\n",
      "doing 283 / 291\n",
      "elapsed time 31441.12079834938\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "batch loss: 0.0017059450037777424\n",
      "batch accuracy: 1.0\n",
      "doing 284 / 291\n",
      "elapsed time 31551.357402324677\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "batch loss: 0.0012661191867664456\n",
      "batch accuracy: 1.0\n",
      "doing 285 / 291\n",
      "elapsed time 31660.178511619568\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "batch loss: 0.002053671982139349\n",
      "batch accuracy: 1.0\n",
      "doing 286 / 291\n",
      "elapsed time 31764.993970155716\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "batch loss: 0.0018376755760982633\n",
      "batch accuracy: 1.0\n",
      "doing 287 / 291\n",
      "elapsed time 31873.663251399994\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "batch loss: 0.0021656583994627\n",
      "batch accuracy: 1.0\n",
      "doing 288 / 291\n",
      "elapsed time 31975.91191291809\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "batch loss: 0.0023547657765448093\n",
      "batch accuracy: 1.0\n",
      "doing 289 / 291\n",
      "elapsed time 32082.846002578735\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.9990\n",
      "batch loss: 0.003775764722377062\n",
      "batch accuracy: 0.9990234375\n",
      "doing 290 / 291\n",
      "elapsed time 32087.5455596447\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.0499e-04 - accuracy: 1.0000\n",
      "batch loss: 0.0003049886436201632\n",
      "batch accuracy: 1.0\n",
      "Train loss 0.01203002560986974\n",
      "Train accuracy 0.9974830863402062\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5940 - accuracy: 0.9198\n",
      "Validation loss: 0.5940369963645935\n",
      "Validation accuracy: 0.9197777509689331\n"
     ]
    }
   ],
   "source": [
    "# model = create_model()\n",
    "# epoch_train_loss = []\n",
    "# epoch_train_acc = []\n",
    "# epoch_validation_loss = []\n",
    "# epoch_validation_acc = []\n",
    "for ep in range(epoch):\n",
    "    print(\"=\" * 50)\n",
    "    print(ep, \"/\", epoch)\n",
    "    step_loss = []\n",
    "    step_acc = []\n",
    "    \n",
    "    # batch_size=1000でHDDからバッチを取得する\n",
    "    for X_batch, Y_batch in get_batch(batch_size):\n",
    "        model.train_on_batch(X_batch, Y_batch)\n",
    "        score = model.evaluate(X_batch, Y_batch)\n",
    "        print(\"batch loss:\", score[0])\n",
    "        print(\"batch accuracy:\", score[1])\n",
    "        step_loss.append(score[0])\n",
    "        step_acc.append(score[1])\n",
    "    print(\"Train loss\", np.mean(step_loss))\n",
    "    print(\"Train accuracy\", np.mean(step_acc))\n",
    "    score = model.evaluate(x_validation, y_validation)\n",
    "    print(\"Validation loss:\", score[0])\n",
    "    print(\"Validation accuracy:\", score[1])\n",
    "    epoch_train_loss.append(np.mean(step_loss))\n",
    "    epoch_train_acc.append(np.mean(step_acc))\n",
    "    epoch_validation_loss.append(score[0])\n",
    "    epoch_validation_acc.append(score[1])\n",
    "    \n",
    "    shuffle_indices = random.sample(list(range(len(x_train))), len(x_train))\n",
    "    x_train = [x_train[i] for i in shuffle_indices]\n",
    "    y_train = y_train[shuffle_indices]\n",
    "    \n",
    "    model.save(cnn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|            Variable Name|    Memory|\n",
      " ------------------------------------ \n",
      "|       ImageDataGenerator|      1064|\n",
      "|                       In|       352|\n",
      "|                    Input|       144|\n",
      "|                    KFold|      1064|\n",
      "|          KerasClassifier|      1064|\n",
      "|            NOTEBOOK_NAME|        84|\n",
      "|                      Out|       248|\n",
      "|                     Pool|        72|\n",
      "|                   TRAINS|   2380496|\n",
      "|              VALIDATIONS|     38224|\n",
      "|                  X_batch|       144|\n",
      "|                  Y_batch|       112|\n",
      "|                      arr|     36072|\n",
      "|               batch_size|        28|\n",
      "|               cnf_matrix|       760|\n",
      "|                 cnn_path|       103|\n",
      "|         confusion_matrix|       144|\n",
      "|                     copy|        88|\n",
      "|             create_model|       144|\n",
      "|          cross_val_score|       144|\n",
      "|                      csv|        88|\n",
      "|                      cv2|        88|\n",
      "|                data_size|        28|\n",
      "|                 datapath|        59|\n",
      "|                   device|        80|\n",
      "|                  dirname|        57|\n",
      "|              encord_size|        28|\n",
      "|                       ep|        28|\n",
      "|                    epoch|        28|\n",
      "|          epoch_train_acc|       200|\n",
      "|         epoch_train_loss|       200|\n",
      "|     epoch_validation_acc|       200|\n",
      "|    epoch_validation_loss|       200|\n",
      "|                     exit|        64|\n",
      "|                        f|       224|\n",
      "|              faulty_case|       144|\n",
      "|                      fig|        64|\n",
      "|                     fig1|        64|\n",
      "|                     fig2|        64|\n",
      "|                 filename|        58|\n",
      "|                filenames|       104|\n",
      "|                get_batch|       144|\n",
      "|              get_ipython|        72|\n",
      "|                     glob|        88|\n",
      "|                 gridspec|        88|\n",
      "|                       gs|        64|\n",
      "|                    image|        88|\n",
      "|                itertools|        88|\n",
      "|                   joblib|        88|\n",
      "|                     join|       144|\n",
      "|                    keras|        88|\n",
      "|                   layers|        88|\n",
      "|              line_notify|       144|\n",
      "|          line_notify_img|       144|\n",
      "|               line_token|        92|\n",
      "|               load_array|       144|\n",
      "|             logical_gpus|       104|\n",
      "|                 max_size|        28|\n",
      "|                    model|        64|\n",
      "|                   models|        88|\n",
      "|                    new_y|       112|\n",
      "|                       np|        88|\n",
      "|                       os|        88|\n",
      "|                        p|        64|\n",
      "|                     path|        62|\n",
      "|                       pd|        88|\n",
      "|         physical_devices|       104|\n",
      "|                   pickle|        88|\n",
      "|    plot_confusion_matrix|       144|\n",
      "|                      plt|        88|\n",
      "|                     quit|        64|\n",
      "|                   random|        88|\n",
      "|                 requests|        88|\n",
      "|                        s|        93|\n",
      "|                    score|       104|\n",
      "|          shuffle_indices|   2376016|\n",
      "|                 step_acc|      2544|\n",
      "|                step_loss|      2544|\n",
      "|                 strategy|        64|\n",
      "|                      sys|        88|\n",
      "|                testscore|        24|\n",
      "|                       tf|        88|\n",
      "|                   tfback|        88|\n",
      "|                     time|        88|\n",
      "|           to_categorical|       144|\n",
      "|         train_test_split|       144|\n",
      "|               trainscore|        32|\n",
      "|                valiscore|        24|\n",
      "|                 var_name|        57|\n",
      "|                 warnings|        88|\n",
      "|                   x_test|  13500144|\n",
      "|                  x_train|   2380496|\n",
      "|             x_validation|       144|\n",
      "|                        y|     36112|\n",
      "|                y_predict|      3696|\n",
      "|                   y_test|       112|\n",
      "|               y_test_max|      3696|\n",
      "|           y_test_predict|      3696|\n",
      "|                  y_train|  10691860|\n",
      "|             y_validation|       112|\n",
      "|         y_validation_max|     36096|\n",
      "|     y_validation_predict|     36096|\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n",
    "print(\" ------------------------------------ \")\n",
    "for var_name in dir():\n",
    "    if not var_name.startswith(\"_\"):\n",
    "        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストデータで評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = joblib.load('./data/multi_' + str(max_size) + '/test/xtest.pickle')\n",
    "y_test = joblib.load('./data/multi_' + str(max_size) + '/test/ytest.pickle')\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 5ms/step - loss: 2.3243 - accuracy: 0.7889\n",
      "Test loss: 2.324291467666626\n",
      "Test accuracy: 0.7888888716697693\n",
      "Train accuracy: 0.9974830863402062\n",
      "Validation accuracy: 0.9197777509689331\n",
      "Test accuracy: 0.7888888716697693\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "# score = model.evaluate(x_validation, y_validation)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "testscore = score[1]\n",
    "trainscore = epoch_train_acc[-1]\n",
    "valiscore = epoch_validation_acc[-1]\n",
    "print(\"Train accuracy:\", trainscore)\n",
    "print(\"Validation accuracy:\", valiscore)\n",
    "print(\"Test accuracy:\", testscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7888888888888889"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = np.argmax(model.predict(x_test), axis=1)\n",
    "y_test_max = np.argmax(y_test, axis=1)\n",
    "np.sum(y_test_max == y_predict, axis=0, dtype='float') / x_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- モデルは以下．\n",
    "    - 入力層\n",
    "    - 畳み込み層3つ\n",
    "    - Flatten層（1次元に）\n",
    "    - 全結合層3つ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100, 100, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 100, 100, 8)       224       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 16)      1168      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 100, 100, 32)      4640      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 320000)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                20480064  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 297       \n",
      "=================================================================\n",
      "Total params: 20,488,473\n",
      "Trainable params: 20,488,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- accuracyグラフ，lossグラフは以下．\n",
    "- 5epoch程度で落ち着いている．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracy plot\n",
    "fig1 = plt.figure()\n",
    "plt.plot(epoch_train_acc)\n",
    "plt.plot(epoch_validation_acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "fig1.savefig(\"multisize_accuracy.png\")\n",
    "\n",
    "# loss plot\n",
    "fig2 = plt.figure()\n",
    "plt.plot(epoch_train_loss)\n",
    "plt.plot(epoch_validation_loss)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "fig2.savefig(\"multisize_loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    fmt = '.4f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.xticks([0, 1, 2, 3, 4, 5, 6, 7 ,8], [\"Center\", \"Donut\", \"Edge-Loc\", \"Edge-Ring\", \"Loc\", \"Near-full\", \"Random\", \"Scratch\", \"None\"])\n",
    "    plt.yticks([0, 1, 2, 3, 4, 5, 6, 7 ,8], [\"Center\", \"Donut\", \"Edge-Loc\", \"Edge-Ring\", \"Loc\", \"Near-full\", \"Random\", \"Scratch\", \"None\"])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- validation confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x1080 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "y_validation_predict = np.argmax(model.predict(x_validation), axis=1)\n",
    "y_validation_max = np.argmax(y_validation, axis=1)\n",
    "cnf_matrix = confusion_matrix(y_validation_max, y_validation_predict)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "from matplotlib import gridspec\n",
    "fig = plt.figure(figsize=(8, 15)) \n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 1]) \n",
    "\n",
    "## Plot non-normalized confusion matrix\n",
    "plt.subplot(gs[0])\n",
    "plot_confusion_matrix(cnf_matrix, title='Confusion matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.subplot(gs[1])\n",
    "plot_confusion_matrix(cnf_matrix, normalize=True, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"multisize_valiconfmat.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x1080 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "y_test_predict = np.argmax(model.predict(x_test), axis=1)\n",
    "y_test_max = np.argmax(y_test, axis=1)\n",
    "cnf_matrix = confusion_matrix(y_test_max, y_test_predict)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "from matplotlib import gridspec\n",
    "fig = plt.figure(figsize=(8, 15)) \n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 1]) \n",
    "\n",
    "## Plot non-normalized confusion matrix\n",
    "plt.subplot(gs[0])\n",
    "plot_confusion_matrix(cnf_matrix, title='Confusion matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.subplot(gs[1])\n",
    "plot_confusion_matrix(cnf_matrix, normalize=True, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"multisize_testconfmat.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='notify-api.line.me', port=443): Max retries exceeded with url: /api/notify (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f493399a310>: Failed to establish a new connection: [Errno 110] Connection timed out'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             )\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             )\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             )\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7f493399a310>: Failed to establish a new connection: [Errno 110] Connection timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    755\u001b[0m             retries = retries.increment(\n\u001b[0;32m--> 756\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m             )\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='notify-api.line.me', port=443): Max retries exceeded with url: /api/notify (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f493399a310>: Failed to establish a new connection: [Errno 110] Connection timed out'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-e7b2220b3d63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, proxies=proxies)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mline_notify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"学習が終了しました \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;31m# line_notify(\"Shawon: \" + str(shawon) + \", rotation_num: \" + str(rotation_num) + \", inversion: \" + str(inversion) + \", trials: \" + str(trials))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mline_notify_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"正解率\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multisize_accuracy.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-e7b2220b3d63>\u001b[0m in \u001b[0;36mline_notify\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;34m'https'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'https://proxy.uec.ac.jp:8080'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     }\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, proxies=proxies)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# LINEに画像を送る関数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \"\"\"\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/student/o1710117/.local/share/virtualenvs/wafermap-fQtCJoMb/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='notify-api.line.me', port=443): Max retries exceeded with url: /api/notify (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f493399a310>: Failed to establish a new connection: [Errno 110] Connection timed out'))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# LINEの設定\n",
    "path = './lineapi.txt'\n",
    "with open(path) as f:\n",
    "    s = f.read()\n",
    "    line_token = s.rstrip('\\n')\n",
    "\n",
    "# LINEに通知する関数\n",
    "def line_notify(text):\n",
    "    url = \"https://notify-api.line.me/api/notify\"\n",
    "    data = {\"message\": text}\n",
    "    headers = {\"Authorization\": \"Bearer \" + line_token}\n",
    "    proxies = {\n",
    "        'http': 'http://proxy.uec.ac.jp:8080',\n",
    "        'https': 'https://proxy.uec.ac.jp:8080',\n",
    "    }\n",
    "    requests.post(url, headers=headers)#, proxies=proxies)\n",
    "\n",
    "# LINEに画像を送る関数\n",
    "def line_notify_img(text, imgpath):\n",
    "    url = \"https://notify-api.line.me/api/notify\"\n",
    "    data = {\"message\": text, \"notificationDisabled\": True}\n",
    "    files = {\"imageFile\": open(imgpath, \"rb\")}\n",
    "    headers = {\"Authorization\": \"Bearer \" + line_token}\n",
    "    proxies = {\n",
    "        'http': 'http://proxy.uec.ac.jp:8080',\n",
    "        'https': 'https://proxy.uec.ac.jp:8080',\n",
    "    }\n",
    "    requests.post(url, data=data, files=files, headers=headers)#, proxies=proxies)\n",
    "    \n",
    "line_notify(\"学習が終了しました \")\n",
    "# line_notify(\"Shawon: \" + str(shawon) + \", rotation_num: \" + str(rotation_num) + \", inversion: \" + str(inversion) + \", trials: \" + str(trials))\n",
    "line_notify_img(\"正解率\", \"multisize_accuracy.png\")\n",
    "line_notify_img(\"Loss\", \"multisize_loss.png\")\n",
    "line_notify_img(\"validation混同行列\", \"multisize_valiconfmat.png\")\n",
    "line_notify_img(\"test混同行列\", \"multisize_testconfmat.png\")\n",
    "line_notify(\"train:\" + str(trainscore) + \"\\nvali:\" + str(valiscore) + \"\\ntest:\" + str(testscore))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wafermap",
   "language": "python",
   "name": "wafermap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
